{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f1136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.nn import GraphConv, GATConv, SAGEConv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s | %(message)s', level=logging.INFO, datefmt='%Y-%m-%d %H:%M:%S') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb4978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./relations.txt\") as fp:\n",
    "    relations = [r.strip() for r in fp.readlines()]\n",
    "with open(\"./label2index.pkl\", \"rb\") as fp:\n",
    "    label2index = pickle.load(fp)\n",
    "with open(\"./index2label.pkl\", \"rb\") as fp:\n",
    "    index2label = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c456ce",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b80e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(event):\n",
    "    global type2attr\n",
    "\n",
    "    srcUUID = event[\"srcNode\"][\"UUID\"]\n",
    "    srcType = event[\"srcNode\"][\"Type\"]\n",
    "    srcAttr = event[\"srcNode\"][type2attr[srcType]]\n",
    "    dstUUID = event[\"dstNode\"][\"UUID\"] if event[\"dstNode\"] != None else srcUUID\n",
    "    dstType = event[\"dstNode\"][\"Type\"] if event[\"dstNode\"] != None else srcType\n",
    "    dstAttr = event[\"dstNode\"][type2attr[dstType]] if event[\"dstNode\"] != None else srcAttr\n",
    "    return srcUUID, srcAttr, dstUUID, dstAttr, event[\"relation\"], event[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9dc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset):\n",
    "    global node_ent2idx, edge_ent2idx, node_ent2emb, edge_ent2emb\n",
    "\n",
    "    data_list = []\n",
    "    for p in tqdm(dataset):\n",
    "        with open(p) as fp:\n",
    "            events = json.load(fp)\n",
    "\n",
    "        nodes = set()\n",
    "        edges = []\n",
    "        relations = []\n",
    "        labels = []\n",
    "        uuid2res = {}\n",
    "        for e in events:\n",
    "            srcUUID, srcAttr, dstUUID, dstAttr, rel, label = get_value(e)\n",
    "\n",
    "            uuid2res[srcUUID], uuid2res[dstUUID] = srcAttr, dstAttr\n",
    "            nodes.add(srcUUID)\n",
    "            nodes.add(dstUUID)\n",
    "            edges.append((srcUUID, dstUUID))\n",
    "            relations.append(edge_ent2idx[rel])\n",
    "            labels.append(label2index[label])\n",
    "        nodes = list(nodes)  \n",
    "        node_feat = [torch.tensor(node_ent2emb[node_ent2idx[uuid2res[uuid]]], dtype=torch.float32) for uuid in nodes]\n",
    "        edge_attr = [torch.tensor(edge_ent2emb[idx], dtype=torch.float32) for idx in relations]\n",
    "\n",
    "        src = [nodes.index(src_uuid) for src_uuid, dst_uuid in edges]\n",
    "        dst = [nodes.index(dst_uuid) for src_uuid, dst_uuid in edges]\n",
    "        edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "        \n",
    "        data_list.append({\n",
    "            \"labels\": labels,\n",
    "            \"num_nodes\": len(nodes),\n",
    "            \"node_feat\": node_feat,\n",
    "            \"edge_attr\": edge_attr,\n",
    "            \"edge_index\": edge_index\n",
    "        })\n",
    "    return data_list         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb57cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6628b8747d4366b3e12eed5a55d29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b02b06540ab4fbc93b0f0c8ed65e14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a563a3bc684799a7d5c905d57ba2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa05542e69c4aa7bd0de3127fc49336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f'./Bert_embedding20240116/nodes/vocab2idx.pkl', 'rb') as fp:\n",
    "    node_ent2idx = pickle.load(fp)\n",
    "with open(f'./Bert_embedding20240116/edges/vocab2idx.pkl', 'rb') as fp:\n",
    "    edge_ent2idx = pickle.load(fp)\n",
    "with open(f'./Bert_embedding20240116/nodes_ent2emb_256.pkl', 'rb') as fp:\n",
    "    node_ent2emb = pickle.load(fp)\n",
    "with open(f'./Bert_embedding20240116/edges_ent2emb_16.pkl', 'rb') as fp:\n",
    "    edge_ent2emb = pickle.load(fp)\n",
    "\n",
    "type2attr = {\n",
    "    \"Process\": \"Cmdline\", \n",
    "    \"File\": \"Name\", \n",
    "    \"Registry\": \"Key\", \n",
    "    \"Network\": \"Dstaddress\"\n",
    "}\n",
    "\n",
    "random.seed(42)\n",
    "trainset, validset, testset = [], [], []\n",
    "for ability in tqdm(os.listdir('./raw_data2/')):\n",
    "    paths = glob(f'./raw_data2/{ability}/number_*/expanded_instance.json')\n",
    "    random.shuffle(paths)\n",
    "    trainset.extend(paths[:80])\n",
    "    validset.extend(paths[80:90])\n",
    "    testset.extend(paths[90:])\n",
    "    \n",
    "train_data = make_dataset(trainset)\n",
    "valid_data = make_dataset(validset)\n",
    "test_data = make_dataset(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b2b2d",
   "metadata": {},
   "source": [
    "# Make Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de9ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        return data\n",
    "\n",
    "def collate(samples):\n",
    "    data_list = samples\n",
    "    batched_graphs = []\n",
    "    for data in data_list:\n",
    "        g = dgl.graph((data[\"edge_index\"][0], data[\"edge_index\"][1]), num_nodes=data[\"num_nodes\"])\n",
    "\n",
    "        g.ndata['feat'] = torch.stack(data[\"node_feat\"])\n",
    "        g.edata['feat'] = torch.stack(data[\"edge_attr\"])\n",
    "        g.edata['label'] = torch.tensor(data[\"labels\"])  \n",
    "\n",
    "        batched_graphs.append(g)\n",
    "    \n",
    "    return dgl.batch(batched_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48e4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GraphDataset = GraphDataset(train_data, device)\n",
    "valid_GraphDataset = GraphDataset(valid_data, device)\n",
    "test_GraphDataset = GraphDataset(test_data, device)\n",
    "\n",
    "train_dataloader = DataLoader(train_GraphDataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_dataloader = DataLoader(valid_GraphDataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_GraphDataset, batch_size=32, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8c620",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35625234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dglnn.SAGEConv(in_dim, hidden_dim, 'pool')\n",
    "        self.layer2 = dglnn.SAGEConv(hidden_dim, out_dim, 'pool')\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.layer1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.layer2(g, h)\n",
    "        return h\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes, edge_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2 + edge_embedding_dim, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges, edge_feat):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        h_e = edge_feat\n",
    "        score = self.W(torch.cat([h_u, h_v, h_e], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h, edge_feat):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            # graph.apply_edges(self.apply_edges)\n",
    "            graph.apply_edges(lambda edges: self.apply_edges(edges, edge_feat))\n",
    "            return graph.edata['score']\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes, edge_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.sage = GraphSAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes, edge_embedding_dim)\n",
    "      \n",
    "    def forward(self, g, node_feat, edge_feat, return_logits=False):\n",
    "        h = self.sage(g, node_feat)\n",
    "        logits = self.pred(g, h, edge_feat)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def model_fn(batched_g, model, criterion, device, which_type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = batched_g.edata['label'].to(device)    \n",
    "    # logits = model(batched_g, batched_g.ndata['feat'].float())\n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float(), batched_g.edata['feat'].float())\n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    output = torch.softmax(logits, dim=1)\n",
    "    preds = output.argmax(1)\n",
    "    \n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c71261a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a190fa5bc94a748231e8d28409110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 02:49:08 | INFO | Epoch 0 | Train Loss: 1.6671 | Train Accuracy: 0.6356\n",
      "2024-01-25 02:49:14 | INFO | Validation Loss: 1.1292 | Validation Accuracy: 0.7849\n",
      "\n",
      "2024-01-25 02:50:08 | INFO | Epoch 1 | Train Loss: 0.9070 | Train Accuracy: 0.8098\n",
      "2024-01-25 02:50:13 | INFO | Validation Loss: 0.7522 | Validation Accuracy: 0.8380\n",
      "\n",
      "2024-01-25 02:51:06 | INFO | Epoch 2 | Train Loss: 0.6708 | Train Accuracy: 0.8620\n",
      "2024-01-25 02:51:12 | INFO | Validation Loss: 0.5653 | Validation Accuracy: 0.8967\n",
      "\n",
      "2024-01-25 02:52:02 | INFO | Epoch 3 | Train Loss: 0.5137 | Train Accuracy: 0.9010\n",
      "2024-01-25 02:52:08 | INFO | Validation Loss: 0.5635 | Validation Accuracy: 0.8834\n",
      "\n",
      "2024-01-25 02:53:00 | INFO | Epoch 4 | Train Loss: 0.4449 | Train Accuracy: 0.9095\n",
      "2024-01-25 02:53:06 | INFO | Validation Loss: 0.4563 | Validation Accuracy: 0.8969\n",
      "\n",
      "2024-01-25 02:53:56 | INFO | Epoch 5 | Train Loss: 0.3904 | Train Accuracy: 0.9178\n",
      "2024-01-25 02:54:00 | INFO | Validation Loss: 0.4586 | Validation Accuracy: 0.8983\n",
      "\n",
      "2024-01-25 02:54:52 | INFO | Epoch 6 | Train Loss: 0.3581 | Train Accuracy: 0.9238\n",
      "2024-01-25 02:54:58 | INFO | Validation Loss: 0.3548 | Validation Accuracy: 0.9195\n",
      "\n",
      "2024-01-25 02:55:47 | INFO | Epoch 7 | Train Loss: 0.3134 | Train Accuracy: 0.9312\n",
      "2024-01-25 02:55:54 | INFO | Validation Loss: 0.3010 | Validation Accuracy: 0.9320\n",
      "\n",
      "2024-01-25 02:56:44 | INFO | Epoch 8 | Train Loss: 0.2896 | Train Accuracy: 0.9350\n",
      "2024-01-25 02:56:49 | INFO | Validation Loss: 0.2502 | Validation Accuracy: 0.9410\n",
      "\n",
      "2024-01-25 02:57:38 | INFO | Epoch 9 | Train Loss: 0.2530 | Train Accuracy: 0.9421\n",
      "2024-01-25 02:57:44 | INFO | Validation Loss: 0.2606 | Validation Accuracy: 0.9389\n",
      "\n",
      "2024-01-25 02:58:38 | INFO | Epoch 10 | Train Loss: 0.2338 | Train Accuracy: 0.9447\n",
      "2024-01-25 02:58:45 | INFO | Validation Loss: 0.2546 | Validation Accuracy: 0.9378\n",
      "\n",
      "2024-01-25 02:59:37 | INFO | Epoch 11 | Train Loss: 0.2228 | Train Accuracy: 0.9458\n",
      "2024-01-25 02:59:44 | INFO | Validation Loss: 0.2047 | Validation Accuracy: 0.9488\n",
      "\n",
      "2024-01-25 03:00:41 | INFO | Epoch 12 | Train Loss: 0.2009 | Train Accuracy: 0.9506\n",
      "2024-01-25 03:00:48 | INFO | Validation Loss: 0.2106 | Validation Accuracy: 0.9455\n",
      "\n",
      "2024-01-25 03:01:42 | INFO | Epoch 13 | Train Loss: 0.1839 | Train Accuracy: 0.9535\n",
      "2024-01-25 03:01:48 | INFO | Validation Loss: 0.1745 | Validation Accuracy: 0.9517\n",
      "\n",
      "2024-01-25 03:02:40 | INFO | Epoch 14 | Train Loss: 0.1577 | Train Accuracy: 0.9599\n",
      "2024-01-25 03:02:46 | INFO | Validation Loss: 0.1518 | Validation Accuracy: 0.9592\n",
      "\n",
      "2024-01-25 03:03:41 | INFO | Epoch 15 | Train Loss: 0.1494 | Train Accuracy: 0.9612\n",
      "2024-01-25 03:03:46 | INFO | Validation Loss: 0.1497 | Validation Accuracy: 0.9598\n",
      "\n",
      "2024-01-25 03:04:40 | INFO | Epoch 16 | Train Loss: 0.1390 | Train Accuracy: 0.9634\n",
      "2024-01-25 03:04:46 | INFO | Validation Loss: 0.1414 | Validation Accuracy: 0.9619\n",
      "\n",
      "2024-01-25 03:05:37 | INFO | Epoch 17 | Train Loss: 0.1351 | Train Accuracy: 0.9642\n",
      "2024-01-25 03:05:42 | INFO | Validation Loss: 0.1232 | Validation Accuracy: 0.9657\n",
      "\n",
      "2024-01-25 03:06:33 | INFO | Epoch 18 | Train Loss: 0.1227 | Train Accuracy: 0.9670\n",
      "2024-01-25 03:06:39 | INFO | Validation Loss: 0.1238 | Validation Accuracy: 0.9661\n",
      "\n",
      "2024-01-25 03:07:32 | INFO | Epoch 19 | Train Loss: 0.1114 | Train Accuracy: 0.9701\n",
      "2024-01-25 03:07:39 | INFO | Validation Loss: 0.1073 | Validation Accuracy: 0.9693\n",
      "\n",
      "2024-01-25 03:08:29 | INFO | Epoch 20 | Train Loss: 0.1058 | Train Accuracy: 0.9710\n",
      "2024-01-25 03:08:34 | INFO | Validation Loss: 0.1055 | Validation Accuracy: 0.9711\n",
      "\n",
      "2024-01-25 03:09:27 | INFO | Epoch 21 | Train Loss: 0.1069 | Train Accuracy: 0.9702\n",
      "2024-01-25 03:09:32 | INFO | Validation Loss: 0.0905 | Validation Accuracy: 0.9733\n",
      "\n",
      "2024-01-25 03:10:26 | INFO | Epoch 22 | Train Loss: 0.0929 | Train Accuracy: 0.9737\n",
      "2024-01-25 03:10:31 | INFO | Validation Loss: 0.0885 | Validation Accuracy: 0.9740\n",
      "\n",
      "2024-01-25 03:11:24 | INFO | Epoch 23 | Train Loss: 0.0892 | Train Accuracy: 0.9747\n",
      "2024-01-25 03:11:31 | INFO | Validation Loss: 0.0989 | Validation Accuracy: 0.9712\n",
      "\n",
      "2024-01-25 03:12:23 | INFO | Epoch 24 | Train Loss: 0.0877 | Train Accuracy: 0.9749\n",
      "2024-01-25 03:12:29 | INFO | Validation Loss: 0.0871 | Validation Accuracy: 0.9747\n",
      "\n",
      "2024-01-25 03:13:16 | INFO | Epoch 25 | Train Loss: 0.0787 | Train Accuracy: 0.9775\n",
      "2024-01-25 03:13:18 | INFO | Validation Loss: 0.0862 | Validation Accuracy: 0.9754\n",
      "\n",
      "2024-01-25 03:13:54 | INFO | Epoch 26 | Train Loss: 0.0770 | Train Accuracy: 0.9780\n",
      "2024-01-25 03:14:00 | INFO | Validation Loss: 0.0881 | Validation Accuracy: 0.9769\n",
      "\n",
      "2024-01-25 03:14:38 | INFO | Epoch 27 | Train Loss: 0.0752 | Train Accuracy: 0.9780\n",
      "2024-01-25 03:14:44 | INFO | Validation Loss: 0.0775 | Validation Accuracy: 0.9765\n",
      "\n",
      "2024-01-25 03:15:28 | INFO | Epoch 28 | Train Loss: 0.0710 | Train Accuracy: 0.9792\n",
      "2024-01-25 03:15:34 | INFO | Validation Loss: 0.0812 | Validation Accuracy: 0.9751\n",
      "\n",
      "2024-01-25 03:16:18 | INFO | Epoch 29 | Train Loss: 0.0646 | Train Accuracy: 0.9812\n",
      "2024-01-25 03:16:23 | INFO | Validation Loss: 0.0732 | Validation Accuracy: 0.9777\n",
      "\n",
      "2024-01-25 03:17:10 | INFO | Epoch 30 | Train Loss: 0.0650 | Train Accuracy: 0.9810\n",
      "2024-01-25 03:17:16 | INFO | Validation Loss: 0.0724 | Validation Accuracy: 0.9773\n",
      "\n",
      "2024-01-25 03:18:00 | INFO | Epoch 31 | Train Loss: 0.0635 | Train Accuracy: 0.9811\n",
      "2024-01-25 03:18:06 | INFO | Validation Loss: 0.0834 | Validation Accuracy: 0.9748\n",
      "\n",
      "2024-01-25 03:18:46 | INFO | Epoch 32 | Train Loss: 0.0609 | Train Accuracy: 0.9819\n",
      "2024-01-25 03:18:51 | INFO | Validation Loss: 0.0634 | Validation Accuracy: 0.9810\n",
      "\n",
      "2024-01-25 03:19:34 | INFO | Epoch 33 | Train Loss: 0.0574 | Train Accuracy: 0.9829\n",
      "2024-01-25 03:19:39 | INFO | Validation Loss: 0.0612 | Validation Accuracy: 0.9808\n",
      "\n",
      "2024-01-25 03:20:25 | INFO | Epoch 34 | Train Loss: 0.0575 | Train Accuracy: 0.9827\n",
      "2024-01-25 03:20:29 | INFO | Validation Loss: 0.0675 | Validation Accuracy: 0.9790\n",
      "\n",
      "2024-01-25 03:21:17 | INFO | Epoch 35 | Train Loss: 0.0591 | Train Accuracy: 0.9824\n",
      "2024-01-25 03:21:20 | INFO | Validation Loss: 0.0742 | Validation Accuracy: 0.9772\n",
      "\n",
      "2024-01-25 03:21:59 | INFO | Epoch 36 | Train Loss: 0.0535 | Train Accuracy: 0.9840\n",
      "2024-01-25 03:22:04 | INFO | Validation Loss: 0.0661 | Validation Accuracy: 0.9795\n",
      "\n",
      "2024-01-25 03:22:50 | INFO | Epoch 37 | Train Loss: 0.0505 | Train Accuracy: 0.9847\n",
      "2024-01-25 03:22:54 | INFO | Validation Loss: 0.0734 | Validation Accuracy: 0.9763\n",
      "\n",
      "2024-01-25 03:23:41 | INFO | Epoch 38 | Train Loss: 0.0507 | Train Accuracy: 0.9848\n",
      "2024-01-25 03:23:47 | INFO | Validation Loss: 0.0535 | Validation Accuracy: 0.9830\n",
      "\n",
      "2024-01-25 03:24:30 | INFO | Epoch 39 | Train Loss: 0.0478 | Train Accuracy: 0.9857\n",
      "2024-01-25 03:24:36 | INFO | Validation Loss: 0.0524 | Validation Accuracy: 0.9837\n",
      "\n",
      "2024-01-25 03:25:20 | INFO | Epoch 40 | Train Loss: 0.0520 | Train Accuracy: 0.9841\n",
      "2024-01-25 03:25:24 | INFO | Validation Loss: 0.0614 | Validation Accuracy: 0.9813\n",
      "\n",
      "2024-01-25 03:26:09 | INFO | Epoch 41 | Train Loss: 0.0475 | Train Accuracy: 0.9856\n",
      "2024-01-25 03:26:14 | INFO | Validation Loss: 0.0582 | Validation Accuracy: 0.9810\n",
      "\n",
      "2024-01-25 03:26:57 | INFO | Epoch 42 | Train Loss: 0.0477 | Train Accuracy: 0.9854\n",
      "2024-01-25 03:27:02 | INFO | Validation Loss: 0.0554 | Validation Accuracy: 0.9818\n",
      "\n",
      "2024-01-25 03:27:49 | INFO | Epoch 43 | Train Loss: 0.0451 | Train Accuracy: 0.9862\n",
      "2024-01-25 03:27:54 | INFO | Validation Loss: 0.0556 | Validation Accuracy: 0.9819\n",
      "\n",
      "2024-01-25 03:28:37 | INFO | Epoch 44 | Train Loss: 0.0455 | Train Accuracy: 0.9861\n",
      "2024-01-25 03:28:43 | INFO | Validation Loss: 0.0457 | Validation Accuracy: 0.9851\n",
      "\n",
      "2024-01-25 03:29:19 | INFO | Epoch 45 | Train Loss: 0.0427 | Train Accuracy: 0.9868\n",
      "2024-01-25 03:29:25 | INFO | Validation Loss: 0.0542 | Validation Accuracy: 0.9824\n",
      "\n",
      "2024-01-25 03:30:08 | INFO | Epoch 46 | Train Loss: 0.0443 | Train Accuracy: 0.9863\n",
      "2024-01-25 03:30:13 | INFO | Validation Loss: 0.0539 | Validation Accuracy: 0.9822\n",
      "\n",
      "2024-01-25 03:30:54 | INFO | Epoch 47 | Train Loss: 0.0423 | Train Accuracy: 0.9870\n",
      "2024-01-25 03:30:59 | INFO | Validation Loss: 0.0471 | Validation Accuracy: 0.9845\n",
      "\n",
      "2024-01-25 03:31:43 | INFO | Epoch 48 | Train Loss: 0.0425 | Train Accuracy: 0.9868\n",
      "2024-01-25 03:31:47 | INFO | Validation Loss: 0.0543 | Validation Accuracy: 0.9824\n",
      "\n",
      "2024-01-25 03:32:31 | INFO | Epoch 49 | Train Loss: 0.0404 | Train Accuracy: 0.9873\n",
      "2024-01-25 03:32:36 | INFO | Validation Loss: 0.0543 | Validation Accuracy: 0.9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "same_seeds(42)\n",
    "model = Model(in_features=256, hidden_features=64, out_features=128, num_classes=len(label2index)-1, edge_embedding_dim = 16)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=36, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_save_path = \"./model/GraphSAGE_emb256\"\n",
    "if not os.path.isdir(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = float('-inf')\n",
    "best_model_path = \"\"\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0    \n",
    "    for data in train_dataloader:\n",
    "        loss, accuracy, _ = model_fn(data, model, criterion, device, which_type='train')        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    avg_accuracy = total_accuracy / len(train_dataloader)\n",
    "    logging.info(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_dataloader:\n",
    "            loss, accuracy, _ = model_fn(data, model, criterion, device, which_type='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_accuracy = total_accuracy / len(valid_dataloader)\n",
    "    current_loss = total_loss / len(valid_dataloader)\n",
    "    if current_loss < best_val_loss and avg_accuracy > best_val_acc:\n",
    "        best_val_loss = current_loss\n",
    "        best_val_acc = avg_accuracy\n",
    "        best_model_path = f'{model_save_path}/epoch_{epoch}_loss_{current_loss:.4f}_acc_{avg_accuracy:.4f}'\n",
    "    \n",
    "    logging.info(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}\\n')    \n",
    "    torch.save(model.state_dict(), f'{model_save_path}/epoch_{epoch}_loss_{current_loss:.4f}_acc_{avg_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d315dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 07:47:58 | INFO | Test Accuracy: 99.0717 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained model\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        loss, accuracy, predicted = model_fn(data, model, criterion, device, which_type='test')\n",
    "        labels = data.edata['label'].to(device)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "                \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "logging.info(f'Test Accuracy: {100 * correct / total:.4f} %\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a3a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Raid6_disk/hitoshi/anaconda3/envs/audit/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/Raid6_disk/hitoshi/anaconda3/envs/audit/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/Raid6_disk/hitoshi/anaconda3/envs/audit/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_data = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "output_path = \"./result/GraphSAGE_emb256\"\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "report_df.reset_index(inplace=True, names='label')\n",
    "label_list = []\n",
    "for idx, row in report_df.iterrows():\n",
    "    if row[\"label\"].isdigit():\n",
    "        row[\"label\"] = index2label[int(row[\"label\"])]\n",
    "    label_list.append(row[\"label\"])\n",
    "report_df[\"label\"] = label_list\n",
    "report_df.to_csv(f'{output_path}/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8f4e766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1105_1095434782a00c8a4772a11e625bcf5d_B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1105_e6715e61f5df646692c624b3499384c4_I</td>\n",
       "      <td>0.900290</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.855960</td>\n",
       "      <td>1140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1003.003_9f73269695e54311dd61dc68940fb3e1_B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89_I</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1112_ba6f6214dbd17c54001e0a163b60f151_I</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>T1120_7b9c7afaefa59aab759b49af0d699ac1_I</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>T1112_fd992e8ecfdac9b56dd6868904044827_I</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.990717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.830426</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.815141</td>\n",
       "      <td>814055.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.990555</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.990371</td>\n",
       "      <td>814055.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                label  precision    recall  \\\n",
       "0            T1105_1095434782a00c8a4772a11e625bcf5d_B   1.000000  1.000000   \n",
       "1            T1105_e6715e61f5df646692c624b3499384c4_I   0.900290  0.815789   \n",
       "2        T1003.003_9f73269695e54311dd61dc68940fb3e1_B   1.000000  1.000000   \n",
       "3    T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89_I   1.000000  0.933333   \n",
       "4            T1112_ba6f6214dbd17c54001e0a163b60f151_I   1.000000  0.941176   \n",
       "..                                                ...        ...       ...   \n",
       "272          T1120_7b9c7afaefa59aab759b49af0d699ac1_I   0.558824  0.527778   \n",
       "273          T1112_fd992e8ecfdac9b56dd6868904044827_I   1.000000  1.000000   \n",
       "274                                          accuracy   0.990717  0.990717   \n",
       "275                                         macro avg   0.830426  0.817683   \n",
       "276                                      weighted avg   0.990555  0.990717   \n",
       "\n",
       "     f1-score        support  \n",
       "0    1.000000      17.000000  \n",
       "1    0.855960    1140.000000  \n",
       "2    1.000000      15.000000  \n",
       "3    0.965517      30.000000  \n",
       "4    0.969697      34.000000  \n",
       "..        ...            ...  \n",
       "272  0.542857     108.000000  \n",
       "273  1.000000      44.000000  \n",
       "274  0.990717       0.990717  \n",
       "275  0.815141  814055.000000  \n",
       "276  0.990371  814055.000000  \n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
