{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94820cd4",
   "metadata": {},
   "source": [
    "# Smaple of the official dgl website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "301aab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch as th\n",
    "\n",
    "# 1~100生成500個nodes\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "\n",
    "\n",
    "# make it symmetric\n",
    "# edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
    "edge_pred_graph = dgl.graph((src, dst))\n",
    "    \n",
    "# synthetic node and edge features, as well as edge labels\n",
    "edge_pred_graph.ndata['feature'] = torch.randn(100, 10).float()\n",
    "\n",
    "edge_pred_graph.edata['feature'] = torch.randn(500, 10).float()\n",
    "# edge_pred_graph.edata['label'] = torch.randn(500)\n",
    "edge_pred_graph.edata['label'] = torch.randint(0, 100, (500,)).long()\n",
    "# edge_pred_graph.edata['label'] = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "\n",
    "# synthetic train-test splits, which is about 3:2(not exactly)\n",
    "# edge_pred_graph.edata['train_mask'] = torch.zeros(500, dtype=torch.bool).bernoulli(0.6)\n",
    "\n",
    "num_edges = 500\n",
    "train_ratio = 0.6\n",
    "num_train = int(num_edges * train_ratio)\n",
    "\n",
    "# 隨機排列的索引\n",
    "permuted_idxs = torch.randperm(num_edges)\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "valid_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "\n",
    "train_mask[permuted_idxs[:num_train]] = True\n",
    "valid_mask[permuted_idxs[num_train:]] = True\n",
    "\n",
    "edge_pred_graph.edata['train_mask'] = train_mask\n",
    "edge_pred_graph.edata['valid_mask'] = valid_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc2ca2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=100, num_edges=500,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'valid_mask': Scheme(shape=(), dtype=torch.bool)})\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "699ebf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58045a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[54 19 88 41 40 63 96 14  7 33 14 95 78 38 89 28 59 92 27  3 37 81 12 79\n",
      "  9 55 50 15 83 55 66 79 64 31 85 71 78  4 92 21 19 45 81 95 30 67 25 14\n",
      " 80 68 89 17 28 30 83 85 14 10 19 75 70 60 72 36 10 25 42 84 20 87 66 50\n",
      " 99 42 43 63 65 43 10 64 80 31 29 92 84 57 15 86 51 72 25 40 52 51 65  6\n",
      " 95 95 90 17 12  1 78 29 28 68 98 76 30 29 18 71 18 82 68 52 77 48 65 92\n",
      " 30  6 30 49 33 76 25 30 25 77 36 29 16 29 95 70 65 33 25 82 30 72 89 42\n",
      " 13 25 67 52 67 17 51 96 10 69 79  6 52 22 31 85 85 80 64 55 33 17 20 30\n",
      " 42 85 91 24 28 95 38 75 91 16 71  3 46  1 51  7 28 93 43 36 89 55  6  0\n",
      " 16 47 40  6 44 97 85 86 29 38 28 66 56 65 91 34 29  9  1 12 66 81 13 78\n",
      " 10 20 43 61 24 94 78 77 14  6 27 22  6 43 29  9 75  4 40 98 57 32 40 19\n",
      " 61 32 83 40 32 46 34 97 74  0 40 27 82 71 53 24 16 36 91 41 63 86 14 63\n",
      " 73 39 78 93 91 48 32 97 85 76 57  9  0 48 54  0 74 48  4 26 45  4 93 73\n",
      " 98 67 82 27 28 47 56  3 85 46 84 38 76 31 43  9 29 45 24 31  9 61 42 80\n",
      " 37 28 26 94  3 78 34 45  6 72 83 55  0 74 58 33 20 10 88 66 55 76 22 10\n",
      " 66 57 74 53 18 34  7 70 99 42 83 48 44 26 87 55 75 47 13 63 40 48 42 50\n",
      " 64 16 28  9 55 46 50 72 34  5 65  2 31 74 26 29 40 75 68 57 94 20 39 75\n",
      " 13  6 28 24  6 45 72 65 74 38 38 98 77 57 62 49 82 91 42 16 36 10 84 58\n",
      " 41  8 74 90 81 84 90 69 76 79  3 24 21 22 25 69 58 39 56 90 46 87 59 73\n",
      " 42 41 61 87 77 78 52 84  6 57 36 70 13 55 61 22 25 22 61 68  2  9  2 73\n",
      "  1 53 28 64 78 78 89 36 13 66 94 11 91 76 71 16 89 31 10 55 59 32 25 63\n",
      " 63  8 77 91  7 79 34 33 86 54 23 57 37 38  7 58  1 34 92 98]\n"
     ]
    }
   ],
   "source": [
    "print(src.shape)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94952595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([500, 10])\n",
      "tensor([79, 76, 81, 17, 21, 16, 89, 32,  5, 72, 37, 96, 92, 45, 28, 59, 49, 35,\n",
      "        38, 73, 27, 71, 62, 89, 90, 19, 88,  8, 13, 56, 84, 68, 19, 63, 37, 83,\n",
      "        89, 16, 71, 73, 27, 59,  1, 51, 96, 42, 80, 58, 71, 53, 66, 84, 36, 49,\n",
      "         3, 63, 11,  4, 37, 32, 92,  9, 56,  3, 75, 29, 15, 88, 21, 71, 61, 82,\n",
      "        54, 59, 49, 80, 58, 87, 15,  3, 13, 28, 56, 13, 18,  9, 36, 37, 81, 31,\n",
      "        52, 36, 56, 48, 26, 54, 83, 54,  3, 65, 60, 87, 58, 67, 23, 30, 39,  3,\n",
      "        63, 12, 47, 45, 75, 56, 43, 25, 55, 33, 21, 79, 46, 55, 93, 81, 99, 17,\n",
      "        15,  6, 94, 31, 67, 95, 97, 50, 64, 69, 24, 32,  1, 35, 50, 70, 33, 95,\n",
      "        10, 67, 93, 47, 65, 61, 38, 66, 24, 44,  3, 91,  1,  3, 96, 88, 64, 79,\n",
      "        69,  3, 42, 61, 24, 20, 26,  0, 24, 62, 27, 67, 98, 49, 60, 35,  8, 64,\n",
      "        88, 19, 79, 57, 94, 44, 32, 79, 51, 77, 89, 52,  0, 99, 88,  5, 91, 35,\n",
      "        93, 91, 17, 69, 22, 74, 54, 92, 79, 11, 47,  4, 90, 80, 82, 66, 74, 44,\n",
      "        46, 58, 56, 66, 14,  3,  5,  4, 91, 57, 13, 17, 46, 47, 47, 48, 86, 25,\n",
      "        64, 88, 98, 63, 56, 83, 69, 10, 74, 49, 11, 66, 90, 80, 89, 63, 98, 45,\n",
      "        93, 65, 62, 93, 84, 67, 79, 97, 87, 12,  4, 98, 59, 85, 39, 37,  8, 44,\n",
      "        38, 90, 99, 50, 16,  4,  8, 46, 10, 21, 90, 65, 32, 98, 68, 11, 89, 16,\n",
      "        79, 37, 85, 30, 84,  2, 32, 67, 52, 25, 48, 72, 19, 10, 16, 93, 12, 50,\n",
      "        42, 76, 87, 93, 76, 95, 12, 51, 83, 55,  0, 91, 99,  3, 19, 37, 47, 25,\n",
      "        69,  3, 83, 33, 59,  2, 64, 92,  8, 11, 68, 68, 32, 72,  4, 45, 92, 82,\n",
      "        99, 47, 23, 14, 95, 35, 24,  5, 43, 28, 11, 53, 37, 81, 22, 73, 91, 63,\n",
      "        62, 78, 69,  5, 12, 82, 60, 85,  3, 40, 82, 53, 75, 77, 50, 71, 61, 57,\n",
      "        88, 13,  9, 90, 63, 67,  6, 33, 84, 88, 32,  7,  3, 20, 75, 43, 83, 60,\n",
      "        36, 45, 89, 57, 39,  6, 94, 75, 20, 53, 99, 39,  2, 49, 91, 47, 18, 88,\n",
      "        63, 72, 99, 35, 89,  6,  0, 97, 40, 98, 18, 42, 15,  7, 19, 54, 13, 50,\n",
      "        14, 18, 13, 46, 65, 91,  4, 82, 62, 72, 31, 13, 12, 79, 45, 20, 34, 52,\n",
      "        30, 86, 97, 51, 12, 59,  0, 90, 37, 83, 77, 29, 49, 30, 95, 22, 14, 30,\n",
      "         8,  8, 99, 85, 55, 97, 82, 36, 11, 67, 71, 17, 68, 63, 41, 85, 42, 15,\n",
      "         3, 70, 31, 46, 48, 91, 86, 49, 67, 76, 68, 46, 44, 96])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)\n",
    "print(edge_pred_graph.edata['feature'].shape)\n",
    "# print(edge_pred_graph.ndata['feature'])\n",
    "print(edge_pred_graph.edata['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53b80682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='lstm')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='lstm')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "#         print(\"weight: \", self.conv1.fc_self.weight)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a9e1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_feats * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12d2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(in_features, num_classes)\n",
    "      \n",
    "    def forward(self, g, x, return_logits=False):\n",
    "        h = self.sage(g, x)\n",
    "        logits = self.pred(g, h)\n",
    "        \n",
    "        if return_logits:\n",
    "            return logits\n",
    "\n",
    "        output = torch.softmax(scores, dim=1)\n",
    "        predicted_classes = torch.argmax(output, dim=1)\n",
    "        return predicted_classes.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "815fdae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dc105a2a7b4b7cae38de4d37dd748f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training pred:  tensor([[-6.1803e+00,  1.5768e+01,  2.9338e+00,  ..., -8.2748e+00,\n",
      "          3.6249e+00,  1.0249e+01],\n",
      "        [ 3.9672e+00, -2.0796e+00, -1.5511e+00,  ..., -1.2419e+01,\n",
      "          2.4626e+00, -6.3839e+00],\n",
      "        [ 1.5139e+00,  4.5422e+00, -2.0551e+00,  ..., -4.2638e-01,\n",
      "         -2.1587e+01, -9.2025e+00],\n",
      "        ...,\n",
      "        [ 6.0072e-01,  1.2354e-02, -7.4666e+00,  ..., -1.2225e+01,\n",
      "         -8.0879e+00, -1.4922e+01],\n",
      "        [ 7.8529e+00, -7.9730e+00, -2.6458e-02,  ...,  4.8978e+00,\n",
      "         -9.0984e+00, -4.0859e+00],\n",
      "        [ 5.2579e+00,  1.4089e+00, -7.3762e+00,  ..., -1.1968e+00,\n",
      "         -1.5337e+01, -9.7243e+00]], grad_fn=<IndexBackward0>)\n",
      "training label:  tensor([79, 76, 81, 17, 21, 32,  5, 72, 37, 92, 59, 35, 38, 73, 71, 62, 89, 90,\n",
      "        19, 84, 19, 63, 37, 89, 73, 59,  1, 51, 96, 42, 80, 53, 66, 49,  3, 11,\n",
      "         4, 37, 32, 92,  9, 56, 75, 29, 88, 21, 71, 61, 82, 80, 87, 15,  3, 13,\n",
      "        13, 18,  9, 37, 81, 31, 36, 26, 65, 47, 45, 56, 25, 33, 21, 79, 93, 81,\n",
      "        15,  6, 31, 95, 97, 64, 69, 24, 32,  1, 35, 50, 70, 47, 65, 38, 24, 44,\n",
      "         3,  3, 96, 64, 79, 69,  3, 42, 20,  0, 67, 60,  8, 64, 88, 19, 79, 44,\n",
      "        51, 77, 89, 52, 99, 88,  5, 91, 35, 91, 69, 22, 74, 54, 79, 47,  4, 90,\n",
      "        80, 74, 58, 56, 14,  3,  5,  4, 91, 17, 47, 47, 48, 86, 64, 98, 63, 56,\n",
      "        83, 69, 10, 49, 66, 90, 89, 98, 45, 93, 65, 93, 84, 79, 97, 12,  4, 98,\n",
      "        59, 85, 39, 37,  8, 90, 16, 46, 10, 21, 90, 68, 16, 79, 37, 85, 30, 67,\n",
      "        52, 25, 72, 16, 50, 42, 87, 95, 12, 51,  0, 37, 47,  3, 33,  2, 64, 92,\n",
      "        68, 68, 32,  4, 45, 82, 99, 47, 23, 14, 95, 35, 43, 53, 91, 62, 78, 69,\n",
      "         5, 12, 85,  3, 53, 71, 61, 88, 13, 63,  6, 84, 32,  3, 20, 75, 43, 60,\n",
      "        36, 57, 75, 99, 39, 49, 47, 18, 88, 72, 99, 89,  6,  0, 98, 18, 42, 15,\n",
      "        19, 54, 13, 14, 18, 13, 46, 91, 62, 72, 31, 13, 12, 20, 34, 30, 86, 51,\n",
      "        12, 59, 90, 37, 83, 22, 14, 30,  8,  8, 99, 85, 55, 82, 36, 11, 67, 68,\n",
      "        63, 41, 42, 15, 70, 46, 48, 91, 86, 67, 76, 96])\n",
      "Epoch: 0, Loss: 4.892219543457031, Accuracy: 1.00%\n",
      "\n",
      "\n",
      "training pred:  tensor([[-6.1803e+00,  1.5768e+01,  2.9338e+00,  ..., -8.2748e+00,\n",
      "          3.6249e+00,  1.0249e+01],\n",
      "        [ 3.9672e+00, -2.0796e+00, -1.5511e+00,  ..., -1.2419e+01,\n",
      "          2.4626e+00, -6.3839e+00],\n",
      "        [ 1.5139e+00,  4.5422e+00, -2.0551e+00,  ..., -4.2638e-01,\n",
      "         -2.1587e+01, -9.2025e+00],\n",
      "        ...,\n",
      "        [ 6.0072e-01,  1.2354e-02, -7.4666e+00,  ..., -1.2225e+01,\n",
      "         -8.0879e+00, -1.4922e+01],\n",
      "        [ 7.8529e+00, -7.9730e+00, -2.6458e-02,  ...,  4.8978e+00,\n",
      "         -9.0984e+00, -4.0859e+00],\n",
      "        [ 5.2579e+00,  1.4089e+00, -7.3762e+00,  ..., -1.1968e+00,\n",
      "         -1.5337e+01, -9.7243e+00]], grad_fn=<IndexBackward0>)\n",
      "training label:  tensor([79, 76, 81, 17, 21, 32,  5, 72, 37, 92, 59, 35, 38, 73, 71, 62, 89, 90,\n",
      "        19, 84, 19, 63, 37, 89, 73, 59,  1, 51, 96, 42, 80, 53, 66, 49,  3, 11,\n",
      "         4, 37, 32, 92,  9, 56, 75, 29, 88, 21, 71, 61, 82, 80, 87, 15,  3, 13,\n",
      "        13, 18,  9, 37, 81, 31, 36, 26, 65, 47, 45, 56, 25, 33, 21, 79, 93, 81,\n",
      "        15,  6, 31, 95, 97, 64, 69, 24, 32,  1, 35, 50, 70, 47, 65, 38, 24, 44,\n",
      "         3,  3, 96, 64, 79, 69,  3, 42, 20,  0, 67, 60,  8, 64, 88, 19, 79, 44,\n",
      "        51, 77, 89, 52, 99, 88,  5, 91, 35, 91, 69, 22, 74, 54, 79, 47,  4, 90,\n",
      "        80, 74, 58, 56, 14,  3,  5,  4, 91, 17, 47, 47, 48, 86, 64, 98, 63, 56,\n",
      "        83, 69, 10, 49, 66, 90, 89, 98, 45, 93, 65, 93, 84, 79, 97, 12,  4, 98,\n",
      "        59, 85, 39, 37,  8, 90, 16, 46, 10, 21, 90, 68, 16, 79, 37, 85, 30, 67,\n",
      "        52, 25, 72, 16, 50, 42, 87, 95, 12, 51,  0, 37, 47,  3, 33,  2, 64, 92,\n",
      "        68, 68, 32,  4, 45, 82, 99, 47, 23, 14, 95, 35, 43, 53, 91, 62, 78, 69,\n",
      "         5, 12, 85,  3, 53, 71, 61, 88, 13, 63,  6, 84, 32,  3, 20, 75, 43, 60,\n",
      "        36, 57, 75, 99, 39, 49, 47, 18, 88, 72, 99, 89,  6,  0, 98, 18, 42, 15,\n",
      "        19, 54, 13, 14, 18, 13, 46, 91, 62, 72, 31, 13, 12, 20, 34, 30, 86, 51,\n",
      "        12, 59, 90, 37, 83, 22, 14, 30,  8,  8, 99, 85, 55, 82, 36, 11, 67, 68,\n",
      "        63, 41, 42, 15, 70, 46, 48, 91, 86, 67, 76, 96])\n",
      "Epoch: 50, Loss: 1.3990440368652344, Accuracy: 66.67%\n",
      "\n",
      "\n",
      "training pred:  tensor([[-6.1803e+00,  1.5768e+01,  2.9338e+00,  ..., -8.2748e+00,\n",
      "          3.6249e+00,  1.0249e+01],\n",
      "        [ 3.9672e+00, -2.0796e+00, -1.5511e+00,  ..., -1.2419e+01,\n",
      "          2.4626e+00, -6.3839e+00],\n",
      "        [ 1.5139e+00,  4.5422e+00, -2.0551e+00,  ..., -4.2638e-01,\n",
      "         -2.1587e+01, -9.2025e+00],\n",
      "        ...,\n",
      "        [ 6.0072e-01,  1.2354e-02, -7.4666e+00,  ..., -1.2225e+01,\n",
      "         -8.0879e+00, -1.4922e+01],\n",
      "        [ 7.8529e+00, -7.9730e+00, -2.6458e-02,  ...,  4.8978e+00,\n",
      "         -9.0984e+00, -4.0859e+00],\n",
      "        [ 5.2579e+00,  1.4089e+00, -7.3762e+00,  ..., -1.1968e+00,\n",
      "         -1.5337e+01, -9.7243e+00]], grad_fn=<IndexBackward0>)\n",
      "training label:  tensor([79, 76, 81, 17, 21, 32,  5, 72, 37, 92, 59, 35, 38, 73, 71, 62, 89, 90,\n",
      "        19, 84, 19, 63, 37, 89, 73, 59,  1, 51, 96, 42, 80, 53, 66, 49,  3, 11,\n",
      "         4, 37, 32, 92,  9, 56, 75, 29, 88, 21, 71, 61, 82, 80, 87, 15,  3, 13,\n",
      "        13, 18,  9, 37, 81, 31, 36, 26, 65, 47, 45, 56, 25, 33, 21, 79, 93, 81,\n",
      "        15,  6, 31, 95, 97, 64, 69, 24, 32,  1, 35, 50, 70, 47, 65, 38, 24, 44,\n",
      "         3,  3, 96, 64, 79, 69,  3, 42, 20,  0, 67, 60,  8, 64, 88, 19, 79, 44,\n",
      "        51, 77, 89, 52, 99, 88,  5, 91, 35, 91, 69, 22, 74, 54, 79, 47,  4, 90,\n",
      "        80, 74, 58, 56, 14,  3,  5,  4, 91, 17, 47, 47, 48, 86, 64, 98, 63, 56,\n",
      "        83, 69, 10, 49, 66, 90, 89, 98, 45, 93, 65, 93, 84, 79, 97, 12,  4, 98,\n",
      "        59, 85, 39, 37,  8, 90, 16, 46, 10, 21, 90, 68, 16, 79, 37, 85, 30, 67,\n",
      "        52, 25, 72, 16, 50, 42, 87, 95, 12, 51,  0, 37, 47,  3, 33,  2, 64, 92,\n",
      "        68, 68, 32,  4, 45, 82, 99, 47, 23, 14, 95, 35, 43, 53, 91, 62, 78, 69,\n",
      "         5, 12, 85,  3, 53, 71, 61, 88, 13, 63,  6, 84, 32,  3, 20, 75, 43, 60,\n",
      "        36, 57, 75, 99, 39, 49, 47, 18, 88, 72, 99, 89,  6,  0, 98, 18, 42, 15,\n",
      "        19, 54, 13, 14, 18, 13, 46, 91, 62, 72, 31, 13, 12, 20, 34, 30, 86, 51,\n",
      "        12, 59, 90, 37, 83, 22, 14, 30,  8,  8, 99, 85, 55, 82, 36, 11, 67, 68,\n",
      "        63, 41, 42, 15, 70, 46, 48, 91, 86, 67, 76, 96])\n",
      "Epoch: 100, Loss: 0.05867863819003105, Accuracy: 99.33%\n",
      "\n",
      "\n",
      "training pred:  tensor([[-6.1803e+00,  1.5768e+01,  2.9338e+00,  ..., -8.2748e+00,\n",
      "          3.6249e+00,  1.0249e+01],\n",
      "        [ 3.9672e+00, -2.0796e+00, -1.5511e+00,  ..., -1.2419e+01,\n",
      "          2.4626e+00, -6.3839e+00],\n",
      "        [ 1.5139e+00,  4.5422e+00, -2.0551e+00,  ..., -4.2638e-01,\n",
      "         -2.1587e+01, -9.2025e+00],\n",
      "        ...,\n",
      "        [ 6.0072e-01,  1.2354e-02, -7.4666e+00,  ..., -1.2225e+01,\n",
      "         -8.0879e+00, -1.4922e+01],\n",
      "        [ 7.8529e+00, -7.9730e+00, -2.6458e-02,  ...,  4.8978e+00,\n",
      "         -9.0984e+00, -4.0859e+00],\n",
      "        [ 5.2579e+00,  1.4089e+00, -7.3762e+00,  ..., -1.1968e+00,\n",
      "         -1.5337e+01, -9.7243e+00]], grad_fn=<IndexBackward0>)\n",
      "training label:  tensor([79, 76, 81, 17, 21, 32,  5, 72, 37, 92, 59, 35, 38, 73, 71, 62, 89, 90,\n",
      "        19, 84, 19, 63, 37, 89, 73, 59,  1, 51, 96, 42, 80, 53, 66, 49,  3, 11,\n",
      "         4, 37, 32, 92,  9, 56, 75, 29, 88, 21, 71, 61, 82, 80, 87, 15,  3, 13,\n",
      "        13, 18,  9, 37, 81, 31, 36, 26, 65, 47, 45, 56, 25, 33, 21, 79, 93, 81,\n",
      "        15,  6, 31, 95, 97, 64, 69, 24, 32,  1, 35, 50, 70, 47, 65, 38, 24, 44,\n",
      "         3,  3, 96, 64, 79, 69,  3, 42, 20,  0, 67, 60,  8, 64, 88, 19, 79, 44,\n",
      "        51, 77, 89, 52, 99, 88,  5, 91, 35, 91, 69, 22, 74, 54, 79, 47,  4, 90,\n",
      "        80, 74, 58, 56, 14,  3,  5,  4, 91, 17, 47, 47, 48, 86, 64, 98, 63, 56,\n",
      "        83, 69, 10, 49, 66, 90, 89, 98, 45, 93, 65, 93, 84, 79, 97, 12,  4, 98,\n",
      "        59, 85, 39, 37,  8, 90, 16, 46, 10, 21, 90, 68, 16, 79, 37, 85, 30, 67,\n",
      "        52, 25, 72, 16, 50, 42, 87, 95, 12, 51,  0, 37, 47,  3, 33,  2, 64, 92,\n",
      "        68, 68, 32,  4, 45, 82, 99, 47, 23, 14, 95, 35, 43, 53, 91, 62, 78, 69,\n",
      "         5, 12, 85,  3, 53, 71, 61, 88, 13, 63,  6, 84, 32,  3, 20, 75, 43, 60,\n",
      "        36, 57, 75, 99, 39, 49, 47, 18, 88, 72, 99, 89,  6,  0, 98, 18, 42, 15,\n",
      "        19, 54, 13, 14, 18, 13, 46, 91, 62, 72, 31, 13, 12, 20, 34, 30, 86, 51,\n",
      "        12, 59, 90, 37, 83, 22, 14, 30,  8,  8, 99, 85, 55, 82, 36, 11, 67, 68,\n",
      "        63, 41, 42, 15, 70, 46, 48, 91, 86, 67, 76, 96])\n",
      "Epoch: 150, Loss: 0.021783260628581047, Accuracy: 99.33%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 24.14871597290039, Validation Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "\n",
    "# the true label, which should be float()\n",
    "edge_label = edge_pred_graph.edata['label'].float()\n",
    "edge_label.requires_grad = True\n",
    "# print(\"label: \", edge_label, \"\\nshape\", edge_label.shape)\n",
    "\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "\n",
    "# model = Model(in_features = 10, hidden_features = 20, out_features = 10)\n",
    "model = Model(in_features=10, hidden_features=20, out_features=10, num_classes=100)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 200\n",
    "\n",
    "for epoch in tqdm(range(total_steps), desc=\"Training\", position=0, leave=True):\n",
    "    model.train()\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    score = scores[train_mask]\n",
    "    true_label = edge_label[train_mask].long()  # CrossEntropyLoss expects Long type for labels\n",
    "\n",
    "    loss = criterion(score, true_label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    with torch.no_grad():\n",
    "        preds_label = model(edge_pred_graph, node_features)\n",
    "        accuracy = (preds_label[train_mask] == true_label.float()).float().mean()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"training pred: \", prediction)\n",
    "        print(\"training label: \", true_label)\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Training Accuracy: {accuracy.item() * 100:.2f}%\\n\\n\")\n",
    "\n",
    "# Validation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    val_score = scores[valid_mask]\n",
    "    val_label = edge_label[valid_mask].long()\n",
    "\n",
    "    val_loss = criterion(val_score, val_label)\n",
    "\n",
    "    val_preds_label = torch.argmax(val_score, dim=1)\n",
    "    val_accuracy = (val_preds_label == val_label).float().mean()\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37050204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed406012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01900107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch as th\n",
    "\n",
    "# 1~100生成500個nodes\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "\n",
    "# make it symmetric\n",
    "# edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
    "edge_pred_graph = dgl.graph((src, dst))\n",
    "    \n",
    "# synthetic node and edge features, as well as edge labels\n",
    "edge_pred_graph.ndata['feature'] = torch.randn(100, 10).float()\n",
    "\n",
    "edge_pred_graph.edata['feature'] = torch.randn(500, 10).float()\n",
    "# edge_pred_graph.edata['label'] = torch.randn(500)\n",
    "edge_pred_graph.edata['label'] = torch.randint(0, 100, (500,)).float()\n",
    "# edge_pred_graph.edata['label'] = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "\n",
    "# synthetic train-test splits, which is 3:2\n",
    "edge_pred_graph.edata['train_mask'] = torch.zeros(500, dtype=torch.bool).bernoulli(0.6)\n",
    "\n",
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "#     def __init__(self, in_features, out_classes):\n",
    "    def __init__(self, in_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_feats * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        # h contains the node representations computed from the GNN defined\n",
    "        # in the node classification section (Section 5.1).\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(in_features, 100)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        h = self.sage(g, x)\n",
    "        score = self.pred(g, h)\n",
    "        \n",
    "        output = torch.softmax(score, dim=1)\n",
    "        \n",
    "        predicted_classes = torch.argmax(output, dim=1)\n",
    "        \n",
    "        row_sums = torch.sum(output, dim=1)\n",
    "        \n",
    "        return predicted_classes.float()\n",
    "    \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "\n",
    "# the true label, which should be float()\n",
    "edge_label = edge_pred_graph.edata['label'].float()\n",
    "edge_label.requires_grad = True\n",
    "# print(\"label: \", edge_label, \"\\nshape\", edge_label.shape)\n",
    "\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "\n",
    "# model = Model(in_features = 10, hidden_features = 20, out_features = 10)\n",
    "model = Model(in_features=10, hidden_features=20, out_features=10, num_classes=100)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 10000\n",
    "\n",
    "for epoch in tqdm(range(total_steps), desc=\"Training\", position=0, leave=True):\n",
    "    model.train()\n",
    "    pred = model(edge_pred_graph, node_features)\n",
    "    \n",
    "    # view(-1, 1) turn into: [num_classes, 1]\n",
    "    # view(1, -1) turn into: [1, num_classes] -> use this since we need [batch_size, num_classes]\n",
    "    prediction = pred[train_mask].view(1,-1)\n",
    "    true_label = edge_label[train_mask].view(1,-1)\n",
    "    \n",
    "    loss = criterion(prediction, true_label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # if epoch % 50==0:\n",
    "        # print(loss.item())\n",
    "#         print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
