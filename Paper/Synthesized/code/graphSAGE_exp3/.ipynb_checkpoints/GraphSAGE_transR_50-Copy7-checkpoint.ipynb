{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GraphSAGE\n",
    "- use DGL\n",
    "- predict `graphs`\n",
    "- valid, test data are in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "import dgl.nn as dglnn\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm  # 使用 notebook 版本的 tqdm\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv, GATConv, SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the GPU and assign the GPU by the best memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_free_gpu():\n",
    "    try:\n",
    "        # Run nvidia-smi command to get GPU details\n",
    "        _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "        command = \"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\"\n",
    "        memory_free_info = _output_to_list(subprocess.check_output(command.split())) \n",
    "        memory_free_values = [int(x) for i, x in enumerate(memory_free_info)]\n",
    "        \n",
    "        # Get the GPU with the maximum free memory\n",
    "        best_gpu_id = memory_free_values.index(max(memory_free_values))\n",
    "        return best_gpu_id\n",
    "    except:\n",
    "        # If any exception occurs, default to GPU 0 (this handles cases where nvidia-smi isn't installed)\n",
    "        return 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the best GPU ID based on free memory and set it\n",
    "    best_gpu_id = get_free_gpu()\n",
    "    device = torch.device(f\"cuda:{best_gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"there's no available GPU\")\n",
    "\n",
    "# device = torch.device(f\"cuda:{1}\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed = 8787):\n",
    "    torch.manual_seed(seed)\n",
    "    # random.seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        return data\n",
    "\n",
    "def collate(samples):\n",
    "    data_list = samples\n",
    "    batched_graphs = []\n",
    "    for data in data_list:\n",
    "        g = dgl.graph((th.tensor(data[\"edge_index\"][0]), th.tensor(data[\"edge_index\"][1])), num_nodes=data[\"num_nodes\"])\n",
    "\n",
    "        g.ndata['feat'] = th.tensor(data[\"node_feat\"])\n",
    "        g.edata['feat'] = th.tensor(data[\"edge_attr\"])\n",
    "        g.edata['label'] = th.tensor(data[\"labels\"])  # Add edge labels to graph\n",
    "\n",
    "        batched_graphs.append(g)\n",
    "    \n",
    "    return dgl.batch(batched_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3740cd52664b3c841bff44c6a8e6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/train.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a26acb81ed44a0b5c9462f10f36f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = ['train', 'valid', 'test']\n",
    "# datasets = ['valid']\n",
    "dataset_data = {}\n",
    "\n",
    "for dataset_name in tqdm(datasets):\n",
    "    file_path = f\"../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/{dataset_name}.jsonl\"\n",
    "    \n",
    "    print(file_path)\n",
    "    with open(file_path) as f:\n",
    "        data_list = [json.loads(line) for line in tqdm(f, position=0, leave=True)]\n",
    "    \n",
    "    dataset_data[dataset_name] = GraphDataset(data_list, device)\n",
    "\n",
    "print(\"Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(batch_size, shuffle=True):\n",
    "    dataloaders = {}\n",
    "    for dataset_name, dataset in dataset_data.items():\n",
    "        # do not shuffle the testing dataset\n",
    "        if dataset_name == \"test\":\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)    \n",
    "        else:\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate)\n",
    "    return dataloaders\n",
    "\n",
    "dataloaders = create_dataloaders(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turn the print message to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "formatted_time = now.strftime(\"%m%d_%H:%M\")\n",
    "\n",
    "log_file_path = f\"../log_message/{formatted_time}_GraphSAGE_transR_50.log\"\n",
    "\n",
    "def add_log_msg(msg, log_file_path=log_file_path):\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}\\n')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}')\n",
    "\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dglnn.SAGEConv(in_dim, out_dim, 'pool')\n",
    "#         self.layer2 = dglnn.SAGEConv(hidden_dim, out_dim, 'pool')\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.layer1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "#         h = self.dropout(h)\n",
    "#         h = self.layer2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage = GraphSAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes)\n",
    "      \n",
    "    def forward(self, g, node_feat, return_logits=False):\n",
    "        h = self.sage(g, node_feat)\n",
    "        logits = self.pred(g, h)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Forward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(batched_g, model, criterion, device, count=1, which_type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "#     batched_g, labels = data\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = batched_g.edata['label'].to(device)\n",
    "    \n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float())\n",
    "\n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    output = torch.softmax(logits, dim=1)\n",
    "    preds = output.argmax(1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "    \n",
    "    if which_type == 'validation' and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Validation: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Validation: {preds} {preds.shape}\")\n",
    "        \n",
    "    elif which_type == 'test'  and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Test: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Test: {preds} {preds.shape}\")\n",
    "        \n",
    "    if count % 5000 == 0: \n",
    "        add_log_msg(f\"labels of {count}: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of {count}: {preds} {preds.shape}\")\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the seed and save the model.state_dict that contains the initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "torch.save(model.state_dict(), 'model3_initial(graphsage)/initial_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layer1.fc_self.weight\n",
    "model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if model really load the model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))\n",
    "model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "\n",
    "seed = 5269\n",
    "same_seeds(seed)\n",
    "\n",
    "# model = GraphSAGE(in_dim=50, hidden_dim=16, out_dim=167)\n",
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))\n",
    "best_model_path = \"../checkpoint_graphSAGE/best_model_GraphSAGE_transR_50-6.pt\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=18, num_training_steps=total_steps)\n",
    "\n",
    "# T_max control the period of the lr changing -> set 1/10 first\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "total_steps = 50\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batched_g in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        num_batches += 1\n",
    "        loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    add_log_msg(f\"total batches: {num_batches}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in tqdm(dataloaders['valid'], desc=\"Validation\", position=0, leave=True):\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "    \n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}\\n')\n",
    "    \n",
    "            \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "            add_log_msg(\"Find a better model!!\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "#         print(best_model_path)\n",
    "\n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"============================== Early stopping ==================================\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test of valid and test part is ``graph``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60 APs in training x 10000times\n",
    "- 5 APs in validation x 4 times\n",
    "- 3 APs in test x 4 times\n",
    "- Batch size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e98d2e3b7104b2abe9562977651c696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 14:11:09# labels of Test: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n",
      "10/11/2023, 14:11:09# predicted of Test: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 82, 70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        82, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82,\n",
      "        70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n",
      "10/11/2023, 14:11:09# labels of 0: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n",
      "10/11/2023, 14:11:09# predicted of 0: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 82, 70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        82, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82,\n",
      "        70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n",
      "10/11/2023, 14:11:09# labels: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n",
      "10/11/2023, 14:11:09# predicted: tensor([65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 82, 70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        82, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 65, 65,\n",
      "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        65, 65, 65, 65, 65, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 82,\n",
      "        70, 70, 70, 70, 82, 70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70, 70, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 70,\n",
      "        70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "        70, 70, 70, 70], device='cuda:2') torch.Size([634])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 14:11:21# labels of Test: tensor([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120],\n",
      "       device='cuda:2') torch.Size([96])\n",
      "10/11/2023, 14:11:21# predicted of Test: tensor([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120],\n",
      "       device='cuda:2') torch.Size([96])\n",
      "10/11/2023, 14:11:21# Test Accuracy: 96.97192381946928 %\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 14:11:58# report path: classification_report/classification_report-transR_50-graphSAGE-5.xlsx\n",
      "10/11/2023, 14:11:58# label path: classification_report/mapped_true_predicted_labels-transR_50-graphSAGE-5.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 14:12:10# mapped_report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00      6400\n",
      "    T1003.001_35d92515122effdd73801c6ac3021da7       0.96      1.00      0.98       600\n",
      "    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00       500\n",
      "    T1003.002_7fa4ea18694f2552547b65e23952cabb       0.99      1.00      0.99      1500\n",
      "    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.00      0.00      0.00       100\n",
      "    T1003.003_f049b89533298c2d6cd37a940248b219       0.00      0.00      0.00       100\n",
      "        T1003_18f31c311ac208802e88ab8d5af8603e       0.98      1.00      0.99       600\n",
      "        T1007_9d03c91bdae5a80f17f89c987942b5a8       0.97      1.00      0.99       600\n",
      "    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.00      0.00      0.00       100\n",
      "        T1007_d6bb2a19da7246731ed9c44831b135f8       0.02      0.03      0.03       300\n",
      "    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.00      0.00      0.00       100\n",
      "        T1016_71b3d2945679566b9d94d8cb11df4b70       0.00      0.00      0.00       100\n",
      "        T1016_7d8ee68f0e9731db82964f558f614608       0.07      0.65      0.13       500\n",
      "    T1016_921055f4-5970-4707-909e-62f594234d91       0.00      0.00      0.00       100\n",
      "    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.00      0.00      0.00       100\n",
      "    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.00      0.00      0.00       100\n",
      "    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.00      0.00      0.00       100\n",
      "        T1018_a44bb43474728496276d5d73aa14588f       0.00      0.00      0.00       100\n",
      "        T1018_ac20e592bc912bddff4d6b88289095f0       0.00      0.00      0.00       100\n",
      "    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       0.88      0.99      0.93       600\n",
      "    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.03      0.01      0.01       100\n",
      "    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.00      0.00      0.00       100\n",
      "    T1036.003_04e8d83e7badf098d50800d6aa1dd487       0.99      0.99      0.99      2300\n",
      "    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       0.99      0.99      0.99      2700\n",
      "    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.01      0.01      0.01       200\n",
      "    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.02      0.01      0.01       200\n",
      "    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       0.98      1.00      0.99       700\n",
      "        T1040_6881a4589710d53f0c146e91db513f01       0.94      1.00      0.97       500\n",
      "        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.00      0.00      0.00       100\n",
      "        T1047_6935e41353aa781bb723462d26114c44       0.00      0.00      0.00       100\n",
      "        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.00      0.00      0.00       100\n",
      "        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.06      0.01      0.02       100\n",
      "        T1047_b0255b5120cbabc062d8d4510a142c3b       0.00      0.00      0.00       100\n",
      "        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.00      0.00      0.00       100\n",
      "        T1047_f4b0b4129560ea66f9751275e82f6bab       0.00      0.00      0.00       100\n",
      "    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.00      0.00      0.00       100\n",
      "        T1049_a14392d713dffba6a397682ff83259a0       0.04      0.08      0.05       300\n",
      "    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.02      0.01      0.01       200\n",
      "    T1053.005_ee454be9197890de62705ce6255933fd       0.00      0.00      0.00       100\n",
      "T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.00      0.00      0.00       100\n",
      "T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.00      0.00      0.00       100\n",
      "    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.00      0.00      0.00       100\n",
      "    T1057_8adf02e8-6e71-4244-886c-98c402857404       0.97      1.00      0.99       700\n",
      "        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.11      0.02      0.03       100\n",
      "        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.00      0.00      0.00       100\n",
      "T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       0.99      1.00      1.00      1000\n",
      "    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00      1500\n",
      "T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       0.95      1.00      0.97       500\n",
      "T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       0.97      1.00      0.98      1000\n",
      "T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       0.86      0.97      0.91       500\n",
      "T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00     13700\n",
      "    T1059.003_6c318ef0339d74d909ad556681b6493e       0.98      1.00      0.99       700\n",
      "    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00       600\n",
      "T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       0.92      0.99      0.96       900\n",
      "    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00       200\n",
      "    T1069.002_6103e503cb444bc7b4187704f2035708       0.01      0.01      0.01       400\n",
      "    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       0.96      0.99      0.97       600\n",
      "    T1071.001_24c3b7b004401d839a5c337201da3484       0.96      1.00      0.98      2000\n",
      "T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      0.99      1.00      1000\n",
      "T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00       300\n",
      "    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00       800\n",
      "    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.00      0.00      0.00       100\n",
      "    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.50      0.01      0.02       100\n",
      "    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      1200\n",
      "    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.00      0.00      0.00       100\n",
      "    T1087.001_6334877e8e3ba48f7835d4856d90a282       0.95      0.99      0.97       500\n",
      "T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.00      0.00      0.00       100\n",
      "    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.18      0.58      0.28       200\n",
      "        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      1100\n",
      "        T1105_1095434782a00c8a4772a11e625bcf5d       0.58      0.94      0.72       200\n",
      "        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00       800\n",
      "    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       0.99      1.00      0.99      2100\n",
      "        T1105_c521e0a70b243a0cf9217907ca3c6d27       0.99      1.00      1.00      2000\n",
      "        T1105_c76968acda4aa1673dadcd67f3ab7664       0.98      1.00      0.99      1300\n",
      "        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00      5700\n",
      "    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00     15000\n",
      "        T1112_257313a3c93e3bb7dfb60d6753b09e34       0.93      1.00      0.96       300\n",
      "        T1112_34041639e6e501856ecaf5969ee29c76       0.91      0.99      0.95       300\n",
      "        T1112_35c0360d226cf38104f300d9d57ce60e       0.89      0.99      0.94       300\n",
      "        T1112_4bfb5f265a5ce07af6bf10da113af7db       0.92      1.00      0.96       300\n",
      "        T1112_7fe6a66d03f4dbfc022609ba311c2b11       0.91      0.99      0.95       300\n",
      "        T1112_ba6f6214dbd17c54001e0a163b60f151       0.90      0.99      0.94       300\n",
      "        T1112_cab7b85611a290c0769546bfa9d6f962       0.86      0.99      0.92       300\n",
      "        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00       200\n",
      "        T1112_e74d2fb4ef5fa6c766a4151554033697       0.93      0.98      0.96       300\n",
      "        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00      1800\n",
      "        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       0.91      0.99      0.95       300\n",
      "        T1112_fd992e8ecfdac9b56dd6868904044827       0.90      0.99      0.94       300\n",
      "    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00       500\n",
      "        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00      1600\n",
      "    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.00      0.00      0.00       100\n",
      "        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       0.99      0.99      0.99      1900\n",
      "        T1119_7121cdf93b951311be9d7078c602efdc       0.97      0.99      0.98      2000\n",
      "        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00       600\n",
      "        T1123_372e6f46fca18e4f1b43209c20ffafa2       0.92      1.00      0.96       600\n",
      "    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.00      0.00      0.00       100\n",
      "        T1125_da86001b5081fcf773d8e62f22cf2b00       0.95      0.99      0.97       600\n",
      "    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.00      0.00      0.00       100\n",
      "    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.00      0.00      0.00       100\n",
      "    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       0.97      1.00      0.98       600\n",
      "        T1137_12ad9edefc86af07700fbf49bfdac6ba       0.98      1.00      0.99      1300\n",
      "        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.00      0.00      0.00       100\n",
      "        T1201_57296a2ddbeb7423c05feef2fe972111       0.00      0.00      0.00       100\n",
      "    T1204.002_522f3f35cd013e63830fa555495a0081       0.99      1.00      0.99      1000\n",
      "        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00       400\n",
      "        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.00      0.00      0.00       100\n",
      "        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00      6700\n",
      "        T1219_af8cb2bf9b436aae5c106a0a9c207e14       0.99      1.00      0.99     10400\n",
      "        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00      5000\n",
      "    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00       500\n",
      "        T1482_cfb61005899996469ae3023796792ca5       0.00      0.00      0.00       100\n",
      "        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00       400\n",
      "        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.00      0.00      0.00       100\n",
      "        T1490_8467c994685ccf178db166964bd80fab       0.03      0.01      0.02       200\n",
      "        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.00      0.00      0.00       100\n",
      "        T1490_c156ac5c9fa67080365268d95f29053d       0.14      0.01      0.02       100\n",
      "        T1490_c8f329d2847ede593b6cb4a1ec6120fb       0.91      0.99      0.95      1000\n",
      "        T1490_e90756bb6dcd21462dc4cc452661df91       0.00      0.00      0.00       100\n",
      "    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00       500\n",
      "    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00       700\n",
      "    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00      8200\n",
      "T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.00      0.00      0.00       100\n",
      "T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.04      0.01      0.02       100\n",
      "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.00      0.00      0.00       100\n",
      "    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.00      0.00      0.00       100\n",
      "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.00      0.00      0.00       100\n",
      "    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00       200\n",
      "    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.00      0.00      0.00       100\n",
      "        T1518_8ddfaf982ab359cda13626b870ccb339       0.82      0.99      0.90       200\n",
      "    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       100\n",
      "        T1531_aa6b15485a5f50ced34d87fda177b758       0.01      0.01      0.01       200\n",
      "        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00       200\n",
      "    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00      1500\n",
      "    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       0.99      1.00      0.99       700\n",
      "    T1547.001_163b023f43aba758d36f524d146cb8ea       0.97      1.00      0.98       500\n",
      "    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       0.95      1.00      0.97       600\n",
      "    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00       200\n",
      "    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00       200\n",
      "    T1547.001_d3ef4145e4144fd694514b1c5cc17350       0.96      1.00      0.98       500\n",
      "    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00       200\n",
      "    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00       200\n",
      "    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      1000\n",
      "    T1547.009_b6e5c895c6709fe289352ee23f062229       0.98      1.00      0.99       800\n",
      "    T1547.010_4593d72a5145e3f494421ac772d37464       0.96      1.00      0.98       600\n",
      "        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00      2200\n",
      "T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00       200\n",
      "    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.07      0.01      0.02       200\n",
      "        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00     21600\n",
      "    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00       200\n",
      "    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       0.83      0.98      0.90       600\n",
      "    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.17      0.01      0.02       100\n",
      "    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00       200\n",
      "    T1562.004_41627f71f968225b9f162cb76d16bd9d       0.99      1.00      0.99      1100\n",
      "    T1562.004_5b93df032e230056c21a3e57334f77d1       0.00      0.00      0.00       100\n",
      "    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.00      0.00      0.00       100\n",
      "    T1562.004_8fe59e288f10a486dc8b44bc872019ff       0.87      0.99      0.93       300\n",
      "    T1564.001_66a5fd5f244819181f074dd082a28905       0.49      0.42      0.45       500\n",
      "    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.49      0.60      0.54       500\n",
      "    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.42      0.37      0.39       200\n",
      "    T1564.004_28862487a99f5f89bc0d68c87396c7e9       0.98      1.00      0.99       600\n",
      "    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00      1600\n",
      "        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.00      0.00      0.00       100\n",
      "    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00       800\n",
      "    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00      6200\n",
      "    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       0.96      1.00      0.98       600\n",
      "                                        benign       1.00      1.00      1.00    134563\n",
      "\n",
      "                                      accuracy                           0.97    310263\n",
      "                                     macro avg       0.57      0.59      0.57    310263\n",
      "                                  weighted avg       0.96      0.97      0.97    310263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained model\n",
    "pretrained_model_path = '../checkpoint_graphSAGE/best_model_GraphSAGE_transR_50-6.pt'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batched_g in tqdm(dataloaders['test'], desc=\"Testing\", position=0, leave=True):\n",
    "#         print(f\"data:{data[1]}\")\n",
    "        loss, accuracy, predicted = model_fn(batched_g, model, criterion, device, count, which_type='test')\n",
    "        labels = batched_g.edata['label'].to(device)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        if count % 5000 == 0:\n",
    "            add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "            add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %\\n\\n\\n')\n",
    "\n",
    "\n",
    "# ======================================== handlig the output excel files ========================================\n",
    "mapping_file = './new_mapping.txt'\n",
    "label_mapping = {}\n",
    "with open(mapping_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(': ')\n",
    "        label_mapping[int(parts[1])] = parts[0]\n",
    "        \n",
    "# 将映射后的标签应用到true和predicted标签列表\n",
    "mapped_true_labels = [label_mapping[label] for label in true_labels]\n",
    "mapped_predicted_labels = [label_mapping[label] for label in predicted_labels]\n",
    "\n",
    "# 生成Scikit-learn报告信息的DataFrame\n",
    "report_data = classification_report(mapped_true_labels, mapped_predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "# mapped_true_labels_np = np.array(mapped_true_labels)\n",
    "# mapped_predicted_labels_np = np.array(mapped_predicted_labels)\n",
    "\n",
    "# print(\"mapped_true_labels 的形状:\", mapped_true_labels_np.shape)\n",
    "# print(\"mapped_predicted_labels 的形状:\", mapped_predicted_labels_np.shape)\n",
    "\n",
    "report_folder = 'classification_report'\n",
    "os.makedirs(report_folder, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    report_filename = f'classification_report-transR_50-graphSAGE-{count}.xlsx'\n",
    "    labels_filename = f'mapped_true_predicted_labels-transR_50-graphSAGE-{count}.xlsx'\n",
    "    \n",
    "    report_path = os.path.join(report_folder, report_filename)\n",
    "    labels_path = os.path.join(report_folder, labels_filename)\n",
    "    \n",
    "    if not os.path.exists(report_path) and not os.path.exists(labels_path):\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "report_df.to_excel(report_path, index_label='Label')\n",
    "\n",
    "mapped_labels_df = pd.DataFrame({'true_label': mapped_true_labels, 'predicted_label': mapped_predicted_labels})\n",
    "mapped_labels_df.to_excel(labels_path, index=False)\n",
    "\n",
    "add_log_msg(f\"report path: {report_path}\")\n",
    "add_log_msg(f\"label path: {labels_path}\")\n",
    "\n",
    "mapped_report = classification_report(mapped_true_labels, mapped_predicted_labels)\n",
    "add_log_msg(f\"mapped_report:\\n{mapped_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554</th>\n",
       "      <td>0.999688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>6400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.001_35d92515122effdd73801c6ac3021da7</th>\n",
       "      <td>0.963082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981194</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.002_5a484b65c247675e3b7ada4ba648d376</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.002_7fa4ea18694f2552547b65e23952cabb</th>\n",
       "      <td>0.990092</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.994691</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.003_9f73269695e54311dd61dc68940fb3e1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1574.011_72249c1e9ffe7d8f30243d838e0791ca</th>\n",
       "      <td>0.959872</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>0.999948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>134563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.969719</td>\n",
       "      <td>0.969719</td>\n",
       "      <td>0.969719</td>\n",
       "      <td>0.969719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.570203</td>\n",
       "      <td>0.587397</td>\n",
       "      <td>0.573316</td>\n",
       "      <td>310263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.963932</td>\n",
       "      <td>0.969719</td>\n",
       "      <td>0.966097</td>\n",
       "      <td>310263.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                precision    recall  f1-score  \\\n",
       "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554   0.999688  1.000000  0.999844   \n",
       "T1003.001_35d92515122effdd73801c6ac3021da7       0.963082  1.000000  0.981194   \n",
       "T1003.002_5a484b65c247675e3b7ada4ba648d376       1.000000  1.000000  1.000000   \n",
       "T1003.002_7fa4ea18694f2552547b65e23952cabb       0.990092  0.999333  0.994691   \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1       0.000000  0.000000  0.000000   \n",
       "...                                                   ...       ...       ...   \n",
       "T1574.011_72249c1e9ffe7d8f30243d838e0791ca       0.959872  0.996667  0.977923   \n",
       "benign                                           0.999948  1.000000  0.999974   \n",
       "accuracy                                         0.969719  0.969719  0.969719   \n",
       "macro avg                                        0.570203  0.587397  0.573316   \n",
       "weighted avg                                     0.963932  0.969719  0.966097   \n",
       "\n",
       "                                                      support  \n",
       "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554    6400.000000  \n",
       "T1003.001_35d92515122effdd73801c6ac3021da7         600.000000  \n",
       "T1003.002_5a484b65c247675e3b7ada4ba648d376         500.000000  \n",
       "T1003.002_7fa4ea18694f2552547b65e23952cabb        1500.000000  \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1         100.000000  \n",
       "...                                                       ...  \n",
       "T1574.011_72249c1e9ffe7d8f30243d838e0791ca         600.000000  \n",
       "benign                                          134563.000000  \n",
       "accuracy                                             0.969719  \n",
       "macro avg                                       310263.000000  \n",
       "weighted avg                                    310263.000000  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data = classification_report(mapped_true_labels, mapped_predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T1003.001_35d92515122effdd73801c6ac3021da7',\n",
       " 1: 'T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517',\n",
       " 2: 'T1047_ac2764f7a67a9ce92b54e8e59b361838',\n",
       " 3: 'T1059.001_6efbccc1869e8cd618c0d3ecda407d5f',\n",
       " 4: 'T1078.001_d0ca00832890baa1d42322cf70fcab1a',\n",
       " 5: 'T1112_257313a3c93e3bb7dfb60d6753b09e34',\n",
       " 6: 'T1119_344e7eaf650763e0d3e9f02e62c1cf4b',\n",
       " 7: 'T1219_7dabcbecab0334b115feefab1630f84a',\n",
       " 8: 'T1562.004_280003641a5cddf916c4f2bf605a71d3',\n",
       " 9: 'T1497.001_1258b063-27d6-489b-a677-4807faacf868',\n",
       " 10: 'T1547.001_4b71ebb2f6f6a01235ba240fa40ce978',\n",
       " 11: 'T1018_a44bb43474728496276d5d73aa14588f',\n",
       " 12: 'T1047_b0255b5120cbabc062d8d4510a142c3b',\n",
       " 13: 'T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2',\n",
       " 14: 'T1082_29451844-9b76-4e16-a9ee-d6feab4b24db',\n",
       " 15: 'T1112_34041639e6e501856ecaf5969ee29c76',\n",
       " 16: 'T1119_7121cdf93b951311be9d7078c602efdc',\n",
       " 17: 'T1219_af8cb2bf9b436aae5c106a0a9c207e14',\n",
       " 18: 'T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81',\n",
       " 19: 'T1003.002_5a484b65c247675e3b7ada4ba648d376',\n",
       " 20: 'T1547.001_777043894e42d2aae3881e63f6c76d33',\n",
       " 21: 'T1562.004_41627f71f968225b9f162cb76d16bd9d',\n",
       " 156: 'T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554',\n",
       " 23: 'T1547.001_d3ef4145e4144fd694514b1c5cc17350',\n",
       " 24: 'T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0',\n",
       " 25: 'T1219_f1b3fca18d7465cd10e5a7477a3bf97d',\n",
       " 26: 'T1120_7b9c7afaefa59aab759b49af0d699ac1',\n",
       " 27: 'T1112_35c0360d226cf38104f300d9d57ce60e',\n",
       " 28: 'T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8',\n",
       " 29: 'T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031',\n",
       " 30: 'T1047_ed736a123da6fb2aab22cfd4f437e8b5',\n",
       " 31: 'T1018_ac20e592bc912bddff4d6b88289095f0',\n",
       " 32: 'T1003.002_7fa4ea18694f2552547b65e23952cabb',\n",
       " 33: 'T1562.004_5b93df032e230056c21a3e57334f77d1',\n",
       " 34: 'T1003.003_9f73269695e54311dd61dc68940fb3e1',\n",
       " 35: 'T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89',\n",
       " 36: 'T1047_f4b0b4129560ea66f9751275e82f6bab',\n",
       " 37: 'T1059.001_ccdb8caf-c69e-424b-b930-551969450c57',\n",
       " 38: 'T1083_6e1a53c0-7352-4899-be35-fa7f364d5722',\n",
       " 39: 'T1112_4bfb5f265a5ce07af6bf10da113af7db',\n",
       " 40: 'T1123_372e6f46fca18e4f1b43209c20ffafa2',\n",
       " 41: 'T1482_6131397e-7765-424e-a594-3d7fb2d93a6a',\n",
       " 42: 'T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731',\n",
       " 43: 'T1547.004_0856714c9810ac55b53e9964d02958a0',\n",
       " 44: 'T1562.004_8d0a4585e7c4646185a912b14cd9cb46',\n",
       " 45: 'T1562.004_8fe59e288f10a486dc8b44bc872019ff',\n",
       " 46: 'T1547.004_aa147165f6c116cb0b0f944abe1db8ce',\n",
       " 47: 'T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba',\n",
       " 48: 'T1482_cfb61005899996469ae3023796792ca5',\n",
       " 49: 'T1124_fa6e8607-e0b1-425d-8924-9b894da5a002',\n",
       " 50: 'T1112_7fe6a66d03f4dbfc022609ba311c2b11',\n",
       " 51: 'T1087.001_6334877e8e3ba48f7835d4856d90a282',\n",
       " 52: 'T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d',\n",
       " 53: 'T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8',\n",
       " 54: 'T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989',\n",
       " 55: 'T1003.003_f049b89533298c2d6cd37a940248b219',\n",
       " 56: 'T1003_18f31c311ac208802e88ab8d5af8603e',\n",
       " 57: 'T1087.001_feaced8f-f43f-452a-9500-a5219488abb8',\n",
       " 58: 'T1059.003_6c318ef0339d74d909ad556681b6493e',\n",
       " 59: 'T1049_a14392d713dffba6a397682ff83259a0',\n",
       " 60: 'T1033_c0da588f-79f0-4263-8998-7496b1a40596',\n",
       " 61: 'T1112_ba6f6214dbd17c54001e0a163b60f151',\n",
       " 62: 'T1125_da86001b5081fcf773d8e62f22cf2b00',\n",
       " 63: 'T1486_d82ceb9939d3d920ee550187ad8235c8',\n",
       " 64: 'T1518.001_33a24ff44719e6ac0614b58f8c9a7c72',\n",
       " 65: 'benign',\n",
       " 66: 'T1547.009_501af516bd8b24fee0c7c650ae5cc861',\n",
       " 67: 'T1564.001_66a5fd5f244819181f074dd082a28905',\n",
       " 68: 'T1053.005_5db2884b6ca3ab932848f295a3896dc0',\n",
       " 69: 'T1007_9d03c91bdae5a80f17f89c987942b5a8',\n",
       " 70: 'T1036.003_04e8d83e7badf098d50800d6aa1dd487',\n",
       " 71: 'T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8',\n",
       " 72: 'T1090.001_ba343199a4f15ed6b57eb52412f62e4e',\n",
       " 73: 'T1112_cab7b85611a290c0769546bfa9d6f962',\n",
       " 74: 'T1135_530e47c6-8592-42bf-91df-c59ffbd8541b',\n",
       " 75: 'T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d',\n",
       " 76: 'T1518.001_b8453a5fe06b24aea12b27592d5c3d3a',\n",
       " 77: 'T1547.009_b6e5c895c6709fe289352ee23f062229',\n",
       " 78: 'T1564.001_dce51e632abdfe5392c7c1f942ac9273',\n",
       " 79: 'T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc',\n",
       " 80: 'T1547.010_4593d72a5145e3f494421ac772d37464',\n",
       " 81: 'T1007_c6607391-d02c-44b5-9b13-d3492ca58599',\n",
       " 82: 'T1036.003_f5ef8466e5ebcd2ae03f338d9416069c',\n",
       " 83: 'T1053.005_ee454be9197890de62705ce6255933fd',\n",
       " 84: 'T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2',\n",
       " 85: 'T1105_0856c235a1d26113d4f2d92e39c9a9f8',\n",
       " 86: 'T1112_cd8be0e6b873919da25530a2c7ea6750',\n",
       " 87: 'T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e',\n",
       " 88: 'T1490_8467c994685ccf178db166964bd80fab',\n",
       " 89: 'T1518_8ddfaf982ab359cda13626b870ccb339',\n",
       " 90: 'T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a',\n",
       " 91: 'T1007_d6bb2a19da7246731ed9c44831b135f8',\n",
       " 92: 'T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c',\n",
       " 93: 'T1069.001_a1f48fa3ddee658b29b414523c9a295b',\n",
       " 94: 'T1105_1095434782a00c8a4772a11e625bcf5d',\n",
       " 95: 'T1112_e74d2fb4ef5fa6c766a4151554033697',\n",
       " 96: 'T1137.002_e2af3c3ab1b0f659c874b8af58c49759',\n",
       " 97: 'T1490_9e5e4c0655fd1b5be88bd40b8251175f',\n",
       " 98: 'T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c',\n",
       " 99: 'T1547_fe9eeee9a7b339089e5fa634b08522c1',\n",
       " 100: 'T1564.004_28862487a99f5f89bc0d68c87396c7e9',\n",
       " 101: 'T1564.004_76b6066fe170d38215251102e42be973',\n",
       " 102: 'T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c',\n",
       " 103: 'T1531_aa6b15485a5f50ced34d87fda177b758',\n",
       " 104: 'T1490_c156ac5c9fa67080365268d95f29053d',\n",
       " 105: 'T1137_12ad9edefc86af07700fbf49bfdac6ba',\n",
       " 106: 'T1112_e7a987cbef27263e666e5b096488dc55',\n",
       " 107: 'T1105_4f683658f161ccdc51337c470d32bab9',\n",
       " 108: 'T1069.002_6103e503cb444bc7b4187704f2035708',\n",
       " 109: 'T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81',\n",
       " 110: 'T1036.004_7de3d7b4922a7b996d8df36fb22bb118',\n",
       " 111: 'T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17',\n",
       " 112: 'T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a',\n",
       " 113: 'T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc',\n",
       " 114: 'T1531_b25ae80dad74142fafb510e9c1949ace',\n",
       " 115: 'T1490_c8f329d2847ede593b6cb4a1ec6120fb',\n",
       " 116: 'T1201_38f6f0e50a6b196140ec40d3dc9cc9e6',\n",
       " 117: 'T1112_fa4ba6a06b4a5cd955ea5a60fae24281',\n",
       " 118: 'T1105_60f63260-39bb-4136-87a0-b6c2dca799fc',\n",
       " 119: 'T1016_71b3d2945679566b9d94d8cb11df4b70',\n",
       " 120: 'T1070.005_1f91076e2be2014cc7b4f1296de02fd6',\n",
       " 121: 'T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65',\n",
       " 122: 'T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7',\n",
       " 123: 'T1546.013_f9a968af61d36983448c74cca5464e17',\n",
       " 124: 'T1490_e90756bb6dcd21462dc4cc452661df91',\n",
       " 125: 'T1201_57296a2ddbeb7423c05feef2fe972111',\n",
       " 126: 'T1112_fd992e8ecfdac9b56dd6868904044827',\n",
       " 127: 'T1105_c521e0a70b243a0cf9217907ca3c6d27',\n",
       " 128: 'T1071.001_24c3b7b004401d839a5c337201da3484',\n",
       " 129: 'T1057_8adf02e8-6e71-4244-886c-98c402857404',\n",
       " 130: 'T1040_6881a4589710d53f0c146e91db513f01',\n",
       " 131: 'T1016_7d8ee68f0e9731db82964f558f614608',\n",
       " 132: 'T1560_a1ee301b0508747b468d578a14e5c1a5',\n",
       " 133: 'T1566.001_1afaec09315ab71fdfb167175e8a019a',\n",
       " 134: 'T1574.001_63bbedafba2f541552ac3579e9e3737b',\n",
       " 135: 'T1562.001_43e3334362b140924f001b256b229ee5',\n",
       " 136: 'T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac',\n",
       " 137: 'T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9',\n",
       " 138: 'T1204.002_522f3f35cd013e63830fa555495a0081',\n",
       " 139: 'T1113_316251ed-6a28-4013-812b-ddf5b5b007f8',\n",
       " 140: 'T1105_c76968acda4aa1673dadcd67f3ab7664',\n",
       " 141: 'T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e',\n",
       " 142: 'T1057_b2a1e430ca6d36eb5af2fe666e769847',\n",
       " 143: 'T1047_09e0f9cf2eb803a1c35deeecf3665fad',\n",
       " 144: 'T1016_921055f4-5970-4707-909e-62f594234d91',\n",
       " 145: 'T1574.011_72249c1e9ffe7d8f30243d838e0791ca',\n",
       " 146: 'T1562.002_6a8d25d65a7d481dc479f89c62af1e6a',\n",
       " 147: 'T1547.001_163b023f43aba758d36f524d146cb8ea',\n",
       " 148: 'T1491_68235976-2404-42a8-9105-68230cfef562',\n",
       " 149: 'T1115_70795de7cbb842edb029b3378c27c008',\n",
       " 150: 'T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69',\n",
       " 151: 'T1047_6935e41353aa781bb723462d26114c44',\n",
       " 152: 'T1057_f8de05d1741dcc468f772ab0ff4dac72',\n",
       " 153: 'T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89',\n",
       " 154: 'T1105_e6715e61f5df646692c624b3499384c4',\n",
       " 155: 'T1217_69bbe2183fa09c00ccaac62d48e214f8',\n",
       " 157: 'T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa',\n",
       " 158: 'T1047_ac122553ab4426ea3362bb4a97d31bfd',\n",
       " 159: 'T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4',\n",
       " 160: 'T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e',\n",
       " 161: 'T1105_eb814e03-811a-467a-bc6d-dcd453750fa2',\n",
       " 162: 'T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2',\n",
       " 163: 'T1217_f7a0f7d704aa52a764d9d1bee81e65d6',\n",
       " 164: 'T1562.002_94f51bf01a7036fe02d07b4c18967669',\n",
       " 165: 'T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4',\n",
       " 166: 'T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1003.003_9f73269695e54311dd61dc68940fb3e1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.003_f049b89533298c2d6cd37a940248b219</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1007_c6607391-d02c-44b5-9b13-d3492ca58599</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1007_d6bb2a19da7246731ed9c44831b135f8</th>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.027510</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.002_94f51bf01a7036fe02d07b4c18967669</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_280003641a5cddf916c4f2bf605a71d3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_5b93df032e230056c21a3e57334f77d1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_8d0a4585e7c4646185a912b14cd9cb46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision    recall  f1-score  \\\n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1   0.000000  0.000000  0.000000   \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219   0.000000  0.000000  0.000000   \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599   0.000000  0.000000  0.000000   \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8       0.023419  0.033333  0.027510   \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17   0.000000  0.000000  0.000000   \n",
       "...                                               ...       ...       ...   \n",
       "T1562.002_94f51bf01a7036fe02d07b4c18967669   0.166667  0.010000  0.018868   \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3   0.000000  0.000000  0.000000   \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1   0.000000  0.000000  0.000000   \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46   0.000000  0.000000  0.000000   \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.000000  0.000000  0.000000   \n",
       "\n",
       "                                            support  \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1    100.0  \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219    100.0  \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599    100.0  \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8        300.0  \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17    100.0  \n",
       "...                                             ...  \n",
       "T1562.002_94f51bf01a7036fe02d07b4c18967669    100.0  \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3    200.0  \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1    100.0  \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46    100.0  \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a        100.0  \n",
       "\n",
       "[67 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.2\n",
    "filtered_report = report_df[report_df['f1-score'] <= threshold]\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1003.003_9f73269695e54311dd61dc68940fb3e1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.003_f049b89533298c2d6cd37a940248b219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1007_c6607391-d02c-44b5-9b13-d3492ca58599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_71b3d2945679566b9d94d8cb11df4b70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_921055f4-5970-4707-909e-62f594234d91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1018_a44bb43474728496276d5d73aa14588f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1018_ac20e592bc912bddff4d6b88289095f0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1033_c0da588f-79f0-4263-8998-7496b1a40596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_09e0f9cf2eb803a1c35deeecf3665fad</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_6935e41353aa781bb723462d26114c44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_ac122553ab4426ea3362bb4a97d31bfd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_b0255b5120cbabc062d8d4510a142c3b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_ed736a123da6fb2aab22cfd4f437e8b5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_f4b0b4129560ea66f9751275e82f6bab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1053.005_ee454be9197890de62705ce6255933fd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1057_f8de05d1741dcc468f772ab0ff4dac72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1078.001_d0ca00832890baa1d42322cf70fcab1a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1083_6e1a53c0-7352-4899-be35-fa7f364d5722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1087.001_feaced8f-f43f-452a-9500-a5219488abb8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1124_fa6e8607-e0b1-425d-8924-9b894da5a002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1135_530e47c6-8592-42bf-91df-c59ffbd8541b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1201_38f6f0e50a6b196140ec40d3dc9cc9e6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1201_57296a2ddbeb7423c05feef2fe972111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1217_f7a0f7d704aa52a764d9d1bee81e65d6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1482_cfb61005899996469ae3023796792ca5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_9e5e4c0655fd1b5be88bd40b8251175f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_e90756bb6dcd21462dc4cc452661df91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1497.001_1258b063-27d6-489b-a677-4807faacf868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1518.001_b8453a5fe06b24aea12b27592d5c3d3a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_5b93df032e230056c21a3e57334f77d1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_8d0a4585e7c4646185a912b14cd9cb46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                precision  recall  f1-score  \\\n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1            0.0     0.0       0.0   \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219            0.0     0.0       0.0   \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599            0.0     0.0       0.0   \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17            0.0     0.0       0.0   \n",
       "T1016_71b3d2945679566b9d94d8cb11df4b70                0.0     0.0       0.0   \n",
       "T1016_921055f4-5970-4707-909e-62f594234d91            0.0     0.0       0.0   \n",
       "T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69            0.0     0.0       0.0   \n",
       "T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa            0.0     0.0       0.0   \n",
       "T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517            0.0     0.0       0.0   \n",
       "T1018_a44bb43474728496276d5d73aa14588f                0.0     0.0       0.0   \n",
       "T1018_ac20e592bc912bddff4d6b88289095f0                0.0     0.0       0.0   \n",
       "T1033_c0da588f-79f0-4263-8998-7496b1a40596            0.0     0.0       0.0   \n",
       "T1047_09e0f9cf2eb803a1c35deeecf3665fad                0.0     0.0       0.0   \n",
       "T1047_6935e41353aa781bb723462d26114c44                0.0     0.0       0.0   \n",
       "T1047_ac122553ab4426ea3362bb4a97d31bfd                0.0     0.0       0.0   \n",
       "T1047_b0255b5120cbabc062d8d4510a142c3b                0.0     0.0       0.0   \n",
       "T1047_ed736a123da6fb2aab22cfd4f437e8b5                0.0     0.0       0.0   \n",
       "T1047_f4b0b4129560ea66f9751275e82f6bab                0.0     0.0       0.0   \n",
       "T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8            0.0     0.0       0.0   \n",
       "T1053.005_ee454be9197890de62705ce6255933fd            0.0     0.0       0.0   \n",
       "T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c        0.0     0.0       0.0   \n",
       "T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81        0.0     0.0       0.0   \n",
       "T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65            0.0     0.0       0.0   \n",
       "T1057_f8de05d1741dcc468f772ab0ff4dac72                0.0     0.0       0.0   \n",
       "T1078.001_d0ca00832890baa1d42322cf70fcab1a            0.0     0.0       0.0   \n",
       "T1083_6e1a53c0-7352-4899-be35-fa7f364d5722            0.0     0.0       0.0   \n",
       "T1087.001_feaced8f-f43f-452a-9500-a5219488abb8        0.0     0.0       0.0   \n",
       "T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2            0.0     0.0       0.0   \n",
       "T1124_fa6e8607-e0b1-425d-8924-9b894da5a002            0.0     0.0       0.0   \n",
       "T1135_530e47c6-8592-42bf-91df-c59ffbd8541b            0.0     0.0       0.0   \n",
       "T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e            0.0     0.0       0.0   \n",
       "T1201_38f6f0e50a6b196140ec40d3dc9cc9e6                0.0     0.0       0.0   \n",
       "T1201_57296a2ddbeb7423c05feef2fe972111                0.0     0.0       0.0   \n",
       "T1217_f7a0f7d704aa52a764d9d1bee81e65d6                0.0     0.0       0.0   \n",
       "T1482_cfb61005899996469ae3023796792ca5                0.0     0.0       0.0   \n",
       "T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d                0.0     0.0       0.0   \n",
       "T1490_9e5e4c0655fd1b5be88bd40b8251175f                0.0     0.0       0.0   \n",
       "T1490_e90756bb6dcd21462dc4cc452661df91                0.0     0.0       0.0   \n",
       "T1497.001_1258b063-27d6-489b-a677-4807faacf868        0.0     0.0       0.0   \n",
       "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0        0.0     0.0       0.0   \n",
       "T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731            0.0     0.0       0.0   \n",
       "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba        0.0     0.0       0.0   \n",
       "T1518.001_b8453a5fe06b24aea12b27592d5c3d3a            0.0     0.0       0.0   \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1            0.0     0.0       0.0   \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46            0.0     0.0       0.0   \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a                0.0     0.0       0.0   \n",
       "\n",
       "                                                support  \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1        100.0  \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219        100.0  \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599        100.0  \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17        100.0  \n",
       "T1016_71b3d2945679566b9d94d8cb11df4b70            100.0  \n",
       "T1016_921055f4-5970-4707-909e-62f594234d91        100.0  \n",
       "T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69        100.0  \n",
       "T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa        100.0  \n",
       "T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517        100.0  \n",
       "T1018_a44bb43474728496276d5d73aa14588f            100.0  \n",
       "T1018_ac20e592bc912bddff4d6b88289095f0            100.0  \n",
       "T1033_c0da588f-79f0-4263-8998-7496b1a40596        100.0  \n",
       "T1047_09e0f9cf2eb803a1c35deeecf3665fad            100.0  \n",
       "T1047_6935e41353aa781bb723462d26114c44            100.0  \n",
       "T1047_ac122553ab4426ea3362bb4a97d31bfd            100.0  \n",
       "T1047_b0255b5120cbabc062d8d4510a142c3b            100.0  \n",
       "T1047_ed736a123da6fb2aab22cfd4f437e8b5            100.0  \n",
       "T1047_f4b0b4129560ea66f9751275e82f6bab            100.0  \n",
       "T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8        100.0  \n",
       "T1053.005_ee454be9197890de62705ce6255933fd        100.0  \n",
       "T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c    100.0  \n",
       "T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81    100.0  \n",
       "T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65        100.0  \n",
       "T1057_f8de05d1741dcc468f772ab0ff4dac72            100.0  \n",
       "T1078.001_d0ca00832890baa1d42322cf70fcab1a        100.0  \n",
       "T1083_6e1a53c0-7352-4899-be35-fa7f364d5722        100.0  \n",
       "T1087.001_feaced8f-f43f-452a-9500-a5219488abb8    100.0  \n",
       "T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2        100.0  \n",
       "T1124_fa6e8607-e0b1-425d-8924-9b894da5a002        100.0  \n",
       "T1135_530e47c6-8592-42bf-91df-c59ffbd8541b        100.0  \n",
       "T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e        100.0  \n",
       "T1201_38f6f0e50a6b196140ec40d3dc9cc9e6            100.0  \n",
       "T1201_57296a2ddbeb7423c05feef2fe972111            100.0  \n",
       "T1217_f7a0f7d704aa52a764d9d1bee81e65d6            100.0  \n",
       "T1482_cfb61005899996469ae3023796792ca5            100.0  \n",
       "T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d            100.0  \n",
       "T1490_9e5e4c0655fd1b5be88bd40b8251175f            100.0  \n",
       "T1490_e90756bb6dcd21462dc4cc452661df91            100.0  \n",
       "T1497.001_1258b063-27d6-489b-a677-4807faacf868    100.0  \n",
       "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0    100.0  \n",
       "T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731        100.0  \n",
       "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba    100.0  \n",
       "T1518.001_b8453a5fe06b24aea12b27592d5c3d3a        100.0  \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1        100.0  \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46        100.0  \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a            100.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] == 0) & (report_df['support'] == 100)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# labels_indices = filtered_report.index.tolist()\n",
    "# # Print to check if the indices are what we expect\n",
    "# print(\"Filtered Report Indices:\", labels_indices)\n",
    "\n",
    "# mapped_labels = [key for label in labels_indices for key, value in label_mapping.items() if value == label]\n",
    "\n",
    "# with open('triplets_1.txt', 'w') as f:\n",
    "#     for label in mapped_labels:\n",
    "#         f.write(f'{label}\\n')\n",
    "\n",
    "# print(f'{len(labels_indices)} labels have been written to filtered_labels.txt')\n",
    "\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a</th>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1036.004_7de3d7b4922a7b996d8df36fb22bb118</th>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1053.005_5db2884b6ca3ab932848f295a3896dc0</th>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1069.001_a1f48fa3ddee658b29b414523c9a295b</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_8467c994685ccf178db166964bd80fab</th>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1518.001_33a24ff44719e6ac0614b58f8c9a7c72</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1531_aa6b15485a5f50ced34d87fda177b758</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1531_b25ae80dad74142fafb510e9c1949ace</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc</th>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_280003641a5cddf916c4f2bf605a71d3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision  recall  f1-score  \\\n",
       "T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a   0.013158   0.005  0.007246   \n",
       "T1036.004_7de3d7b4922a7b996d8df36fb22bb118   0.016260   0.010  0.012384   \n",
       "T1053.005_5db2884b6ca3ab932848f295a3896dc0   0.015385   0.005  0.007547   \n",
       "T1069.001_a1f48fa3ddee658b29b414523c9a295b   0.000000   0.000  0.000000   \n",
       "T1490_8467c994685ccf178db166964bd80fab       0.030769   0.010  0.015094   \n",
       "T1518.001_33a24ff44719e6ac0614b58f8c9a7c72   0.000000   0.000  0.000000   \n",
       "T1531_aa6b15485a5f50ced34d87fda177b758       0.011494   0.005  0.006969   \n",
       "T1531_b25ae80dad74142fafb510e9c1949ace       0.000000   0.000  0.000000   \n",
       "T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc   0.069767   0.015  0.024691   \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3   0.000000   0.000  0.000000   \n",
       "\n",
       "                                            support  \n",
       "T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a    200.0  \n",
       "T1036.004_7de3d7b4922a7b996d8df36fb22bb118    200.0  \n",
       "T1053.005_5db2884b6ca3ab932848f295a3896dc0    200.0  \n",
       "T1069.001_a1f48fa3ddee658b29b414523c9a295b    200.0  \n",
       "T1490_8467c994685ccf178db166964bd80fab        200.0  \n",
       "T1518.001_33a24ff44719e6ac0614b58f8c9a7c72    200.0  \n",
       "T1531_aa6b15485a5f50ced34d87fda177b758        200.0  \n",
       "T1531_b25ae80dad74142fafb510e9c1949ace        200.0  \n",
       "T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc    200.0  \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3    200.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] <= 0.2) & (report_df['support'] == 200)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# labels_indices = filtered_report.index.tolist()\n",
    "# print(\"Filtered Report Indices:\", labels_indices)\n",
    "\n",
    "# mapped_labels = [key for label in labels_indices for key, value in label_mapping.items() if value == label]\n",
    "# print(mapped_labels)\n",
    "\n",
    "# with open('triplets_2.txt', 'w') as f:\n",
    "#     for label in mapped_labels:\n",
    "#         f.write(f'{label}\\n')\n",
    "\n",
    "# print(f'{len(labels_indices)} labels have been written to filtered_labels.txt')\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1007_d6bb2a19da7246731ed9c44831b135f8</th>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.027510</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_7d8ee68f0e9731db82964f558f614608</th>\n",
       "      <td>0.072731</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.130905</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1049_a14392d713dffba6a397682ff83259a0</th>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1069.002_6103e503cb444bc7b4187704f2035708</th>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision    recall  f1-score  \\\n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8       0.023419  0.033333  0.027510   \n",
       "T1016_7d8ee68f0e9731db82964f558f614608       0.072731  0.654000  0.130905   \n",
       "T1049_a14392d713dffba6a397682ff83259a0       0.037618  0.080000  0.051173   \n",
       "T1069.002_6103e503cb444bc7b4187704f2035708   0.013825  0.007500  0.009724   \n",
       "\n",
       "                                            support  \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8        300.0  \n",
       "T1016_7d8ee68f0e9731db82964f558f614608        500.0  \n",
       "T1049_a14392d713dffba6a397682ff83259a0        300.0  \n",
       "T1069.002_6103e503cb444bc7b4187704f2035708    400.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] <= 0.2) & (report_df['support'] > 200)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filtered_report[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize = (12,8))\n",
    "filtered_report[['f1-score']].plot(kind='bar', figsize = (16,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
