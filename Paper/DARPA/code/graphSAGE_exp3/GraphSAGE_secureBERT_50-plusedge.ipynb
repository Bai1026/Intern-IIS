{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GraphSAGE\n",
    "- use DGL\n",
    "- predict `graphs`\n",
    "- valid, test data are in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from dgl.nn import GraphConv, GATConv, SAGEConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the GPU and assign the GPU by the best memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_free_gpu():\n",
    "    try:\n",
    "        # Run nvidia-smi command to get GPU details\n",
    "        _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "        command = \"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\"\n",
    "        memory_free_info = _output_to_list(subprocess.check_output(command.split())) \n",
    "        memory_free_values = [int(x) for i, x in enumerate(memory_free_info)]\n",
    "        \n",
    "        # Get the GPU with the maximum free memory\n",
    "        best_gpu_id = memory_free_values.index(max(memory_free_values))\n",
    "        return best_gpu_id\n",
    "    except:\n",
    "        # If any exception occurs, default to GPU 0 (this handles cases where nvidia-smi isn't installed)\n",
    "        return 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the best GPU ID based on free memory and set it\n",
    "    best_gpu_id = get_free_gpu()\n",
    "    device = torch.device(f\"cuda:{best_gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"there's no available GPU\")\n",
    "\n",
    "# device = torch.device(f\"cuda:{1}\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(f\"cuda:1\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed = 8787):\n",
    "    torch.manual_seed(seed)\n",
    "    # random.seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding function\n",
    "def load_embedding(input_embedding_name, model):\n",
    "    if model.startswith('trans'):\n",
    "        with open(input_embedding_name) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # trans family wouldn't consider the relation embedding -> directly use the word embedding\n",
    "        # so the dimension of the node and the edge would be the same\n",
    "        ent_embeddings = np.array(data['ent_embeddings.weight'])\n",
    "        rel_embeddings = np.array(data['rel_embeddings.weight'])\n",
    "        return ent_embeddings, rel_embeddings\n",
    "    \n",
    "    elif model == 'secureBERT':\n",
    "        ent_embeddings = np.empty((0, 768), dtype=np.float32)\n",
    "        for filename in sorted(os.listdir(input_embedding_name)):\n",
    "            print(filename)\n",
    "\n",
    "            if not filename.startswith('embeddings_chunk'):\n",
    "                continue\n",
    "\n",
    "            embedding = np.load(f'{input_embedding_name}/{filename}')\n",
    "\n",
    "            print(ent_embeddings.shape, embedding.shape)\n",
    "\n",
    "            ent_embeddings = np.concatenate((ent_embeddings, embedding), axis=0)\n",
    "            print(filename, ent_embeddings.shape)\n",
    "\n",
    "        print(f'Reducing entity embedding to ({DIM},)')\n",
    "        print(ent_embeddings.shape, '->', end=' ')\n",
    "        \n",
    "        pca = PCA(n_components=DIM)\n",
    "        ent_embeddings = pca.fit_transform(ent_embeddings)\n",
    "        print(ent_embeddings.shape)\n",
    "\n",
    "        # secureBERT would consider the edge embedding -> input is relation.npy\n",
    "        # dimension of the node -> depends on us\n",
    "        # dimension of the edge -> 26 (since PCA)\n",
    "        rel_embeddings = np.load(f'{input_embedding_name}/relation.npy')\n",
    "        print(f'Reducing relation embedding to ({len(rel_embeddings)},)')\n",
    "        print(rel_embeddings.shape, '->', end=' ')\n",
    "        pca = PCA(n_components=len(rel_embeddings))\n",
    "        rel_embeddings = pca.fit_transform(rel_embeddings)\n",
    "        print(rel_embeddings.shape)\n",
    "        return ent_embeddings, rel_embeddings\n",
    "    else:\n",
    "        print('Error!!')\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import numpy as np\n",
    "# from tqdm.notebook import tqdm\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Load embedding function\n",
    "# def load_embedding(input_embedding_name, model):\n",
    "#     if model.startswith('trans'):\n",
    "#         with open(input_embedding_name) as f:\n",
    "#             data = json.load(f)\n",
    "#         ent_embeddings = np.array(data['ent_embeddings.weight'])\n",
    "#         rel_embeddings = np.array(data['rel_embeddings.weight'])\n",
    "#         return ent_embeddings, rel_embeddings\n",
    "\n",
    "#     elif model == 'secureBERT':\n",
    "#         ent_embeddings = np.empty((0, 768), dtype=np.float32)\n",
    "#         for filename in sorted(os.listdir(input_embedding_name)):\n",
    "#             filepath = os.path.join(input_embedding_name, filename)\n",
    "#             if not os.path.isfile(filepath) or not filename.startswith('embeddings_chunk'):\n",
    "#                 continue\n",
    "\n",
    "#             embedding = np.load(filepath)\n",
    "#             print(filename)\n",
    "#             print(ent_embeddings.shape, embedding.shape)\n",
    "#             ent_embeddings = np.concatenate((ent_embeddings, embedding), axis=0)\n",
    "#             print(filename, ent_embeddings.shape)\n",
    "            \n",
    "#             ent_embeddings = np.concatenate((ent_embeddings, embedding), axis=0)\n",
    "\n",
    "#         # 对实体嵌入进行 PCA 降维\n",
    "#         print(f'Reducing entity embedding to ({DIM},)')\n",
    "#         pca_ent = PCA(n_components=DIM)\n",
    "#         ent_embeddings = pca_ent.fit_transform(ent_embeddings)\n",
    "#         print(f'Entity embeddings reduced: {ent_embeddings.shape}')\n",
    "        \n",
    "#         # 直接加载关系嵌入，不进行 PCA 降维\n",
    "#         rel_embeddings = np.load(f'{input_embedding_name}/relation.npy')\n",
    "#         print(f'Relation embeddings: {rel_embeddings.shape}')\n",
    "\n",
    "#         return ent_embeddings, rel_embeddings\n",
    "\n",
    "#     else:\n",
    "#         print('Error!!')\n",
    "#         return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"../../data/4_embedding/synthesize/secureBERT\"\n",
    "input_filename = '../../data/source_data/before_embedding/3.10/all_graph_data.jsonl'\n",
    "\n",
    "model = 'secureBERT'\n",
    "DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a080b85621f4955b0caf1e5eac290c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH...\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open(input_filename, \"r\") as f:\n",
    "    print(\"Loading the data...\")\n",
    "\n",
    "    # only process 40000 data from 400000 data\n",
    "    wanted_data = 200000\n",
    "    input_data = []\n",
    "    for idx, line in tqdm(enumerate(f), total=wanted_data, desc=\"Loading\"):\n",
    "        if idx == wanted_data:\n",
    "            break\n",
    "        input_data.append(json.loads(line))\n",
    "        \n",
    "    print(\"FINISH...\")\n",
    "\n",
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Embedding ...\n",
      "embeddings_chunk_0.npy\n",
      "(0, 768) (160000, 768)\n",
      "embeddings_chunk_0.npy (160000, 768)\n",
      "embeddings_chunk_1.npy\n",
      "(160000, 768) (160000, 768)\n",
      "embeddings_chunk_1.npy (320000, 768)\n",
      "embeddings_chunk_2.npy\n",
      "(320000, 768) (160000, 768)\n",
      "embeddings_chunk_2.npy (480000, 768)\n",
      "embeddings_chunk_3.npy\n",
      "(480000, 768) (20281, 768)\n",
      "embeddings_chunk_3.npy (500281, 768)\n",
      "relation.npy\n",
      "Reducing entity embedding to (50,)\n",
      "(500281, 768) -> (500281, 50)\n",
      "Reducing relation embedding to (23,)\n",
      "(23, 768) -> (23, 23)\n",
      "Process Embedding ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6e66836c7b4c738dd5d436eac80784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Embedding:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = embedding_file.split('/')[-1].split('_')[0]\n",
    "print('Load Embedding ...')\n",
    "ent_embeddings, rel_embeddings = load_embedding(embedding_file, model)\n",
    "\n",
    "print('Process Embedding ...')\n",
    "# if not tolist(), the original format is array -> error format\n",
    "for data_point in tqdm(input_data, desc='Processing Embedding'):\n",
    "    data_point['node_feat'] = [ent_embeddings[node_id].tolist() for node_id in data_point['node_feat']]\n",
    "    data_point['edge_attr'] = [rel_embeddings[edge_id].tolist() for edge_id in data_point['edge_attr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_data[0]['node_feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_data[0]['edge_attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        return data\n",
    "\n",
    "def collate(samples):\n",
    "    data_list = samples\n",
    "    batched_graphs = []\n",
    "    for data in data_list:\n",
    "        g = dgl.graph((th.tensor(data[\"edge_index\"][0]), th.tensor(data[\"edge_index\"][1])), num_nodes=data[\"num_nodes\"])\n",
    "\n",
    "        g.ndata['feat'] = th.tensor(data[\"node_feat\"])\n",
    "        g.edata['feat'] = th.tensor(data[\"edge_attr\"])\n",
    "        g.edata['label'] = th.tensor(data[\"labels\"])  # Add edge labels to graph\n",
    "\n",
    "        batched_graphs.append(g)\n",
    "    \n",
    "    return dgl.batch(batched_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded and ready for training!\n"
     ]
    }
   ],
   "source": [
    "# split 8:1:1 (train, valid, test)\n",
    "train_data, remaining_data = train_test_split(input_data, test_size=0.2, random_state=42)\n",
    "valid_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "dataset_data = {\n",
    "    'train': GraphDataset(train_data, device),\n",
    "    'valid': GraphDataset(valid_data, device),\n",
    "    'test': GraphDataset(test_data, device)\n",
    "}\n",
    "\n",
    "print(\"Datasets loaded and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(batch_size, shuffle=True):\n",
    "    dataloaders = {}\n",
    "    for dataset_name, dataset in dataset_data.items():\n",
    "        # do not shuffle the testing dataset\n",
    "        if dataset_name == \"test\":\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)    \n",
    "        else:\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate)\n",
    "    return dataloaders\n",
    "\n",
    "dataloaders = create_dataloaders(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=54917, num_edges=119235,\n",
      "      ndata_schemes={'feat': Scheme(shape=(50,), dtype=torch.float32)}\n",
      "      edata_schemes={'feat': Scheme(shape=(23,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}) \n",
      "\n",
      "edata['feat'] size: torch.Size([119235, 23]) \n",
      "\n",
      "edata['label']: tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "\n",
      "\n",
      "edge embedding dimension:  23\n"
     ]
    }
   ],
   "source": [
    "edge_embedding_dim = 0\n",
    "\n",
    "# Assuming dataloaders is a dictionary with 'test' as one of the keys\n",
    "for batch in dataloaders['train']:\n",
    "    # Your batch processing code here\n",
    "    print(batch, \"\\n\")\n",
    "#     print(\"edata:\", batch.edata, '\\n')\n",
    "    print(\"edata['feat'] size:\", batch.edata['feat'].shape, '\\n')\n",
    "    print(\"edata['label']:\", batch.edata['label'])\n",
    "\n",
    "    edge_embedding_dim = batch.edata['feat'].shape[1]\n",
    "\n",
    "    break  # To break out after the first batch if needed\n",
    "\n",
    "print(\"\\n\\nedge embedding dimension: \", edge_embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turn the print message to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./log_message/0124_01:22_GraphSAGE_secureBERT_50-plusedge.log\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "formatted_time = now.strftime(\"%m%d_%H:%M\")\n",
    "\n",
    "log_file_path = f\"./log_message/{formatted_time}_GraphSAGE_secureBERT_50-plusedge.log\"\n",
    "\n",
    "def add_log_msg(msg, log_file_path=log_file_path):\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}\\n')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}')\n",
    "\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dglnn.SAGEConv(in_dim, hidden_dim, 'pool')\n",
    "        self.layer2 = dglnn.SAGEConv(hidden_dim, out_dim, 'pool')\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.layer1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "#         h = self.dropout(h)\n",
    "        h = self.layer2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes, edge_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2 + edge_embedding_dim, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges, edge_feat):\n",
    "#     def apply_edges(self, edges):\n",
    "\n",
    "        h_u = edges.src['new_node_feat']\n",
    "        h_v = edges.dst['new_node_feat']\n",
    "        \n",
    "        num_edges, edge_feat_dim = edge_feat.shape\n",
    "#         print(num_edges, edge_feat_dim)\n",
    "        \n",
    "        h_e = edge_feat\n",
    "        \n",
    "        # concat 3 features\n",
    "#         test = torch.cat([h_u, h_v, h_e],1)\n",
    "#         print(\"with edge: \", test.shape)\n",
    "        \n",
    "#         test = torch.cat([h_u, h_v],1)\n",
    "#         print(\"without edge: \", test.shape)\n",
    "        \n",
    "        score = self.W(torch.cat([h_u, h_v, h_e], 1))\n",
    "#         score = self.W(torch.cat([h_u, h_v], 1))\n",
    "\n",
    "        return {'score': score}\n",
    "\n",
    "\n",
    "    def forward(self, graph, new_node_feat, edge_feat):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['new_node_feat'] = new_node_feat\n",
    "#             graph.apply_edges(self.apply_edges)\n",
    "\n",
    "            # 在 apply_edges 时传递 edge_feat\n",
    "            graph.apply_edges(lambda edges: self.apply_edges(edges, edge_feat))\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes, edge_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.sage = GraphSAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes, edge_embedding_dim)\n",
    "      \n",
    "    def forward(self, g, node_feat, edge_feat, return_logits=False):\n",
    "        new_node_feat = self.sage(g, node_feat)\n",
    "        logits = self.pred(g, new_node_feat, edge_feat)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Forward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(batched_g, model, criterion, device, count=1, which_type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "#     batched_g, labels = data\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = batched_g.edata['label'].to(device)\n",
    "    \n",
    "#     logits = model(batched_g, batched_g.ndata['feat'].float())\n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float(), batched_g.edata['feat'].float())\n",
    "\n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    output = torch.softmax(logits, dim=1)\n",
    "    preds = output.argmax(1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the seed and save the model.state_dict that contains the initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 8787\n",
    "# same_seeds(seed)\n",
    "\n",
    "# model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "# torch.save(model.state_dict(), 'model3_initial(graphsage)/initial_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.layer1.fc_self.weight\n",
    "# model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if model really load the model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "# model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))\n",
    "# model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define all the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8787\n",
    "in_dim = DIM # dimension of the node feature\n",
    "hidden_dim = 64\n",
    "out_dim = 128\n",
    "num_classes = 2 # for DARPA\n",
    "edge_dim = edge_embedding_dim\n",
    "\n",
    "lr = 5e-4\n",
    "\n",
    "total_steps = 100\n",
    "patience = 5\n",
    "waiting = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_dim, hidden_dim, out_dim, num_classes, edge_dim)\n",
    "best_model_path = \"./checkpoint_graphSAGE/best_model_GraphSAGE_secureBERT_50-plusedge.pt\"\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=36, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd566a4b7324929acf6dc231dd4a5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65973ade1a8944b3af3be4a76c0afe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:28:47# total batches: 800\n",
      "01/24/2024, 01:28:47# Epoch 0 | Train Loss: 0.1468 | Train Accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f679b0e3b6453b99bc7bc634f2180f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:29:28# Validation Loss: 0.1003 | Validation Accuracy: 0.9679\n",
      "\n",
      "01/24/2024, 01:29:28# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19afaa06c95746d68fea826040e54755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:34:37# total batches: 800\n",
      "01/24/2024, 01:34:37# Epoch 1 | Train Loss: 0.0837 | Train Accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42641e277d8148e291b9714b8625b5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:35:17# Validation Loss: 0.0685 | Validation Accuracy: 0.9757\n",
      "\n",
      "01/24/2024, 01:35:17# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95412e23297f41799e95ece4459c2e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:40:37# total batches: 800\n",
      "01/24/2024, 01:40:37# Epoch 2 | Train Loss: 0.0524 | Train Accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b7d95559b9466e9e8565337853f7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:41:15# Validation Loss: 0.0391 | Validation Accuracy: 0.9830\n",
      "\n",
      "01/24/2024, 01:41:15# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26f69454c5547d28282f62fbf2ca992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:49:08# total batches: 800\n",
      "01/24/2024, 01:49:08# Epoch 3 | Train Loss: 0.0316 | Train Accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58aefdea327c4f10b98de5d900af853b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:49:46# Validation Loss: 0.0283 | Validation Accuracy: 0.9862\n",
      "\n",
      "01/24/2024, 01:49:46# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b60321c49484ebeaf48d0b173c8ce1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:54:57# total batches: 800\n",
      "01/24/2024, 01:54:57# Epoch 4 | Train Loss: 0.0267 | Train Accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d14b7cea8c433da44877cfc4aa0f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 01:55:37# Validation Loss: 0.0263 | Validation Accuracy: 0.9862\n",
      "\n",
      "01/24/2024, 01:55:37# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac3350a6a5148cfbdab40963a300098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:00:48# total batches: 800\n",
      "01/24/2024, 02:00:48# Epoch 5 | Train Loss: 0.0256 | Train Accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd639bfa6024507a12dfd8fd79c467b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:01:26# Validation Loss: 0.0256 | Validation Accuracy: 0.9863\n",
      "\n",
      "01/24/2024, 02:01:26# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c09beb164d24be1af1dd4191da01ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:06:41# total batches: 800\n",
      "01/24/2024, 02:06:41# Epoch 6 | Train Loss: 0.0252 | Train Accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d275343f3f6f472dab6599f6a24569e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:07:20# Validation Loss: 0.0252 | Validation Accuracy: 0.9863\n",
      "\n",
      "01/24/2024, 02:07:20# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0748695d76d42fa99a475ee68bf7e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:12:36# total batches: 800\n",
      "01/24/2024, 02:12:36# Epoch 7 | Train Loss: 0.0248 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5539111e9c4547a3a2aea9cf08d605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:13:17# Validation Loss: 0.0251 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 02:13:17# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1360de7ea33349d6a451174de5c6a606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:18:28# total batches: 800\n",
      "01/24/2024, 02:18:28# Epoch 8 | Train Loss: 0.0248 | Train Accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b6876912784113862969cace4f8ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:19:06# Validation Loss: 0.0248 | Validation Accuracy: 0.9866\n",
      "\n",
      "01/24/2024, 02:19:06# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da08984bd9fb41c68cba6021b52c412c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:24:21# total batches: 800\n",
      "01/24/2024, 02:24:21# Epoch 9 | Train Loss: 0.0246 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d9446129b840fb8ab182cc8f7fa36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:24:59# Validation Loss: 0.0247 | Validation Accuracy: 0.9863\n",
      "\n",
      "01/24/2024, 02:24:59# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8c83f704324db68ce3be843240be45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:30:14# total batches: 800\n",
      "01/24/2024, 02:30:14# Epoch 10 | Train Loss: 0.0245 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad48883f0344ef78aa1c395bc4232fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:30:54# Validation Loss: 0.0246 | Validation Accuracy: 0.9863\n",
      "\n",
      "01/24/2024, 02:30:54# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9026b1095ddf4ebc8caa2bfff6c934a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:36:10# total batches: 800\n",
      "01/24/2024, 02:36:10# Epoch 11 | Train Loss: 0.0242 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937f4a7055c41488df552ce055135cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:36:49# Validation Loss: 0.0246 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 02:36:49# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b8ad692bd7486fa8d1bef80d48bacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:42:02# total batches: 800\n",
      "01/24/2024, 02:42:02# Epoch 12 | Train Loss: 0.0244 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e68a8b66c2d4a8f9b496ddb066f820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:42:41# Validation Loss: 0.0245 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 02:42:41# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8c0774c6d348e781be39a9ed39c61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:47:53# total batches: 800\n",
      "01/24/2024, 02:47:53# Epoch 13 | Train Loss: 0.0241 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4007df92d5674aa48c0b5b9e2031cec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:51:03# Validation Loss: 0.0246 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bffe11ef924543ac2c66fa850c3e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:56:16# total batches: 800\n",
      "01/24/2024, 02:56:16# Epoch 14 | Train Loss: 0.0244 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eeefa9d2e24fa68d9d0357d4810bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 02:56:57# Validation Loss: 0.0244 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 02:56:57# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c148edb48314a44a29a4873e363172c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:02:08# total batches: 800\n",
      "01/24/2024, 03:02:08# Epoch 15 | Train Loss: 0.0241 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9236440d26ec43a1856ab2729d62fbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:02:50# Validation Loss: 0.0244 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 03:02:50# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac421fb8223d4135a3b3aacca7a71868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:08:06# total batches: 800\n",
      "01/24/2024, 03:08:06# Epoch 16 | Train Loss: 0.0242 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b2432a366415bab9b89aa549fa5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:08:45# Validation Loss: 0.0255 | Validation Accuracy: 0.9861\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a344106ef8b7452482fa319315176da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:14:03# total batches: 800\n",
      "01/24/2024, 03:14:03# Epoch 17 | Train Loss: 0.0240 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57405aeb99994d4cacdad6af3e70abf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:14:41# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 03:14:41# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b473a1893141718a40d3b347384436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:19:58# total batches: 800\n",
      "01/24/2024, 03:19:58# Epoch 18 | Train Loss: 0.0241 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf529a0a77842e3ba5befcbeda6d1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:20:37# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 03:20:37# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7454a6ae8144ac687599a5ab4c9ae5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:25:51# total batches: 800\n",
      "01/24/2024, 03:25:51# Epoch 19 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931f98ef843c420f8265e3d7d2d1e4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:26:30# Validation Loss: 0.0246 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4750c07d55a4518b7d392384ee8505e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:31:44# total batches: 800\n",
      "01/24/2024, 03:31:44# Epoch 20 | Train Loss: 0.0241 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752cc914923e403e99b01a73ab291ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:32:24# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 03:32:24# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa304b59c142cba9aea162d4b601de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:37:38# total batches: 800\n",
      "01/24/2024, 03:37:38# Epoch 21 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f805acaae923464787d1680176c8e7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:38:16# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6406499d9017482b957d9820665627a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:43:32# total batches: 800\n",
      "01/24/2024, 03:43:32# Epoch 22 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ac71d108a6495c9d73af28c49ee072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:44:11# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5964d96e75844c198eac80d8de541ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:49:27# total batches: 800\n",
      "01/24/2024, 03:49:27# Epoch 23 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85611e8438674f7abe638e7ce8a050dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:50:06# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 03:50:06# Find a better model!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8514231f01274ae592c15fe3dad10c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:55:18# total batches: 800\n",
      "01/24/2024, 03:55:18# Epoch 24 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc995ddb4254870bbfd394142341ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 03:58:26# Validation Loss: 0.0244 | Validation Accuracy: 0.9863\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881fb5e6dbb432596c24c1fa81c4b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:03:42# total batches: 800\n",
      "01/24/2024, 04:03:42# Epoch 25 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601da14beed492e9db292c6494d34a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:04:20# Validation Loss: 0.0243 | Validation Accuracy: 0.9866\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4e0a490609401f958d11a25f7bc111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:09:34# total batches: 800\n",
      "01/24/2024, 04:09:34# Epoch 26 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368c6a42bf314d6b9420491e2f19b91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:10:12# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9387ca2342d4d5f8b7e1042f7b8cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:15:24# total batches: 800\n",
      "01/24/2024, 04:15:24# Epoch 27 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981c88524d82494fb1b38e0036776102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:16:07# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3b3f1436374aec97d6cff067c54cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:22:03# total batches: 800\n",
      "01/24/2024, 04:22:03# Epoch 28 | Train Loss: 0.0239 | Train Accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb64243006459889a9af1ac6378590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 04:22:45# Validation Loss: 0.0243 | Validation Accuracy: 0.9864\n",
      "\n",
      "01/24/2024, 04:22:45# ============================== Early stopping ==================================\n"
     ]
    }
   ],
   "source": [
    "same_seeds(seed)\n",
    "model = model.to(device)\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batched_g in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        num_batches += 1\n",
    "        loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    add_log_msg(f\"total batches: {num_batches}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in tqdm(dataloaders['valid'], desc=\"Validation\", position=0, leave=True):\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "    \n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}\\n')\n",
    "    \n",
    "            \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "            add_log_msg(\"Find a better model!!\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    " \n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"============================== Early stopping ==================================\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test of valid and test part is ``graph``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60 APs in training x 10000times\n",
    "- 5 APs in validation x 4 times\n",
    "- 3 APs in test x 4 times\n",
    "- Batch size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88acca3b8b0d4e6bbbf0caa74aeead6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/24/2024, 13:20:15# Test Accuracy: 98.66362192795707 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained model\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batched_g in tqdm(dataloaders['test'], desc=\"Testing\", position=0, leave=True):\n",
    "\n",
    "        loss, accuracy, predicted = model_fn(batched_g, model, criterion, device, count, which_type='test')\n",
    "        labels = batched_g.edata['label'].to(device)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.995460</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>8.936242e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.849996</td>\n",
       "      <td>0.734672</td>\n",
       "      <td>0.788137</td>\n",
       "      <td>3.129370e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.986636</td>\n",
       "      <td>0.986636</td>\n",
       "      <td>0.986636</td>\n",
       "      <td>9.866362e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.920374</td>\n",
       "      <td>0.865066</td>\n",
       "      <td>0.890619</td>\n",
       "      <td>9.249179e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.985990</td>\n",
       "      <td>0.986636</td>\n",
       "      <td>0.986166</td>\n",
       "      <td>9.249179e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.990752  0.995460  0.993101  8.936242e+06\n",
       "1              0.849996  0.734672  0.788137  3.129370e+05\n",
       "accuracy       0.986636  0.986636  0.986636  9.866362e-01\n",
       "macro avg      0.920374  0.865066  0.890619  9.249179e+06\n",
       "weighted avg   0.985990  0.986636  0.986166  9.249179e+06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If wanna output the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_data = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "# report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "# report_folder = 'classification_report'\n",
    "# os.makedirs(report_folder, exist_ok=True)\n",
    "\n",
    "# count = 0\n",
    "# while True:\n",
    "#     report_filename = f'classification_report-transE_50-graphSAGE-{count}.xlsx'\n",
    "#     labels_filename = f'mapped_true_predicted_labels-transE_50-graphSAGE-{count}.xlsx'\n",
    "    \n",
    "#     report_path = os.path.join(report_folder, report_filename)\n",
    "#     labels_path = os.path.join(report_folder, labels_filename)\n",
    "    \n",
    "#     if not os.path.exists(report_path) and not os.path.exists(labels_path):\n",
    "#         break\n",
    "#     count += 1\n",
    "\n",
    "    \n",
    "# report_df.to_excel(report_path, index_label='Label')\n",
    "\n",
    "# labels_df = pd.DataFrame({'true_label': true_labels, 'predicted_label': predicted_labels})\n",
    "# labels_df.to_excel(labels_path, index=False)\n",
    "\n",
    "# add_log_msg(f\"report path: {report_path}\")\n",
    "# add_log_msg(f\"label path: {labels_path}\")\n",
    "\n",
    "# report = classification_report(true_labels, predicted_labels)\n",
    "# add_log_msg(f\"report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
