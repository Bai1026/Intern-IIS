{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bbf5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "RELATION_INPUT_PATH = './data/3_openKE/synthesize/relation2id.txt'\n",
    "RELATION_INPUT_LABEL_PATH = './data/3_openKE/synthesize/relation2id_type.txt'\n",
    "\n",
    "RELATION_OUTPUT_PATH = './data/4_embedding/synthesize/secureBERT/relation.npy'\n",
    "MODEL_SAVE_PATH = './data/4_embedding/synthesize/model/secureBERT/relation/'\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c5a8b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Cnt: 23 ['RegDeleteKey', 'Process Create', 'ReadFile', 'TCP Accept', 'RegOpenKey']\n",
      "Label Cnt: 23 ['registry', 'process', 'file', 'network', 'registry', 'file', 'network', 'file', 'file', 'registry', 'file', 'registry', 'file', 'network', 'file', 'file', 'unknown', 'process', 'network', 'file', 'file', 'file', 'network']\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "with open(RELATION_INPUT_LABEL_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        cat, rid = row.split('\\t')\n",
    "        Y.append(cat)\n",
    "        \n",
    "with open(RELATION_INPUT_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        value, rid = row.split('\\t')\n",
    "        X.append(value)\n",
    "\n",
    "print(f'Sentence Cnt: {len(X)}' , X[:5])\n",
    "# print(f'Label Cnt: {len(Y)}', Y[:5])\n",
    "print(f'Label Cnt: {len(Y)}', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d29edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category labels to tensor\n",
    "# label_dict = {'file':0, 'registry':1, 'network':2, 'process':3}\n",
    "label_dict = {'file':0, 'registry':1, 'network':2, 'process':3, 'unknown':4}\n",
    "\n",
    "labels = torch.tensor([label_dict[y] for y in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e886db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SecureBERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"ehsanaghaei/SecureBERT\")\n",
    "encoded_inputs = tokenizer.batch_encode_plus(\n",
    "    X,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=32,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e89e0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 32])\n",
      "torch.Size([23, 32])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fc84993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02e02372",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b9ee4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 32]) Counter({'file': 11, 'network': 5, 'registry': 4, 'process': 2, 'unknown': 1})\n",
      "torch.Size([5, 32]) Counter({'file': 3, 'network': 2})\n"
     ]
    }
   ],
   "source": [
    "# splitter_tmp = int(0.9 * len(input_ids))\n",
    "splitter1 = int(0.8 * len(input_ids))\n",
    "train_inputs, val_inputs= input_ids, input_ids[splitter1:]\n",
    "train_masks, val_masks= attention_mask, attention_mask[splitter1:]\n",
    "train_labels, val_labels = labels, labels[splitter1:]\n",
    "print(train_inputs.shape, Counter(Y))\n",
    "print(val_inputs.shape, Counter(Y[splitter1:]))\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "734efbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at ehsanaghaei/SecureBERT were not used when initializing BertForSequenceClassification: ['roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'lm_head.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'classifier.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_labels is important -> remember to modify\n",
    "model = BertForSequenceClassification.from_pretrained(\"ehsanaghaei/SecureBERT\", num_labels=5, output_hidden_states=True)\n",
    "# Move the model to GPU\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e08c1345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 1, Val Loss: 0.4458, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 2, Val Loss: 0.5651, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 3, Val Loss: 0.3430, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 4, Val Loss: 0.4620, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 5, Val Loss: 0.3214, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 6, Val Loss: 0.3277, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 7, Val Loss: 0.2673, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 8, Val Loss: 0.2737, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 9, Val Loss: 0.2657, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 10, Val Loss: 0.1874, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 11, Val Loss: 0.2155, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 12, Val Loss: 0.1533, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 13, Val Loss: 0.1651, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 14, Val Loss: 0.1283, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 15, Val Loss: 0.1092, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 16, Val Loss: 0.0969, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 17, Val Loss: 0.1019, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 18, Val Loss: 0.0724, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 19, Val Loss: 0.2306, Val Accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 20, Val Loss: 0.0769, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 21, Val Loss: 0.1263, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 22, Val Loss: 0.0610, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 23, Val Loss: 0.0907, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 24, Val Loss: 0.0633, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 25, Val Loss: 0.0418, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 26, Val Loss: 0.0420, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 27, Val Loss: 0.0266, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 28, Val Loss: 0.0346, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 29, Val Loss: 0.0203, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 30, Val Loss: 0.0193, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 31, Val Loss: 0.0296, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 32, Val Loss: 0.0104, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 33, Val Loss: 0.0197, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 34, Val Loss: 0.0128, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 35, Val Loss: 0.0070, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 36, Val Loss: 0.0096, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 37, Val Loss: 0.0105, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 38, Val Loss: 0.0062, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 39, Val Loss: 0.0052, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 40, Val Loss: 0.0055, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 41, Val Loss: 0.0058, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 42, Val Loss: 0.0058, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 43, Val Loss: 0.0053, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 44, Val Loss: 0.0047, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 45, Val Loss: 0.0042, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 46, Val Loss: 0.0040, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 47, Val Loss: 0.0039, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 48, Val Loss: 0.0038, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 49, Val Loss: 0.0037, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(23, 768)\n",
      "Epoch: 50, Val Loss: 0.0037, Val Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the BERT model on my task: \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 50\n",
    "batch_chunk_size = 10000  # Number of batches to process before saving to disk\n",
    "\n",
    "# Training loop\n",
    "min_val_loss = 999999\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    embeddings = []\n",
    "#     print(f'Epoch {epoch+1} start!!!!!!!')\n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Extract the embeddings from the model's hidden states\n",
    "        hidden_states = model.bert(input_ids, attention_mask=attention_mask)[2]\n",
    "        last_hidden_layer_embeddings = hidden_states[-1].detach().cpu().numpy()\n",
    "        embeddings.append(last_hidden_layer_embeddings)\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    \n",
    "    # embeddings[sequence number, sequence length(26), hidden dimension(768)]\n",
    "    embeddings = embeddings[:, 0, :]  # Take the embedding of the [CLS] token -> output = [26, 768]\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    np.save(RELATION_OUTPUT_PATH, embeddings)\n",
    "    print(f'{RELATION_OUTPUT_PATH}, shape={embeddings.shape}')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(logits, dim=1)\n",
    "            val_correct += (predicted_labels == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        # Save the trained model\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        min_val_loss = avg_val_loss\n",
    "        \n",
    "#     print(f'Epoch {epoch+1} end!!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434aa365",
   "metadata": {},
   "source": [
    "#### The complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "RELATION_INPUT_PATH = './data/3_openKE/synthesize/relation2id.txt'\n",
    "RELATION_INPUT_LABEL_PATH = './data/3_openKE/synthesize/relation2id_type.txt'\n",
    "RELATION_OUTPUT_PATH = './data/4_embedding/synthesize/secureBERT/relation.npy'\n",
    "MODEL_SAVE_PATH = './data/4_embedding/synthesize/model/secureBERT/relation/'\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)\n",
    "    \n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "with open(RELATION_INPUT_LABEL_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        cat, rid = row.split('\\t')\n",
    "        Y.append(cat)\n",
    "        \n",
    "with open(RELATION_INPUT_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        value, rid = row.split('\\t')\n",
    "        X.append(value)\n",
    "\n",
    "print(f'Sentence Cnt: {len(X)}' , X[:5])\n",
    "# print(f'Label Cnt: {len(Y)}', Y[:5])\n",
    "print(f'Label Cnt: {len(Y)}', Y)\n",
    "\n",
    "label_dict = {'file':0, 'registry':1, 'network':2, 'process':3, 'unknown':4}\n",
    "\n",
    "\n",
    "labels = torch.tensor([label_dict[y] for y in Y])\n",
    "\n",
    "# SecureBERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"ehsanaghaei/SecureBERT\")\n",
    "encoded_inputs = tokenizer.batch_encode_plus(\n",
    "    X,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=32,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']\n",
    "\n",
    "\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)\n",
    "\n",
    "# Move data to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# splitter_tmp = int(0.9 * len(input_ids))\n",
    "splitter1 = int(0.8 * len(input_ids))\n",
    "train_inputs, val_inputs= input_ids, input_ids[splitter1:]\n",
    "train_masks, val_masks= attention_mask, attention_mask[splitter1:]\n",
    "train_labels, val_labels = labels, labels[splitter1:]\n",
    "print(train_inputs.shape, Counter(Y))\n",
    "print(val_inputs.shape, Counter(Y[splitter1:]))\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# num_labels is important -> remember to modify\n",
    "model = BertForSequenceClassification.from_pretrained(\"ehsanaghaei/SecureBERT\", num_labels=5, output_hidden_states=True)\n",
    "# Move the model to GPU\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "# Fine-tune the BERT model on my task: \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 50\n",
    "batch_chunk_size = 10000  # Number of batches to process before saving to disk\n",
    "\n",
    "# Training loop\n",
    "min_val_loss = 999999\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    embeddings = []\n",
    "#     print(f'Epoch {epoch+1} start!!!!!!!')\n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Extract the embeddings from the model's hidden states\n",
    "        hidden_states = model.bert(input_ids, attention_mask=attention_mask)[2]\n",
    "        last_hidden_layer_embeddings = hidden_states[-1].detach().cpu().numpy()\n",
    "        embeddings.append(last_hidden_layer_embeddings)\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    \n",
    "    # embeddings[sequence number, sequence length(26), hidden dimension(768)]\n",
    "    embeddings = embeddings[:, 0, :]  # Take the embedding of the [CLS] token -> output = [26, 768]\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    np.save(RELATION_OUTPUT_PATH, embeddings)\n",
    "    print(f'{RELATION_OUTPUT_PATH}, shape={embeddings.shape}')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(logits, dim=1)\n",
    "            val_correct += (predicted_labels == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        # Save the trained model\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        min_val_loss = avg_val_loss\n",
    "        \n",
    "#     print(f'Epoch {epoch+1} end!!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa79025",
   "metadata": {},
   "source": [
    "#### the complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c60edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Cnt: 26 ['QueryAllInformationFile', 'QueryNetworkOpenInformationFile', 'RegSetValue', 'CreateFile', 'SetDispositionInformationFile']\n",
      "Label Cnt: 26 ['file', 'network', 'registry', 'file', 'file']\n",
      "torch.Size([26, 32])\n",
      "torch.Size([26, 32])\n",
      "torch.Size([26, 32]) Counter({'file': 11, 'network': 7, 'registry': 7, 'process': 1})\n",
      "torch.Size([6, 32]) Counter({'file': 3, 'network': 2, 'process': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at ehsanaghaei/SecureBERT were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'lm_head.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['encoder.layer.9.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'classifier.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 1, Val Loss: 1.2403, Val Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 2, Val Loss: 1.0358, Val Accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 3, Val Loss: 0.8378, Val Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 4, Val Loss: 0.5766, Val Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 5, Val Loss: 0.3496, Val Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 6, Val Loss: 0.1853, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 7, Val Loss: 0.1194, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 8, Val Loss: 0.0854, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 9, Val Loss: 0.0480, Val Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/4_embedding/synthesize/secureBERT/relation.npy, shape=(26, 768)\n",
      "Epoch: 10, Val Loss: 0.0362, Val Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "RELATION_INPUT_PATH = './data/3_openKE/synthesize/relation2id.txt'\n",
    "RELATION_INPUT_LABEL_PATH = './data/3_openKE/synthesize/relation2id_type.txt'\n",
    "RELATION_OUTPUT_PATH = './data/4_embedding/synthesize/secureBERT/relation.npy'\n",
    "MODEL_SAVE_PATH = './data/4_embedding/synthesize/model/secureBERT/relation/'\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)\n",
    "\n",
    "    \n",
    "X = list()\n",
    "Y = list()\n",
    "with open(RELATION_INPUT_LABEL_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        cat, rid = row.split('\\t')\n",
    "        Y.append(cat)\n",
    "with open(RELATION_INPUT_PATH, 'r') as f:\n",
    "    for row in f.readlines()[1:]:\n",
    "        value, rid = row.split('\\t')\n",
    "        X.append(value)\n",
    "\n",
    "print(f'Sentence Cnt: {len(X)}' , X[:5])\n",
    "print(f'Label Cnt: {len(Y)}', Y[:5])\n",
    "\n",
    "\n",
    "# Convert category labels to tensor\n",
    "label_dict = {'file':0, 'registry':1, 'network':2, 'process':3}\n",
    "labels = torch.tensor([label_dict[y] for y in Y])\n",
    "\n",
    "\n",
    "# SecureBERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"ehsanaghaei/SecureBERT\")\n",
    "encoded_inputs = tokenizer.batch_encode_plus(\n",
    "    X,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=32,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']\n",
    "\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)\n",
    "\n",
    "\n",
    "# Move data to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "# splitter_tmp = int(0.9 * len(input_ids))\n",
    "splitter1 = int(0.8 * len(input_ids))\n",
    "train_inputs, val_inputs= input_ids, input_ids[splitter1:]\n",
    "train_masks, val_masks= attention_mask, attention_mask[splitter1:]\n",
    "train_labels, val_labels = labels, labels[splitter1:]\n",
    "print(train_inputs.shape, Counter(Y))\n",
    "print(val_inputs.shape, Counter(Y[splitter1:]))\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"ehsanaghaei/SecureBERT\", num_labels=4, output_hidden_states=True)\n",
    "# Move the model to GPU\n",
    "model.to('cuda')\n",
    "\n",
    "# Fine-tune the BERT model on my task:\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "epochs = 10\n",
    "batch_chunk_size = 10000  # Number of batches to process before saving to disk\n",
    "\n",
    "# Training loop\n",
    "min_val_loss = 999999\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    embeddings = []\n",
    "#     print(f'Epoch {epoch+1} start!!!!!!!')\n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Extract the embeddings from the model's hidden states\n",
    "        hidden_states = model.bert(input_ids, attention_mask=attention_mask)[2]\n",
    "        last_hidden_layer_embeddings = hidden_states[-1].detach().cpu().numpy()\n",
    "        embeddings.append(last_hidden_layer_embeddings)\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    embeddings = embeddings[:, 0, :]  # Take the embedding of the [CLS] token\n",
    "    embeddings = np.array(embeddings)\n",
    "    np.save(RELATION_OUTPUT_PATH, embeddings)\n",
    "    print(f'{RELATION_OUTPUT_PATH}, shape={embeddings.shape}')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(logits, dim=1)\n",
    "            val_correct += (predicted_labels == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        # Save the trained model\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        min_val_loss = avg_val_loss\n",
    "        \n",
    "#     print(f'Epoch {epoch+1} end!!!!!!!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b348fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
