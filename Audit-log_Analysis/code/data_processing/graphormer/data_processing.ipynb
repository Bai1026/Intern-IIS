{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7UcTh6JEqE7"
      },
      "source": [
        "# This is the file to create the labeled data that can be the input of the **Graphormer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxd3odRvuAZ6"
      },
      "source": [
        "## Merge the **triplet and the label** into a txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsvRq5FZ3lsT"
      },
      "outputs": [],
      "source": [
        "%mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aYw3KN2LNV0z"
      },
      "outputs": [],
      "source": [
        "def process_second_file(file_path):\n",
        "    result_dict = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        next(file) # pass the first row(total num of the triplets)\n",
        "\n",
        "        for line in file:\n",
        "            columns = line.strip().split()\n",
        "\n",
        "            if len(columns) >= 2:\n",
        "                value = columns[1]\n",
        "\n",
        "                # let the label be the string for the new dataset    \n",
        "                if value == 'benign':\n",
        "                    # value = 0\n",
        "                    value = '0'   \n",
        "                # elif value.startswith('T'):\n",
        "\n",
        "                #     # Check if it's a float value (e.g., T1003.001)\n",
        "                #     value = float(value[1:]) if '.' in value else int(value[1:])\n",
        "                elif value.startswith('T'):\n",
        "\n",
        "                    # Check if it's a float value (e.g., T1003.001)\n",
        "                    if '.' in value[1:]:\n",
        "                        value = value[1:]\n",
        "                    else:\n",
        "                        try:\n",
        "                            int_value = int(value[1:])\n",
        "                            value = str(int_value)\n",
        "                        except ValueError:\n",
        "                            # If not an integer or float, keep it as a string\n",
        "                            pass\n",
        "\n",
        "            result_dict.append(value)\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "def merge_files_txt(first_file_path, label_list, output_txt_file):\n",
        "    if len(label_list) == 0:\n",
        "        raise ValueError(\"Label list is empty!\")\n",
        "\n",
        "    with open(output_txt_file, 'w') as txt_file:\n",
        "        txt_file.write(\"src,dest,rel,label\\n\")\n",
        "\n",
        "        with open(first_file_path, 'r') as first_file:\n",
        "            next(first_file)\n",
        "\n",
        "            for idx, line in enumerate(first_file):\n",
        "                columns = line.strip().split()\n",
        "\n",
        "                if len(columns) == 3:\n",
        "                    src, rel, dest = columns\n",
        "                    label = label_list[idx] if idx < len(label_list) else ''\n",
        "                    txt_file.write(f\"{src},{rel},{dest},{label}\\n\")\n",
        "\n",
        "\n",
        "# first_file_path = '/content/train2id.txt'\n",
        "# second_file_path = '/content/train2id_label.txt'\n",
        "first_file_path = './data_euni/train2id.txt'\n",
        "second_file_path = './data_euni/train2id_label.txt'\n",
        "\n",
        "label_list = process_second_file(second_file_path)\n",
        "\n",
        "output_txt_file = 'labeled_data.txt'\n",
        "merge_files_txt(first_file_path, label_list, output_txt_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7vXsEwb5Yua"
      },
      "source": [
        "## Add the **node_num, node_feat and edge_feat** into the txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7_GST3SFP9yG"
      },
      "outputs": [],
      "source": [
        "def add_column_to_txt(file_path, output_file_path):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()  # 讀取所有行到一個列表中\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        output_file.write(lines[0].rstrip() + \",num_nodes,node_feat,edge_attr\\n\")  # 寫入新的標題行，加在最後一個欄位後面\n",
        "        for line in lines[1:]:\n",
        "            output_file.write(line.rstrip() + \",3,0,0,0,0,0\\n\")  # 寫入每一行的內容，加上新的欄位值，加在最後一個欄位後面\n",
        "\n",
        "\n",
        "# input_file_path = '/content/data/labeled_data.txt'\n",
        "# output_file_path = '/content/data/labeled_data_final.txt'\n",
        "input_file_path = 'labeled_data.txt'\n",
        "output_file_path = 'labeled_data_final.txt'\n",
        "\n",
        "add_column_to_txt(input_file_path, output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vH-cUX6-7JY"
      },
      "source": [
        "## Convert to the **jsonl** file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "384ZdEUa0dM1",
        "outputId": "b26e9702-d22a-4c78-e163-cedaa59070c2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def convert_to_jsonl(file_path, output_file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        header = lines[0].rstrip().split(',')  # 讀取標題行，以逗號分隔欄位\n",
        "\n",
        "    jsonl_data = []\n",
        "    for line in lines[1:]:\n",
        "        values = line.rstrip().split(',')  # 以逗號分隔每一行的欄位值\n",
        "        data = {}\n",
        "        for i, field in enumerate(header):\n",
        "            data[field] = values[i]  # 構建 JSON 對象\n",
        "\n",
        "        edge_index = [[data['src'], data['rel']], [data['rel'], data['dest']]]\n",
        "        data.pop('src')\n",
        "        data.pop('rel')\n",
        "        data.pop('dest')\n",
        "        data['edge_index'] = edge_index  # 添加 edge_index 值\n",
        "        data['node_feat'] = [[0], [0], [0]]  # 添加 node_feat 值\n",
        "        data['edge_attr'] = [[0], [0]]  # 添加 edge_feat 值\n",
        "        data['label'] = [data['label']]  # Convert label value to a list\n",
        "\n",
        "\n",
        "        jsonl_data.append(json.dumps(data))  # 將 JSON 對象轉換為 JSON 字串並添加到列表中\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for json_str in jsonl_data:\n",
        "            output_file.write(json_str + '\\n')  # 寫入每個 JSON 字串到新的 JSONL 檔案中\n",
        "\n",
        "# 設定輸入文本檔案的路徑和輸出 JSONL 檔案的路徑\n",
        "# input_file_path = '/content/data/labeled_data_final.txt'\n",
        "# output_file_path = '/content/data/labeled_data_final.jsonl'\n",
        "input_file_path = 'labeled_data_final.txt'\n",
        "output_file_path = 'labeled_data_final.jsonl'\n",
        "\n",
        "# 呼叫函式以轉換為 JSONL 檔案\n",
        "convert_to_jsonl(input_file_path, output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2bBniAkEFBG"
      },
      "source": [
        "# TEST version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrn8iaurEEHm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def process_file(file_path, second_file_path):\n",
        "    result_dict = []\n",
        "\n",
        "    # Process the second file and create the label list\n",
        "    label_list = []\n",
        "    with open(second_file_path, 'r') as second_file:\n",
        "        next(second_file) # pass the first row(total num of the triplets)\n",
        "\n",
        "        for line in second_file:\n",
        "            columns = line.strip().split()\n",
        "\n",
        "            if len(columns) >= 2:\n",
        "                value = columns[1]\n",
        "\n",
        "                if value == 'benign':\n",
        "                    value = 0\n",
        "                elif value.startswith('T'):\n",
        "                    value = float(value[1:]) if '.' in value else int(value[1:])\n",
        "\n",
        "                label_list.append(value)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        header = lines[0].rstrip().split(',')  # 讀取標題行，以逗號分隔欄位\n",
        "\n",
        "    jsonl_data = []\n",
        "    for idx, line in enumerate(lines[1:]):\n",
        "        values = line.rstrip().split(',')  # 以逗號分隔每一行的欄位值\n",
        "        data = {}\n",
        "        for i, field in enumerate(header):\n",
        "            data[field] = values[i]  # 構建 JSON 對象\n",
        "\n",
        "        edge_index = [[data['src'], data['rel']], [data['rel'], data['dest']]]\n",
        "        data.pop('src')\n",
        "        data.pop('rel')\n",
        "        data.pop('dest')\n",
        "        data['edge_index'] = edge_index  # 添加 edge_index 值\n",
        "        data['node_feat'] = [[0], [0], [0]]  # 添加 node_feat 值\n",
        "        data['edge_feat'] = [[0], [0]]  # 添加 edge_feat 值\n",
        "        data['label'] = [label_list[idx]]  # Convert label value to a list\n",
        "\n",
        "        jsonl_data.append(json.dumps(data))  # 將 JSON 對象轉換為 JSON 字串並添加到列表中\n",
        "\n",
        "    return jsonl_data\n",
        "\n",
        "def write_jsonl(data_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for json_str in data_list:\n",
        "            output_file.write(json_str + '\\n')  # 寫入每個 JSON 字串到新的 JSONL 檔案中\n",
        "\n",
        "# 設定輸入文本檔案的路徑和輸出 JSONL 檔案的路徑\n",
        "input_file_path = '/content/train2id.txt'\n",
        "second_file_path = '/content/train2id_label.txt'\n",
        "output_file_path = '/content/data/labeled_data_final.jsonl'\n",
        "\n",
        "jsonl_data = process_file(input_file_path, second_file_path)\n",
        "write_jsonl(jsonl_data, output_file_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
