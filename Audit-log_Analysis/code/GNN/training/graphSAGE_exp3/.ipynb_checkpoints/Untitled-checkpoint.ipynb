{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20a58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个2层的GNN模型\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        # 实例化SAGEConve，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregator_type是聚合函数的类型\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        \n",
    "        # 输入是节点的特征\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c11024f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c75f11ced46c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnode_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "node_features = graph.ndata['feat']\n",
    "node_labels = graph.ndata['label']\n",
    "train_mask = graph.ndata['train_mask']\n",
    "valid_mask = graph.ndata['val_mask']\n",
    "test_mask = graph.ndata['test_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32539c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b80da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    # 使用所有节点(全图)进行前向传播计算\n",
    "    logits = model(graph, node_features)\n",
    "    # 计算损失值\n",
    "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "    # 计算验证集的准确度\n",
    "    acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
    "    # 进行反向传播计算\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())\n",
    "\n",
    "    # 如果需要的话，保存训练好的模型。本例中省略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142dfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de15c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "301aab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch as th\n",
    "\n",
    "# 1~100生成500個nodes\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "\n",
    "\n",
    "# make it symmetric\n",
    "# edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
    "edge_pred_graph = dgl.graph((src, dst))\n",
    "    \n",
    "# synthetic node and edge features, as well as edge labels\n",
    "edge_pred_graph.ndata['feature'] = torch.randn(100, 10).float()\n",
    "\n",
    "edge_pred_graph.edata['feature'] = torch.randn(500, 10).float()\n",
    "# edge_pred_graph.edata['label'] = torch.randn(500)\n",
    "edge_pred_graph.edata['label'] = torch.randint(0, 100, (500,)).float()\n",
    "# edge_pred_graph.edata['label'] = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "\n",
    "# synthetic train-test splits, which is 3:2\n",
    "edge_pred_graph.edata['train_mask'] = torch.zeros(500, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc2ca2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=100, num_edges=500,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool)})\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "699ebf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd593c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606335a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58045a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[75 22 31 90 84 83 21 19  9  5  5 36 42 15 28 68 52 63 80  6 71  6 45 47\n",
      " 17 60 71 30 18 78 76 69 52 28 14 89 87 72  3 74 95 23 86 26 49 92  3 89\n",
      " 27 92 72 40 26 26 19 68 81 60 53 34 39 13 49 54 55 50 83 61 47 39 63 99\n",
      " 32 50 39 77 42 21 94 18 69 17 17 97  2 53 64 21 85 86 14 81 40 28 68 11\n",
      " 31 54 15 80 32 38 38 46 85  2 68 99 88 40 71 52 85 51 35 78 93 33 76 86\n",
      " 85 59 59 80 84  8  7  7 81 31 68 77 58 74  5 21 13 96 53 85 70 55 69 82\n",
      " 77  8 97 93 54 28 94 32 33 25  0  2 76 40 13 48 78  8 88 92 11 99 49 77\n",
      " 11  4 33 69 18 30 59 52 97 43  7 77 90 11 91 23 34 79 73 87 60 71 19  0\n",
      "  5 77 85 70 65 49 34 44 29 54 21 62 33 15 75 14 32 47 57  2 59  0 18 35\n",
      " 49 72 63 34 57 21 67 87  8 73 70 27 97 85 52 49 35 85 29 28 26 32  4  3\n",
      " 43 21 67 94  6 21 67 34 70 10 24 85 13 30 17 26 98  9 84 27  9 71 15 95\n",
      " 33 85 66 85 43 27 57 16 91 11  2 19 61 73  2 20 42 29 67 26 34 96 76 84\n",
      "  3 12 80 22 63 15 11 33  1 56 98 27 95 44 26 61  1 36 52 69 53 14 43  2\n",
      " 51 61 48 86 27 18 80  1 53 15  9 41 86 99 46  9 24 53 52 17 61 80 89 65\n",
      " 16 93 44 41 22 62 96 51 61 67 81 23 18 52 53 88 21 74 96 46 65 72 62  4\n",
      " 50 18  7 77 58 88 81 23 85 22 52 93 18  6 55 59 61 14 33 20 91 89 36 48\n",
      "  2 45 42 35 57 37 77  6 38 81  1 77 87 46 46 66 34 89 38 46 43 95 13  6\n",
      " 95 71 70 27 32 49 52 12 40 28  7  7 75 13 48  8 76 44 61 62 31 23 41 24\n",
      " 86 31 79 48  7 41  5 25 59 44 32  3 38 90 10 60 32 41 18 69 58 82 33 60\n",
      " 89 78 57 31 43 88 30 87 18 45 81 91  7 41 95 59 50 99 13 75 26 45 13 75\n",
      " 36 88 55  6  0 34 64 14 14  2 82 66 86 24 94 92 13 15 77 87]\n"
     ]
    }
   ],
   "source": [
    "print(src.shape)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94952595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([500, 10])\n",
      "tensor([69., 54.,  7., 33., 95., 56., 69.,  0., 56., 52., 67., 87., 93., 54.,\n",
      "        86., 93., 69.,  8., 26., 74., 26., 49., 37., 85., 34., 69.,  4., 31.,\n",
      "        57., 52., 99., 57., 97., 22., 84., 26., 72., 10., 69., 12., 92., 22.,\n",
      "        36., 89., 73., 65., 55., 93., 47., 14., 86., 91., 67., 33., 54., 70.,\n",
      "        35., 22., 11.,  6., 95., 50., 92., 84., 57., 41., 64., 62., 32., 71.,\n",
      "        59.,  9., 17., 86., 35., 91., 98., 12.,  4., 71., 44., 41., 56., 77.,\n",
      "        90.,  6., 98., 55., 94., 36., 23., 76., 20., 31., 27., 49., 49., 43.,\n",
      "        16., 12., 93., 74., 92.,  1., 99., 11., 66., 27., 80., 91.,  8.,  8.,\n",
      "        15., 27., 42., 21., 35., 63., 55., 78., 66., 30., 38., 63., 41., 85.,\n",
      "        56., 73., 87., 87., 40., 73., 32., 68., 68., 86., 62., 84., 91.,  8.,\n",
      "        61., 35., 47., 93., 76., 58., 85.,  5., 74., 34., 69.,  7., 49., 42.,\n",
      "        49.,  8., 59.,  4., 38., 53., 52., 25., 31., 95.,  3., 55., 81., 80.,\n",
      "        65.,  2., 98., 42., 67., 41., 36., 26., 87., 24., 94., 51., 98., 35.,\n",
      "         8.,  4., 76., 81., 77., 80.,  4., 52., 14., 21., 92., 75., 52.,  4.,\n",
      "        14., 34., 42., 73.,  2., 40., 79., 50., 94.,  1., 76., 74., 55., 31.,\n",
      "        67., 50., 22., 96., 24., 83.,  0., 43., 65., 41., 51., 57., 47., 66.,\n",
      "        33., 16., 24., 78., 87., 59.,  4., 78., 95., 79., 21., 19., 20., 99.,\n",
      "        46., 11., 38., 39., 19., 85., 70., 74., 33., 77., 90., 48., 15., 40.,\n",
      "        35., 92., 40., 56., 68., 59., 79., 52., 30., 91.,  4., 82., 81., 34.,\n",
      "        43., 48., 56., 98., 14., 77., 83., 28., 76., 79., 98., 84., 90., 17.,\n",
      "        53., 63., 80., 75.,  3., 52., 12., 30., 17., 56., 41., 40.,  7., 36.,\n",
      "        72., 85., 43.,  5., 50., 44., 19., 47., 96., 70., 85., 97., 35., 93.,\n",
      "         2., 90., 16., 37., 17., 82., 82., 78., 83., 77.,  0., 85., 29., 75.,\n",
      "        10., 90., 87., 20., 14., 83.,  0., 61., 14., 10., 53., 42.,  2., 98.,\n",
      "        22., 47., 95., 28., 46., 34., 84., 54.,  4., 44., 79., 76., 24., 78.,\n",
      "        22.,  5., 26., 27.,  7., 68., 72., 37., 52., 70., 10., 54., 50., 71.,\n",
      "         0., 15., 94., 80., 88., 23., 35., 29., 46., 73., 62., 17., 74., 14.,\n",
      "        88., 75., 32., 96., 85., 91., 45., 67., 66., 79., 75., 33., 95., 35.,\n",
      "        39., 90., 38.,  2., 64., 99., 54.,  1., 60., 70.,  5., 34., 60., 61.,\n",
      "        21., 13., 38., 67., 82., 19.,  6., 56., 54., 63., 56.,  3., 51., 56.,\n",
      "        74., 67., 92., 94., 21., 76., 26., 70., 78.,  4., 73.,  9., 79., 83.,\n",
      "        39., 64., 81., 96., 70., 36., 70., 67., 75., 94., 94., 58., 40., 75.,\n",
      "        91., 10., 41., 75., 61., 66., 88., 86., 16., 28., 31.,  0., 10., 41.,\n",
      "        31., 15., 25., 73., 31., 11., 58.,  7., 74., 87., 23., 82., 78., 42.,\n",
      "        68., 36., 47., 11., 77., 54., 42., 73., 24., 89.,  3., 87.,  0., 91.,\n",
      "        78., 70., 17., 15., 12., 29., 90., 39., 57., 37.])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)\n",
    "print(edge_pred_graph.edata['feature'].shape)\n",
    "# print(edge_pred_graph.ndata['feature'])\n",
    "print(edge_pred_graph.edata['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53b80682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a9e1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        # h contains the node representations computed from the GNN defined\n",
    "        # in the node classification section (Section 5.1).\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12d2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(in_features, 100)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        h = self.sage(g, x)\n",
    "        score = self.pred(g, h)\n",
    "        \n",
    "        output = torch.softmax(score, dim=1)\n",
    "#         print(\"output\", output)\n",
    "#         print(\"output's shape\", output.shape)\n",
    "        \n",
    "        predicted_classes = torch.argmax(output, dim=1)\n",
    "#         print(\"Predicted label:\", predicted_classes)\n",
    "#         print(\"shape\", predicted_classes.shape)\n",
    "        \n",
    "        row_sums = torch.sum(output, dim=1)\n",
    "#         print(\"sum\", row_sums)\n",
    "#         print(\"shape\", row_sums.shape)\n",
    "        \n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "815fdae8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  tensor([69., 54.,  7., 33., 95., 56., 69.,  0., 56., 52., 67., 87., 93., 54.,\n",
      "        86., 93., 69.,  8., 26., 74., 26., 49., 37., 85., 34., 69.,  4., 31.,\n",
      "        57., 52., 99., 57., 97., 22., 84., 26., 72., 10., 69., 12., 92., 22.,\n",
      "        36., 89., 73., 65., 55., 93., 47., 14., 86., 91., 67., 33., 54., 70.,\n",
      "        35., 22., 11.,  6., 95., 50., 92., 84., 57., 41., 64., 62., 32., 71.,\n",
      "        59.,  9., 17., 86., 35., 91., 98., 12.,  4., 71., 44., 41., 56., 77.,\n",
      "        90.,  6., 98., 55., 94., 36., 23., 76., 20., 31., 27., 49., 49., 43.,\n",
      "        16., 12., 93., 74., 92.,  1., 99., 11., 66., 27., 80., 91.,  8.,  8.,\n",
      "        15., 27., 42., 21., 35., 63., 55., 78., 66., 30., 38., 63., 41., 85.,\n",
      "        56., 73., 87., 87., 40., 73., 32., 68., 68., 86., 62., 84., 91.,  8.,\n",
      "        61., 35., 47., 93., 76., 58., 85.,  5., 74., 34., 69.,  7., 49., 42.,\n",
      "        49.,  8., 59.,  4., 38., 53., 52., 25., 31., 95.,  3., 55., 81., 80.,\n",
      "        65.,  2., 98., 42., 67., 41., 36., 26., 87., 24., 94., 51., 98., 35.,\n",
      "         8.,  4., 76., 81., 77., 80.,  4., 52., 14., 21., 92., 75., 52.,  4.,\n",
      "        14., 34., 42., 73.,  2., 40., 79., 50., 94.,  1., 76., 74., 55., 31.,\n",
      "        67., 50., 22., 96., 24., 83.,  0., 43., 65., 41., 51., 57., 47., 66.,\n",
      "        33., 16., 24., 78., 87., 59.,  4., 78., 95., 79., 21., 19., 20., 99.,\n",
      "        46., 11., 38., 39., 19., 85., 70., 74., 33., 77., 90., 48., 15., 40.,\n",
      "        35., 92., 40., 56., 68., 59., 79., 52., 30., 91.,  4., 82., 81., 34.,\n",
      "        43., 48., 56., 98., 14., 77., 83., 28., 76., 79., 98., 84., 90., 17.,\n",
      "        53., 63., 80., 75.,  3., 52., 12., 30., 17., 56., 41., 40.,  7., 36.,\n",
      "        72., 85., 43.,  5., 50., 44., 19., 47., 96., 70., 85., 97., 35., 93.,\n",
      "         2., 90., 16., 37., 17., 82., 82., 78., 83., 77.,  0., 85., 29., 75.,\n",
      "        10., 90., 87., 20., 14., 83.,  0., 61., 14., 10., 53., 42.,  2., 98.,\n",
      "        22., 47., 95., 28., 46., 34., 84., 54.,  4., 44., 79., 76., 24., 78.,\n",
      "        22.,  5., 26., 27.,  7., 68., 72., 37., 52., 70., 10., 54., 50., 71.,\n",
      "         0., 15., 94., 80., 88., 23., 35., 29., 46., 73., 62., 17., 74., 14.,\n",
      "        88., 75., 32., 96., 85., 91., 45., 67., 66., 79., 75., 33., 95., 35.,\n",
      "        39., 90., 38.,  2., 64., 99., 54.,  1., 60., 70.,  5., 34., 60., 61.,\n",
      "        21., 13., 38., 67., 82., 19.,  6., 56., 54., 63., 56.,  3., 51., 56.,\n",
      "        74., 67., 92., 94., 21., 76., 26., 70., 78.,  4., 73.,  9., 79., 83.,\n",
      "        39., 64., 81., 96., 70., 36., 70., 67., 75., 94., 94., 58., 40., 75.,\n",
      "        91., 10., 41., 75., 61., 66., 88., 86., 16., 28., 31.,  0., 10., 41.,\n",
      "        31., 15., 25., 73., 31., 11., 58.,  7., 74., 87., 23., 82., 78., 42.,\n",
      "        68., 36., 47., 11., 77., 54., 42., 73., 24., 89.,  3., 87.,  0., 91.,\n",
      "        78., 70., 17., 15., 12., 29., 90., 39., 57., 37.]) \n",
      "shape torch.Size([500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eb3965a35c4f12bc2faf1905391ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n",
      "torch.Size([300])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-eef5be3257af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_pred_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "\n",
    "# the true label, which should be float()\n",
    "edge_label = edge_pred_graph.edata['label'].float()\n",
    "print(\"label: \", edge_label, \"\\nshape\", edge_label.shape)\n",
    "\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "\n",
    "model = Model(10, 20, 10)\n",
    "# self.sage = SAGE(in_feats=10, hidden_feats=20, out_feats=1)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 10000\n",
    "\n",
    "for epoch in tqdm(range(total_steps), desc=\"Training\", position=0, leave=True):\n",
    "    \n",
    "    pred = model(edge_pred_graph, node_features)    \n",
    "    print(pred[train_mask].shape)\n",
    "    print(edge_label[train_mask].shape)\n",
    "    \n",
    "    loss = criterion(pred[train_mask], edge_label[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50==0:\n",
    "        print(loss.item())\n",
    "#         print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37050204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed406012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
