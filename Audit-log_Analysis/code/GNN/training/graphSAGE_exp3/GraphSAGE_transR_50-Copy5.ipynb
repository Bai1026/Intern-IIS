{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GraphSAGE\n",
    "- the version of the 80 repeat times\n",
    "- use DGL\n",
    "- predict `graphs`\n",
    "- valid, test data are in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "import dgl.nn as dglnn\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm  # 使用 notebook 版本的 tqdm\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv, GATConv, SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the GPU and assign the GPU by the best memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_free_gpu():\n",
    "    try:\n",
    "        # Run nvidia-smi command to get GPU details\n",
    "        _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "        command = \"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\"\n",
    "        memory_free_info = _output_to_list(subprocess.check_output(command.split())) \n",
    "        memory_free_values = [int(x) for i, x in enumerate(memory_free_info)]\n",
    "        \n",
    "        # Get the GPU with the maximum free memory\n",
    "        best_gpu_id = memory_free_values.index(max(memory_free_values))\n",
    "        return best_gpu_id\n",
    "    except:\n",
    "        # If any exception occurs, default to GPU 0 (this handles cases where nvidia-smi isn't installed)\n",
    "        return 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the best GPU ID based on free memory and set it\n",
    "    best_gpu_id = get_free_gpu()\n",
    "    device = torch.device(f\"cuda:{best_gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"there's no available GPU\")\n",
    "\n",
    "# device = torch.device(f\"cuda:{1}\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed = 8787):\n",
    "    torch.manual_seed(seed)\n",
    "    # random.seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        return data\n",
    "\n",
    "def collate(samples):\n",
    "    data_list = samples\n",
    "    batched_graphs = []\n",
    "    for data in data_list:\n",
    "        g = dgl.graph((th.tensor(data[\"edge_index\"][0]), th.tensor(data[\"edge_index\"][1])), num_nodes=data[\"num_nodes\"])\n",
    "\n",
    "        g.ndata['feat'] = th.tensor(data[\"node_feat\"])\n",
    "        g.edata['feat'] = th.tensor(data[\"edge_attr\"])\n",
    "        g.edata['label'] = th.tensor(data[\"labels\"])  # Add edge labels to graph\n",
    "\n",
    "        batched_graphs.append(g)\n",
    "    \n",
    "    return dgl.batch(batched_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c30de63977343168020fe9094e76195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/repeat_train_80.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d216e94e7a44daeb5bf3494db8bdcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/valid.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8227784d544f46f0b6fa1af5c951a958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/test.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89eeb46ba0e415e9de35b18af06f807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "datasets = ['repeat_train_80', 'valid', 'test']\n",
    "# datasets = ['valid']\n",
    "dataset_data = {}\n",
    "\n",
    "for dataset_name in tqdm(datasets):\n",
    "    file_path = f\"../../data_processing/dgl/data_new/exp3/training_data_repeat/transR_50/{dataset_name}.jsonl\"\n",
    "    \n",
    "    print(file_path)\n",
    "    with open(file_path) as f:\n",
    "        data_list = [json.loads(line) for line in tqdm(f, position=0, leave=True)]\n",
    "    \n",
    "    dataset_data[dataset_name] = GraphDataset(data_list, device)\n",
    "\n",
    "print(\"Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(batch_size, shuffle=True):\n",
    "    dataloaders = {}\n",
    "    for dataset_name, dataset in dataset_data.items():\n",
    "        # do not shuffle the testing dataset\n",
    "        if dataset_name == \"test\":\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)    \n",
    "        else:\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate)\n",
    "    return dataloaders\n",
    "\n",
    "dataloaders = create_dataloaders(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turn the print message to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log_message/1010_22:15_GraphSAGE_transR_50.log\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "formatted_time = now.strftime(\"%m%d_%H:%M\")\n",
    "\n",
    "log_file_path = f\"../log_message/{formatted_time}_GraphSAGE_transR_50.log\"\n",
    "\n",
    "def add_log_msg(msg, log_file_path=log_file_path):\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}\\n')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}')\n",
    "\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dglnn.SAGEConv(in_dim, hidden_dim, 'pool')\n",
    "        self.layer2 = dglnn.SAGEConv(hidden_dim, out_dim, 'pool')\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.layer1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.layer2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage = GraphSAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes)\n",
    "      \n",
    "    def forward(self, g, node_feat, return_logits=False):\n",
    "        h = self.sage(g, node_feat)\n",
    "        logits = self.pred(g, h)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Forward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(batched_g, model, criterion, device, count=1, which_type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "#     batched_g, labels = data\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = batched_g.edata['label'].to(device)\n",
    "    \n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float())\n",
    "\n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    output = torch.softmax(logits, dim=1)\n",
    "    preds = output.argmax(1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "    \n",
    "    if which_type == 'validation' and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Validation: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Validation: {preds} {preds.shape}\")\n",
    "        \n",
    "    elif which_type == 'test'  and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Test: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Test: {preds} {preds.shape}\")\n",
    "        \n",
    "    if count % 5000 == 0: \n",
    "        add_log_msg(f\"labels of {count}: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of {count}: {preds} {preds.shape}\")\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the seed and save the model.state_dict that contains the initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "torch.save(model.state_dict(), 'model3_initial(graphsage)/initial_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0682,  0.0153, -0.1769,  ...,  0.0375,  0.2321, -0.2812],\n",
       "        [-0.2271,  0.2290, -0.1997,  ..., -0.0095,  0.1509,  0.2686],\n",
       "        [-0.2743,  0.0406, -0.1222,  ...,  0.1036, -0.1590, -0.2555],\n",
       "        ...,\n",
       "        [-0.0758,  0.0461,  0.1273,  ...,  0.1367,  0.0671, -0.2605],\n",
       "        [-0.2425, -0.1362,  0.2474,  ..., -0.3221, -0.0595,  0.3141],\n",
       "        [ 0.0234, -0.2783,  0.2146,  ..., -0.3020, -0.1751,  0.0528]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layer1.fc_self.weight\n",
    "model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if model really load the model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0682,  0.0153, -0.1769,  ...,  0.0375,  0.2321, -0.2812],\n",
       "        [-0.2271,  0.2290, -0.1997,  ..., -0.0095,  0.1509,  0.2686],\n",
       "        [-0.2743,  0.0406, -0.1222,  ...,  0.1036, -0.1590, -0.2555],\n",
       "        ...,\n",
       "        [-0.0758,  0.0461,  0.1273,  ...,  0.1367,  0.0671, -0.2605],\n",
       "        [-0.2425, -0.1362,  0.2474,  ..., -0.3221, -0.0595,  0.3141],\n",
       "        [ 0.0234, -0.2783,  0.2146,  ..., -0.3020, -0.1751,  0.0528]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))\n",
    "model.sage.layer1.fc_self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926e685e7d1d4d7dbc61348fe3074e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360173c28a8e42c38ef83a829cae3505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 22:19:42# labels of 5000: tensor([ 34,  18,  44, 112,   4, 111, 144,   9,   9,  48,  67,  67,  67,  67,\n",
      "         67,  33,  97, 152,  54,  57,  31, 152,  44,  38,  83,  97,  87, 143,\n",
      "        121,  49,  18,  92, 109, 121, 111,  97], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 22:19:42# predicted of 5000: tensor([121,  57, 121,  36, 121,  36, 121,  36,  36,   9,   9,   3,   3,   3,\n",
      "          3, 121,  36,  57,  57, 121,  57,  36, 121,  36, 121, 121, 121, 121,\n",
      "         57, 121, 121, 121, 121, 121, 121, 121], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 22:21:10# labels of 10000: tensor([158, 111,  97, 124,  54, 163,  48, 164, 164,  14, 150,  24, 104, 143,\n",
      "         53, 151,  55,  18,  34, 162,  74, 122, 122, 122, 122, 122, 122, 122,\n",
      "         36, 119,  74,  11,  54,   9,  74, 109, 119, 116], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:21:10# predicted of 10000: tensor([ 31, 158,  31, 158,  31,  31,  31,  31,  31,   4,  31,  31,  31, 158,\n",
      "         18,  31,  31,  31,  31,  31, 112, 122, 122, 122, 122, 122, 122, 122,\n",
      "         31,  31,  31,  31,  31,  31,  48,  31,  31,  31], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:22:38# labels of 15000: tensor([119,  36, 143,  87, 162, 119,   4,  34,  54,  97, 150, 109,  76,  54,\n",
      "          1, 150,  83,  14, 158, 162,  47,  55,  54,  24,  14, 109,  24, 144,\n",
      "         44,  87,  53, 112], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:22:38# predicted of 15000: tensor([ 44, 104, 104, 104, 142,  14, 104,  14, 104, 104,  44, 104,  44, 104,\n",
      "         44, 144, 104,  81,  81, 104,  31,  44,  49, 158, 104,  81, 104,  44,\n",
      "        144,  44,  44, 163], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:24:03# labels of 20000: tensor([ 30, 104,  24, 163, 104,   2,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 150, 100,\n",
      "        100, 100, 100, 100, 100,  14,  18, 150,  42, 164,  75,  29,  29,  29,\n",
      "         29,  29,  29,  29,  29,  29,  29, 104,  54,  12, 104,  60, 142,  38,\n",
      "         81,   4,  14,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,\n",
      "        152,   2, 158, 150,  53], device='cuda:0') torch.Size([89])\n",
      "10/10/2023, 22:24:03# predicted of 20000: tensor([163,  55,   1, 163, 158, 163,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 163, 100,\n",
      "        100, 100, 100, 100, 100, 163, 163,  30,  44,  57, 164,  29,  29,  29,\n",
      "         29,  29,  29,  29,  29,  29,  17, 163, 158,   9,   2,  54,   4, 158,\n",
      "          1,  49,   1,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,\n",
      "        163,   4, 150, 112, 163], device='cuda:0') torch.Size([89])\n",
      "10/10/2023, 22:25:31# labels of 25000: tensor([ 49, 116, 125, 112,  42, 158,  53,   8,   8, 158, 143,   4,  60,  54,\n",
      "         57,  18,  81,  60,  24,  42,  30, 142,  97,  74, 119,  34, 124,   1,\n",
      "        116,  49,  24,  34,  42], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:25:31# predicted of 25000: tensor([124, 111,  92, 111,  14, 143, 104,  14,  14,  47, 124,  47, 143,  47,\n",
      "         53, 142,  12,  34, 111, 142, 111, 111,  81, 111, 111,  14, 142, 111,\n",
      "          4, 111,  14, 125, 158], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:27:00# labels of 30000: tensor([ 49, 109, 121, 163,   9, 164,  44, 104,  48, 157, 119, 162,  33, 112,\n",
      "        116,  12,  44,   1, 151, 125,  49,  87,  48,  97,  11, 124, 104, 143,\n",
      "         18,  87,  42,  12], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:27:00# predicted of 30000: tensor([ 97,  81, 124, 162,  81,  42,  81, 143,  81,  81,  55,  81,  81,  81,\n",
      "         81,  97,  42,  42, 124,  97,  81, 124, 142,  97,  81,  14,  81,  12,\n",
      "         97,  81,  14,  97], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:28:26# labels of 35000: tensor([ 33, 164, 112,  87,  18,  57,  75, 143, 119,  42,  24,  87,  60,  87,\n",
      "        111, 151, 163,  18,  34,  49, 111,  76,  31, 124, 144, 157,  60,  14,\n",
      "         60,  18, 116, 151], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:28:26# predicted of 35000: tensor([ 74,  14,  81,  14,  44,  92,  24, 142,  44,  60,  55,  42,  60,  81,\n",
      "        163,  81,  55,  92,  60, 142, 163, 104,  14, 109, 142, 144, 142,  81,\n",
      "         60,  44,  81,   1], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:29:52# labels of 40000: tensor([162,  55,  18,  81,  83,  55,   2,  87, 142, 162, 111,  83, 158, 121,\n",
      "         36,   9,  84,  84,  84,  84,  84,  84,  84,  84,  84,  30,  42,  57,\n",
      "         97, 162, 163,  83,   9,   2, 125,   4,  92,  97,  31, 111],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/10/2023, 22:29:52# predicted of 40000: tensor([163,   4,  92, 158, 150, 143,  47,  92, 158,  92,  24, 163, 119,  24,\n",
      "        158, 162,  84,  84,  84,  84,  84,  84,  84,  84,  84, 111, 104, 111,\n",
      "        142, 164, 142,  55, 143,  14, 111,   9,  76, 158, 111, 158],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/10/2023, 22:31:20# labels of 45000: tensor([119, 143,  54,   2, 121, 163, 104, 144, 104, 162, 143,  31,  14,  31,\n",
      "         83,  49,  75,  18,  75, 124,  47,   2,  55,  14,  57,  14, 163,  36,\n",
      "         42,  34, 152,  38], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:31:20# predicted of 45000: tensor([124,  11, 124, 163, 163, 124, 104, 163,  42,  97, 164, 158, 121, 151,\n",
      "        119,  97, 124,   4, 152,  49, 119, 163, 163, 119,  47,  60,  81,  14,\n",
      "         81,  44,   4,  76], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:32:50# labels of 50000: tensor([ 11, 144,  33, 125,  57,   8,   8, 116, 124,  77,  77,  77,  77,  77,\n",
      "         77,  77,  77, 162,  38, 150,  14, 163,  47, 164, 151,  81,  93,  93,\n",
      "        104,  31,   4,  18,  75,  24, 152,  83,   4,  57,  54,  38,   4],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/10/2023, 22:32:50# predicted of 50000: tensor([150, 164,  54,  57,  57, 121, 121,  75,  31,  77,  77,  77,  77,  77,\n",
      "         77,  77,  77,  81, 112,  30, 164,  42, 124,  30, 142, 112,   4,   4,\n",
      "         42, 112,  14, 112,  74, 164, 112,   4,  54,  75, 164,   4, 104],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/10/2023, 22:34:17# labels of 55000: tensor([ 42,  11, 112,  44,  81,  54,  31, 112, 152,  57,  49, 121,  14,  48,\n",
      "        116,  97, 163,   9, 124,   4,  87, 164,  11,  24,  14,   2,  87,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 116,  44,\n",
      "         48,  42], device='cuda:0') torch.Size([520])\n",
      "10/10/2023, 22:34:17# predicted of 55000: tensor([144, 121, 158,  44, 109,  53,  34, 144,  44,  36,  44,  34,  44,  87,\n",
      "         44,  34, 157,  34, 157,  34, 158, 143,  14,  18, 144,  34,  14,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106, 149, 106,\n",
      "        149, 106, 149, 106, 106, 106, 106, 106, 106, 106, 106, 106,  31,  44,\n",
      "         34,  18], device='cuda:0') torch.Size([520])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 22:35:43# labels of 60000: tensor([163,   1, 144,  83, 150,  14, 111, 124, 111,  33,  11,  60,  49, 143,\n",
      "        109, 163,  53, 158,  74,   4,  87, 116, 151,  55,  42,  55,  11, 162,\n",
      "        158, 157,  35,  35,  35,  35,  35,  35,  55], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 22:35:43# predicted of 60000: tensor([ 92,  42,  57,  47,  14,  12, 124, 162,   1, 121,  83,  11, 150,  11,\n",
      "         12, 150,  47, 124, 163,  42,  18,   1,  87,  11, 143,  34, 158, 158,\n",
      "        158,  12,  35,  35,  35,  35,  35,  35,  92], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 22:37:11# labels of 65000: tensor([ 36, 164,  13,  13,  13,  13,  13,  44,  83, 124, 164,  57,  83, 152,\n",
      "        142,  49, 152,  83, 124, 125, 158,  42, 158,  76,  31,  53,  31, 144,\n",
      "         60,  60,   9,  65,  46,  46, 151,   1, 125,  24], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:37:11# predicted of 65000: tensor([158,   2,  13,  13,  13,  13,  13,  14,   2,  92,  53,  92,  83, 104,\n",
      "          2,  49, 157,  53, 109,  74,  18, 157, 109,   2,  92, 158, 157,   2,\n",
      "        121,  92,  18,  65,  46,  46,  92, 162,  47, 164], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:38:37# labels of 70000: tensor([ 81,  74,   4,  49,   1,  36, 121,  31,  75, 143, 112, 112, 119, 144,\n",
      "         33,  92,   2,  83, 143,  30,  18,   9,  31, 158,  44,  30, 163,  18,\n",
      "         47, 143,  92,  83], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:38:37# predicted of 70000: tensor([ 34, 142,  34, 119, 124, 121, 121,  53, 119, 142,  34,  24, 162,  42,\n",
      "         33,  53, 142,  38,  34, 142, 142,  92,  38, 121,  12,  47, 112, 142,\n",
      "        112,   1,  30,  47], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:40:03# labels of 75000: tensor([104,  97,  18, 111, 119, 143, 142, 162,  53,  36,  42,  60,  57,  47,\n",
      "         54,  18,  57,  18, 152, 119,  34,  33,   9,  81, 119, 144, 164, 111,\n",
      "         97,  49,   4,  47], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:40:03# predicted of 75000: tensor([150, 150, 150,  81, 119, 150, 150, 150, 125,  12,   1, 142, 109,  33,\n",
      "        150, 150, 150,  12,  75,  76, 142, 116, 150, 150, 150, 111, 158, 142,\n",
      "         12, 164, 150, 150], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:41:33# labels of 80000: tensor([ 31,   4, 103, 103, 152, 152, 163,   4, 164,  11,  34,  30, 157, 151,\n",
      "         97,  92,  14, 152,  34,  14,  48,  14,  33, 164, 163,  14, 144, 151,\n",
      "         49,  18,  75, 162, 157], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:41:33# predicted of 80000: tensor([ 36,  38, 124, 124, 163, 150, 151,  42, 142,  34,  34, 119,  44, 163,\n",
      "         49,  38, 144, 158,  36, 144,  42,  12,  42,  34, 163, 163,   2, 121,\n",
      "         53,  44, 124, 124, 121], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:43:00# labels of 85000: tensor([163,  47,  76,  54,  57, 121, 164,  12, 157, 109,  49, 111,  38,  44,\n",
      "         44,  76,  11, 109, 121,  57,   3,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3, 111,  83,   4, 151, 144, 124, 143,\n",
      "        158,  76,  81,  47], device='cuda:0') torch.Size([46])\n",
      "10/10/2023, 22:43:00# predicted of 85000: tensor([143,  74,  47, 121,  92, 121, 143,  24, 157, 143,  59,  24,  36,  87,\n",
      "         11, 121, 150,  14, 143,  38,   3,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   4,  36, 142,  74,  74,  12,   4,\n",
      "        163, 143,  18,  36], device='cuda:0') torch.Size([46])\n",
      "10/10/2023, 22:44:27# labels of 90000: tensor([144,  53, 116,  49,  48,  60,  18,  76, 162,  83, 157,   2,  31,  44,\n",
      "        112, 151, 150,  80,  80,  80,  80,  80,  80,  81,  53,  74, 142,  97,\n",
      "         47,  12,  54,   4, 158,  90,  90,  75,  34,  54], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:44:27# predicted of 90000: tensor([ 18,   2,   1, 124,  11, 125,  74,  87,  47, 119,  36,  31, 157,  36,\n",
      "          1, 112,  31,  80,  80,  80,  80,  80,  80,  12,  87,   2, 119, 152,\n",
      "         11, 150, 119,  18,  92,  74,  74,  30,  18, 119], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 22:45:53# labels of 95000: tensor([ 83, 121,  97,  81,  54,  42, 121,  44, 152,  14,  47, 163,  60,  60,\n",
      "        163,  11, 142,  24,  76,  14, 150, 144,  30,  74,  74,   1,  30,  38,\n",
      "          4,  75, 162,  48], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:45:53# predicted of 95000: tensor([ 75, 121, 163, 152,  11,  87,   1,  76,  92, 162,  83,  75,  18,  75,\n",
      "         74, 158,  76,  74, 116,  81,  74, 163,  75, 152, 163, 150, 150, 121,\n",
      "        152,  76,  76, 121], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:47:24# labels of 100000: tensor([162,  34,  34,  47, 151,  31,  74, 121,  76,  60,  87, 152, 109,   4,\n",
      "         34,  44, 144, 124, 163,  93,  93,  44,  97, 162,  18,  11,  76, 152,\n",
      "        144,  92, 144, 157,  44], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:47:24# predicted of 100000: tensor([150,  74,   4,  36,  14, 150, 144,   4, 144,  74,  47, 111, 142, 152,\n",
      "         47,  87, 109, 157,  53,  74,  74,  18, 116,  49,  76,  47, 152,  24,\n",
      "         97,  18,  14,  74,  74], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 22:48:50# labels of 105000: tensor([124,  42,  69,  69,  69,  69,  69,  69,   1, 151,  11,   1,  33,  14,\n",
      "         34, 144,  53,  14, 157,  57,  74,  47,  61,  61,  61, 119,  14,  48,\n",
      "          2, 109,   4, 150,   1, 112, 116,  33, 143, 121,  97],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 22:48:50# predicted of 105000: tensor([142,  49,  69,  69,  69,  69,  69,  69, 131,   9,  49,  47, 150, 142,\n",
      "        163, 142,  47, 104,  55,  75,  38, 142,  61,  61,  61,  38,  81, 125,\n",
      "        125,  75,  47,  34, 124, 125, 125, 116,  38,  76,  55],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 22:49:56# total batches: 108800\n",
      "10/10/2023, 22:49:56# Epoch 0 | Train Loss: 3.3480 | Train Accuracy: 0.1845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10939cf7d8df48c2a8cc78d6879a1a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 22:49:56# labels of Validation: tensor([ 34,   5,   5,   5,  53,  71,  71,  71,  71,  71,  71, 129, 129, 129,\n",
      "        129, 129, 129, 129,  80,  80,  80,  80,  80,  80,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16, 121, 125, 126, 126, 126,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,  31, 103, 103, 164, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,\n",
      "         65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 111,\n",
      "          1,  56,  56,  56,  56,  56,  56,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135, 117, 117, 117, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  65,  65, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156,  67,  67,  67,  67,  67,  65, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  36,  13,  13,  13,  13,  13,\n",
      "        148, 148, 148, 148, 148, 148, 148,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3, 151], device='cuda:0') torch.Size([681])\n",
      "10/10/2023, 22:49:56# predicted of Validation: tensor([152,   5,   5,   5,  42,  71,  71,  71,  71,  71,  71, 129, 129, 129,\n",
      "        129, 129, 129, 129,  80,  80,  80,  80,  80,  80,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16, 125, 142, 126, 126, 126,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 124, 121, 121,  49, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,\n",
      "         65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  49,\n",
      "        152,  56,  56,  56,  56,  56,  56,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135, 117, 117, 117, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  65,  65, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156,  78,  78,  78,  78,  78,  65, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 157,  13,  13,  13,  13,  13,\n",
      "        148, 148, 148, 148, 148, 148, 148,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3, 104], device='cuda:0') torch.Size([681])\n",
      "10/10/2023, 22:49:56# labels of 0: tensor([ 34,   5,   5,   5,  53,  71,  71,  71,  71,  71,  71, 129, 129, 129,\n",
      "        129, 129, 129, 129,  80,  80,  80,  80,  80,  80,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16, 121, 125, 126, 126, 126,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,  31, 103, 103, 164, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,\n",
      "         65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 111,\n",
      "          1,  56,  56,  56,  56,  56,  56,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135, 117, 117, 117, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  65,  65, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156,  67,  67,  67,  67,  67,  65, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  36,  13,  13,  13,  13,  13,\n",
      "        148, 148, 148, 148, 148, 148, 148,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3, 151], device='cuda:0') torch.Size([681])\n",
      "10/10/2023, 22:49:56# predicted of 0: tensor([152,   5,   5,   5,  42,  71,  71,  71,  71,  71,  71, 129, 129, 129,\n",
      "        129, 129, 129, 129,  80,  80,  80,  80,  80,  80,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16, 125, 142, 126, 126, 126,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 124, 121, 121,  49, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,\n",
      "         65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  49,\n",
      "        152,  56,  56,  56,  56,  56,  56,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135, 117, 117, 117, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  65,  65, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156,  78,  78,  78,  78,  78,  65, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 157,  13,  13,  13,  13,  13,\n",
      "        148, 148, 148, 148, 148, 148, 148,   3,   3,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3, 104], device='cuda:0') torch.Size([681])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 22:50:06# Validation Loss: 0.2187 | Validation Accuracy: 0.9509\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6524aa1a957d4c0882d63e4269c7d2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 22:51:35# labels of 5000: tensor([104,  55,  18,  53, 152,   9, 121,  42,  76, 162, 112,  39,  39,  39,\n",
      "         59,  59,  59, 142,   1,  60,  18, 121, 157, 109,  55, 158, 124,  38,\n",
      "         74,  74,  36,  57,   4,  54,  14, 163], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 22:51:35# predicted of 5000: tensor([ 14, 142,  48,  47,  49,  83,  31,  87,  92,  81, 104,  39,  39,  39,\n",
      "         38,  38,  38, 164, 164, 119,   9,  31,  12, 142, 121, 158,  83,  74,\n",
      "         14, 142,  60, 143,   9, 142,  92,  76], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 22:53:03# labels of 10000: tensor([ 34,  83,  57,  87,   4,  87, 112,  14,  48, 144,  53, 150,  18,   1,\n",
      "        152,  87,  76, 142,  18, 144,  48, 108, 108, 108, 108,  74,  54,  12,\n",
      "         74,  18,   2,  83,  48, 116, 121], device='cuda:0') torch.Size([35])\n",
      "10/10/2023, 22:53:03# predicted of 10000: tensor([ 34, 119, 119,  34,  44,   1,  74, 151, 142,  87,  33, 162, 124, 151,\n",
      "         55,   4,  34, 157, 104,  12,  33, 131, 131, 131, 131,  12,  33, 164,\n",
      "         83, 150,  33,  33, 104,  49,  11], device='cuda:0') torch.Size([35])\n",
      "10/10/2023, 22:54:31# labels of 15000: tensor([121,  42, 121,  34, 124,   9,  74, 150, 143,  81,  11, 144,  87,  97,\n",
      "        151,  11,  81, 164,  83, 162,  18,  31, 150, 112, 158,  76,  97,  92,\n",
      "         74,  74,  33,  44], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:54:31# predicted of 15000: tensor([ 42,   9, 162,  31, 164,  12,  31, 109, 104,  12, 143,  76, 112,  31,\n",
      "         31, 152,   1,  92,  49,  12,  42,  49,  14,  24,  11, 143,  53, 119,\n",
      "         49,  53,  76,  92], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:55:58# labels of 20000: tensor([ 11,  53,  60, 162,  54,  36, 144,  76,  53,  34,  74,   4,  60,  18,\n",
      "         42, 158,  15,  15,  15,  36, 111, 116,  81,  33,  33, 162, 151,  11,\n",
      "        150,  14,   4,  75, 152, 142], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 22:55:58# predicted of 20000: tensor([ 30,  92,   1,  24,  24, 157,  18, 109,  75, 142,  18,  81,  60, 121,\n",
      "         74,  60,  15,  15,  15,  54, 121, 163,  81, 125,  34,  60, 116,  53,\n",
      "        144, 151,  81, 158,  74,  48], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 22:57:27# labels of 25000: tensor([ 81,  81, 121, 152,  54, 162, 152,  75,  81,  14,  34,  44, 116, 109,\n",
      "         30, 121, 152,  55, 152, 157, 124,  75, 151, 109, 143,  30,  30, 162,\n",
      "         60,  60,  30,  30], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:57:27# predicted of 25000: tensor([157,  47, 121, 121, 157,  53, 144,  30,  34, 157, 121,  34,  38,  75,\n",
      "        163,  87, 111,  92,  54,  36, 124,  74,  14,   1,  34,   1,   4, 157,\n",
      "        157, 162, 163,  30], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:59:27# labels of 30000: tensor([111,  18,  97,  34, 112, 157,  44,  44, 116, 121,  47,  48, 109,  74,\n",
      "         12, 109, 124,  53,  47,  75,  33,  11,  76,  30, 112, 104, 111,  42,\n",
      "          9,  24, 121,  44], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 22:59:27# predicted of 30000: tensor([157,  54,  34, 109, 111,  49,  60,  24,  60, 121,  11, 164,   1,  49,\n",
      "        157, 163,  24, 164,  34,  75,  14,  60, 104,  30,  49,   9, 157,  30,\n",
      "        124, 157, 121, 104], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:00:58# labels of 35000: tensor([ 10,  10,  53, 125,  48,  81,  81,  92,   9, 164, 112,  30,  12,  33,\n",
      "        112, 109, 164,  42, 164, 109, 104,  14,  49,  18,   2,  12,   9,  30,\n",
      "        144,  44,  81, 104,   4], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:00:58# predicted of 35000: tensor([ 10,  10,  42, 125,  14,  60,  75,  14, 164,  83, 144, 163,  38, 104,\n",
      "          9,  12,  60,  12,  87, 163,  31,  53,  11,  81,  44, 121,  14,  92,\n",
      "         47, 162, 142, 104,  14], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:02:27# labels of 40000: tensor([ 31, 164,  47,  54,  24, 158,  57,  34,  57,  53,  92,  49, 116,  47,\n",
      "         48, 162, 158, 109, 164,  18, 143, 163,   9,  93,  93, 164,  74, 124,\n",
      "         31,  92,  55, 125, 163], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:02:27# predicted of 40000: tensor([ 18, 152,  83,  47, 119, 162,  38,  81,  42,  42,  92, 109, 116, 111,\n",
      "         54,  48, 124, 162,   4, 124, 119,  57, 164,   9,   9,  49,  47,  76,\n",
      "         47, 163,  47, 150, 162], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:03:56# labels of 45000: tensor([152,  38,  75,  57,  42, 109,  87, 152, 157, 125, 112,  31,  49,  55,\n",
      "         30,   2, 119,  75,  24,  92,  49,  57,  54,  87,  18,  74,   2, 111,\n",
      "         87,  76, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101,  97], device='cuda:0') torch.Size([47])\n",
      "10/10/2023, 23:03:56# predicted of 45000: tensor([ 60,  87, 121,  87, 163, 116,  34, 152,  75, 112,  12, 121, 112,  49,\n",
      "        112,   2, 109, 164, 109,  14, 151, 121,   2,   1,  38, 116,  14,   2,\n",
      "        162, 144, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101,  55], device='cuda:0') torch.Size([47])\n",
      "10/10/2023, 23:05:24# labels of 50000: tensor([ 11, 158,  34, 151, 124,  49, 116,  54,  14,  44,  48,  12, 163, 151,\n",
      "         69,  69,  69,  69,  69,  69,  42,  50,  50,  50, 109, 158,  53,  76,\n",
      "        150,  30, 143,  31, 112, 142, 119,  42,  75, 163,  55],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 23:05:24# predicted of 50000: tensor([ 18, 162,  33,  53, 111, 104, 116, 164,  34,  47, 152, 164,  34,  81,\n",
      "         69,  69,  69,  69,  69,  69,  60,  50,  50,  50,  53, 152, 152,  74,\n",
      "         47, 158, 119, 111, 163, 152,  24,  11,  92, 158,   1],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 23:06:51# labels of 55000: tensor([ 30,  53,  83,  47, 121, 158, 158,  38, 121,  34,  83,  31,  44,   9,\n",
      "        104,  76, 150,  87,  11,  14, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,  60, 124, 150,  54, 119,  55,\n",
      "          2,   4,  33,   4, 151], device='cuda:0') torch.Size([103])\n",
      "10/10/2023, 23:06:51# predicted of 55000: tensor([119, 150, 121, 150,  55, 119, 150, 157,  87, 150, 119, 116, 150,   1,\n",
      "        157,   1, 150,  75,  34,  38, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156,   1, 162,  34,  74,  97, 112,\n",
      "        150, 157, 112, 109,   9], device='cuda:0') torch.Size([103])\n",
      "10/10/2023, 23:08:17# labels of 60000: tensor([ 24,  12,  97,  83,  83, 104, 124,  81,  74,  74, 109, 112,  44,  54,\n",
      "          2,  97,  54, 144,  57,  60, 121, 125,  24, 152,  49,  36,  18,  34,\n",
      "         44,  30, 124,  55], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:08:17# predicted of 60000: tensor([163,  75,  75,  83, 142,  53,  81,   1,   1,  97,  60,   9, 152,  92,\n",
      "         47, 163,  14, 158,  75, 131,   4, 116,   4,   1, 152,  92,  92,  53,\n",
      "        162,  92,  74,  55], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:09:46# labels of 65000: tensor([ 36, 158,  53, 121, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,\n",
      "        158,  83, 119,  42, 112,  18,  57,  53,  47, 144,  44, 143, 104,  24,\n",
      "         49, 109, 158,  24,  53,  60,  44,  55,  34, 151, 151,  57,  97],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/10/2023, 23:09:46# predicted of 65000: tensor([ 92, 142, 142,  30, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,\n",
      "         18,  34, 119,  38,  18, 104, 158, 143,  42,  12,  12, 121,  11, 109,\n",
      "         38, 121,  49,  12,  55, 121,  31,   1,  75,  18,  74,  81,  47],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/10/2023, 23:11:19# labels of 70000: tensor([ 14,   4,  47,  87,  18,  49,  47, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 121,\n",
      "         42,  11,  24,  76, 144,  36,  66,  66,  66,  66,  66,  66,  66,  66,\n",
      "         66,  66, 143,  30,  33,  76,  75,  48,  24,  54,   2,   9, 112,  57,\n",
      "         44,   2,  11, 104], device='cuda:0') torch.Size([60])\n",
      "10/10/2023, 23:11:19# predicted of 70000: tensor([112, 164,  76,  53,  60,  53,  18, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,  14,\n",
      "         24,  75, 164,  97, 119,  44,  66,  66,  66,  66,  66,  66,  66,  66,\n",
      "         66,  66,  49,  55,  38,  87,  24, 150, 162,  81, 119,   2, 152, 157,\n",
      "         31, 116,  42,  12], device='cuda:0') torch.Size([60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:12:49# labels of 75000: tensor([ 60,  36, 150,  33,  30,  47,  49,  87,  54, 150,  60,  31,  53, 162,\n",
      "         31,  11, 143,  81, 125,  36,  83,  55, 144, 104,  87,  42,   1,  11,\n",
      "        111,  74, 119,  24], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:12:49# predicted of 75000: tensor([ 60,  38, 112,  55,  97, 124,  38, 116, 116,  48,  34, 150,  53, 152,\n",
      "        150, 163, 112,  34,  74,   9,  30,  53,  11,   4, 124,  53, 164,  11,\n",
      "         12,   4,  81,  11], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:14:17# labels of 80000: tensor([ 47, 125, 116,  97,  92,  24, 116,  11,  14,  14,  10,  10, 152, 164,\n",
      "         47, 157,  33,  42, 163,  60, 143,  42,  34,  87,  76,  48, 112, 142,\n",
      "          2, 112,  80,  80,  80,  80,  80,  80, 157, 109], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:14:17# predicted of 80000: tensor([ 92,  92,  87,  53,  76, 112,  49, 104,  97,  53,  10,  10,  31, 163,\n",
      "         92,  14,  81,  87,  92,  33,  53,  60, 163,  30,  76, 162,  30,  92,\n",
      "         31,  75,  80,  80,  80,  80,  80,  80, 157,  92], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:15:48# labels of 85000: tensor([109,  44,  38, 144,   1,  33, 125,  81,  87,   9,  38,  53,   2,  47,\n",
      "        142,  34, 152,  60, 111,  11,  18,  57, 119,  14,  30,  55,  92,  48,\n",
      "        104,  55,  97,  75], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:15:48# predicted of 85000: tensor([ 12,  33,   2,  44, 163,  87,  47,  97, 116,   1, 162, 121,  33, 116,\n",
      "         30, 164, 121,  76,   9,  92, 119,  42,  60,  74,  60,  38, 116, 121,\n",
      "         42, 124,  47,  75], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:17:17# labels of 90000: tensor([ 81,  47,  60,  14,  31,  57, 151,  36,  44, 112,  74,  47,  34,  48,\n",
      "        158, 163,  11,  36, 163,  60, 129, 129, 129, 129, 129, 129, 129,  11,\n",
      "         53,  87,  97,  60,  31,  75, 157, 104,  11,  42], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:17:17# predicted of 90000: tensor([150,  87,  34,  33,  60,  48, 150,  33,  53,  76, 150, 150, 121, 158,\n",
      "        158, 163, 142,   1, 121,   4, 129, 129, 129, 129, 129, 129, 129,  34,\n",
      "        142, 125,  92, 124,  11, 158, 150, 116, 104, 144], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:18:49# labels of 95000: tensor([ 83,  31,  30, 111, 142, 121, 109,   4, 143, 121,  33, 111, 109,   2,\n",
      "         53, 125,  42, 116,   2,  24,  31,   1,  24,   9, 144,  14,  11,  92,\n",
      "         75, 157,  74,  81], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:18:49# predicted of 95000: tensor([150,  12, 152, 150, 125,  38,  92, 109,  75, 164,  12, 112, 125,  34,\n",
      "         87, 109,  18, 116,  81,  24,  97,  33, 164,  55,  87,  34, 125,  14,\n",
      "         87,  36,  92, 151], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:20:18# labels of 100000: tensor([162,  47,  34,  14, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  57,  57,   1,  44,\n",
      "        119,  76,  57, 109,  36,  83, 150, 157,  76, 119, 142,  49,   9,  83,\n",
      "         83, 109,  31,  76,  44,  42,  53,  18, 119], device='cuda:0') torch.Size([93])\n",
      "10/10/2023, 23:20:18# predicted of 100000: tensor([ 75,  49, 112,  14, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  47,  18,  12, 162,\n",
      "         92,  57,  38,  12,  34,  53,  47, 121,  76,  18, 121, 111, 109,  18,\n",
      "        112,  92,  75, 124,  42, 157, 121,  33, 151], device='cuda:0') torch.Size([93])\n",
      "10/10/2023, 23:21:47# labels of 105000: tensor([123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123,  92,  18,  11, 162,  85,  85,  85,  85,  85,  85,  85,  85,  85,\n",
      "         85,  85,  81, 144,  14, 121, 119,  12,  50,  50,  50,  42,  55,  11,\n",
      "         42,  60, 124,  76, 119,  74,  33,  34, 116,  92,  81, 142,  14,  30,\n",
      "        112, 152], device='cuda:0') torch.Size([58])\n",
      "10/10/2023, 23:21:47# predicted of 105000: tensor([123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123,  92,  18, 116, 144,  85,  85,  85,  85,  85,  85,  85,  85,  85,\n",
      "         85,  85,  47, 119, 144,  18, 112,  97,  50,  50,  50, 143,   9,  48,\n",
      "        121,  42,  92, 119,  53,  53, 116, 163, 124, 144, 116,  57, 116,  55,\n",
      "         18, 109], device='cuda:0') torch.Size([58])\n",
      "10/10/2023, 23:22:54# total batches: 108800\n",
      "10/10/2023, 23:22:54# Epoch 1 | Train Loss: 3.2078 | Train Accuracy: 0.2123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c68cd94e11497595f3b9404bd4db4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:22:55# labels of Validation: tensor([ 21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  18,  75,  67,\n",
      "         67,  67,  67,  67, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127,  97,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17, 142,  73,  73,  73,\n",
      "         71,  71,  71,  71,  71,  71,  10,  10,   5,   5,   5, 144,  18, 116,\n",
      "         44, 107, 107, 107, 107, 107, 107, 107, 107,  44,  71,  71,  71,  71,\n",
      "         71,  71,  53,  34, 125,  98, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 140,  69,  69,  69,  69,  69,  69,  60, 145, 145,\n",
      "        145, 145, 145, 145,  75,  34, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,  97],\n",
      "       device='cuda:0') torch.Size([447])\n",
      "10/10/2023, 23:22:55# predicted of Validation: tensor([ 21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  11, 152,  78,\n",
      "         78,  78,  78,  78, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127,  76,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  34,  73,  73,  73,\n",
      "         71,  71,  71,  71,  71,  71,  10,  10,   5,   5,   5, 121,  74, 144,\n",
      "         60, 107, 107, 107, 107, 107, 107, 107, 107, 163,  71,  71,  71,  71,\n",
      "         71,  71,  75,  14, 109,  98, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 140,  69,  69,  69,  69,  69,  69,   9, 145, 145,\n",
      "        145, 145, 145, 145,  60,  81, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 121],\n",
      "       device='cuda:0') torch.Size([447])\n",
      "10/10/2023, 23:22:55# labels of 0: tensor([ 21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  18,  75,  67,\n",
      "         67,  67,  67,  67, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127,  97,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17, 142,  73,  73,  73,\n",
      "         71,  71,  71,  71,  71,  71,  10,  10,   5,   5,   5, 144,  18, 116,\n",
      "         44, 107, 107, 107, 107, 107, 107, 107, 107,  44,  71,  71,  71,  71,\n",
      "         71,  71,  53,  34, 125,  98, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 140,  69,  69,  69,  69,  69,  69,  60, 145, 145,\n",
      "        145, 145, 145, 145,  75,  34, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,  97],\n",
      "       device='cuda:0') torch.Size([447])\n",
      "10/10/2023, 23:22:55# predicted of 0: tensor([ 21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  11, 152,  78,\n",
      "         78,  78,  78,  78, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 127, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127,  76,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  34,  73,  73,  73,\n",
      "         71,  71,  71,  71,  71,  71,  10,  10,   5,   5,   5, 121,  74, 144,\n",
      "         60, 107, 107, 107, 107, 107, 107, 107, 107, 163,  71,  71,  71,  71,\n",
      "         71,  71,  75,  14, 109,  98, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 140,  69,  69,  69,  69,  69,  69,   9, 145, 145,\n",
      "        145, 145, 145, 145,  60,  81, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 121],\n",
      "       device='cuda:0') torch.Size([447])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:23:05# Validation Loss: 0.2221 | Validation Accuracy: 0.9511\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f341a8758d4289aad30e79f496e598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:24:35# labels of 5000: tensor([ 12,  36, 162, 143, 139, 139, 139, 139, 139, 157, 125,  49,  81,  33,\n",
      "         11, 163,  92,  34,  92,  76, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 112,  36, 130, 130, 130, 130, 130,\n",
      "        112, 150, 124, 124,   1,  54,  42,  92, 109,  55, 151, 112],\n",
      "       device='cuda:0') torch.Size([54])\n",
      "10/10/2023, 23:24:35# predicted of 5000: tensor([ 24,  92,   1, 143, 139, 139, 139, 139, 139,  48,  81,  76, 151,  87,\n",
      "        152,  30,  92, 119,  24, 116, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 143,  55, 130, 130, 130, 130, 130,\n",
      "          2,  81,  87,  36,  75, 162,  53,  11,  34,  38,  53, 112],\n",
      "       device='cuda:0') torch.Size([54])\n",
      "10/10/2023, 23:26:04# labels of 10000: tensor([119, 125,  54,  83, 150, 157,  11, 116, 158,  11, 112, 125,   2,  97,\n",
      "        104,  83, 152,   9, 150,  42,  18, 119,  57,  97,  14, 111, 150,  57,\n",
      "        143, 142,  60,  76], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:26:04# predicted of 10000: tensor([119, 121,  31,  18,  97, 125,  33, 116, 142,  57,  92,  14, 109,  92,\n",
      "         47,   4,  14,   9, 143, 152,  48,  36, 157,  34,  83, 121, 158,  47,\n",
      "         49, 164, 143,  42], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:27:30# labels of 15000: tensor([162, 143, 150,  44,  87, 119, 121,  81,  97, 164,  75,  24, 104,  14,\n",
      "         33, 142, 158,  18, 125,  92,  54,  48, 144, 142,  74, 109,  48,  53,\n",
      "         44, 119,   4, 144], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:27:30# predicted of 15000: tensor([163,  48, 158, 142, 109, 119, 104, 163,  12,  36,  83, 164, 152, 121,\n",
      "         76,  12, 121, 142, 125,  34, 116, 158, 119,  36, 112,  33,  47,  53,\n",
      "        142,  97, 150,  48], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:28:57# labels of 20000: tensor([ 57, 109, 143,  44, 116,  36,  55,  83, 163,  75, 104, 151, 164, 121,\n",
      "         36, 104,  30,  42, 151,  76,  60,   4, 158,  24,  31,  81, 143,  48,\n",
      "        144,  42,  74, 125], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:28:57# predicted of 20000: tensor([ 34,  24,   2, 112, 163, 152, 162, 152, 150, 124, 142,  14, 124,  14,\n",
      "         57, 116, 109, 119, 142, 112,  33, 111, 121,  36,  31, 157,  14,  55,\n",
      "         14,  76,  14,  24], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:30:26# labels of 25000: tensor([ 83, 104,  14,  36,  92, 152,  60,  38, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 119, 157,  18,  83,  75,  12,  34,  89,  89,  60,  14, 125,\n",
      "         74, 111, 142, 153, 153, 153, 150,  30, 116,  24,  87,  30, 151,  92],\n",
      "       device='cuda:0') torch.Size([42])\n",
      "10/10/2023, 23:30:26# predicted of 25000: tensor([116,  76, 151,  57,  11,  76,   9,  76, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160,  12, 150, 142, 116,  12,  11,   4,  89,  89,  36,  12, 111,\n",
      "        151, 124, 142, 153, 153, 153, 150,  60, 124,  76,  75,   4,  47, 119],\n",
      "       device='cuda:0') torch.Size([42])\n",
      "10/10/2023, 23:31:52# labels of 30000: tensor([ 18, 104, 116, 164,  44, 151,  33,  14,  92,   1,  97, 121,  60, 124,\n",
      "        124, 112,  34,  14, 104, 162,   2, 111,  53,  47,   1,  47, 157,  49,\n",
      "         42, 116,  44, 121], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:31:52# predicted of 30000: tensor([112,  97,   1, 112,   1, 116, 150, 121,  47,  44,  47,   9,  76,  36,\n",
      "         34, 112,  12, 163, 152,  42,  42, 164, 116,  12, 142,  44,  33, 124,\n",
      "        163, 158,  44, 151], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:33:21# labels of 35000: tensor([ 33,   2,  11,  48,  74,  48,  36,  62,  62,  62,  62,  62,  62,  31,\n",
      "         92,  57,  44, 163,  11, 104,  30,  24,  30,  54,  75,  48, 143, 116,\n",
      "          9,  30, 158, 143, 125,  57,   2, 158, 163], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 23:33:21# predicted of 35000: tensor([152, 121,  55,  74, 124, 104, 144,  62,  62,  62,  62,  62,  62,  18,\n",
      "        150,  24,  14, 163,  47,  42,  31,  74,  47, 116,  49,  87,  36,  74,\n",
      "        124, 119, 116,  55, 152,  14,  87,  53, 158], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 23:34:49# labels of 40000: tensor([ 54,  54,  49, 143,  53, 164,   1,  49,  87, 139, 139, 139, 139, 139,\n",
      "         24,  38,  18, 109,  18,  14,  34, 119,  87,  57,  11,  47,  34,  24,\n",
      "         33,   9, 125,  47,  55, 164,  44, 116], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 23:34:49# predicted of 40000: tensor([ 30,  53,  38, 164,  87, 164,  31,  87,  38, 139, 139, 139, 139, 139,\n",
      "         47,  14,  97,  83,  49,   2,  75,   2,  38,  18, 164,  47,  97,  31,\n",
      "        109, 150,  97,  75, 164, 121,  47, 150], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 23:36:16# labels of 45000: tensor([162,  57,  75, 124, 143,  47,  12,  36,  38,   9,  36, 158,  44, 104,\n",
      "         92,  44,  49,  92,   1, 119, 158, 109,  18,  44,  75,  33, 163,  31,\n",
      "          9,  24,  31,   2], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:36:16# predicted of 45000: tensor([ 81,  57,  75, 163,  12,  92, 104,  47,  49,  38,  92, 162,  31,  31,\n",
      "         47,  97,  49,  34,  11,  92,  92,  11,  87, 104, 116, 104,  47,  47,\n",
      "         11, 157, 152,  44], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:37:45# labels of 50000: tensor([ 92, 144, 109, 164,  55, 119,  18, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "          1, 162,  55,  48,  57,  36,  36,  33,  33,  57, 116,  18,  74,  11,\n",
      "         54,  42, 151, 143,  38, 119,  47,  14,  92,  49], device='cuda:0') torch.Size([52])\n",
      "10/10/2023, 23:37:45# predicted of 50000: tensor([124, 144,  34, 116, 143, 162,  49, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "         24, 162,  42,  48, 164,  57,  54,  33,   2,  36, 124,  18,  33,   4,\n",
      "          4, 124, 158, 143, 124, 151,   2,  74,  76,  97], device='cuda:0') torch.Size([52])\n",
      "10/10/2023, 23:39:16# labels of 55000: tensor([ 74, 152, 157, 112,  11, 121, 150,  36,  34, 164,  75, 144,  12,  76,\n",
      "         33, 152, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  92,   4,\n",
      "          2,  42, 143,  83,   4, 104,  36,  92,  74,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  87, 162, 119],\n",
      "       device='cuda:0') torch.Size([195])\n",
      "10/10/2023, 23:39:16# predicted of 55000: tensor([150, 142,  48,  11,  87, 119,  18,  12, 124,  60,   1, 163,  12,  53,\n",
      "        157, 142, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  87,   4,\n",
      "         47, 162,  92, 150, 119, 150,  30,  57,   1,   3,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  47, 144,  74],\n",
      "       device='cuda:0') torch.Size([195])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:40:44# labels of 60000: tensor([  4,   2,   4,  36,  24,  36, 112, 144, 157,  75,  48, 109, 116, 157,\n",
      "         97,  30,  87,  55,  30, 163, 125,  44,  18,  36,  31,  97,  81,  11,\n",
      "         53,  36,  35,  35,  35,  35,  35,  35,  97], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 23:40:44# predicted of 60000: tensor([121, 151,  30,   4,  14,  53,  53, 124,  34,  24,  92,  97,  76,  81,\n",
      "         53, 157, 143,  55,  18,  36,  47,  54,  74,  81,  97,  87, 158,  53,\n",
      "        119,   9,  35,  35,  35,  35,  35,  35,   4], device='cuda:0') torch.Size([37])\n",
      "10/10/2023, 23:42:10# labels of 65000: tensor([ 36,  81,  24,  75,  74, 157,  34, 119,  87,   2,  83,  36,   1,   9,\n",
      "        111,   4, 112, 125,  30,  47, 109, 142, 152, 164,  59,  59,  59,  54,\n",
      "        125,  14, 163,  74,  54, 125], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 23:42:10# predicted of 65000: tensor([ 53, 163,  60, 119,   9,  33, 124, 119, 150,  81,  83, 150,  92,   9,\n",
      "         38,  47,  34,  12,  76, 158, 150,  92, 162, 112,  24,  18,  18, 143,\n",
      "        158,  53, 125,  74,  53, 119], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 23:44:13# labels of 70000: tensor([ 34,  34,  36,  87, 164,  12,  64,  64,   9, 121,  36,  81, 124,  24,\n",
      "         31,  54, 124,   1, 121,  81, 125, 125,   1,  36,  47,  47,  57, 164,\n",
      "          4,  12, 142,  18,  34], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:44:13# predicted of 70000: tensor([164,  75, 143, 164, 142, 158,  60,  60, 150,  83,  48, 152,  81,  55,\n",
      "        109, 112, 164,  47,  83,  97, 163, 109,  53, 142, 121, 164,  57, 116,\n",
      "        116, 163,  30, 121,  30], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:45:39# labels of 75000: tensor([150, 162, 158, 125, 157,  49,  49,  47, 111,  36,  97,  54, 116, 142,\n",
      "        109,  34,  92, 125,  97, 142, 121, 116, 111,  58,  58,  58,  58,  58,\n",
      "         58,  58,  54,  42, 157,  30,  54,  57,   9,   1], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:45:39# predicted of 75000: tensor([ 92,  31,  92,  33,  49,  87,  24,  81,  83, 119,   2,  14,  18, 144,\n",
      "         81,  42, 144,  12, 144,  47,  18, 116, 158,  58,  58,  58,  58,  58,\n",
      "         58,  58,   1,  30, 163,  30,   1,  57,   1,  53], device='cuda:0') torch.Size([38])\n",
      "10/10/2023, 23:47:06# labels of 80000: tensor([ 14, 119, 157, 158, 112, 111,  76,  49,  14, 158,  83,  60,  57,   9,\n",
      "        144, 142,   2,  30,   1,  81, 163,  48,  81, 163,   2,  74, 119,  47,\n",
      "         83, 116,  55,  74], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:47:06# predicted of 80000: tensor([116, 119,  76, 109,  14, 150,  87, 109, 163,  81,  83,  92, 143,  38,\n",
      "        144, 116,  92,  47,  33,  74,   2, 124,  33, 163, 109, 121,  12,  34,\n",
      "         44, 163,  54,  36], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:48:34# labels of 85000: tensor([ 49,  83,  14,  76, 157,  30,  12,  83, 144,   9,  92,  42,  24, 112,\n",
      "        121,   2,  18,  42, 143,   1, 164,  44, 143, 109,  38,  33,   2,  81,\n",
      "         31,  76, 116,  38], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:48:34# predicted of 85000: tensor([ 75,  53, 158, 163,  34, 150,  30,  30,  44,  38,  76,  30,  31, 116,\n",
      "        112, 112,  36,  30,  24, 151,  53,  83, 112, 143,   2, 142, 124, 164,\n",
      "        121,  55,  76,  34], device='cuda:0') torch.Size([32])\n",
      "10/10/2023, 23:50:04# labels of 90000: tensor([158, 143,  36, 143, 150,  54, 162,  87, 151,  34,   9,  33,  92,  49,\n",
      "         48, 158, 125,  14, 162,  11,   4,  60,   1,  64,  64,  44, 143,  76,\n",
      "         11,  54,  48,  75,  36], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:50:04# predicted of 90000: tensor([ 38,  42,  48,  47, 109, 163, 162,  36, 104,  54,  76, 124, 111,  87,\n",
      "         42,  75,  92, 104,  76,  76,  48,  57,  75,  34,  34,  49,  12,  53,\n",
      "          9,  54,  47,  57,  12], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:51:31# labels of 95000: tensor([104,  14,  54,  83, 144,  44,  44,  55,  48,  47, 116,  36, 157,  18,\n",
      "         47,   9, 158,   2,  74, 157,  76,  34, 124,   4,   2, 150,  34,  30,\n",
      "         44, 131, 131, 131, 131, 131,   4,  31], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 23:51:31# predicted of 95000: tensor([ 34,  74, 152,  31,  12,  83, 163,  55,   2,  34, 158,  42,  74,  33,\n",
      "        163, 121,  47,  87,  34, 157,  48,  14,  47, 164,  18,  83, 152,  33,\n",
      "         74,  14, 157,  14, 131,  14,  83,  49], device='cuda:0') torch.Size([36])\n",
      "10/10/2023, 23:52:59# labels of 100000: tensor([ 87, 109, 119,   4,  24, 121, 104, 143,  73,  73,  73, 158, 151,  14,\n",
      "         49, 158, 162,  92,  42,  75,  38, 150, 162,  38,  48,  92,  87,  87,\n",
      "         42,  48,  42,  18,  53,  57], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 23:52:59# predicted of 100000: tensor([104,  76,  92, 158, 121,  55, 119, 163,  73,  73,  73,  11, 124, 121,\n",
      "         12,  14, 152,  48,  92, 163, 116,  97, 151, 158,  97,  31,  48, 163,\n",
      "        142,  83, 142, 116, 121,  76], device='cuda:0') torch.Size([34])\n",
      "10/10/2023, 23:54:26# labels of 105000: tensor([ 54,  81, 151,  74, 111, 142,   2,   1, 151,  44,  95,  95,  95,  76,\n",
      "         47,  12, 121,   9,  83, 124, 124,  44, 142, 152,  85,  85,  85,  85,\n",
      "         85,  85,  85,  85,  85,  85,  85, 104, 109,   4, 151, 164, 151, 144,\n",
      "        164, 152], device='cuda:0') torch.Size([44])\n",
      "10/10/2023, 23:54:26# predicted of 105000: tensor([ 38,  81, 116,  74,   4,  49,  24, 143,  74, 116,  95,  95,  95,  47,\n",
      "         48,  97, 121, 121,  48,  44, 111,  75,   1,  53,  85,  85,  85,  85,\n",
      "         85,  85,  85,  85,  85,  85,  85,  92, 121,  74,  92,   1,  47, 144,\n",
      "         92,  53], device='cuda:0') torch.Size([44])\n",
      "10/10/2023, 23:55:33# total batches: 108800\n",
      "10/10/2023, 23:55:33# Epoch 2 | Train Loss: 3.1245 | Train Accuracy: 0.2283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c00ae6ea7a4aeea98052eb53470bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:55:33# labels of Validation: tensor([146, 146, 146,  ...,  80,  14,   4], device='cuda:0') torch.Size([2096])\n",
      "10/10/2023, 23:55:33# predicted of Validation: tensor([146, 146, 146,  ...,  80,  75,  76], device='cuda:0') torch.Size([2096])\n",
      "10/10/2023, 23:55:33# labels of 0: tensor([146, 146, 146,  ...,  80,  14,   4], device='cuda:0') torch.Size([2096])\n",
      "10/10/2023, 23:55:33# predicted of 0: tensor([146, 146, 146,  ...,  80,  75,  76], device='cuda:0') torch.Size([2096])\n",
      "10/10/2023, 23:55:44# Validation Loss: 0.2390 | Validation Accuracy: 0.9497\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36039984d3743cd8afa80c206e469ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10/2023, 23:57:13# labels of 5000: tensor([ 49,  74, 163, 151,  87,  14, 163, 158, 116, 109,  60,  81, 111,  75,\n",
      "         47,  74,  76, 107, 107, 107, 107, 107, 107, 107, 107, 163, 142,  11,\n",
      "        121, 104, 162, 125,   4, 125,  81,  87, 125,  55,   2],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 23:57:13# predicted of 5000: tensor([131,  49,  92, 119,  48, 119,  87,  92, 104, 112,  49, 109,  81, 163,\n",
      "         53,  97,  81, 107, 107, 107, 107, 107, 107, 107, 107, 163, 162, 163,\n",
      "         83,  12,  87, 125, 142, 152,  12, 104,  12,  49,  38],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/10/2023, 23:58:43# labels of 10000: tensor([112, 158,  97, 104,  92,  60,  11, 121,   2, 143,   1,  83,  57, 144,\n",
      "         87,  49,  33,  47, 157, 143, 104,  30,  44,  33, 151, 114, 114, 157,\n",
      "        152,  12, 152, 150, 143], device='cuda:0') torch.Size([33])\n",
      "10/10/2023, 23:58:43# predicted of 10000: tensor([119,  55,  57,  30,  92,  18,  11,  81,  42, 164,  48, 109,  34, 111,\n",
      "         97,  36,  34,  48, 150, 143, 163,  18,  76,  60,  76,  60,  60, 150,\n",
      "         33,  48,  49,  34,  34], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:00:19# labels of 15000: tensor([ 75,  24,  47, 125,  76,   2, 112,  18,  14, 124,  30,  55, 157,  14,\n",
      "         47,   1,  75, 142,  53,  53, 151, 112, 116, 116,  18,  54,  36, 124,\n",
      "        144, 157,  54,  57], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:00:19# predicted of 15000: tensor([ 74, 152,  48,  76,  92, 163,  92,  44,  14,   1,  30, 163,  42,  33,\n",
      "         75,  18,  48,  47,  33, 112,  48, 142, 116, 124, 151,  57,  38,  34,\n",
      "         47,  92,  76,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:02:11# labels of 20000: tensor([ 83,  30,  24,  38,  83,  24,   1,  34,  74, 164,  81, 157, 158,  12,\n",
      "         84,  84,  84,  84,  84,  84,  84,  84,  84,  12, 158,  36, 157, 163,\n",
      "         11, 162,   1, 111, 112,  83, 124, 151, 125,   4,   1, 104],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 00:02:11# predicted of 20000: tensor([ 42,  33, 112,  12, 144, 109, 150,  42,  34, 164,  60,  55, 152, 121,\n",
      "         84,  84,  84,  84,  84,  84,  84,  84,  84,  57,  49, 150,  12, 157,\n",
      "         53, 164,  92,  42, 142,  81, 124,  12,  92, 152,  57, 116],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 00:03:47# labels of 25000: tensor([119,   4, 125,  55,  54, 157,  47, 162,   4,  12,  42,   9,  44,   4,\n",
      "          9,  30, 142, 162,  76, 144,  11, 143,  60,  83,   2, 150,  31, 109,\n",
      "        164, 125,  36,  38], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:03:47# predicted of 25000: tensor([116,  57,  53,  34, 109, 144, 162, 151, 143,  76,  18, 164, 121, 150,\n",
      "         76,  87,  24,  92,   9, 116,  47,  87, 158,  48, 163, 150, 151, 121,\n",
      "         34, 163,  54,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:05:40# labels of 30000: tensor([ 75,  75, 121,  55, 144, 162, 112,  38,  75,   9,  54,  38,  45,  65,\n",
      "         45,  45,  93,  93,  87,  79,  79, 121, 121,   2,  36,  42,  34, 142,\n",
      "         55,  75, 104,  42, 124, 112,  47,  14,  53], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:05:40# predicted of 30000: tensor([157, 116, 104, 112,   1,  11,  48, 104, 119, 119,  30,  75,  45,  65,\n",
      "         45,  45, 163,   1, 164,  47,  79,  55,  38,  24, 124,  49, 111,  74,\n",
      "         87, 143,   2,   4, 125, 119,   1, 142,  53], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:07:24# labels of 35000: tensor([ 54,  84,  84,  84,  84,  84,  84,  84,  84,  84,  33, 125, 124,   2,\n",
      "         55, 163,  14,  74,  44, 104,  14, 143, 109, 124,  33, 112,  75,  12,\n",
      "         55, 121, 104,  60,  81,  18,  31, 143,  47, 143, 119, 112],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 00:07:24# predicted of 35000: tensor([ 87,  84,  84,  84,  84,  84,  84,  84,  84,  84, 119,   1, 131, 143,\n",
      "        151,   9,  33,  74, 121,  34,  97,  97, 151,   2,  97, 152, 164,   9,\n",
      "         55,   1,  74, 162,  42,  11,  24,  92,  47,  14,  34, 112],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 00:09:16# labels of 40000: tensor([ 83,  57,  57,  49,  60, 109,  75, 151,  75,  53,  97,  14, 142, 144,\n",
      "         44,  24,  12,  60,  57,  87, 124,  92, 163, 158, 142, 158,  54,  92,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17, 111,   1,   1], device='cuda:0') torch.Size([135])\n",
      "10/11/2023, 00:09:16# predicted of 40000: tensor([ 81, 116,  74, 163,  38, 163,  42,  53,  97, 121,  49,  49,  33,  12,\n",
      "          4,  83, 144,  60, 162, 151,  60, 119,   2,  55, 142, 157, 152,  97,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,   9, 152, 164], device='cuda:0') torch.Size([135])\n",
      "10/11/2023, 00:10:59# labels of 45000: tensor([  1,  54,  81,  36,   2,  60,  42,   1, 121, 125, 152,  36,   1,   9,\n",
      "        144,  87,  47,  54,  18, 119,  76, 157,  31, 111, 142,  97,   1,   1,\n",
      "         76,   1,   4,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:10:59# predicted of 45000: tensor([ 14,  81,  47,  38,  48, 121, 163, 143,  33, 142,  92, 150, 142,  49,\n",
      "         54,  49,  92,  53, 150,  33, 157,  34,  97, 164,  53,  92,  53, 112,\n",
      "         57, 163,   2,  47], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:12:48# labels of 50000: tensor([ 60, 116,   9,  30,  30,  57, 112,  83, 157,  49,  31, 150,  60,  14,\n",
      "        116,  87,  86,  86,   2,  12, 119,  60,  11, 119, 162,  33, 164, 144,\n",
      "        150,  54, 116,  14,  36], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:12:48# predicted of 50000: tensor([124,  54,  87, 163, 157,  57,  18, 162,  34,  49, 163,  74, 162,  60,\n",
      "        157, 142,  86,  86,  76,  11,  75,  55,  48,  92,  44,  31,  12, 150,\n",
      "        150,  44,  54, 142,  34], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:14:38# labels of 55000: tensor([150,   2, 164, 125,  75,  92,  81,  24,   1,  38, 142, 119,  44,  53,\n",
      "        119, 109, 116,  31,  53,  12, 157,  24,  34, 143,  36,  36,  33,  97,\n",
      "         48,  31,  74,   4], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:14:38# predicted of 55000: tensor([  2,  11, 150,  47, 116,  33,   4,  55,  83,  38,  47,   4,   4, 119,\n",
      "        162,  44,  83,  49, 125,  34,  87,  49, 164,  75, 111,  57, 119, 125,\n",
      "         81, 116, 121,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:16:22# labels of 60000: tensor([ 99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99,  99,  99,  99,  99,  99,  99, 144, 119,  30,  49, 125,  83,\n",
      "        124, 157, 119, 164,   9, 125,  53,  24, 157,   2,  75,  36,  74, 142,\n",
      "         83, 151,  97, 112,  76,  42, 111,  75,  11, 121,   4],\n",
      "       device='cuda:0') torch.Size([53])\n",
      "10/11/2023, 00:16:22# predicted of 60000: tensor([ 99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99,  99,  99,  99,  99,  99,  99,  54,  97,  11, 163,   9,   2,\n",
      "        124, 162, 152,  34,   9, 157,  18, 124,  14,  87, 112,  76,  11, 142,\n",
      "         42,  34, 150, 112,  34,  11, 125, 163, 150, 124, 109],\n",
      "       device='cuda:0') torch.Size([53])\n",
      "10/11/2023, 00:18:05# labels of 65000: tensor([ 36, 121,  87,  18,  76, 144,  75,  55,  57, 163,  54,   1, 144, 157,\n",
      "        111,  53,  97, 121,  54,  74, 164,  24, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118,  42, 158,  14,  53, 109,  42,  81,   4,  48], device='cuda:0') torch.Size([52])\n",
      "10/11/2023, 00:18:05# predicted of 65000: tensor([162, 121,  31, 150,  42, 163,  75, 119,  53, 150,  12,   4,  74,  83,\n",
      "         12, 124,  76,  33, 163,  57,   4,  74, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118,  36,  38,  53, 119, 112,  34, 111,  87,  75], device='cuda:0') torch.Size([52])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 00:19:59# labels of 70000: tensor([143,  36, 125,   9, 124,  47, 164, 142, 119, 111, 121, 143,  30,   4,\n",
      "        121,   4,  60, 164,  74,  83,  38, 119, 121, 163,   9, 150,   9,  97,\n",
      "          9, 144, 116, 119], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:19:59# predicted of 70000: tensor([ 14,  34, 150,  57,  14,  74, 116,  57,  34,  97, 158,  97,  47,  31,\n",
      "        121,  60,  57,  30,  57,  97,  57, 150, 142, 164,  57, 142, 158,  83,\n",
      "         97,  14, 116, 111], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:21:49# labels of 75000: tensor([ 55, 116, 119,  36,  55, 104,   2, 121,  75,  42, 164, 119, 125, 143,\n",
      "         47,  54,  18,  92,  42,  36,   2, 112, 143, 112,  18,  38, 142,  97,\n",
      "         53, 142, 112,  53], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:21:49# predicted of 75000: tensor([ 81, 150, 143, 124, 119,   9,  75,  60,  24, 158,   4,  87,  92,   1,\n",
      "        152, 142,  97, 125, 144,  92,  81,  47,  87,   1,  75,  60,  60,  97,\n",
      "        163, 151,   9,  54], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:23:30# labels of 80000: tensor([157, 157,  92,  81, 124,  33, 121, 163, 125,  92, 152, 150, 163, 121,\n",
      "        144, 124,  14, 150, 109,  47,  42,   1,   9,  57,  47, 121, 150,  76,\n",
      "        104,  76, 163,  55], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:23:30# predicted of 80000: tensor([142, 157,  97,  38, 150,   2,  81,   9,  47, 163,   4,  60,  42,  57,\n",
      "        163,  49,   2, 150, 109,  53,  81,   4, 143,  74, 150,  60,  14,  53,\n",
      "         92,  87,  30,   1], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:25:12# labels of 85000: tensor([ 47, 158,  81, 142,  48,   2,   9,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,   1,  33,   1,  57,  34,  75,   9,  18, 125, 119, 116,  67,  67,\n",
      "         67,  67,  67, 124, 150,  30,   9, 162,  81, 119,  30,   2, 152, 116,\n",
      "         92], device='cuda:0') torch.Size([85])\n",
      "10/11/2023, 00:25:12# predicted of 85000: tensor([ 34,  74,   9,  34, 163, 124, 116,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  47,  53,  75,  83, 164,  12, 163,  12,   2, 116, 104,  67,  78,\n",
      "         78,  78,  78,  44, 150,  14, 119,  55,  76,  83,   2, 116,  47, 125,\n",
      "         18], device='cuda:0') torch.Size([85])\n",
      "10/11/2023, 00:26:54# labels of 90000: tensor([111,  47, 114, 114,   9,  36, 121,  34,  75,   1, 150,  87,  87, 163,\n",
      "         24,   4,  76, 125,  55,  54,  36,  60,  60,  30, 144, 116, 158,  30,\n",
      "         14,  92,  55,  87,  38], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:26:54# predicted of 90000: tensor([ 49,  24,   1,   1,  14,  12, 121, 163,  36, 121, 121,  87, 144,  44,\n",
      "        124, 116, 158,  81,  30,  76, 150,  18,  49,  97, 144,   2,  11, 164,\n",
      "         49, 109,  34, 109,  30], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:28:40# labels of 95000: tensor([  4,  44,   4,  53, 121,  97, 120, 120, 120, 120, 120, 120, 164,  30,\n",
      "        109, 158,  97, 119,  34, 144, 150,  83, 121, 142, 104,  74, 116, 142,\n",
      "        151, 116,   1,  60,  42, 119,   2, 142,  38], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:28:40# predicted of 95000: tensor([ 74,  14, 151,  53,   9, 158, 120, 120, 120, 120, 120, 120,  75, 157,\n",
      "        142, 152, 104,  81,  47, 152, 150, 163, 163,  49,  48,  76, 163,  92,\n",
      "         97,  92,  55,  31,  92, 119,  47, 163, 119], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:30:29# labels of 100000: tensor([ 97,  75, 150, 163,  30, 111, 143,  31,  90,  90, 162,  83, 112, 143,\n",
      "          2,  76,  83,  38,  55,  57, 143,  42,  30,  42,  49,  42,  74,  18,\n",
      "         55,  74, 119,  87,  60], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:30:29# predicted of 100000: tensor([112,  97,  14, 163,  12,  14, 163,   9, 121,  60,  55,  36,  30,  34,\n",
      "        112,  49, 116,  75,  55,  92,  53,  14,   1,  60,  49, 152,  55,  75,\n",
      "         31,  83, 119,  92,  60], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 00:32:45# labels of 105000: tensor([104,  24, 152,  92, 142, 151, 152,  31,  83,  42,  81,  24,  81,  57,\n",
      "          2,  31,  75, 116,  74,   1,  60,  54,  44,  74, 109, 109, 142, 125,\n",
      "         24,  55,   2,  47], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:32:45# predicted of 105000: tensor([  1,  12, 164,  47,   9,  24,  33, 163,  30, 116,  14,  81,  11,  83,\n",
      "         33,   1,  75, 112,  49,   1,  44,  38, 116,  76, 144, 121, 142, 162,\n",
      "        162,  55,  92, 144], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:33:56# total batches: 108800\n",
      "10/11/2023, 00:33:56# Epoch 3 | Train Loss: 3.0742 | Train Accuracy: 0.2378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6533de17d64abb825b45695e5d7f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 00:33:56# labels of Validation: tensor([ 60,  55, 100, 100, 100, 100, 100, 100,  73,  73,  73, 147,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147,\n",
      "         28,  28,  28,  28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  90,\n",
      "         90,  69,  69,  69,  69,  69,  69, 104,  60, 130, 130, 130, 130, 130,\n",
      "         86,  86,  35,  35,  35,  35,  35,  35,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52, 144, 146, 146, 146, 146, 146, 146,  12,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "         42,  57,  44,  88,  88, 125,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 144, 129, 129,\n",
      "        129, 129, 129, 129, 129,  40,  40,  40,  40,  40,  40,  35,  35,  35,\n",
      "         35,  35,  35,  97, 125,  56,  56,  56,  56,  56,  56],\n",
      "       device='cuda:0') torch.Size([333])\n",
      "10/11/2023, 00:33:56# predicted of Validation: tensor([152, 150, 100, 100, 100, 100, 100, 100,  73,  73,  73, 147,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147,\n",
      "         28,  28,  28,  28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  38,\n",
      "         38,  69,  69,  69,  69,  69,  69,  92, 124, 130, 130, 130, 130, 130,\n",
      "         86,  86,  35,  35,  35,  35,  35,  35,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52, 109, 146, 146, 146, 146, 146, 146,   1,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        125,  60, 164, 121, 121,   4,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  14, 129, 129,\n",
      "        129, 129, 129, 129, 129,  40,  40,  40,  40,  40,  40,  35,  35,  35,\n",
      "         35,  35,  35, 112,   1,  56,  56,  56,  56,  56,  56],\n",
      "       device='cuda:0') torch.Size([333])\n",
      "10/11/2023, 00:33:56# labels of 0: tensor([ 60,  55, 100, 100, 100, 100, 100, 100,  73,  73,  73, 147,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147,\n",
      "         28,  28,  28,  28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  90,\n",
      "         90,  69,  69,  69,  69,  69,  69, 104,  60, 130, 130, 130, 130, 130,\n",
      "         86,  86,  35,  35,  35,  35,  35,  35,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52, 144, 146, 146, 146, 146, 146, 146,  12,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "         42,  57,  44,  88,  88, 125,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 144, 129, 129,\n",
      "        129, 129, 129, 129, 129,  40,  40,  40,  40,  40,  40,  35,  35,  35,\n",
      "         35,  35,  35,  97, 125,  56,  56,  56,  56,  56,  56],\n",
      "       device='cuda:0') torch.Size([333])\n",
      "10/11/2023, 00:33:56# predicted of 0: tensor([152, 150, 100, 100, 100, 100, 100, 100,  73,  73,  73, 147,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147,\n",
      "         28,  28,  28,  28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  38,\n",
      "         38,  69,  69,  69,  69,  69,  69,  92, 124, 130, 130, 130, 130, 130,\n",
      "         86,  86,  35,  35,  35,  35,  35,  35,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52, 109, 146, 146, 146, 146, 146, 146,   1,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        125,  60, 164, 121, 121,   4,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  14, 129, 129,\n",
      "        129, 129, 129, 129, 129,  40,  40,  40,  40,  40,  40,  35,  35,  35,\n",
      "         35,  35,  35, 112,   1,  56,  56,  56,  56,  56,  56],\n",
      "       device='cuda:0') torch.Size([333])\n",
      "10/11/2023, 00:34:13# Validation Loss: 0.2321 | Validation Accuracy: 0.9508\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db015a93f3044a6cb4594e87017188ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 00:35:48# labels of 5000: tensor([ 57, 111, 151, 111,  38,  53,  44,  60,  60,  14, 157,  11,   2, 158,\n",
      "         11, 125, 104, 151, 162,   2, 112, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 116,\n",
      "          9,   1,  74,  44,  48,  81,  60, 143,  47], device='cuda:0') torch.Size([51])\n",
      "10/11/2023, 00:35:48# predicted of 5000: tensor([ 24,  33,   1,  74, 157,  54,  92,   9, 121, 152,  47, 109,  92,  14,\n",
      "        164,   1,  30, 151, 162, 112,  53, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,  92,\n",
      "         12, 144,  92,  12, 124, 125, 124,  97,  72], device='cuda:0') torch.Size([51])\n",
      "10/11/2023, 00:37:19# labels of 10000: tensor([ 42, 104,  87,  57, 164,  83,  48,  12, 162, 139, 139, 139, 139, 139,\n",
      "        116,  42, 119,  31,  53, 157,  55,  48, 124,  24,  53,  31, 157, 121,\n",
      "         44, 125,  76, 109, 109,  83,  92,  76], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 00:37:19# predicted of 10000: tensor([  4,  14,  74,  48,  92, 142, 121, 164, 152, 139, 139, 139, 139, 139,\n",
      "        111,   2,  92,  38, 158,  76,  12, 121,  31,  60,  97,  76,  47, 121,\n",
      "        109, 125, 124, 151, 104, 163,  42, 150], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 00:38:57# labels of 15000: tensor([ 44, 150, 163, 142, 150,  11,  24,  18, 111,  60,  31,  74,   2,  31,\n",
      "          4,  49,  74, 142,  55,  74,  11,  54, 119,  74,  49, 109, 151,  97,\n",
      "        119,   1, 119,  48], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:38:57# predicted of 15000: tensor([  4,  47, 163,  47,  34, 104, 111,  97,  92,   1,   4,  34, 152,  44,\n",
      "         11,  97,  74,  30,  92,  14, 164, 143, 150, 150,  42,  36, 121,  97,\n",
      "        109,  33,  60, 124], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:40:27# labels of 20000: tensor([111,  48, 120, 120, 120, 120, 120, 120, 143,  14,  83, 151, 143, 119,\n",
      "         55,  12,  60, 157, 121, 163, 142,  60,  12,  83,  12,  87,  87, 125,\n",
      "         53, 143,  83,  48, 150,  57, 142,  47,  12], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:40:27# predicted of 20000: tensor([ 48, 150, 120, 120, 120, 120, 120, 120,  42,  48,  83,  48, 111,  34,\n",
      "         48, 163, 104,  34,  75, 163, 163,  33,  92,  30,  92,  87,   4, 163,\n",
      "         48, 119, 163,  42, 150, 163, 104,  47,  48], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:41:58# labels of 25000: tensor([125, 124,   1, 104,   4,  83,  38,  14,  34, 150, 121,  74, 142, 125,\n",
      "         65,  65, 135, 135,   6,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6, 150,  74, 150, 152,  53, 142,   1, 111, 119,   4,  33, 112,  76,\n",
      "         87,  31,   2], device='cuda:0') torch.Size([87])\n",
      "10/11/2023, 00:41:58# predicted of 25000: tensor([124,  36,  31, 124, 151, 142,  18,  14, 164,  36,  74,  57,  42, 125,\n",
      "         65,  65, 135, 135,   6,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,  76,  14,  31,  60, 116,  83,  42,  36,  11, 157, 150, 116,  76,\n",
      "        151, 119,  97], device='cuda:0') torch.Size([87])\n",
      "10/11/2023, 00:43:39# labels of 30000: tensor([151,  60,  12, 162,  87,  87,  48,  53,  54,  92,  38,  24, 104,  31,\n",
      "        162, 151,  48,  75,  47,   9,  60, 142,  53,  38,  74, 157, 119, 144,\n",
      "         75, 143,  56,  56,  56,  56,  56,  56,  14], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:43:39# predicted of 30000: tensor([151,  34,   1, 119, 121,  33,  42,  87, 162, 109,  76,  31,  34, 119,\n",
      "        162,  14,  34,  12,  97,  18,   1,  44, 121,  42,  54,   4, 119,  54,\n",
      "         92,  30,  56,  56,  56,  56,  56,  56,  14], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 00:45:14# labels of 35000: tensor([ 75, 157, 150, 150,  74, 158,  76,  42, 163, 158, 116, 104,  14, 158,\n",
      "         24,  36,  83, 125,  30,  36,  49,  24, 112, 125, 116,  33, 157, 119,\n",
      "        151,  33, 142,  44], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:45:14# predicted of 35000: tensor([  1, 162,  34, 116, 109, 158,  47,  97,  75,  42,  87,  12,  14,  48,\n",
      "         11,  47, 150,  31, 112, 116,   4,  49, 163,  87, 116, 158, 119,  34,\n",
      "        109,  48, 125,  97], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:46:50# labels of 40000: tensor([157,  48, 152, 162,  40,  40,  40,  40,  40,  40, 144,  18, 158,  11,\n",
      "        162,  14, 143,  83,  12, 150,  11,  57,  57, 121,  97,  13,  13,  13,\n",
      "         13,  13,  97,  30, 162,  57,   2, 152, 119, 116, 112,   2, 112],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 00:46:50# predicted of 40000: tensor([ 60,  92, 152,  31,  40,  40,  40,  40,  40,  40, 164,  60, 158, 124,\n",
      "        150, 163, 143, 164, 151,  97, 125,  55, 112,  11,   2,  13,  13,  13,\n",
      "         13,  13,  97,  24, 152,   2,  34,  87, 116,  14,   1,  11,  55],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 00:48:18# labels of 45000: tensor([ 54,  36, 125,  34,  75,  97, 125,   1,  53,   9, 116,  47,  55,  57,\n",
      "        162,   2,  87,  31,   2,  55,   9,  30,  53, 157,  24,  49,  55,  44,\n",
      "         31, 121,  76, 162], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:48:18# predicted of 45000: tensor([ 18, 157, 116, 162, 157,  18, 112, 119,  47, 109,  53,  33,  47,  55,\n",
      "         33,  87, 151,  87,   2, 157,  36,  47,   4,  31, 164, 109,  97,  12,\n",
      "          1, 121,  47,  54], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:49:48# labels of 50000: tensor([112,  87,  18,  57, 162,   2,   4, 163, 151,  12,  36,  53,  57, 157,\n",
      "         54,  57,  97,  18, 111,  60,  42, 111,  36,   2,  60,  18, 116,  97,\n",
      "         81, 112, 124,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:49:48# predicted of 50000: tensor([  2,  97,  47,  60,  49, 121, 162, 163,  53,   1,  47,  31,  74,  76,\n",
      "         24,  48, 158,  34,   2,   1,   2,  11,  81,   2, 162,  55, 119, 150,\n",
      "        119,  30, 119,  14], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:51:19# labels of 55000: tensor([  1, 112,   2, 143, 143,  11,  42,  12, 142,  74,  34, 144,  47,  48,\n",
      "        111,  42,  97, 158, 121, 144, 157,   2,  76,  75,  18,  42,  44,  47,\n",
      "         97, 163,  12,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:51:19# predicted of 55000: tensor([109,  92, 119, 112,  75,  24,  24,  60, 163,  38, 150, 152,  60,  92,\n",
      "        119, 142,  97,  60, 162,  36,  92,   4, 157,  87, 157,  34, 164, 124,\n",
      "        124, 142, 164,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:52:49# labels of 60000: tensor([  2, 158,  53,  34,  55,   1,  44,  97, 124,  34,  14,  60,  38,  74,\n",
      "        124,  83, 152, 143, 162,  74,  76,  12,  75,  44,  47,  31,  75,  24,\n",
      "        151, 143,  24, 163], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:52:49# predicted of 60000: tensor([116,  76,  97, 163,  33,  18, 164,  31, 163,  12,  42,  42, 162,   1,\n",
      "        152,  57, 152, 119,  14,  57,   1,  76,  92,  47,  38, 112,   1,  47,\n",
      "        142,  42,  12,  75], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:54:20# labels of 65000: tensor([150, 124,   2,  57,  78,  78,  78,  78,  78, 152,  42,  49, 164, 121,\n",
      "         24,  81,  24, 104, 162,  65,  65,  65,  65,  65,  65,  65, 135, 135,\n",
      "         34,   9,  30, 111,  18,  74,  49, 150, 111,  48, 109,  83,  24,  34,\n",
      "         75, 124], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 00:54:20# predicted of 65000: tensor([ 81,   4,   2, 143,  67,  67,  67,  67,  67, 163, 150,  34,  87,  74,\n",
      "        142,  12,  24,  60, 162,  65,  65,  65,  65,  65,  65,  65, 135, 135,\n",
      "        157,  38,  87,  75, 162,  74,  53,  47, 116,  48,  57, 164,  38,  30,\n",
      "        163,  34], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 00:55:51# labels of 70000: tensor([ 57, 150,  18,  54, 119,  33,  18,  33, 104, 104,   4,  34,   2,  30,\n",
      "        124,  44, 163, 152,  31,  57, 151,  48,  57,  24,  53, 162,  24,  60,\n",
      "         11,  84,  84,  84,  84,  84,  84,  84,  84,  84,  30,  74],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 00:55:51# predicted of 70000: tensor([151,  53, 119, 152,  34, 163, 152, 104,  42,  81, 109, 162, 143,  12,\n",
      "         76,  42,  38, 119, 163,  12,  87,  74,  57,  24, 158, 109,  24, 162,\n",
      "         81,  84,  84,  84,  84,  84,  84,  84,  84,  84,  36,  34],\n",
      "       device='cuda:0') torch.Size([40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 00:57:26# labels of 75000: tensor([  9,  83, 151,  74, 112,  49,  36,  30, 124,  31, 112,  44, 163, 164,\n",
      "        164, 151,  53,  83,  12,  48, 111, 111,  74,  81, 150, 151, 109,  74,\n",
      "        157,  87,  81,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:57:26# predicted of 75000: tensor([ 55, 119, 125,  24,   4,  24,  36,  30,  57, 163,  14,  81,  97,  53,\n",
      "        157,  97, 124,   2,  11,  53,  83,  76,  97,  24, 152,  31, 116,  92,\n",
      "         47, 112,  81,  74], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:58:53# labels of 80000: tensor([116,  74, 150,  14,  81, 112, 124,  33,  48,  24,  42,  60, 125,  76,\n",
      "         83,  57,  97,  92,  97,   4,  74,   9,   9,  55,  87,  12,  36,   1,\n",
      "        119,  44,  33, 142], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 00:58:53# predicted of 80000: tensor([119,   1,  97, 142, 162,  24, 152,  74,  36,  97,  18,  53,  47,  76,\n",
      "          4,   1,  97,  57, 162, 142,  76,  47,  11,  48, 124,  92,  30, 162,\n",
      "         76, 164,  75,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:00:27# labels of 85000: tensor([ 57,  36,  34,  47,  44, 119, 143,  30,  18, 109, 142,  47, 157, 158,\n",
      "          0,   0,   0,   0,   0,   0,  44,  81,  36, 121,  48,  48, 163,  14,\n",
      "        142, 150, 151,  47,  38,  42, 125,  18, 143], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:00:27# predicted of 85000: tensor([ 57,  81,  76, 119, 109, 157, 143, 142,  38,  34, 109,  18,  48,  38,\n",
      "          0,   0,   0,   0,   0,   0,  55, 116,  31,  33, 116,  48,  34,  83,\n",
      "         34, 150,  12, 116,  38, 116, 152,  36, 163], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:01:55# labels of 90000: tensor([ 44, 119, 124, 150,  14,  92, 143, 109,  18, 163, 151,  75,  38,  47,\n",
      "        112, 124, 121, 163, 163,  42, 144,  76,  14,   2,  97, 112, 104,  31,\n",
      "        158,  36, 111,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:01:55# predicted of 90000: tensor([ 30, 164,  81,  76, 116,   2,  87,  36,  38,  97,   1, 150, 119,  74,\n",
      "         74,   4, 158, 163, 163,  34,  44, 121,  36,  48, 152,  18,  47, 124,\n",
      "        143,  87,  34, 163], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:03:27# labels of 95000: tensor([ 31, 104,  42,   2,  60, 142, 158,  81, 142,  33, 162,  60,  18, 158,\n",
      "         55, 125,  60,  81,  44,  33,   9, 121,  31,  33,  87,  14,  97, 119,\n",
      "         11,  47, 163,   4], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:03:27# predicted of 95000: tensor([ 33,  92, 119,  74,  38,  31,  18,  53,  49,  57, 152,  12,  81,  97,\n",
      "         47,  60,   1, 158,  97,  36,   1,  74,  31,  81,  87, 131,  83,  11,\n",
      "          2, 157,  92,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:04:55# labels of 100000: tensor([124,  49,  49,  31, 164,  36,  54,   2,   1, 119,  34,  75,   8,   8,\n",
      "         11,  36, 164,  24,   1, 163,   4,  53,  76,  42, 109,  74,  30, 125,\n",
      "        157, 155,  65,  65,  65,  65,  65,  65,  65, 155, 155, 155,  74,  75,\n",
      "         30], device='cuda:0') torch.Size([43])\n",
      "10/11/2023, 01:04:55# predicted of 100000: tensor([ 60, 119,  97, 152,  34,  53, 125,  81, 152, 124,  60, 152, 152, 152,\n",
      "         14,   4, 119, 152, 158, 163, 112,  76,  31,  42,  55,  74,  12, 109,\n",
      "         54, 155,  65,  65,  65,  65,  65,  65,  65, 155, 155, 155,  53,   1,\n",
      "         38], device='cuda:0') torch.Size([43])\n",
      "10/11/2023, 01:06:26# labels of 105000: tensor([111, 121, 125,  44,   9,  92,  14,   9,  87, 150, 144,  12,  44,   1,\n",
      "         74, 151, 152,  97,  76,  54,  36, 151,  47,  97, 152,  24,  38,  55,\n",
      "         74, 163, 119,  44], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:06:26# predicted of 105000: tensor([163,  30,  24,  54,  47,  55, 121,  14, 163,  38, 162,  34, 150,  14,\n",
      "         75, 164, 151,  81,  57, 125,   9,  33,  47,  49,  53,  38,   1,  47,\n",
      "        111,  11,  42, 104], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:07:33# total batches: 108800\n",
      "10/11/2023, 01:07:33# Epoch 4 | Train Loss: 3.0482 | Train Accuracy: 0.2432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c500b504446e584120fa138d87721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:07:33# labels of Validation: tensor([143,  18,  96,  96,  96,  96,  96,  96,  47,  14,  65,  65,  65,  65,\n",
      "         65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 110, 110,   1,\n",
      "          0,   0,   0,   0,   0,   0, 124,  64,  64, 130, 130, 130, 130, 130,\n",
      "         65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141,  55, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,   4,\n",
      "        129, 129, 129, 129, 129, 129, 129,  43,  43,  26,  26,  26,  26,  26,\n",
      "         26,  43,  43, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  55, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161,  38, 104, 157,  48, 157,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 147,  65,  65,  65,\n",
      "         65,  65, 147, 147, 147, 147,  18], device='cuda:0') torch.Size([609])\n",
      "10/11/2023, 01:07:33# predicted of Validation: tensor([116, 121,  96,  96,  96,  96,  96,  96, 143,  83,  65,  65,  65,  65,\n",
      "         65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,   9,   9,  92,\n",
      "          0,   0,   0,   0,   0,   0, 124,  49,  49, 130, 130, 130, 130, 130,\n",
      "         65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141, 144, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 152,\n",
      "        129, 129, 129, 129, 129, 129, 129,  43,  43,  26,  26,  26,  26,  26,\n",
      "         26,  43,  43, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  57, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 163,  33,  54, 144, 163,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 147,  65,  65,  65,\n",
      "         65,  65, 147, 147, 147, 147,  31], device='cuda:0') torch.Size([609])\n",
      "10/11/2023, 01:07:33# labels of 0: tensor([143,  18,  96,  96,  96,  96,  96,  96,  47,  14,  65,  65,  65,  65,\n",
      "         65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 110, 110,   1,\n",
      "          0,   0,   0,   0,   0,   0, 124,  64,  64, 130, 130, 130, 130, 130,\n",
      "         65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141,  55, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,   4,\n",
      "        129, 129, 129, 129, 129, 129, 129,  43,  43,  26,  26,  26,  26,  26,\n",
      "         26,  43,  43, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  55, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161,  38, 104, 157,  48, 157,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 147,  65,  65,  65,\n",
      "         65,  65, 147, 147, 147, 147,  18], device='cuda:0') torch.Size([609])\n",
      "10/11/2023, 01:07:33# predicted of 0: tensor([116, 121,  96,  96,  96,  96,  96,  96, 143,  83,  65,  65,  65,  65,\n",
      "         65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,   9,   9,  92,\n",
      "          0,   0,   0,   0,   0,   0, 124,  49,  49, 130, 130, 130, 130, 130,\n",
      "         65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141, 144, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 152,\n",
      "        129, 129, 129, 129, 129, 129, 129,  43,  43,  26,  26,  26,  26,  26,\n",
      "         26,  43,  43, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  57, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 163,  33,  54, 144, 163,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 147,  65,  65,  65,\n",
      "         65,  65, 147, 147, 147, 147,  31], device='cuda:0') torch.Size([609])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:07:47# Validation Loss: 0.2322 | Validation Accuracy: 0.9503\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e6f361ed4343008980aaab4bb1607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:09:17# labels of 5000: tensor([ 57,  18, 163, 144,  57,  49, 116,  57, 163,  47, 157,  53,   2,  53,\n",
      "         74,  48, 157,   2, 162,  57,   9, 164, 152, 111,  12,  97,   4, 111,\n",
      "        144,  30,  44,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:09:17# predicted of 5000: tensor([109,  18,  30, 144,  81,  49,  53, 124,  97,  81, 144,  36, 142,  47,\n",
      "          4,   1, 157, 163, 142,  34, 121, 152,  87, 119,  87,  97,  92, 142,\n",
      "         81, 163, 116,  97], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:10:46# labels of 10000: tensor([ 33,  57,  18,  97, 112,  60, 119,  75, 143,  12,  12,  34,  57, 164,\n",
      "         42,  12,  57, 116,  49,   2,   1, 112, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160,  60,  12,  36, 109,  55,  33,   4,  11, 162],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 01:10:46# predicted of 10000: tensor([158,  31, 152,  97, 111,  54,  83, 121,   2,  36,  42,  18, 121,  97,\n",
      "         87,  83,  18, 116, 109, 109,  54,  48, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160,  57,  76,   9, 163,  11,  49, 164,   4,  38],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 01:12:18# labels of 15000: tensor([ 55,  92, 109,  42,   9, 125, 104,   4, 116, 109,  47, 158,  30,  18,\n",
      "        144,  33, 152,  11,   4,   2,  31,   2,  76,  76,   9, 125,  55,  18,\n",
      "        163,  57,  11,  74], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:12:18# predicted of 15000: tensor([ 47, 116, 104,  42,  49, 125, 124,  12, 124,  38,  48,  33,  92,  34,\n",
      "         33,  14,  97,  74, 125, 124,  57, 164,  54,  92,  76, 125, 163,  11,\n",
      "         55,  60, 124,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:13:45# labels of 20000: tensor([112,  47,  74,  31,  60,  50,  50,  50,  49,  55,  81,  42,  14, 119,\n",
      "        125, 151, 124, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  31, 109,  48,  42,   9, 111,  48, 103, 103,  12, 151,  49,\n",
      "         44,  74,  54,  75,  55], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 01:13:45# predicted of 20000: tensor([ 33,  53, 142, 109, 116,  50,  50,  50,  92,  18,  48,  12,   2,  11,\n",
      "         14, 124,  74, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105,  57, 109,  57,  30,  30, 152,  60,  49,  49,  48,  11,  75,\n",
      "         55, 112,  76,  33,  36], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 01:15:17# labels of 25000: tensor([104,  10,  10,   4,  49,  11,  55, 162,  36,  81, 116,  55, 158, 119,\n",
      "         75,  24,  18, 112, 144,  60, 150,  76,  97,  49,  11, 143, 164, 142,\n",
      "        143,  83,  30, 119,  31], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:15:17# predicted of 25000: tensor([ 18,  10,  10,  24, 125, 119, 164,  60,  74,  36,  92,  12, 158,  92,\n",
      "         53,  24,  24, 109,  31,   2,  24, 112,  49,  11, 112,  42, 150, 158,\n",
      "         33, 119,  83,  42,  24], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:16:50# labels of 30000: tensor([ 83,   1, 125,  11,  83, 125,  74,  44,  38,  31,  55,   4,  55, 150,\n",
      "         92,  31, 124,  53,  81,  11,  57,  14,  81, 164,  44, 151,  34,  60,\n",
      "         74,  57,  47,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:16:50# predicted of 30000: tensor([152,  33,  92,  11,   2,  31,  33,  44, 158,  31, 119,  83,  48, 116,\n",
      "         87,  47,  97,  24, 119, 144,  49,  47, 162, 116,  87, 109,  34,   2,\n",
      "          9, 119,  55, 158], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:18:51# labels of 35000: tensor([ 49, 112,  34, 121, 125,   1,  76,  12,  14,  36,  44, 152, 111, 162,\n",
      "         74,  36,  75,  24,  36, 112,  12,  47,   2,  11,  12,  18,  30, 144,\n",
      "        158, 151, 164, 144], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:18:51# predicted of 35000: tensor([ 24,   2,  11, 119,  75, 121, 109,  81, 131,  47, 109,  53,  30,  33,\n",
      "         14,  49, 157, 116,  24, 119,   1,  57,  48,  48,  38,   9,  97,  34,\n",
      "        152,   9, 152, 119], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:20:22# labels of 40000: tensor([ 54,  12, 143,  54,  74, 124,  36, 116, 104,  36,  53,  81,  36,  74,\n",
      "         33, 158,  83, 143,   9,   9, 124,  55, 104,   1,  34,  11,   2,  75,\n",
      "         30,  76,  18,  31], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:20:22# predicted of 40000: tensor([ 14,   4, 143, 151,  74,  31,  36,  49, 119, 121, 124,  38,  87,  75,\n",
      "         76,  81,  97,  34,  97,  24,  11,  30,  18, 116,  53,  83,  18,  75,\n",
      "         38,  76, 151,  81], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:21:51# labels of 45000: tensor([ 47, 104, 162, 124, 164,  83, 121, 109,  87,  92, 158,  12, 151,  34,\n",
      "         11, 163, 163,  60,   4,  30,  36, 143,  60, 124,  48, 124,  97,  36,\n",
      "         55, 104,  42,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:21:51# predicted of 45000: tensor([ 31,  53,  24, 143,  53,  53,   2, 109,  97,   4,  48, 116,  81, 125,\n",
      "        142, 163, 112,  60,  97,  55, 163, 157, 162, 150,   4,  81,  97, 124,\n",
      "         74,  92,  53,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:23:21# labels of 50000: tensor([ 53, 162,   2, 162,   2, 125,  38, 114, 114,  55,  18, 144,  38,  31,\n",
      "        109,  53,  47,  60,  97,  44, 121,   1,  33, 158,  54,  12, 125,  33,\n",
      "         49, 121, 158,  92, 152], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:23:21# predicted of 50000: tensor([112, 121,  11,  87,  81,   4,  38, 158,  14,  92,   1,  53,   9,  47,\n",
      "         97, 104, 121,  48, 112,  31,  75, 152,  33,  18, 111,  60,  30, 121,\n",
      "         34, 121,  92, 125, 119], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:24:49# labels of 55000: tensor([125,  34,  53, 109,  24, 151,  60, 124, 111,   5,   5,   5, 104,  83,\n",
      "         81,  11, 116, 164,  11,  30,  18, 112, 121, 111,  12,  57, 109, 125,\n",
      "        150,  92,  49, 158,  31,  36], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 01:24:49# predicted of 55000: tensor([ 81,  92, 151, 144,  18,  48,  42,  18, 143,   5,   5,   5, 124,   2,\n",
      "         53,  97, 152, 143, 150,  53,  18,  60, 121,  74,  12, 121,  31,  11,\n",
      "        162,  12,  74, 142, 119,  30], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 01:26:17# labels of 60000: tensor([104, 151,  97, 142,  18, 111,  60,  47,  68,  68, 152,  48,  75,   1,\n",
      "         47,  12,  76,  34,  76,  55, 111, 144, 151, 111, 119,  74,   1,  48,\n",
      "         18, 150, 157, 152,  31], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:26:17# predicted of 60000: tensor([ 36,  87,  14, 163,   1, 116, 143,  30,  76,  76,  49, 163, 116,  42,\n",
      "        152,  30,  87, 104,   1,  57, 119,  12, 163,  42, 150,  74, 112,  42,\n",
      "         11, 152, 150, 109,   1], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:27:51# labels of 65000: tensor([166, 166, 166, 166, 166, 166, 111,  30,  83, 124,  36,  36,  34,  47,\n",
      "         97,  57,  47,  38, 104, 152, 111, 125, 119, 142,  54,  30, 157, 151,\n",
      "         76,  42, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101,  24,  92,  38, 104, 143, 157], device='cuda:0') torch.Size([52])\n",
      "10/11/2023, 01:27:51# predicted of 65000: tensor([166, 166, 166, 166, 166, 166,   9,  12,  12,  49, 112,   1,  74,   4,\n",
      "         34, 144,  92, 151, 158, 112,  55,  76, 164,  34,  53, 158,  33,  53,\n",
      "         76,  49, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101, 150,  42,  49,  42,  97,   1], device='cuda:0') torch.Size([52])\n",
      "10/11/2023, 01:29:18# labels of 70000: tensor([  4,  44, 162,  33,   1,  76,  74, 119,  48, 163, 119,  92,  57, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101,  18,  14,  57,   9,  97, 111,  18, 157,  48,  60, 144, 164,  83,\n",
      "         54,  81,  31, 112,  12], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 01:29:18# predicted of 70000: tensor([ 33,  48,  53, 164,  53,  18,  47,   4,  92, 125, 124,  92, 125, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101,  92,  38,  57, 109,   9, 157, 150, 157, 163, 121,  60, 121, 119,\n",
      "         33,   2, 104, 151, 162], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 01:30:48# labels of 75000: tensor([164,  45,  45,  45,  12,  42,  92,  24, 116,  74, 109,   4,  33,  48,\n",
      "         87,  83, 151,  31, 112, 144,  53,  83, 143,  18,  36, 143,  34,  54,\n",
      "        124,  57,  47,  57, 146, 146, 146, 146, 146, 146, 125],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 01:30:48# predicted of 75000: tensor([ 97,  45,  45,  45,  30,  38, 150,  75, 116, 152, 121,  12, 124,  48,\n",
      "        144,  74, 119,  30,  12, 152,  92,   1,  92,  60,  97, 119, 158,  74,\n",
      "         57, 162,  55, 119, 146, 146, 146, 146, 146, 146,  33],\n",
      "       device='cuda:0') torch.Size([39])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:32:16# labels of 80000: tensor([ 76,   9, 104, 109, 152, 158,  92,  87, 104, 111, 125,  14,  75, 144,\n",
      "        163,  88,  88, 109,   4,  37,  37,  37,  37,  37,  60, 164,  14, 109,\n",
      "         97,  92,  48,  60,  11,  33,  48,  76,  60], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:32:16# predicted of 80000: tensor([ 34,  12,  57,   1,   4, 116,  53, 124,  76,  34,   4, 162,  31,  34,\n",
      "        157,  42,  42,  57,  76,  37,  37,  37,  37,  37, 124, 164, 121,  57,\n",
      "        116,  33,  12,  81,  57,  30,  53,  76,  18], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:33:45# labels of 85000: tensor([ 44,  75,   2,  30,  12,  47,  49,  18,  83,  11, 109,  24,   9, 111,\n",
      "         92, 142,  34,  87,  57,  55, 151,  97, 162, 112,  33, 111,  31, 142,\n",
      "         83,  76,  36, 119], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:33:45# predicted of 85000: tensor([143,  92,   2, 163,  92, 116,  49,  34, 158, 119, 112,  74, 124,   4,\n",
      "        152, 116,  47,  75, 151, 150,  12,  76, 125, 124,  49,  87, 142, 163,\n",
      "         83,  81,  74,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:35:12# labels of 90000: tensor([ 83, 150,  24,  55,  83,  53,  14, 157, 125,  33, 144,  49,   2,   2,\n",
      "        162,  18,  36,  31,  54,  42,  31,  87,  47, 104,  36,   2,  87,  74,\n",
      "         33,   9,  48,  97], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:35:12# predicted of 90000: tensor([ 14,  74, 112,  55,  34,  24, 162,  49, 109, 157,  83,  34, 124, 158,\n",
      "         14, 162,  42,   4,  48,  60, 119,  76, 163,  53,  57, 152, 109,  57,\n",
      "        116,  57,  14,  49], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:36:46# labels of 95000: tensor([ 49,  76,  97, 125,   1,  75, 163,  97, 164, 109,  24, 164, 151,  18,\n",
      "         76,  11,  54, 109,  87,  14,   4,  87,  14,  48,  42, 151,  83,  60,\n",
      "         87,  31,  76,  12], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:36:46# predicted of 95000: tensor([163,  36,  97,  24,  76,  33, 143,  30,  87, 158, 151,  76, 162, 121,\n",
      "         81,  11,  34,  87, 162, 163,   4, 112,   9,  74,  53,  36,  76,  38,\n",
      "        116,  57, 163,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:38:14# labels of 100000: tensor([ 57,  18,  44, 152, 142,  74, 162, 125, 152,  54,  54, 121, 162, 152,\n",
      "        112,  75, 152, 109,  61,  61,  61,  60, 162,   9, 124,  49, 112,  53,\n",
      "        164, 144, 112,   4, 112,   4], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 01:38:14# predicted of 100000: tensor([163,  81, 152,  33, 142,  81,  54,  92, 143,  92, 163, 150,  81, 124,\n",
      "         34,  87,  92,  74,  61,  61,  61,   4,  54, 112,  34, 163,  49, 112,\n",
      "         87,  11,  47,  57,  14, 124], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 01:39:41# labels of 105000: tensor([ 31,  11, 109,  12,  11, 116,  42,  57, 112,  31, 116, 143, 144,  47,\n",
      "         55,  55,  47,  55,  38,  42,  11,  92,  31,  73,  73,  73,   0,   0,\n",
      "          0,   0,   0,   0, 152,  33, 116,   9, 100, 100, 100, 100, 100, 100,\n",
      "         31,   1], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 01:39:41# predicted of 105000: tensor([ 92,  31, 109,  12,  87, 116,  12,   4, 151, 124, 125,  92, 163,  14,\n",
      "        143,  87, 157, 163,  38,  30,  81,  34,  74,  73,  73,  73,   0,   0,\n",
      "          0,   0,   0,   0, 163,  42,  34, 121, 100, 100, 100, 100, 100, 100,\n",
      "         81,  24], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 01:40:46# total batches: 108800\n",
      "10/11/2023, 01:40:46# Epoch 5 | Train Loss: 3.0442 | Train Accuracy: 0.2435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b19f621f8dc4bb788b10c54320fb2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:40:46# labels of Validation: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  61,  61,  61, 158,\n",
      "        137, 137, 137, 137, 137,  28,  28,  28,  28,  28,  65,  28,  28,  28,\n",
      "         28,  28,  28,  28, 139, 139, 139, 139, 139, 131, 131, 131, 131, 131,\n",
      "         96,  96,  96,  96,  96,  96, 146, 146, 146, 146, 146, 146,  15,  15,\n",
      "         15,  71,  71,  71,  71,  71,  71,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  71,  71,  71,  71,  71,  71,  14, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138,  43,  43,  98,  41,  41,  41,  41,  41,  83,  49,\n",
      "        100, 100, 100, 100, 100, 100, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 121, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 147, 147, 147, 147, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         72,  72,  35,  35,  65,  35,  35,  35,  35, 103, 103,  84,  84,  84,\n",
      "         84,  84,  84,  84,  84,  84, 130, 130, 130, 130, 130, 148, 148, 148,\n",
      "        148, 148, 148, 148, 166, 166, 166, 166, 166, 166], device='cuda:0') torch.Size([416])\n",
      "10/11/2023, 01:40:46# predicted of Validation: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  61,  61,  61,  57,\n",
      "        137, 137, 137, 137, 137,  28,  28,  28,  28,  28,  65,  28,  28,  28,\n",
      "         28,  28,  28,  28, 139, 139, 139, 139, 139, 131, 131, 131, 131, 131,\n",
      "         96,  96,  96,  96,  96,  96, 146, 146, 146, 146, 146, 146,  15,  15,\n",
      "         15,  71,  71,  71,  71,  71,  71,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  71,  71,  71,  71,  71,  71, 121, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138,  43,  43,  98,  41,  41,  41,  41,  41,  75, 116,\n",
      "        100, 100, 100, 100, 100, 100, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138,  81, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 147, 147, 147, 147, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         72,  72,  35,  35,  65,  35,  35,  35,  35,  18,  18,  84,  84,  84,\n",
      "         84,  84,  84,  84,  84,  84, 130, 130, 130, 130, 130, 148, 148, 148,\n",
      "        148, 148, 148, 148, 166, 166, 166, 166, 166, 166], device='cuda:0') torch.Size([416])\n",
      "10/11/2023, 01:40:46# labels of 0: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  61,  61,  61, 158,\n",
      "        137, 137, 137, 137, 137,  28,  28,  28,  28,  28,  65,  28,  28,  28,\n",
      "         28,  28,  28,  28, 139, 139, 139, 139, 139, 131, 131, 131, 131, 131,\n",
      "         96,  96,  96,  96,  96,  96, 146, 146, 146, 146, 146, 146,  15,  15,\n",
      "         15,  71,  71,  71,  71,  71,  71,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  71,  71,  71,  71,  71,  71,  14, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138,  43,  43,  98,  41,  41,  41,  41,  41,  83,  49,\n",
      "        100, 100, 100, 100, 100, 100, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 121, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 147, 147, 147, 147, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         72,  72,  35,  35,  65,  35,  35,  35,  35, 103, 103,  84,  84,  84,\n",
      "         84,  84,  84,  84,  84,  84, 130, 130, 130, 130, 130, 148, 148, 148,\n",
      "        148, 148, 148, 148, 166, 166, 166, 166, 166, 166], device='cuda:0') torch.Size([416])\n",
      "10/11/2023, 01:40:46# predicted of 0: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  61,  61,  61,  57,\n",
      "        137, 137, 137, 137, 137,  28,  28,  28,  28,  28,  65,  28,  28,  28,\n",
      "         28,  28,  28,  28, 139, 139, 139, 139, 139, 131, 131, 131, 131, 131,\n",
      "         96,  96,  96,  96,  96,  96, 146, 146, 146, 146, 146, 146,  15,  15,\n",
      "         15,  71,  71,  71,  71,  71,  71,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  71,  71,  71,  71,  71,  71, 121, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138,  43,  43,  98,  41,  41,  41,  41,  41,  75, 116,\n",
      "        100, 100, 100, 100, 100, 100, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138,  81, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65, 147, 147, 147, 147, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         72,  72,  35,  35,  65,  35,  35,  35,  35,  18,  18,  84,  84,  84,\n",
      "         84,  84,  84,  84,  84,  84, 130, 130, 130, 130, 130, 148, 148, 148,\n",
      "        148, 148, 148, 148, 166, 166, 166, 166, 166, 166], device='cuda:0') torch.Size([416])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:40:57# Validation Loss: 0.2329 | Validation Accuracy: 0.9501\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d44c0f4bfc436bbff5e93d6955c7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:42:25# labels of 5000: tensor([125,  81, 164,  54, 104,  11,  74,  12,   6,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,  87,  14, 112,  11, 119,  47,  75,  31, 143,\n",
      "        125,  94,  94, 151,  87, 157, 112,  81,  42, 150, 142,  42, 151, 112,\n",
      "        164], device='cuda:0') torch.Size([99])\n",
      "10/11/2023, 01:42:25# predicted of 5000: tensor([152,  81,  30, 152, 158, 124,  87,  53,   6,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,  97, 164,  30, 158, 124,  47,  53, 119, 163,\n",
      "        142,  94,  94,  42,   1, 157,  55, 111,   2,  83,  12, 125,  97,  57,\n",
      "          2], device='cuda:0') torch.Size([99])\n",
      "10/11/2023, 01:43:54# labels of 10000: tensor([ 56,  56,  56,  56,  56,  56, 157, 157,   2,  83,  14,  30, 119,  92,\n",
      "         18,   1, 148, 148, 148, 148, 148, 148, 148, 158,  97,  11, 142,  54,\n",
      "         11, 158,  57,  87,  47,   4,   6,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6, 163, 144,  60,\n",
      "          4,   2,  49, 116,  18], device='cuda:0') torch.Size([145])\n",
      "10/11/2023, 01:43:54# predicted of 10000: tensor([ 56,  56,  56,  56,  56,  56,  42, 121,  92, 164, 163,   4, 112,  92,\n",
      "        143,  92, 148, 148, 148, 148, 148, 148, 148, 163,  11,  92, 158, 121,\n",
      "        119, 119, 124,  48,  92, 164,   6,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,  33,   4,  42,\n",
      "         42, 116,  24,   1,  87], device='cuda:0') torch.Size([145])\n",
      "10/11/2023, 01:45:23# labels of 15000: tensor([164,  12,  54,  47, 164,  24,  31,  38,  81, 151,  36, 144, 124, 144,\n",
      "         48, 125,  83,   4, 125, 150,  38, 150, 124, 104, 125,  75, 162, 150,\n",
      "         92,   4,  30, 125], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:45:23# predicted of 15000: tensor([162, 163,  54,  18, 157, 119,  76,  38,  38,  74,  36,  12,  97,  18,\n",
      "        163,  81,  11,  12, 111, 109,  92,  49, 144,  60,  31,  42, 162,  42,\n",
      "         74,  24, 121,  47], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:46:52# labels of 20000: tensor([152,  33,  76,  92, 163,  33,  49, 163,  44,  97, 111,  11, 142, 164,\n",
      "        125,  81, 158,  53,  48, 158,   2,  14, 124,  18, 158,  54, 112, 150,\n",
      "         24,  47,  48, 125], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:46:52# predicted of 20000: tensor([152,  76,  24,  12,  47,  57,  49,  12,  42, 116,  87, 116, 121,   9,\n",
      "         76,  74, 162,  53, 150, 111,  42,   9, 163, 150,  38,  74, 112, 150,\n",
      "         75, 109,  30,  33], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:48:20# labels of 25000: tensor([ 76,  74,  75, 116,  49,  74,  47, 110, 110,  55, 121,  44,  57, 157,\n",
      "         12,  12, 116,  44, 124,  60, 142, 151, 124,  49,  38, 142,  49, 111,\n",
      "         55,  76, 142,  33,   1], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:48:20# predicted of 25000: tensor([  9, 121, 125,  76, 142,  75,  53,  34,  34,  12,  34,  87, 151,  92,\n",
      "        119,   4, 163, 163,   1,  76,  92, 142, 162, 121,  60, 163,  54,  76,\n",
      "        152,  14,  33,  49, 163], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:49:46# labels of 30000: tensor([151, 119,  54,  57,  36,  40,  40,  40,  40,  40,  40,  34,  53,  36,\n",
      "         57,  55,  33, 152,  87, 125, 144,  18,   4,  57,   9,  33,  97,  75,\n",
      "         12,  12,  18,  55, 163,  18,  97,  83,   9], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:49:46# predicted of 30000: tensor([ 48, 119, 121,  49,  48,  40,  40,  40,  40,  40,  40, 152, 151, 125,\n",
      "         38,  48, 124, 124, 112,  97, 112, 142, 150, 125,  34,  11,  97, 164,\n",
      "        144,  76,   2, 109, 144,  92,  48,  31,  14], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 01:51:20# labels of 35000: tensor([ 47,  55,  34,  83, 112,  53, 109, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  75, 151,  48, 126, 126, 126,  34,  54,  24, 124, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,  54,   9, 162, 152,  24,   9,  34,\n",
      "        109, 144, 104, 144, 142,  38,  47, 109], device='cuda:0') torch.Size([260])\n",
      "10/11/2023, 01:51:20# predicted of 35000: tensor([ 97, 158,  92, 150, 112,  76, 119, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  11, 104, 163, 126, 126, 126, 150, 163,  24, 124, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132,   4, 152,  54, 150,  87,  76,  24,\n",
      "          4,  11,  92,  14, 112,  36,  55, 109], device='cuda:0') torch.Size([260])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 01:52:47# labels of 40000: tensor([ 74, 157,  83,  49,  24,  92,   1,  54,  49, 125,  48,  54,  87,   4,\n",
      "        121, 104,  74,  24, 142,  34,   4, 143, 111,  66,  66,  66,  66,  66,\n",
      "         66,  66,  66,  66,  66, 162,  48,  60,  92,  75, 152,  12,   9],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 01:52:47# predicted of 40000: tensor([151,  14,  47,   1,  33,  48,  55, 121,  81,  47, 152, 109,  33, 152,\n",
      "         24,  49, 143,  30,  34, 150, 150,   2,  11,  66,  66,  66,  66,  66,\n",
      "         66,  66,  66,  66,  66,   4,  48,  74,  47,  75,  81,  92, 124],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 01:54:15# labels of 45000: tensor([ 42,  92,  36,  55, 125,   9, 111,  34,   4, 143,  76,  47, 152,  55,\n",
      "        124,   2, 113, 113,  83,  55, 111,  18,  54, 111,  24,  24,  83, 162,\n",
      "         54,  97,  83,  30,  44], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:54:15# predicted of 45000: tensor([158,  92, 163,  47,  34, 109, 111, 164, 152, 116,  24,  47,   1,  42,\n",
      "         83, 150,  49,  83,  36, 142, 143,  83, 157,  57,  47, 164,  14,   2,\n",
      "         54, 142, 109, 163,  47], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:55:45# labels of 50000: tensor([163,  34,  49,  34,  76,  97,  14, 153, 153, 153, 152, 112, 157,  30,\n",
      "         24, 144,  87,  76, 157, 116,  90,  90, 104,  76, 164,  47,  81,  44,\n",
      "        150, 112,  57,  60,  53,  31, 151], device='cuda:0') torch.Size([35])\n",
      "10/11/2023, 01:55:45# predicted of 50000: tensor([163, 163,  55,  42,  81,  30,  97, 153, 153, 153,  83,   9,  75,  42,\n",
      "         33,  30,  74, 121,  57, 116,  33,  33, 124,  76,  74,  47, 142,  42,\n",
      "        164, 119,  14, 124, 109,  49, 112], device='cuda:0') torch.Size([35])\n",
      "10/11/2023, 01:57:17# labels of 55000: tensor([111,   9, 111,  53,  60, 121,  94,  94, 112,  34,  18, 144,  24,  53,\n",
      "         47, 158,  47,  38, 152,  44,  12, 163, 142,  33, 157,   9,   2, 125,\n",
      "         49, 111,  36,  81,  57], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:57:17# predicted of 55000: tensor([  4, 162, 112,  53,  42,  14,  94,  94, 112,  14,  18,  92,  92, 119,\n",
      "         36,  97, 157,  54, 163, 163, 124,  75,  44,  34, 124,  97, 152,  47,\n",
      "         74, 150,  44, 116,  47], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 01:58:44# labels of 60000: tensor([157,  33,  42,  97,  12,  49,  48, 125, 116, 158, 143,   1,  53, 150,\n",
      "         30,  31, 142,  33, 116,   4, 143, 111,  36,  34, 125,  24,  97,  36,\n",
      "         11,  75,  48,  57], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 01:58:44# predicted of 60000: tensor([ 47, 157, 116, 163, 109, 151,  75,  92, 152, 163,  87, 157, 164,  60,\n",
      "        164,  30,  92, 152,  53,  49,  30, 158,  92,  34,  34, 121,  92, 112,\n",
      "        142,  92,  74, 162], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:00:13# labels of 65000: tensor([ 44,  44,  30, 152, 157,  92,  83,  54,  31, 150, 164, 157,  74, 164,\n",
      "         12,  42,  24,  60,  83,  97,  36,  36,  49,   9, 144, 112,  42,   1,\n",
      "        119,  53, 163,  11], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:00:13# predicted of 65000: tensor([ 30,  97, 142,  75, 162,  12,  83,   1,  75, 119,  49,  12,  47, 163,\n",
      "         34,  34,  75,  55,  92, 119, 164,  47, 119,  76,  97, 112,  97,   1,\n",
      "         24,  30, 112,  48], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:02:11# labels of 70000: tensor([125, 164, 150,  44,  33, 158, 152,  44,  12,  31, 119,   2,  57,  57,\n",
      "         31, 144, 142, 144,  75,  81,  49,   9,  18,  11,  42,  83,  33,  38,\n",
      "        158, 151,  49,  54], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:02:11# predicted of 70000: tensor([ 36, 143, 150, 112,  57,  42, 112,  92,   9, 163,  34,  11,   1,  47,\n",
      "        162, 109, 112,  44,  42,  97, 163, 142,  57, 152, 152, 162, 104,  18,\n",
      "         47,  92,  54, 116], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:03:43# labels of 75000: tensor([121, 112,  75, 164, 150,  76,  36,   2,  76,  44,   9, 109,  83,   2,\n",
      "         48, 121, 112, 109,  30,  38, 162,  24,  57, 112, 112, 109, 144, 142,\n",
      "         11,  31, 151, 124], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:03:43# predicted of 75000: tensor([151, 119,  75,   9,  33,  34,  49,   2,  57,  36,  83, 119, 152,  76,\n",
      "         54,  92,  36, 151,  92,  33, 121, 109,  60,  76, 164,  47, 104,  33,\n",
      "         12, 119, 150,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:05:17# labels of 80000: tensor([ 49, 116,  81,  53, 143,   1,  55, 163, 150,  11,  11,  48,  55,  81,\n",
      "        109, 163, 104, 162,   2,  81,  48,  14,  97,  49,  31,  54,  12,   4,\n",
      "         34, 150,  38,  81], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:05:17# predicted of 80000: tensor([104, 150, 157,  34,  57,  57, 164,  47,  83, 119,  75,  12, 109,  81,\n",
      "        119, 111, 150,  30,   2,  36,  81,  30, 116, 116,  42, 124,  12,  31,\n",
      "         49,  38,  34, 116], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:06:44# labels of 85000: tensor([116,  87,  36,  57,  87,   1, 144,  42,  11,   1,  24,  42, 111,  74,\n",
      "         76,  97,   4,   2,  12, 163, 116,  81,   1,  14,  76,  24,  18, 152,\n",
      "         44,  38,  42, 109], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:06:44# predicted of 85000: tensor([116, 109, 125, 142, 158,  81,   4,  55,   1, 112,  53,  18,  47,  54,\n",
      "         49,  74,  97, 152,  30,  47, 142, 116,   1,  14,  76,  49, 151, 116,\n",
      "          4,  97, 104,  48], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:08:14# labels of 90000: tensor([ 44,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  33, 109,  87, 157,  30, 157, 143,\n",
      "         42,  42, 164,  53,   2, 151,  38,  57,  76,  24,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 152,   2, 151,\n",
      "         18, 125,  55, 142,  30,  76,  12, 111, 121], device='cuda:0') torch.Size([149])\n",
      "10/11/2023, 02:08:14# predicted of 90000: tensor([142,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  92,  92,  57, 143, 121,  33,  47,\n",
      "         12,  34,  55,  60,   1,  92, 152,  60,  76, 121,   3,   3,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  49, 109, 158,\n",
      "         49, 119, 158,   2,  49,  18,  12,  76, 121], device='cuda:0') torch.Size([149])\n",
      "10/11/2023, 02:09:42# labels of 95000: tensor([157,  74,  12,  49, 163,  24, 124, 109, 111,  65,  65, 102, 102, 151,\n",
      "         44,  11, 111, 109, 157, 158,  42,  24,  18,  34, 164,  57, 144, 163,\n",
      "        163,  26,  26,  26,  26,  26,  26,  53, 116,  30,  48,  87],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 02:09:42# predicted of 95000: tensor([ 76, 116,  48, 121,  92, 109,  12,  57,  33,  65,  65, 102, 102, 144,\n",
      "        121, 162,  34, 152,  11, 151, 124,  75,  74, 143, 150,  53,  38, 144,\n",
      "         49,  26,  26,  26,  26,  26,  26,  60, 116,  33,  18,  11],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 02:11:09# labels of 100000: tensor([124, 121, 143, 142, 142,   9,   1, 151, 112,  43,  43, 151, 119,  24,\n",
      "         83,  48, 143, 162,  34,  44, 144,   2, 151,  31,  42,  74, 164, 116,\n",
      "        104,   4,  44, 151,  42], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:11:09# predicted of 100000: tensor([116,  55,  83, 116, 142, 157,  83,  47,  74,  43,  43, 109, 109,  34,\n",
      "         38,  53,  11, 157,  34,  47,  12,  34,  36, 150,  30,  87, 164,  18,\n",
      "         49,  11,  49,   1,  31], device='cuda:0') torch.Size([33])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:12:36# labels of 105000: tensor([ 42,  42,  97, 111, 104,  53,  12, 152,  92, 116,  75,  87,  30,  34,\n",
      "          1,  47,  44,  54,  30, 144, 125,   2, 121,  92,  44,   9,  74, 109,\n",
      "         63,  63,  63,  63, 116, 121, 124], device='cuda:0') torch.Size([35])\n",
      "10/11/2023, 02:12:36# predicted of 105000: tensor([ 42, 109, 116,  12, 158,  53,  12, 158, 125, 151, 116, 142,  53, 119,\n",
      "          1,  47, 121,  74,   9,  33,  76, 150, 121,  92,  83, 151, 162, 109,\n",
      "         63,  63,  63,  63,  36,  34,  49], device='cuda:0') torch.Size([35])\n",
      "10/11/2023, 02:13:41# total batches: 108800\n",
      "10/11/2023, 02:13:41# Epoch 6 | Train Loss: 3.0411 | Train Accuracy: 0.2443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b78f22ef43c46ae8a3d1207002d8b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:13:41# labels of Validation: tensor([125,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  87,  50,  50,  50,   2,  27,  27,\n",
      "         27,  91,  91,  91,   0,   0,   0,   0,   0,   0, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 110, 110,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  98,  45,  65,\n",
      "         45,  45, 147,  65,  65,  65, 147, 147, 147, 147, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 160, 160, 160, 160, 160, 160, 160, 160, 139, 139, 139, 139,\n",
      "        139,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "        125,  34,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  20,  20,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  21, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105,   0,   0,   0,   0,   0,   0,  93,  93,\n",
      "        158,   8,   8, 139, 139, 139, 139, 139, 109,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  20,  20], device='cuda:0') torch.Size([409])\n",
      "10/11/2023, 02:13:41# predicted of Validation: tensor([ 47,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  97,  50,  50,  50, 143,  27,  27,\n",
      "         27,  38, 162, 162,   0,   0,   0,   0,   0,   0, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 163, 163,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  98,  45,  65,\n",
      "         45,  45, 147,  65,  65,  65, 147, 147, 147, 147, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 160, 160, 160, 160, 160, 160, 160, 160, 139, 139, 139, 139,\n",
      "        139,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         49,   4,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  20,  20,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  21, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105,   0,   0,   0,   0,   0,   0,  92,  92,\n",
      "        112,  14,  14, 139, 139, 139, 139, 139,  44,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  20,  20], device='cuda:0') torch.Size([409])\n",
      "10/11/2023, 02:13:41# labels of 0: tensor([125,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  87,  50,  50,  50,   2,  27,  27,\n",
      "         27,  91,  91,  91,   0,   0,   0,   0,   0,   0, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 110, 110,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  98,  45,  65,\n",
      "         45,  45, 147,  65,  65,  65, 147, 147, 147, 147, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 160, 160, 160, 160, 160, 160, 160, 160, 139, 139, 139, 139,\n",
      "        139,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "        125,  34,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  20,  20,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  21, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105,   0,   0,   0,   0,   0,   0,  93,  93,\n",
      "        158,   8,   8, 139, 139, 139, 139, 139, 109,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  20,  20], device='cuda:0') torch.Size([409])\n",
      "10/11/2023, 02:13:41# predicted of 0: tensor([ 47,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  97,  50,  50,  50, 143,  27,  27,\n",
      "         27,  38, 162, 162,   0,   0,   0,   0,   0,   0, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 163, 163,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  98,  45,  65,\n",
      "         45,  45, 147,  65,  65,  65, 147, 147, 147, 147, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 160, 160, 160, 160, 160, 160, 160, 160, 139, 139, 139, 139,\n",
      "        139,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         49,   4,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  20,  20,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  21, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105,   0,   0,   0,   0,   0,   0,  92,  92,\n",
      "        112,  14,  14, 139, 139, 139, 139, 139,  44,  16,  16,  16,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         16,  20,  20], device='cuda:0') torch.Size([409])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:13:54# Validation Loss: 0.2314 | Validation Accuracy: 0.9504\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dee29d60ec645ba922df2a2a9adf7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:15:25# labels of 5000: tensor([109, 162, 151, 163,  38,  54,  36,  76,  48, 151,  49, 158,  42, 143,\n",
      "         36,  54,  55,  64,  64,  36,  30,  38, 151,  53,  87,  36, 150, 164,\n",
      "         87, 163, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123,  33, 144], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 02:15:25# predicted of 5000: tensor([ 33,   1,  92,  18, 150,  42,   2, 143,   1,  87,  42, 158,  97, 150,\n",
      "        144,  60,  18,  76,  76, 125, 163, 144,  97, 119,  87,  47,  92,  38,\n",
      "         33, 104, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 116,   2], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 02:16:57# labels of 10000: tensor([ 57,  36,   9, 152,  65,  65,  65,  65, 102, 102, 104,  92,  87, 116,\n",
      "         54, 104,  39,  39,  39,  11, 119,  75,  92, 111, 144,  48,  38, 162,\n",
      "        109,  36, 125,  33,  55,  74,  44, 119, 125,  11, 143],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 02:16:57# predicted of 10000: tensor([ 36,   1, 157,  74,  65,  65,  65,  65, 102, 102,  75,  92,  49,  49,\n",
      "         54, 158,  39,  39,  39,  97, 119,   4,  49,  34,  14,  87,  38,  47,\n",
      "        125,  36, 157, 151,  74, 151, 151, 151, 152, 152,  18],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 02:18:28# labels of 15000: tensor([  9,  76, 111, 112,  54, 100, 100, 100, 100, 100, 100,  12,  75,  14,\n",
      "         42,  14,  57, 150, 111,  55, 109, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160,  38,   1,  76, 111,  47,   2,  76, 162, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 164, 109, 152,  38,\n",
      "         87, 111], device='cuda:0') torch.Size([58])\n",
      "10/11/2023, 02:18:28# predicted of 15000: tensor([ 11,  49,  97,  92, 150, 100, 100, 100, 100, 100, 100, 124,  24, 121,\n",
      "        163, 121, 121,  48,  11,  87, 125, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160,  60, 109, 157, 150,  60,   2,  83, 162, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 144,  11, 119,  97,\n",
      "         87,   2], device='cuda:0') torch.Size([58])\n",
      "10/11/2023, 02:19:55# labels of 20000: tensor([  9,  31,  75, 164, 152,  57,   9, 163, 151,  74,  44, 119,  76,  53,\n",
      "         83,  48,  12,  36,  30,  49,   1, 150,   1, 124, 144,   1,  47,  75,\n",
      "        144,  14, 143, 162], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:19:55# predicted of 20000: tensor([ 18,  81, 125, 163, 152,  11, 150,  47, 104, 116,  87, 152, 144,  12,\n",
      "         33,  14,  12,  83,  60, 157, 111,   4, 111, 112,  87, 152,  83, 116,\n",
      "        152,  54,   4,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:21:25# labels of 25000: tensor([  2, 158, 124,  92, 142, 119, 151,  60,  11,   1,   2,  83,  83, 109,\n",
      "         57,  38,  36,  11,   9, 152,  54,  81, 143,  54,  48, 143,  83,  92,\n",
      "        112,  38,  57, 144], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:21:25# predicted of 25000: tensor([112,  87,  74, 158,   4,  49,  12, 121, 158,  97, 152, 163, 109, 152,\n",
      "         53,  97,  34,  92,  49,  34,  76,  47,  55,  54,  81,  18,  38,  30,\n",
      "         55,  38, 164,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:22:51# labels of 30000: tensor([109,  74, 162,  60,   9,  81, 144,  30, 158, 150,   9, 150, 119,  54,\n",
      "        164, 144,  36, 124, 104,  87,  76,  97, 158,  11,  36,  57, 119,  53,\n",
      "          9,  47,   2, 121], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:22:51# predicted of 30000: tensor([ 55,  47, 164, 121,  55,   4,  44, 164,  97, 150, 157,  12,  74,  11,\n",
      "         55,  74, 109,  76,  12,  34,  42,  14,  92, 121,  47,  74,  87, 109,\n",
      "         55,  92, 143,  97], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:24:18# labels of 35000: tensor([ 42, 116,  44, 152,  76, 164,  31,  92, 151, 109,   4,  30,  60, 162,\n",
      "        150, 157, 114, 114, 144, 164, 121, 125,  44,  24, 143,  31, 104,  76,\n",
      "        144,  18,  54, 157, 150], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:24:18# predicted of 35000: tensor([ 53, 163,  31, 144,  75,   1,  24, 124,  14,  97,  97, 164,  57,  42,\n",
      "         55, 163,  33,  33, 144, 143,  75,   4,  33,  24,  57, 150,  18,  57,\n",
      "         14,  76, 109,  75,  87], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:25:47# labels of 40000: tensor([ 44,  76,  49, 112,  18,  31,  36,  57,  92,  36, 151, 116, 150,  30,\n",
      "        150, 151, 151,  81,  49, 143,  33, 112,  76,  36,  11, 157, 109,  83,\n",
      "         60,  60,  87, 142], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:25:47# predicted of 40000: tensor([ 30, 121,  11,  12,  49,  44,  24, 121,  92, 163,  12,  55,  87,  87,\n",
      "         12,  11, 151,  38,  33,  97,  34, 125,  76,   4, 112, 157,  38,  83,\n",
      "        164, 164,  12, 164], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:27:16# labels of 45000: tensor([ 60, 157, 125,  14,  57,   9,  11,  53,  57, 164,  49, 111,  47,  75,\n",
      "         48,  33, 125, 143, 112, 109,  30,  38, 151,  97,  18,  47, 150, 125,\n",
      "        144,  36,  55, 125], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:27:16# predicted of 45000: tensor([ 31,  34,  92,  38,  18, 143,  53,   4, 125,  53, 158,  34,  54,  24,\n",
      "        162,  81,  76, 104,  47,  47,   9,  42,  53,  12,  49,  30,  53, 109,\n",
      "         18,  81,  47, 142], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:28:43# labels of 50000: tensor([124,  14, 143,  48,  31, 143,  49,  75,  57,  53,  83, 124,  33,  75,\n",
      "         75, 111,  97, 162,  38, 109,  97,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7, 116,  44,  12,  97,  97,  14, 109,   4, 142,   4],\n",
      "       device='cuda:0') torch.Size([98])\n",
      "10/11/2023, 02:28:43# predicted of 50000: tensor([ 33,   2, 163,  47,  47, 143,  60, 104,  57, 150,   9, 151,  92,   4,\n",
      "         53,   2,  38, 158, 119, 163,  12,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,  60,  60,  18, 143,  74,  97, 109,  83, 142, 151],\n",
      "       device='cuda:0') torch.Size([98])\n",
      "10/11/2023, 02:30:09# labels of 55000: tensor([ 65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 150, 112,  49, 124,\n",
      "        116,  12, 125, 146, 146, 146, 146, 146, 146,  83, 152,  34, 121, 112,\n",
      "        151,  36, 121,  31, 157, 163, 111,   2,   2, 144, 121, 150,  81, 111,\n",
      "         47, 121,  49, 121], device='cuda:0') torch.Size([74])\n",
      "10/11/2023, 02:30:09# predicted of 55000: tensor([ 65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 164, 112, 162,  92,\n",
      "        109,  33,  53, 146, 146, 146, 146, 146, 146, 158,  92, 119,   4, 152,\n",
      "         34,   2, 121,  18, 104,   9, 119, 163,  97,  11,  38,  87,  18, 104,\n",
      "         47, 124,  14,  53], device='cuda:0') torch.Size([74])\n",
      "10/11/2023, 02:31:38# labels of 60000: tensor([125,  83, 158, 144,  24,  60, 162,   2,  38, 144,  24,  48,  31, 151,\n",
      "         92, 157,   2, 111,  76, 111, 152, 144, 157,  57,  97,  83, 151,  97,\n",
      "         42,  30, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  53],\n",
      "       device='cuda:0') torch.Size([181])\n",
      "10/11/2023, 02:31:38# predicted of 60000: tensor([ 33,  47,  12, 121, 150, 121, 150,   1, 157,  30,  14,  48,  31, 112,\n",
      "         48,  97,  49, 142, 163,  83,  47,  14, 124, 162,  57,  57,  44, 142,\n",
      "        152, 162, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 158],\n",
      "       device='cuda:0') torch.Size([181])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:33:11# labels of 65000: tensor([ 42,  38,   9,  74, 119,  54, 163,  36,  48,  42,  18,  68,  68,  97,\n",
      "         97,  48, 164,  76,  11,  12, 150, 158,  41,  41,  41,  41,  41,   1,\n",
      "         11, 116,  76, 162, 119,  48, 112,  33,  31], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:33:11# predicted of 65000: tensor([ 42, 112,  60,  24,  36,  33,  34,   4, 121, 119, 143,  54, 112,  74,\n",
      "        142,  42, 151, 124, 112, 121,  55, 112,  41,  41,  41,  41,  41, 163,\n",
      "        151, 116, 158, 121, 116,  30, 163, 119,  81], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:34:41# labels of 70000: tensor([104,  36,  34, 150,  34,  44, 151,  76,  60, 163,  11,  34,  14, 162,\n",
      "         36,  48,  12, 152,  83,  53, 164,  53, 143,   9,   4,  48,  44, 124,\n",
      "         53, 150, 121,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:34:41# predicted of 70000: tensor([ 83,  81, 119, 150, 111,  81, 163, 152,  31,   9,  24,  57,  18, 162,\n",
      "         76,  12, 151,  92,  47, 112,   1, 125,  92,  81,  53,  87,  97,  34,\n",
      "        116,  92,  75,  30], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:36:09# labels of 75000: tensor([ 81,  48,  97,   1,  33,  42,  76,   4, 158, 125, 104, 164,  38,  42,\n",
      "         55, 152,  86,  86, 111,  48,  74,  60,  55,  81, 109,  30,  11,  76,\n",
      "         30,  53,  54, 158,   9], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:36:09# predicted of 75000: tensor([119, 152, 142,  49,  55,  11,   1, 150,  76, 116,  12,  34, 121,  92,\n",
      "         76, 109,  86,  86, 119,  38,   2, 143,  38,  54, 104, 125,  14, 163,\n",
      "         55, 124,  53,  60,  97], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:37:38# labels of 80000: tensor([111,  47,  42,  60,  47,  92, 153, 153, 153, 144, 150,  33, 164,  24,\n",
      "         34, 112, 151,  14,   1,  74,  30,  97,  54, 164,  33,   4,  63,  63,\n",
      "         63,  63, 119,   9,  83,  42, 162, 150,  97], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:37:38# predicted of 80000: tensor([ 11,  54,  12, 121, 112, 125, 153, 153, 153,  12,  76,  38,  92, 121,\n",
      "        163,  53,  11,  14,  18,   1, 112,  18, 150, 109,  81, 112,  63,  63,\n",
      "         63,  63,  60,  38, 112, 144,  75, 158,  24], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:39:06# labels of 85000: tensor([  1,  53, 143,  49,   9,  18,  54, 111, 151,  76,   1,  49,  49,  60,\n",
      "        142, 117, 117, 117,  47,  36,  55,   9, 162, 158, 162,  81, 157,  74,\n",
      "         55, 124,  31, 116,  55,  33], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:39:06# predicted of 85000: tensor([ 74,  12, 104,  24,  87, 116, 151,  53,   9, 104,  55, 121,  36,  18,\n",
      "         24, 117, 117, 117,  97,  76,  55,  31,  33, 163,  18,   1, 142,  12,\n",
      "         49, 124, 157, 152,  36,  76], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:40:34# labels of 90000: tensor([125, 157,  31, 164, 125, 131, 131, 131, 131, 131,  76,  47,  83,  92,\n",
      "         55, 104, 112,  34,  30,  38,  38,  87, 150, 104, 152, 157, 162,  36,\n",
      "         54, 158,  55, 158, 124,  42, 163,  42], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 02:40:34# predicted of 90000: tensor([ 92,  12, 119,  18,  31, 131, 131, 131, 131, 131,  24,  60, 151,  92,\n",
      "         47,  42, 125, 124,  48, 150, 112,  30,  76, 104,  97,  49, 116,  36,\n",
      "         48,  48,  75, 163, 158, 109, 157,  74], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 02:42:01# labels of 95000: tensor([ 34,  60,  92,  74,  55,  65, 135, 135, 111,  24, 119,  24,  76, 152,\n",
      "         53,  11, 112,  60, 142,  60, 112,  11,  24, 111,  47,  11,  60,  33,\n",
      "         42, 150,   2,  24,   9,  55], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:42:01# predicted of 95000: tensor([ 34,  24, 119, 143,  11,  65, 135, 135,  97, 158,  55, 164, 158,   1,\n",
      "        164, 150, 112,  97, 142,  14, 104,  87,  76, 142,  48,  55,  74,  33,\n",
      "          4, 143,  38, 152, 119,  14], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:43:30# labels of 100000: tensor([ 47,   4, 116,  55,  38, 111,   9, 109,  49,  33,  97, 109,  18, 104,\n",
      "         47,  42,  33,  74,  87,  74,  83,  34,  60,  88,  88, 151, 104,  83,\n",
      "        124, 144, 124,  81, 109], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:43:30# predicted of 100000: tensor([ 44,  81,  48, 162, 119, 152, 162,  33,  75, 150,  14,  12,  75,  12,\n",
      "         47,  30,   9,  92,  75,  74, 163, 158,  60, 121, 121,  53,  24, 112,\n",
      "         55,  97,  11, 124,  53], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:45:32# labels of 105000: tensor([ 87,  57, 121, 110, 110,   1,  57, 143,  57,  12, 163,  34,  97,  87,\n",
      "         38,  30, 109,  83,  74, 143, 116,  48,   4,  24,  53, 111,  55, 152,\n",
      "         33,  48, 143, 151,  60], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:45:32# predicted of 105000: tensor([ 97, 109,  47, 162, 162,  92,  81,  54, 151,  92, 163,  76, 152,  31,\n",
      "        150,  18, 150,  74, 152,  34,  42,  54, 109,  49,  76, 152, 163, 116,\n",
      "        151,  24,  12, 152,  18], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:46:43# total batches: 108800\n",
      "10/11/2023, 02:46:43# Epoch 7 | Train Loss: 3.0458 | Train Accuracy: 0.2426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be9e49aab324d8dbfed675b19bb678f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:46:43# labels of Validation: tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  12, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  53,\n",
      "        126, 126, 126,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         65,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  71,  71,  71,  71,  71,  71, 140,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118,  18, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165,   9, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160,  81, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "         19,  19,  19,  19,  19,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,   5,   5,   5, 163,  42,\n",
      "          0,   0,   0,   0,   0,   0,  18, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "         76, 108, 108, 108, 108,  54,  55], device='cuda:0') torch.Size([777])\n",
      "10/11/2023, 02:46:43# predicted of Validation: tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 116, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  47,\n",
      "        126, 126, 126,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         65,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  71,  71,  71,  71,  71,  71, 140,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 157, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165,  30, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 163, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "         19,  19,  19,  19,  19,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,   5,   5,   5,  49, 121,\n",
      "          0,   0,   0,   0,   0,   0,   1, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "         12,  49,  49,  49,  49, 163,  74], device='cuda:0') torch.Size([777])\n",
      "10/11/2023, 02:46:43# labels of 0: tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  12, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  53,\n",
      "        126, 126, 126,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         65,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  71,  71,  71,  71,  71,  71, 140,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118,  18, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165,   9, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160,  81, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "         19,  19,  19,  19,  19,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,   5,   5,   5, 163,  42,\n",
      "          0,   0,   0,   0,   0,   0,  18, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "         76, 108, 108, 108, 108,  54,  55], device='cuda:0') torch.Size([777])\n",
      "10/11/2023, 02:46:43# predicted of 0: tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 116, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  47,\n",
      "        126, 126, 126,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         65,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  71,  71,  71,  71,  71,  71, 140,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 157, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165,  30, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 163, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123, 123,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "         19,  19,  19,  19,  19,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70,  70,  70,  70,  70,  70,   5,   5,   5,  49, 121,\n",
      "          0,   0,   0,   0,   0,   0,   1, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "         12,  49,  49,  49,  49, 163,  74], device='cuda:0') torch.Size([777])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:46:55# Validation Loss: 0.2312 | Validation Accuracy: 0.9507\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fb7d01d6c94489acb12cad0aa8434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 02:48:22# labels of 5000: tensor([ 81,  49,  31, 142,  30, 143,  30, 163,  47, 112,  60, 116,  34, 151,\n",
      "        116,   6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6,  34,   1,  54, 142,  83,  74, 144,  12,\n",
      "         33, 151,  74, 157,  11,  54, 158,  24], device='cuda:0') torch.Size([106])\n",
      "10/11/2023, 02:48:22# predicted of 5000: tensor([ 92, 158,   4, 164, 112, 104, 104,  31,  49,   4, 124,  92, 112,  38,\n",
      "         38,   6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,   6,   6, 104,   1, 142, 109, 111,  24,  92,  34,\n",
      "         33,  57,  53,  12,   4, 142,  49,  24], device='cuda:0') torch.Size([106])\n",
      "10/11/2023, 02:49:53# labels of 10000: tensor([ 76,   2, 143,  33, 112, 143, 164, 122, 122, 122, 122, 122, 122, 122,\n",
      "         54,  97,  11, 164,  34,  97, 116,  42, 162,  11, 125,   2, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132,  44, 112,  33, 158,  87,  54,  44, 119, 162, 125,\n",
      "        116], device='cuda:0') torch.Size([253])\n",
      "10/11/2023, 02:49:53# predicted of 10000: tensor([121,  18,  34, 116, 112, 152,  76, 122, 122, 122, 122, 122, 122, 122,\n",
      "        152,  42, 112,  53, 119, 112, 157,  42,  12, 109,  75, 112, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 124,  18,  33,   9,  38,   9,  60,  14,  97, 125,\n",
      "        124], device='cuda:0') torch.Size([253])\n",
      "10/11/2023, 02:51:19# labels of 15000: tensor([ 24, 164,  83,  24,  60, 157,  57, 163, 111,  92, 104,  53, 142,  38,\n",
      "        109,  12,  75, 124,  47, 164, 111,  69,  69,  69,  69,  69,  69,  34,\n",
      "         24, 142, 163, 109, 150, 163, 124,  34,  76], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:51:19# predicted of 15000: tensor([ 14,  92, 119,  24, 109, 121, 144, 162, 164, 124,  57, 109, 142,  81,\n",
      "        112,  12,  42, 142,  74,  57,  31,  69,  69,  69,  69,  69,  69,  76,\n",
      "        157,  97,  92,  47, 150, 163,  42,  76,  47], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 02:52:46# labels of 20000: tensor([ 53,  14, 121,   9,  42, 119, 143,  30, 144,  92, 150,  76,   2, 109,\n",
      "         55,  57, 142, 152, 119, 125,  57,  92, 158, 124,  57,  27,  27,  27,\n",
      "         55,  48,  57,  60, 124,  11], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:52:46# predicted of 20000: tensor([ 57,   9, 121,  57,  75,  24,  47,  42, 157, 109,  92,  34, 109,  97,\n",
      "         36, 109,  83, 162,   9, 116,  74,   4,  14, 157,  49,  27,  27,  27,\n",
      "        112, 164,  57,   1,  31,  18], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:54:15# labels of 25000: tensor([ 30, 151, 143,  42,  44,   4,  48, 111, 151, 119,  18,  55,  30, 142,\n",
      "         81,  36, 144,  97, 125, 162,  42,  81, 142, 143, 162,  97, 125,  87,\n",
      "        143, 152, 152,  95,  95,  95], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:54:15# predicted of 25000: tensor([ 30, 104, 150,  38,  76,  87, 152,  60, 124, 150,  74,  47, 119, 162,\n",
      "         81,  74,  76,  53,  42,  76,  60,  81, 125, 143,  97,  81,  30,  42,\n",
      "        158,  44,  34,  95,  95,  95], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 02:55:43# labels of 30000: tensor([ 60,  33,   4,  83,  97,  55,  53, 157,  30,  34,  76,  54,  42,  55,\n",
      "        152,  31,  54, 143,  49,  72,  72,  87, 164, 162,  60,  81,  76,  31,\n",
      "        144,  31, 112,  47,  42], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:55:43# predicted of 30000: tensor([116,  97, 151,  48, 124,  75,  57,  97, 157, 164,  42,  57,  11, 162,\n",
      "         97,  87,  36, 112, 111,  72,  72,  97,  14,  75, 109, 116,  81, 109,\n",
      "         92,  87,  31, 119,   2], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 02:57:11# labels of 35000: tensor([ 18,   2,  47,  53,  18,  54,  44,  11, 111,  31, 150,  83,  24,   1,\n",
      "         36,   1,  75,  38,   2,  74, 144,  38,  24,  54,   9,  12, 152,  81,\n",
      "         24,  14, 143, 109], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:57:11# predicted of 35000: tensor([  9,  92, 163,  49, 142,  49,  14, 119, 116, 124,  34,  30,  60, 143,\n",
      "         24,   1,   2, 151,  53,  49, 162,  49, 104,   2,  12,  75, 163,   2,\n",
      "         12,  14,  34,  24], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 02:58:42# labels of 40000: tensor([ 11, 109,  81,  65,  65,  65,  65,  65,  65,  65, 135, 135,  97,  47,\n",
      "         74,  47,  81,  30, 121,  34, 152,  60, 144, 162,  75,  55, 158, 112,\n",
      "         48, 162, 164,   1,  83, 109,  54, 116,  55,  76,  81, 164],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 02:58:42# predicted of 40000: tensor([ 11, 163, 124,  65,  65,  65,  65,  65,  65,  65, 135, 135,  57,  47,\n",
      "         76,   1, 119,  18,  49, 116,  34,  44,  55, 164,  34,  12, 124, 157,\n",
      "         36,  49,  38,  42, 152,  60,  47,  42,  55,  81, 152,  42],\n",
      "       device='cuda:0') torch.Size([40])\n",
      "10/11/2023, 03:00:16# labels of 45000: tensor([111,   2,  11,  97,  60,   2, 125, 163,  54, 124,  54,  14,  60,  54,\n",
      "        150, 152,  48,   9, 152, 143,  74,  55,   1,  91,  91,  91, 112, 162,\n",
      "         36, 121,  47,  60, 151, 121], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 03:00:16# predicted of 45000: tensor([119, 152,  76,  87,  33, 104, 158, 164,  12,  87,  92,  47,  49,  54,\n",
      "        111, 111,   9,  53, 119,   9,  54,  55,  54,  76,  76,  76,  55,  34,\n",
      "         36,  14, 158, 109,  87,  75], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 03:01:42# labels of 50000: tensor([ 48, 150, 109, 151, 109,   4,  49, 164,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,   2, 125,  33, 125,  49,  47,  54, 144,  54,  54,   1,  34,\n",
      "        111, 163, 124,  81, 125, 112, 125, 157, 109, 164, 112],\n",
      "       device='cuda:0') torch.Size([81])\n",
      "10/11/2023, 03:01:42# predicted of 50000: tensor([152,  48,  36,  74, 152,  24,  34,  12,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  49, 158,  33,  33,  47, 163,  54,  14, 125,  33, 104,  75,\n",
      "         60,  44, 124, 162, 125, 109,  24,  97,  57, 143, 144],\n",
      "       device='cuda:0') torch.Size([81])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:03:11# labels of 55000: tensor([  1, 109, 163,  34,  53,  47, 164, 119, 163,  75,  87, 163,  55,  92,\n",
      "        164,  44, 164, 112,  60, 145, 145, 145, 145, 145, 145,  54,  76, 150,\n",
      "        158,  24,  14,  44,  81,  38,  47,  55, 150], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:03:11# predicted of 55000: tensor([  1,  57, 163, 143, 121,  47,  92,  75,  34,  12,  83,  47,  42,  92,\n",
      "        144, 164, 109, 124,  14, 145, 145, 145, 145, 145, 145, 116,  42,  42,\n",
      "        109,  11,  47,  30,  47,  92, 150,  38, 150], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:04:37# labels of 60000: tensor([163,  18, 109, 157,  76,   2, 119, 158,  76,  12, 111, 152, 144,   2,\n",
      "        104, 111,  76, 116, 111,  24,  53,  42,   1,  83,  31,  11,  11, 162,\n",
      "         24, 152, 142,  47], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:04:37# predicted of 60000: tensor([ 24,  38,  33,  31, 144,  33,  11,  33,   2, 151, 119, 157,  47,   1,\n",
      "        150,  12,  12, 164,  76, 124, 125, 163,  76, 152,  49, 152,  11,  36,\n",
      "        104,  31,   1,  81], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:06:05# labels of 65000: tensor([ 55,  18, 112,   2,  92,  11,  34,  24,   1, 109,  55,  81, 104, 121,\n",
      "        143,  42,  97,  12,  60, 119,  18, 164,  44,  87,  12,   2, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        111,  60, 104,   1,  48], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 03:06:05# predicted of 65000: tensor([ 81,   1, 150,  55,  75, 163, 119, 150,  75,  38, 162,  81, 104,  12,\n",
      "         87, 157, 152,  53,  31,   4,  81,  31,  42,  76,  54, 152, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        163,  14,  36,  53,  55], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 03:07:33# labels of 70000: tensor([151, 121,  53, 162,  81,  30,  80,  80,  80,  80,  80,  80, 125,  55,\n",
      "          4,  54, 109,  97,  81,  55,  83,  34, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 164,   1,  54,   2,  31,  34,  54,  36,  43,  43,  81, 111,  34,\n",
      "        116, 112], device='cuda:0') torch.Size([58])\n",
      "10/11/2023, 03:07:33# predicted of 70000: tensor([158,  30,  12,  33,  24,  92,  80,  80,  80,  80,  80,  80,   4,  38,\n",
      "        125,   2, 157,  97, 111, 125,  33,   1, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118,  47, 164, 112,  42,  54, 125, 151,  81,  43,  43, 104,  92,  34,\n",
      "         48, 119], device='cuda:0') torch.Size([58])\n",
      "10/11/2023, 03:09:00# labels of 75000: tensor([ 53,  12,  38, 162,  74,  53,  97, 125,  55,  57,  14, 144,  87,  81,\n",
      "         36,  75, 111, 111,  33,  83,  92, 144,  49, 164, 142, 163, 150,  49,\n",
      "        151, 157, 158,  74], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:09:00# predicted of 75000: tensor([ 34, 150,  49,  60,  33,  44, 152,   9,  60, 151, 158,  75,  31,  60,\n",
      "         47,  42, 125,  42, 125, 111, 152, 158,  47, 150,  76,  97,   1,  49,\n",
      "        158,   1,   9,  38], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:10:26# labels of 80000: tensor([ 92, 104,  53,  76, 121,  53, 144,  48, 142, 152, 111, 157, 109,   4,\n",
      "         53,  92, 119,  33,   9, 121,  83, 112,  44, 112,  42, 124,   1,  83,\n",
      "         53, 104,  34,  57], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:10:26# predicted of 80000: tensor([ 92,   9,  36,  49,  54, 112, 144, 163,  47, 143,  60,  47,  47,   4,\n",
      "        124, 150, 150,  49,  18, 162,  47,  76,  60,  48, 125, 152, 144, 125,\n",
      "        124,  30, 150,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:11:53# labels of 85000: tensor([ 18, 107, 107, 107, 107, 107, 107, 107, 107, 119, 164, 142,  18,  66,\n",
      "         66,  66,  66,  66,  66,  66,  66,  66,  66,  97,  55, 143, 151,  53,\n",
      "         57,  74,  42, 157,  44,  31,  76,  54, 109,  76, 150, 164,  92,  49,\n",
      "        152,  30,  12, 143,  74, 164], device='cuda:0') torch.Size([48])\n",
      "10/11/2023, 03:11:53# predicted of 85000: tensor([  1, 107, 107, 107, 107, 107, 107, 107, 107,  76, 125,  76,  34,  66,\n",
      "         66,  66,  66,  66,  66,  66,  66,  66,  66, 151,  60,  76,  11,  30,\n",
      "        125,  92,  36, 121, 151, 109,  76, 157, 150,  42,  81, 125, 124, 124,\n",
      "        152,   1, 119, 162,  30, 150], device='cuda:0') torch.Size([48])\n",
      "10/11/2023, 03:13:23# labels of 90000: tensor([142,  31,  11,   4,   1,  11, 158, 150,  14,  34, 116,   2, 121,  97,\n",
      "         31, 124,  92,  31,  34,  31,  92,  49,  49,  34,  11,  75, 162,  48,\n",
      "        150, 112, 158, 121], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:13:23# predicted of 90000: tensor([ 97, 152,  48,  14,   1, 152, 104,  31, 152, 112, 142,  42,  76,  31,\n",
      "         31, 124, 163,  44,  97,  12,  24, 109,  55, 142,  11,   9, 162, 163,\n",
      "         14,  38,  83, 109], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:14:52# labels of 95000: tensor([ 24,   9,  55,  97, 111,   9,  75,  33,  14,  87,   9,  48, 152, 109,\n",
      "        157,  49,  33,  42,  54,  36,  36,  49,  97,  24,  75,  92,  33, 112,\n",
      "        157,  53,  48,  75], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:14:52# predicted of 95000: tensor([  4,  24,   4,  42,  48,   9,  12,  47, 119, 164, 151, 152, 111, 104,\n",
      "         47,  49,  33,  36, 152, 104,   4,  49,  60,  11,  97, 104,  33, 119,\n",
      "         44, 109,  34,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:16:18# labels of 100000: tensor([159, 159, 159, 159, 159, 159, 159, 159, 159, 159,   4,  55,  92,  83,\n",
      "        109,  11, 144, 111, 164, 143, 158, 124,  47,  75, 116,  60, 111,   2,\n",
      "         34, 119, 112, 143,  57,  97, 158, 144,  24,  57,  55,  24, 158],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 03:16:18# predicted of 100000: tensor([159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 121, 152,  31,  55,\n",
      "         42, 150,  83,  38, 164,  55,  83, 125, 164, 111, 121,  14, 164,   2,\n",
      "         54, 116,  87,  30,  47,  31, 157, 151, 124,  57,  14,  18, 158],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 03:17:47# labels of 105000: tensor([151,  75,   2,  92, 124, 104,  44,  75,  97, 121,  14,  97,  81,  36,\n",
      "         54, 104,  97,  75,  47,   0,   0,   0,   0,   0,   0,  76,  76, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 158, 151,  36,  18,  75,  24,  14,\n",
      "         53,  42], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 03:17:47# predicted of 105000: tensor([125,  60, 164,  31,  57,  49, 162, 121,  97,  55, 163,  14,  53,  42,\n",
      "         49, 104, 162, 109, 104,   0,   0,   0,   0,   0,   0,  76, 157, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160,  55, 116,  33,   9,  34, 112,  14,\n",
      "         55,  53], device='cuda:0') torch.Size([44])\n",
      "10/11/2023, 03:18:56# total batches: 108800\n",
      "10/11/2023, 03:18:56# Epoch 8 | Train Loss: 3.0468 | Train Accuracy: 0.2428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0436582e05d948838a5100a7268d57d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:18:56# labels of Validation: tensor([ 52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  65,\n",
      "         65,  65,  65,  65, 135, 135,  61,  61,  61, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161,  14,  98, 148, 148, 148, 148, 148, 148, 148,\n",
      "         62,  62,  62,  62,  62,  62, 104,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  14,  73,  73,  73,  96,  96,  96,  96,\n",
      "         96,  96,  67,  67,  67,  67,  67, 145, 145, 145, 145, 145, 145, 122,\n",
      "        122, 122, 122, 122, 122, 122, 116,   5,   5,   5,   4, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132,  71,  71,  71,  71,  71,  71,  27,  27,  27, 147,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147, 111,   4,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  69,  69,  69,  69,  69,  69,  45,  45,\n",
      "         45,  79,  79, 146, 146, 146, 146, 146, 146, 158], device='cuda:0') torch.Size([682])\n",
      "10/11/2023, 03:18:56# predicted of Validation: tensor([ 52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  65,\n",
      "         65,  65,  65,  65, 135, 135,  61,  61,  61, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161,  97,  98, 148, 148, 148, 148, 148, 148, 148,\n",
      "         62,  62,  62,  62,  62,  62,  57,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82, 162,  73,  73,  73,  96,  96,  96,  96,\n",
      "         96,  96,  78,  78,  78,  78,  78, 145, 145, 145, 145, 145, 145, 122,\n",
      "        122, 122, 122, 122, 122, 122,  18,   5,   5,   5, 116, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132,  71,  71,  71,  71,  71,  71,  27,  27,  27, 147,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147, 163, 104,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  69,  69,  69,  69,  69,  69,  45,  45,\n",
      "         45, 109,  79, 146, 146, 146, 146, 146, 146,  92], device='cuda:0') torch.Size([682])\n",
      "10/11/2023, 03:18:56# labels of 0: tensor([ 52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  65,\n",
      "         65,  65,  65,  65, 135, 135,  61,  61,  61, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161,  14,  98, 148, 148, 148, 148, 148, 148, 148,\n",
      "         62,  62,  62,  62,  62,  62, 104,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  14,  73,  73,  73,  96,  96,  96,  96,\n",
      "         96,  96,  67,  67,  67,  67,  67, 145, 145, 145, 145, 145, 145, 122,\n",
      "        122, 122, 122, 122, 122, 122, 116,   5,   5,   5,   4, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132,  71,  71,  71,  71,  71,  71,  27,  27,  27, 147,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147, 111,   4,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  69,  69,  69,  69,  69,  69,  45,  45,\n",
      "         45,  79,  79, 146, 146, 146, 146, 146, 146, 158], device='cuda:0') torch.Size([682])\n",
      "10/11/2023, 03:18:56# predicted of 0: tensor([ 52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  65,\n",
      "         65,  65,  65,  65, 135, 135,  61,  61,  61, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161,  97,  98, 148, 148, 148, 148, 148, 148, 148,\n",
      "         62,  62,  62,  62,  62,  62,  57,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  82,  82,  82,  82, 162,  73,  73,  73,  96,  96,  96,  96,\n",
      "         96,  96,  78,  78,  78,  78,  78, 145, 145, 145, 145, 145, 145, 122,\n",
      "        122, 122, 122, 122, 122, 122,  18,   5,   5,   5, 116, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132,  71,  71,  71,  71,  71,  71,  27,  27,  27, 147,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65, 147, 147, 147, 147, 163, 104,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128,  69,  69,  69,  69,  69,  69,  45,  45,\n",
      "         45, 109,  79, 146, 146, 146, 146, 146, 146,  92], device='cuda:0') torch.Size([682])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:19:08# Validation Loss: 0.2415 | Validation Accuracy: 0.9493\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f3abbedffb415999bc652acdc4f050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:20:37# labels of 5000: tensor([151,  18, 143,  33,  14,  24,  83, 144,  57, 112,  48, 109,  11,  76,\n",
      "         24,   9, 116,   9, 119, 142, 163, 157,  83,  11,  42, 119,  12,  34,\n",
      "        163,  14,  48, 116], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:20:37# predicted of 5000: tensor([ 87,  87,  49,  33, 109,  60,  60, 116, 109,  75,   9, 109, 142,  76,\n",
      "         11,  74, 116, 163,  75, 152, 162,  60, 152,  47, 164, 116,  14,  92,\n",
      "        164,  81,  24, 116], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:22:06# labels of 10000: tensor([ 92,  30, 164,  60,  57,  44, 157,  14, 162, 112,  34, 164,   2,   4,\n",
      "         60,   1,  55,  81,  38,  92,   1, 152, 112,  18, 144,  75,  47,  49,\n",
      "         18,  81,  14,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:22:06# predicted of 10000: tensor([ 42, 131, 150,  97,  44,  83,  12,  53, 152, 152,   9, 116, 150,  12,\n",
      "        143, 125,  47, 124, 125,  92,  42,  49, 163, 157, 112,  44,  75,  97,\n",
      "         92, 157, 150,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:23:34# labels of 15000: tensor([112,  14,  36, 143, 111, 151,  83,  53,  97,  42,  48, 112, 125,  57,\n",
      "         76,  83,  33,   9, 125, 152,  38,  30, 143,  14, 143,   4, 164,  49,\n",
      "          4, 143, 158, 144], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:23:34# predicted of 15000: tensor([ 97,  74,  81,  47, 164,  75,  76,  53,  97,   2,  12,  38,  54, 157,\n",
      "        162,  47, 157,  33, 162,  44,  47, 125, 143,  24, 158,  34,   2,  47,\n",
      "          4,  38,  57,  33], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:25:01# labels of 20000: tensor([ 97,  31,   4,  47,  31,  76,  49,  74, 150,   4, 111,  74, 150, 100,\n",
      "        100, 100, 100, 100, 100,  75,  57,  48,   9, 151,  18,  53,  74, 112,\n",
      "         87,  49,   2,   9,  87,  75,  11,  83,  75], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:25:01# predicted of 20000: tensor([150, 152,  33,  55, 164,  12,  97, 152,  34,  54, 163, 158, 142, 100,\n",
      "        100, 100, 100, 100, 100,  31,  55,  18, 112,  76,  18,  53,   4,  76,\n",
      "        144,  76, 104,  14, 121,  75,  83,   2, 143], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:26:28# labels of 25000: tensor([162, 142,  60, 162, 144, 112, 111,  47, 109,  76,  33,   4,  30,  53,\n",
      "        152,  87,  81,  47, 116,  47,  60,  36,  60,  97,   4, 111, 157, 112,\n",
      "        162,  55,  47,  47], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:26:28# predicted of 25000: tensor([ 74,   4, 124, 124,  36,  53, 112,  55,  92, 124,  33,  76,  30,  31,\n",
      "        157,  97,  97,   1,  92,  11, 121,  14, 157,  97,  33, 119, 119,  48,\n",
      "         47,  30,   2,  30], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:27:58# labels of 30000: tensor([ 76,  60,  49,  88,  88, 112, 162,  42,  47, 144,  33, 111,  30,  92,\n",
      "         49,  81,  44,  31,  60,  92, 124, 112, 158, 121,  44, 125, 157, 152,\n",
      "         33, 104, 164,  11, 125], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 03:27:58# predicted of 30000: tensor([ 57,  12,  54,  31,  31, 119,  55,  55,  30, 143,  11,  53,  53,  48,\n",
      "         53, 119,  34, 116,  60, 151,  53,  53,  18, 163,  55,  18,  75,  18,\n",
      "         38, 104, 142, 158,  83], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 03:30:00# labels of 35000: tensor([ 31,  81,  87,  34, 109,  97, 151,   9, 142, 157, 112,   9,  36,   1,\n",
      "        111, 125, 150,  11,   1, 164,   2,  44,  75, 116, 164,  97,  33, 109,\n",
      "          2,  12, 150,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:30:00# predicted of 35000: tensor([164, 157,   2,  33, 124,  33, 163,  44, 157,  42, 143,  97, 119,   1,\n",
      "         42,  75, 121, 157,   1,  57,  53, 150,  55,  11, 164,  97,  53, 109,\n",
      "        116,  76, 124,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:31:27# labels of 40000: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  47, 119, 124,  34,\n",
      "          9,  47,  75,  53, 119,  60,  33,  81, 124, 164,  83, 142, 142,  24,\n",
      "         74,   4,  24,  18,  30,  75, 119, 162,  97,  97, 119, 157,  49],\n",
      "       device='cuda:0') torch.Size([181])\n",
      "10/11/2023, 03:31:27# predicted of 40000: tensor([161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161, 161, 161, 161, 161,  83, 112, 162,  54,\n",
      "         76,  83, 162,  47, 119,  24,  76,  87, 124,  92, 142,  97, 163,  14,\n",
      "         47, 152,  14,  18, 142, 109, 163, 162,  75,  55,  33, 121,  55],\n",
      "       device='cuda:0') torch.Size([181])\n",
      "10/11/2023, 03:32:58# labels of 45000: tensor([164, 143,  53,  11, 104,  36,  48, 144,  38,  60,  57,  75,  34, 121,\n",
      "        150, 104, 157, 121, 109,  87, 125,   9,  48,  76, 116,  33,   1,  44,\n",
      "         11,  31, 121,  87], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:32:58# predicted of 45000: tensor([ 83, 162,   4,  30, 125, 125, 116,  87, 164,  92, 150,  38, 164,  30,\n",
      "         53, 151, 162,  14,  11,  87,  34,  76, 162,  74, 163,  11,  36,  47,\n",
      "        121, 163, 111, 163], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:34:27# labels of 50000: tensor([152,  53,  53,  60, 116,  54,  48,  42,  36, 163,  31, 162,  47,  31,\n",
      "        109, 143,  55,  14,  53, 151,  87,  48,   4,  47, 151, 163,  55, 111,\n",
      "        111,  36,  53,   4], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:34:27# predicted of 50000: tensor([ 76, 125,  44, 144, 163, 150,  42,  24,  74, 163,  83,  83,  75, 143,\n",
      "        150, 112,  55,  33,  11,  53,  30, 116,  30,  83, 164, 124,  55, 144,\n",
      "         76, 112,  33,  55], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:35:54# labels of 55000: tensor([ 38, 164, 157,  57,  42,  97, 158,  60, 112,  87,  48,  47,  34,  20,\n",
      "         20, 150,  49, 112,  87,  54,  33, 158, 125, 119,  30, 125,  48,  47,\n",
      "        150, 162, 151,  75,  83], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 03:35:54# predicted of 55000: tensor([ 76, 112,  47,  38,  24,  97, 142, 162,  30,  31, 164,  14,  49,  20,\n",
      "         20, 152,  49,  33,  42, 125, 162,  30, 150,  74, 151,  33,  81,  47,\n",
      "         31,  49, 104,  30,  48], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 03:37:24# labels of 60000: tensor([ 12, 144,  36,  55,  87,  53, 109, 109, 152, 125, 158, 162,  18,  81,\n",
      "         97,  54,  75, 124, 150, 164,  33, 111, 164,  11,  83, 143,   1,  33,\n",
      "         47,   2, 164,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:37:24# predicted of 60000: tensor([121, 125,   2, 104,  31,  92,  34,  34, 142, 125, 104,  81, 152,  81,\n",
      "        104, 119, 157,  92, 158,  54,  81, 157,  33, 119,  92,  11,  87, 163,\n",
      "        119,  49,  34,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:38:52# labels of 65000: tensor([109, 121, 143,  14, 157,   4,  18,  92,  30,  33,  54,  54, 125,  44,\n",
      "          2,   1,  34,   4,  24,  12, 150, 121,  38, 152,  76, 143,  36,  18,\n",
      "          1,  47,  60,  14], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:38:52# predicted of 65000: tensor([ 75,  36, 162,  57,  44,   4,  12, 163,  11, 150,  60,  49,  55,  57,\n",
      "        124,  47,  12,  81,  76,  18, 150, 112,  55,  76,  55,   9,  81,   9,\n",
      "        163,  92,  24,  97], device='cuda:0') torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:40:22# labels of 70000: tensor([112,  53,  14,  81, 163,  48, 121, 152,   4, 124,  49,  31,  47,  14,\n",
      "        158,   1,  75, 111, 151, 109, 164,  44, 162,  76,  60, 124, 121,  11,\n",
      "        125,   9, 157,  44], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:40:22# predicted of 70000: tensor([152,  34, 157,  30, 163,  97, 125,  30,  44, 131,  55,  47,  49,  74,\n",
      "        121,  11, 162, 111,   1,   2, 119,  83, 152,  12, 104, 142, 121,  42,\n",
      "        158,  24, 112,  34], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:41:50# labels of 75000: tensor([ 54,  75,  60,  49,  49,  81,  74,  36,  38,  55,  47,  75,  36, 121,\n",
      "        150, 158, 162,  57,  12,  44, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "         47,  42, 121,  38, 111, 104,  47, 143, 119,  33,  36],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 03:41:50# predicted of 75000: tensor([ 87, 163,  47, 163,  36, 158, 112,  12, 158,  24, 163,  75,  76, 112,\n",
      "        164,  87, 162,  24, 158,  12, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "         47,  38,  18,  42,   2,  42,  47, 164,  12, 119, 152],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 03:43:18# labels of 80000: tensor([143,  49,  92,  44,  55,  97,  83,  53,  11,  57,  55, 150,  74,  18,\n",
      "         24,  49, 142, 157,  97,  33, 109, 112,  24,  76, 152,  60,  81,  74,\n",
      "         34, 151,  83, 158], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:43:18# predicted of 80000: tensor([ 57,  47, 142, 116,  33, 116,  53, 112,  36, 158,   9, 109, 121,  92,\n",
      "         18,  83,  83, 157, 125,  24,  97, 151, 121,  81, 152,  92,  81,  54,\n",
      "         47,  83, 152,  42], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:44:46# labels of 85000: tensor([ 54, 143,  49, 116,  87,  97, 104, 112, 163, 151,  31,  11, 150,  55,\n",
      "         31,  54, 142,  34, 163, 111,  24,   4,   1, 163,  31,  31, 152, 125,\n",
      "          2,  24,  36,  14], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:44:46# predicted of 85000: tensor([125, 111,  42, 116,  92,  55,  42, 164,  34,  42, 124,   1, 150,  42,\n",
      "        162, 142, 157,  34, 163, 144,  36,  36,  30,  48,  92,  97,  83,  76,\n",
      "         30, 104,  87,  11], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:46:17# labels of 90000: tensor([  4,  11,  42,   2, 164,  59,  59,  59, 119,  81,  24, 158, 157,  60,\n",
      "         18,  76,   1, 124,  97,  55,  57,  34, 150, 150,  49,  34, 119, 163,\n",
      "         53,  57,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 158,  38, 112], device='cuda:0') torch.Size([60])\n",
      "10/11/2023, 03:46:17# predicted of 90000: tensor([ 30,   2,  81, 116, 157,  49,  49,  49,  38, 152,  34, 142,  34,   9,\n",
      "         57,  44,  81,  38,  87, 150, 119,  18,  55,  36,  49,  49, 125,  83,\n",
      "         60, 163,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149,  81, 152,   2], device='cuda:0') torch.Size([60])\n",
      "10/11/2023, 03:47:44# labels of 95000: tensor([ 24, 164,  33,  48,  42,  11,  87, 111,   4, 125,  47, 152, 152, 142,\n",
      "        121, 116, 112, 124,  92, 151, 142,  60,  57,  42,   2,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135,  30,   2, 157, 158,  92,  48],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 03:47:44# predicted of 95000: tensor([ 74, 163, 163,  92,  60,  81, 108,  76, 163, 125,   9,  48, 111, 157,\n",
      "        121,  76, 111,  49,  36,  34, 109,  76,  55, 152,  18,  65,  65,  65,\n",
      "         65,  65,  65, 135, 135,  30,  81,  81,  48,  38,  60],\n",
      "       device='cuda:0') torch.Size([39])\n",
      "10/11/2023, 03:49:21# labels of 100000: tensor([142,  55,  81, 142,  36, 124,  92,  11,  81,  30,  12,  34, 151,  57,\n",
      "        124, 122, 122, 122, 122, 122, 122, 122, 112,  83, 151,  53,  53, 121,\n",
      "        104,   1,  44,  57, 150,  31,  97,   9, 142,  81], device='cuda:0') torch.Size([38])\n",
      "10/11/2023, 03:49:21# predicted of 100000: tensor([ 55, 125, 142,  31,  92,   4, 124, 142,  92, 157,  24, 163, 158, 152,\n",
      "         47, 122, 122, 122, 122, 122, 122, 122,  92,  54, 142,  54,  53,   9,\n",
      "        144,  97, 152,  18, 150,  38,  97, 152,  42, 142], device='cuda:0') torch.Size([38])\n",
      "10/11/2023, 03:50:48# labels of 105000: tensor([ 42, 144, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 158,  12,  53,  49,  54, 142,\n",
      "         38,  87, 121, 109,  53, 104, 116,  34,  14, 121, 163,  97, 150, 164,\n",
      "         92,  31,  38, 116, 164, 124,  34,  55, 109], device='cuda:0') torch.Size([51])\n",
      "10/11/2023, 03:50:48# predicted of 105000: tensor([  2,  34, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 164, 163,  47,  76,  33,  92,\n",
      "        121,  38, 162,  34, 119, 164,  30, 104, 150,  34, 144,  54,  54,  14,\n",
      "        112,  31,  38, 162,  34, 151,  11, 151, 119], device='cuda:0') torch.Size([51])\n",
      "10/11/2023, 03:51:59# total batches: 108800\n",
      "10/11/2023, 03:51:59# Epoch 9 | Train Loss: 3.0426 | Train Accuracy: 0.2438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4668d3afb9c547f38275df24703adbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:51:59# labels of Validation: tensor([ 29,  29,  29,  29,  29,  29,  29,  29,  29,  29, 120, 120, 120, 120,\n",
      "        120, 120, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 150, 151,  88,  88,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,  72,  72,  33,  50,  50,  50,  13,  13,  13,  13,  13, 102,\n",
      "        102, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154,  73,  73,  73,  95,  95,  95, 152, 125, 166,\n",
      "        166, 166, 166, 166, 166,  93,  93,  81,  44,  45,  65,  45,  45,  43,\n",
      "         43,   9,  65,  46,  46, 112, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 125, 144,\n",
      "        112, 136, 136, 136, 136, 136, 136, 136, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105, 105], device='cuda:0') torch.Size([371])\n",
      "10/11/2023, 03:51:59# predicted of Validation: tensor([ 29,  29,  29,  29,  29,  29,  29,  29,  29,  29, 120, 120, 120, 120,\n",
      "        120, 120, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 124,  36,  38,  38,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,  72,  72, 109,  50,  50,  50,  13,  13,  13,  13,  13, 102,\n",
      "        102, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154,  73,  73,  73,  95,  95,  95,  60,  14, 166,\n",
      "        166, 166, 166, 166, 166,  34,  34,  60, 150,  45,  65,  45,  45,  43,\n",
      "         43, 142,  65,  46,  46,  34, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,  87,  18,\n",
      "         34, 136, 136, 136, 136, 136, 136, 136, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105, 105], device='cuda:0') torch.Size([371])\n",
      "10/11/2023, 03:51:59# labels of 0: tensor([ 29,  29,  29,  29,  29,  29,  29,  29,  29,  29, 120, 120, 120, 120,\n",
      "        120, 120, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 150, 151,  88,  88,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,  72,  72,  33,  50,  50,  50,  13,  13,  13,  13,  13, 102,\n",
      "        102, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154,  73,  73,  73,  95,  95,  95, 152, 125, 166,\n",
      "        166, 166, 166, 166, 166,  93,  93,  81,  44,  45,  65,  45,  45,  43,\n",
      "         43,   9,  65,  46,  46, 112, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 125, 144,\n",
      "        112, 136, 136, 136, 136, 136, 136, 136, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105, 105], device='cuda:0') torch.Size([371])\n",
      "10/11/2023, 03:51:59# predicted of 0: tensor([ 29,  29,  29,  29,  29,  29,  29,  29,  29,  29, 120, 120, 120, 120,\n",
      "        120, 120, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 124,  36,  38,  38,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,  72,  72, 109,  50,  50,  50,  13,  13,  13,  13,  13, 102,\n",
      "        102, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154, 154,  73,  73,  73,  95,  95,  95,  60,  14, 166,\n",
      "        166, 166, 166, 166, 166,  34,  34,  60, 150,  45,  65,  45,  45,  43,\n",
      "         43, 142,  65,  46,  46,  34, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,  87,  18,\n",
      "         34, 136, 136, 136, 136, 136, 136, 136, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 105, 105, 105], device='cuda:0') torch.Size([371])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:52:11# Validation Loss: 0.2385 | Validation Accuracy: 0.9493\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922563d2e4b84e65aec512bfdb275b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/108800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 03:53:41# labels of 5000: tensor([164, 109, 111, 109, 150,  54,  55,  31,   1,  48,  11, 162, 163, 142,\n",
      "         97,   4,  65, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 142,  11,  24,   1,  44,  83,  24,  42,  18, 112,\n",
      "          1,  49,  60, 142,  53], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 03:53:41# predicted of 5000: tensor([152, 109,  47,  55, 116, 111,  14, 109,  53,   1,  97, 162,  55,  87,\n",
      "        104,  92,  65, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123,  54, 109,  55,  53, 163,  75,  30,  24,   1, 119,\n",
      "         60,  49, 158,  18,  87], device='cuda:0') torch.Size([47])\n",
      "10/11/2023, 03:55:07# labels of 10000: tensor([ 48,  31,  44, 125, 109,  48, 163,   2,  44,  18,  36,  48,  75,  12,\n",
      "         33, 151,  87,  31,  44,  47,  83, 111, 143,  57, 112,  33, 104,  55,\n",
      "         36,  31, 146, 146, 146, 146, 146, 146, 109], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:55:07# predicted of 10000: tensor([ 48,  76,   4,   1,   4,  53,  60,  36, 116, 109, 116,  87,  81, 152,\n",
      "         12, 151,  14,  87,  30,  12,  31, 112,  87, 143,   4,  33,  57,  48,\n",
      "        158, 112, 146, 146, 146, 146, 146, 146, 109], device='cuda:0') torch.Size([37])\n",
      "10/11/2023, 03:56:35# labels of 15000: tensor([ 60, 109,  36, 112,  12,  53, 109, 142, 157, 151, 158,  38, 112,  47,\n",
      "        111,   9,  97, 157,   9,   2,  38,  54,  57,  36,  92, 150,  47,  34,\n",
      "        150,  11, 104,  31], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:56:35# predicted of 15000: tensor([162,  60, 151,  30, 157, 157, 119, 163, 150, 143, 142,  38,  87, 112,\n",
      "         33, 125,   2,  18,   1,  36, 121,  92,   1,  55,  42,  44,  75,   1,\n",
      "         14,  47,  55,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:58:05# labels of 20000: tensor([ 54,  53,  34, 150,  75, 121,  47,  31, 112,  30, 116,  36,  18, 124,\n",
      "        162, 119, 116,  83,   9, 112, 164, 144,  75,  30,   4,   9, 162,  55,\n",
      "        151,  57,  60,  57], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:58:05# predicted of 20000: tensor([125,   4, 125,  44,  75,   1,  53,  33,  34, 163,   1,  33, 163,  60,\n",
      "         49, 104,  81,  83, 152,  47,  47,  92,  47,  83, 150,   1,   1,  81,\n",
      "        143,  55, 119,   1], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 03:59:31# labels of 25000: tensor([ 83,  57,  83, 162,   1,  34, 109,  30,  42,  33,  44,  81, 112,  97,\n",
      "         10,  10,  74, 125,  60, 104,  75,  81, 162,  18,  36,  34, 116,  44,\n",
      "         53, 116,  38,  30,   9], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 03:59:31# predicted of 25000: tensor([ 83, 152,  49,   4, 142, 157, 158, 116, 164,  53, 142, 116, 112,  87,\n",
      "         10,  10,   4,  30, 116,  54,  92, 112,  30, 124, 158, 158, 150, 157,\n",
      "        112, 142,  36,  30,  31], device='cuda:0') torch.Size([33])\n",
      "10/11/2023, 04:01:03# labels of 30000: tensor([119,  60,  12,   1,  44,  31,  54,  53, 109,  47,  42,   9, 152,  30,\n",
      "         76, 121, 150,  34,  83,  18,  49,  55, 119,  38, 119,  60,  57, 116,\n",
      "         83, 111,  30, 109], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:01:03# predicted of 30000: tensor([119,  48,  81,  38,  44, 116, 151,  12, 119,  31, 142, 150,  81,  55,\n",
      "        150, 150, 152,  53, 150, 104,  53,  47, 119,  53,  44,  33,  57,  53,\n",
      "        151, 152,  75, 119], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:02:30# labels of 35000: tensor([ 81, 158, 111,  36,  33,   2,  44, 164, 142,  53,  55, 124,  81, 150,\n",
      "        116,  12, 121, 109,  75, 121,  14, 143, 162,  11,  48,  92, 111, 142,\n",
      "        112,  60,  97, 125], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:02:30# predicted of 35000: tensor([ 76, 142,  11,  92, 124, 150,  33, 163,   9,  75,  49, 157,  12,  47,\n",
      "         11,  75,  81,  47,  12, 163,  97,  87, 124,  12,  18, 144,  42,  30,\n",
      "         55, 158,  57, 150], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:03:58# labels of 40000: tensor([ 97,  81,   9,  14, 124,  38,  81,  55, 162, 152,  55, 143,  30,  42,\n",
      "         12, 116, 143,  14,   9,  49,  33, 104,  76, 131, 131, 131, 131, 131,\n",
      "         92, 162, 112, 162, 104,  33,  18,  12], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 04:03:58# predicted of 40000: tensor([ 97,  42,   9,  14, 124, 162, 163, 152,  24, 162,  92,  14, 162, 109,\n",
      "          9,   2,  57,  57,   9, 164, 124,  30, 119, 131, 131, 131, 131, 131,\n",
      "        143, 119, 112,  57,  18,  81,  49,  76], device='cuda:0') torch.Size([36])\n",
      "10/11/2023, 04:05:24# labels of 45000: tensor([ 87,  14,  92, 144,  36,  83,  57,  83, 112,   2, 116,   2, 151, 151,\n",
      "        150, 163,  30, 158,  54, 125,  42, 157,   9,  55,  42,  24, 124,   2,\n",
      "         60,  81, 119,  36], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:05:24# predicted of 45000: tensor([  1,  76,  60, 121, 158, 142, 151,  87, 104,   1,  49,  83, 158,  11,\n",
      "        124, 144,  60,  60,  74,  31, 164,  97,  48, 163,  33,  24,  30,  87,\n",
      "         31,   1,  83, 163], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:06:51# labels of 50000: tensor([ 47,  48,  74,  74,  81,  34,  34, 116,  97,  53,  38,  42,   1,  83,\n",
      "          1,  48,  48,  38,  48,  11, 125,  24,  34,  12, 151,  14,  97,  47,\n",
      "         60,  74,  38,  75], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:06:51# predicted of 50000: tensor([ 47,  57,  47,  83,  33,  47,  57, 164, 158, 116,   2, 119, 119, 152,\n",
      "         53, 152, 125,  38,  47,  53, 104,  74,  38,  12,  42,  55,   1, 152,\n",
      "        157,  87,  76,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:08:18# labels of 55000: tensor([ 30, 158, 111,  92, 111,   2, 143, 119,   2,   1, 143, 124, 158,  60,\n",
      "          4,  49,  97, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156, 164,\n",
      "         83, 104, 163, 164, 151,  44, 125, 109, 119,  53,  44, 162,  64,  64],\n",
      "       device='cuda:0') torch.Size([98])\n",
      "10/11/2023, 04:08:18# predicted of 55000: tensor([ 92, 112,  75,  92,  42, 162,  33,  87,  24, 143,  34,  18,  92,  55,\n",
      "         33, 152,  54, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156,  92,\n",
      "         31,   1, 163, 152, 151,   9,  36,  76,  76,  31,   4,  55, 152, 152],\n",
      "       device='cuda:0') torch.Size([98])\n",
      "10/11/2023, 04:09:47# labels of 60000: tensor([ 12, 125, 111, 147,  65,  65,  65,  65,  65, 147, 147, 147, 147,  75,\n",
      "        121,  12,  33,   9,  97, 116,  48, 119,   2,  18,  30,  55,  81,  31,\n",
      "          1,  18,  81, 124,  47, 124,  44, 112, 152, 121,  83,  38,  48],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 04:09:47# predicted of 60000: tensor([ 24, 125,  75, 147,  65,  65,  65,  65,  65, 147, 147, 147, 147,   1,\n",
      "        121, 121,  81,  47, 119,   1,  48, 163,  30, 119, 125,  55,  55,  83,\n",
      "          1,  14,  74, 131, 164, 116,  60,  92,  55,  60,  74,  12,   1],\n",
      "       device='cuda:0') torch.Size([41])\n",
      "10/11/2023, 04:11:17# labels of 65000: tensor([ 55,   9,  14, 116,  48,  18,  74,  47,  14, 157, 151,  11,   9, 163,\n",
      "         48,  47, 121,  49,  60,  36,  42,   2,  38, 162,  42,  92,  34,  48,\n",
      "        136, 136, 136, 136, 136, 136, 136, 121, 157, 162], device='cuda:0') torch.Size([38])\n",
      "10/11/2023, 04:11:17# predicted of 65000: tensor([ 34,   2,  14, 116,  48,  34, 109, 164, 151, 144,  55,  11, 121,  31,\n",
      "         81,  97,  75,  11,  38,   4,  30,  38, 157,  97,  53, 116,  42,  54,\n",
      "        136, 136, 136, 136, 136, 136, 136,  75, 163, 162], device='cuda:0') torch.Size([38])\n",
      "10/11/2023, 04:13:16# labels of 70000: tensor([ 55,  55, 164, 162,  75,  54,  36,  60,  57,  87,   4,  14,  97, 112,\n",
      "         75,  75, 143, 119,   2,  74,  55,  76,  92, 121,  47,   1, 111,   1,\n",
      "        124,  36,  34,   2], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:13:16# predicted of 70000: tensor([ 55, 163, 116, 163, 152, 124,  30,  24,  57, 111,  83,  48,  97,  92,\n",
      "        157,  34, 144,   1,  87,  38, 151,  83,  92,   4,  31,   1,  47,  55,\n",
      "          2, 125, 119, 124], device='cuda:0') torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:14:44# labels of 75000: tensor([ 18,   4, 116,  47,   1, 142, 119, 116, 104,  83,  53, 121,  87,  24,\n",
      "         47,  97,  87,  18,  49,  49, 119,  55, 125,  47,  57, 104,   2, 162,\n",
      "         75,  11,  44,   9], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:14:44# predicted of 75000: tensor([  1,   4, 116,   1,   1,  54,  97, 152,  81,  74,  31, 162,  49,   4,\n",
      "         14, 112,  92,  92, 151,  87, 143,  55,  34, 150,  49, 104,  34, 162,\n",
      "         54, 164,  44,  81], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:16:12# labels of 80000: tensor([158,  14,  57,  81,  55,  33,  47,  30,  34,  49,  14,  55,  14,  81,\n",
      "         60,  48,   4, 121,   2,  38,  97,  75,  74, 157,  83, 111,  33, 112,\n",
      "         60,  54,   9,  97], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:16:12# predicted of 80000: tensor([  1, 121,  57,  18,  55,  81,  55,  11, 143, 152,  14,  55, 124, 125,\n",
      "         12, 121,  47, 121, 152,  38,  55, 121,   2,  49, 142,  14,  31,  18,\n",
      "         74,  97,  30,  83], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:17:38# labels of 85000: tensor([ 49,  76,  42,  48,  81,  92,  74,  87,  57, 104,  57,  81,  57, 125,\n",
      "        121, 163,  49,  38,  48,  91,  91,  91,  18, 104,  48, 121,  33, 124,\n",
      "          9,  53,  30,  76, 157, 151], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 04:17:38# predicted of 85000: tensor([ 42, 121,  55,  48, 152,  38, 109, 164,  38,  55,  81,  57, 109,  74,\n",
      "        152,  34,  60,  38, 158,  74, 162,  74,  47,  48,  87,  76, 162, 112,\n",
      "        112, 143,  38,  14, 150, 150], device='cuda:0') torch.Size([34])\n",
      "10/11/2023, 04:19:07# labels of 90000: tensor([112,   1,  54, 111,  97,  12,  38,  42,  42,   2,  38,  57,  54, 121,\n",
      "        111, 142, 104,  34, 151,  53,  34,  60,  92,  42,  12,  83,  47,  75,\n",
      "        111, 142, 124, 164], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:19:07# predicted of 90000: tensor([ 92, 109,  47, 119,  53, 125,  76,  97,  60, 125,  31,  74, 152,  81,\n",
      "        158,   4,  36, 119, 125, 109,  97, 158,   1,  18,  30,  18,  47,   4,\n",
      "        124, 163,   1, 144], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:20:35# labels of 95000: tensor([  1,  33, 163, 150,  75, 112,  83, 162,   1,  12,  11, 158,   1, 164,\n",
      "         42,  97,  87,  12,  42,  60,  87,  36, 150,  74,  36,  14, 125,  18,\n",
      "        112,   9, 111,  92], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:20:35# predicted of 95000: tensor([116,  48, 124,  47,  74, 109, 162,  33,  92, 121,  87, 116,  33, 157,\n",
      "          1,  97,  87,  33, 152,  54,  87, 109, 158,  74, 151,  87, 125,  18,\n",
      "        158,  76,  34, 109], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:22:05# labels of 100000: tensor([124,  57, 152,  42,  53, 144, 143,  42,  12, 112,  83,  55,  49, 150,\n",
      "          2, 151, 142,  11,  42, 144, 151,  87,  97,   2,  83,  49, 109, 150,\n",
      "        124,  31,   1, 164], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:22:05# predicted of 100000: tensor([121,  75, 109,  60,  75, 109, 163, 150,   4,  54,  92, 124,  11,   1,\n",
      "        112,  74, 142,   4,  42,  30,  34, 142,  92,   4, 163,  47, 109,  31,\n",
      "         38,  33, 142, 163], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:23:33# labels of 105000: tensor([158,  83, 164, 150,  44,  24, 125, 144,   9, 142,  75, 163, 152,  81,\n",
      "         33,  48,  74, 111,   9,  30,  44,  30, 162,   4, 124,  54, 104,  31,\n",
      "        121, 152, 116, 150], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:23:33# predicted of 105000: tensor([112,  34,  54, 152,  87, 163, 125,  55, 111, 104,   9, 150, 119, 152,\n",
      "        163,  97, 112, 111,   1,  55,  38, 121,  76,  18,  81,  30,  42,  18,\n",
      "        150,  42,  34, 143], device='cuda:0') torch.Size([32])\n",
      "10/11/2023, 04:24:40# total batches: 108800\n",
      "10/11/2023, 04:24:40# Epoch 10 | Train Loss: 3.0275 | Train Accuracy: 0.2470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300555b444954e7c8ffbac5ab0447a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:24:40# labels of Validation: tensor([ 50,  50,  50, 150, 146, 146, 146, 146, 146, 146,  59,  59,  59, 129,\n",
      "        129, 129, 129, 129, 129, 129,  76, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 163,   5,   5,   5, 158,  53, 158,  11,   4,\n",
      "         80,  80,  80,  80,  80,  80,  91,  91,  91,   0,   0,   0,   0,   0,\n",
      "          0,  78,  78,  78,  78,  78,  43,  43,  72,  72,  19,  19,  19,  19,\n",
      "         19, 120, 120, 120, 120, 120, 120, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        106,  61,  61,  61,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141, 119, 145, 145, 145, 145, 145, 145,  63,\n",
      "         63,  63,  63,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
      "         62,  62,  62,  62,  62,  62, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
      "       device='cuda:0') torch.Size([699])\n",
      "10/11/2023, 04:24:40# predicted of Validation: tensor([ 50,  50,  50,   1, 146, 146, 146, 146, 146, 146, 162, 162, 162, 129,\n",
      "        129, 129, 129, 129, 129, 129, 152, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 109,   5,   5,   5,  42, 125,  54,  18,  53,\n",
      "         80,  80,  80,  80,  80,  80,  76,  76,  76,   0,   0,   0,   0,   0,\n",
      "          0,  78,  78,  78,  78,  78,  43,  43,  72,  72,  19,  19,  19,  19,\n",
      "         19, 120, 120, 120, 120, 120, 120, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        106,  61,  61,  61,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141,  53, 145, 145, 145, 145, 145, 145,  63,\n",
      "         63,  63,  63,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
      "         62,  62,  62,  62,  62,  62, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
      "       device='cuda:0') torch.Size([699])\n",
      "10/11/2023, 04:24:40# labels of 0: tensor([ 50,  50,  50, 150, 146, 146, 146, 146, 146, 146,  59,  59,  59, 129,\n",
      "        129, 129, 129, 129, 129, 129,  76, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 163,   5,   5,   5, 158,  53, 158,  11,   4,\n",
      "         80,  80,  80,  80,  80,  80,  91,  91,  91,   0,   0,   0,   0,   0,\n",
      "          0,  78,  78,  78,  78,  78,  43,  43,  72,  72,  19,  19,  19,  19,\n",
      "         19, 120, 120, 120, 120, 120, 120, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        106,  61,  61,  61,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141, 119, 145, 145, 145, 145, 145, 145,  63,\n",
      "         63,  63,  63,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
      "         62,  62,  62,  62,  62,  62, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
      "       device='cuda:0') torch.Size([699])\n",
      "10/11/2023, 04:24:40# predicted of 0: tensor([ 50,  50,  50,   1, 146, 146, 146, 146, 146, 146, 162, 162, 162, 129,\n",
      "        129, 129, 129, 129, 129, 129, 152, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165, 165, 109,   5,   5,   5,  42, 125,  54,  18,  53,\n",
      "         80,  80,  80,  80,  80,  80,  76,  76,  76,   0,   0,   0,   0,   0,\n",
      "          0,  78,  78,  78,  78,  78,  43,  43,  72,  72,  19,  19,  19,  19,\n",
      "         19, 120, 120, 120, 120, 120, 120, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        106,  61,  61,  61,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
      "         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141,  53, 145, 145, 145, 145, 145, 145,  63,\n",
      "         63,  63,  63,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
      "         62,  62,  62,  62,  62,  62, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118],\n",
      "       device='cuda:0') torch.Size([699])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:24:50# Validation Loss: 0.2396 | Validation Accuracy: 0.9496\n",
      "\n",
      "10/11/2023, 04:24:50# ============================== Early stopping ==================================\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "\n",
    "seed = 5269\n",
    "same_seeds(seed)\n",
    "\n",
    "# model = GraphSAGE(in_dim=50, hidden_dim=16, out_dim=167)\n",
    "model = Model(in_features=50, hidden_features=64, out_features=128, num_classes=167)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model3_initial(graphsage)/initial_weight.pth'))\n",
    "best_model_path = \"../checkpoint_graphSAGE/best_model_GraphSAGE_transR_50-5.pt\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=18, num_training_steps=total_steps)\n",
    "\n",
    "# T_max control the period of the lr changing -> set 1/10 first\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "total_steps = 50\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batched_g in tqdm(dataloaders['repeat_train_80'], desc=\"Training\", position=0, leave=True):\n",
    "        num_batches += 1\n",
    "        loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    add_log_msg(f\"total batches: {num_batches}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in tqdm(dataloaders['valid'], desc=\"Validation\", position=0, leave=True):\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, num_batches, which_type='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "    \n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}\\n')\n",
    "    \n",
    "            \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "            add_log_msg(\"Find a better model!!\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "#         print(best_model_path)\n",
    "\n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"============================== Early stopping ==================================\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test of valid and test part is ``graph``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60 APs in training x 10000times\n",
    "- 5 APs in validation x 4 times\n",
    "- 3 APs in test x 4 times\n",
    "- Batch size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c83ab11a5d34baab76490ab57e1cde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:24:50# labels of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:24:50# predicted of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:24:50# labels of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:24:50# predicted of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:24:50# labels: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:24:50# predicted: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([1340])\n",
      "10/11/2023, 04:25:00# Test Accuracy: 97.14629201677286 %\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:25:32# report path: classification_report/classification_report-transR_50-graphSAGE-3.xlsx\n",
      "10/11/2023, 04:25:32# label path: classification_report/mapped_true_predicted_labels-transR_50-graphSAGE-3.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11/2023, 04:25:45# mapped_report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00      6400\n",
      "    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00       600\n",
      "    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00       500\n",
      "    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00      1500\n",
      "    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.01      0.02      0.02       100\n",
      "    T1003.003_f049b89533298c2d6cd37a940248b219       0.03      0.03      0.03       100\n",
      "        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00       600\n",
      "        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00       600\n",
      "    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.01      0.01      0.01       100\n",
      "        T1007_d6bb2a19da7246731ed9c44831b135f8       0.00      0.00      0.00       300\n",
      "    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.00      0.00      0.00       100\n",
      "        T1016_71b3d2945679566b9d94d8cb11df4b70       0.02      0.02      0.02       100\n",
      "        T1016_7d8ee68f0e9731db82964f558f614608       0.29      1.00      0.44       500\n",
      "    T1016_921055f4-5970-4707-909e-62f594234d91       0.00      0.00      0.00       100\n",
      "    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.01      0.02      0.02       100\n",
      "    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.00      0.00      0.00       100\n",
      "    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.00      0.00      0.00       100\n",
      "        T1018_a44bb43474728496276d5d73aa14588f       0.08      0.03      0.04       100\n",
      "        T1018_ac20e592bc912bddff4d6b88289095f0       0.02      0.02      0.02       100\n",
      "    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       0.99      1.00      0.99       600\n",
      "    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.02      0.01      0.01       100\n",
      "    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.01      0.01      0.01       100\n",
      "    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00      2300\n",
      "    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00      2700\n",
      "    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00       200\n",
      "    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00       200\n",
      "    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00       700\n",
      "        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00       500\n",
      "        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.05      0.01      0.02       100\n",
      "        T1047_6935e41353aa781bb723462d26114c44       0.00      0.00      0.00       100\n",
      "        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.05      0.02      0.03       100\n",
      "        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.00      0.00      0.00       100\n",
      "        T1047_b0255b5120cbabc062d8d4510a142c3b       0.03      0.02      0.02       100\n",
      "        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.00      0.00      0.00       100\n",
      "        T1047_f4b0b4129560ea66f9751275e82f6bab       0.00      0.00      0.00       100\n",
      "    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.10      0.02      0.03       100\n",
      "        T1049_a14392d713dffba6a397682ff83259a0       0.00      0.00      0.00       300\n",
      "    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00       200\n",
      "    T1053.005_ee454be9197890de62705ce6255933fd       0.00      0.00      0.00       100\n",
      "T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.01      0.01      0.01       100\n",
      "T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.02      0.04      0.03       100\n",
      "    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.01      0.02      0.01       100\n",
      "    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00       700\n",
      "        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.03      0.04      0.03       100\n",
      "        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.02      0.09      0.03       100\n",
      "T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      1000\n",
      "    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00      1500\n",
      "T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00       500\n",
      "T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      1.00      1.00      1000\n",
      "T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00       500\n",
      "T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00     13700\n",
      "    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00       700\n",
      "    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00       600\n",
      "T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00       900\n",
      "    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00       200\n",
      "    T1069.002_6103e503cb444bc7b4187704f2035708       0.00      0.00      0.00       400\n",
      "    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00       600\n",
      "    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00      2000\n",
      "T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      1000\n",
      "T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00       300\n",
      "    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00       800\n",
      "    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.03      0.01      0.01       100\n",
      "    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.01      0.01      0.01       100\n",
      "    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      1200\n",
      "    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.01      0.06      0.02       100\n",
      "    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      0.99      0.99       500\n",
      "T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.01      0.01      0.01       100\n",
      "    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.98      0.87      0.92       200\n",
      "        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      1100\n",
      "        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      1.00      1.00       200\n",
      "        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00       800\n",
      "    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00      2100\n",
      "        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00      2000\n",
      "        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00      1300\n",
      "        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00      5700\n",
      "    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00     15000\n",
      "        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00       300\n",
      "        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00       300\n",
      "        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00       300\n",
      "        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00       300\n",
      "        T1112_7fe6a66d03f4dbfc022609ba311c2b11       0.99      1.00      1.00       300\n",
      "        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00       300\n",
      "        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00       300\n",
      "        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00       200\n",
      "        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00       300\n",
      "        T1112_e7a987cbef27263e666e5b096488dc55       1.00      0.99      1.00      1800\n",
      "        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00       300\n",
      "        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00       300\n",
      "    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00       500\n",
      "        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00      1600\n",
      "    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.02      0.05      0.03       100\n",
      "        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00      1900\n",
      "        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00      2000\n",
      "        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00       600\n",
      "        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00       600\n",
      "    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.01      0.10      0.02       100\n",
      "        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00       600\n",
      "    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.02      0.04      0.02       100\n",
      "    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.03      0.03      0.03       100\n",
      "    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00       600\n",
      "        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00      1300\n",
      "        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.00      0.00      0.00       100\n",
      "        T1201_57296a2ddbeb7423c05feef2fe972111       0.00      0.00      0.00       100\n",
      "    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      1000\n",
      "        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00       400\n",
      "        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.01      0.01      0.01       100\n",
      "        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00      6700\n",
      "        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     10400\n",
      "        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00      5000\n",
      "    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00       500\n",
      "        T1482_cfb61005899996469ae3023796792ca5       0.02      0.05      0.03       100\n",
      "        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00       400\n",
      "        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.03      0.03      0.03       100\n",
      "        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00       200\n",
      "        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.00      0.00      0.00       100\n",
      "        T1490_c156ac5c9fa67080365268d95f29053d       0.00      0.00      0.00       100\n",
      "        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      1000\n",
      "        T1490_e90756bb6dcd21462dc4cc452661df91       0.01      0.03      0.01       100\n",
      "    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00       500\n",
      "    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00       700\n",
      "    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00      8200\n",
      "T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.00      0.01      0.01       100\n",
      "T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.01      0.02      0.01       100\n",
      "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.00      0.00      0.00       100\n",
      "    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.02      0.04      0.03       100\n",
      "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.00      0.00      0.00       100\n",
      "    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00       200\n",
      "    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.02      0.02      0.02       100\n",
      "        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00       200\n",
      "    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       100\n",
      "        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00       200\n",
      "        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00       200\n",
      "    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00      1500\n",
      "    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00       700\n",
      "    T1547.001_163b023f43aba758d36f524d146cb8ea       1.00      1.00      1.00       500\n",
      "    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00       600\n",
      "    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00       200\n",
      "    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00       200\n",
      "    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00       500\n",
      "    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00       200\n",
      "    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00       200\n",
      "    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      1000\n",
      "    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00       800\n",
      "    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00       600\n",
      "        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00      2200\n",
      "T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00       200\n",
      "    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00       200\n",
      "        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00     21600\n",
      "    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00       200\n",
      "    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      0.99      0.99       600\n",
      "    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.03      0.02      0.02       100\n",
      "    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00       200\n",
      "    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      1100\n",
      "    T1562.004_5b93df032e230056c21a3e57334f77d1       0.00      0.00      0.00       100\n",
      "    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.00      0.00      0.00       100\n",
      "    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00       300\n",
      "    T1564.001_66a5fd5f244819181f074dd082a28905       0.52      0.66      0.58       500\n",
      "    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.53      0.38      0.45       500\n",
      "    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.99      0.43      0.60       200\n",
      "    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00       600\n",
      "    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00      1600\n",
      "        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.00      0.00      0.00       100\n",
      "    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00       800\n",
      "    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00      6200\n",
      "    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00       600\n",
      "                                        benign       1.00      1.00      1.00    134563\n",
      "\n",
      "                                      accuracy                           0.97    310263\n",
      "                                     macro avg       0.60      0.60      0.59    310263\n",
      "                                  weighted avg       0.97      0.97      0.97    310263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# load the pretrained model\n",
    "pretrained_model_path = '../checkpoint_graphSAGE/best_model_GraphSAGE_transR_50-5.pt'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batched_g in tqdm(dataloaders['test'], desc=\"Testing\", position=0, leave=True):\n",
    "#         print(f\"data:{data[1]}\")\n",
    "        loss, accuracy, predicted = model_fn(batched_g, model, criterion, device, count, which_type='test')\n",
    "        labels = batched_g.edata['label'].to(device)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        if count % 5000 == 0:\n",
    "            add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "            add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %\\n\\n\\n')\n",
    "\n",
    "\n",
    "# ======================================== handlig the output excel files ========================================\n",
    "mapping_file = './new_mapping.txt'\n",
    "label_mapping = {}\n",
    "with open(mapping_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(': ')\n",
    "        label_mapping[int(parts[1])] = parts[0]\n",
    "        \n",
    "# 将映射后的标签应用到true和predicted标签列表\n",
    "mapped_true_labels = [label_mapping[label] for label in true_labels]\n",
    "mapped_predicted_labels = [label_mapping[label] for label in predicted_labels]\n",
    "\n",
    "# 生成Scikit-learn报告信息的DataFrame\n",
    "report_data = classification_report(mapped_true_labels, mapped_predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "# mapped_true_labels_np = np.array(mapped_true_labels)\n",
    "# mapped_predicted_labels_np = np.array(mapped_predicted_labels)\n",
    "\n",
    "# print(\"mapped_true_labels 的形状:\", mapped_true_labels_np.shape)\n",
    "# print(\"mapped_predicted_labels 的形状:\", mapped_predicted_labels_np.shape)\n",
    "\n",
    "report_folder = 'classification_report'\n",
    "os.makedirs(report_folder, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    report_filename = f'classification_report-transR_50-graphSAGE-{count}.xlsx'\n",
    "    labels_filename = f'mapped_true_predicted_labels-transR_50-graphSAGE-{count}.xlsx'\n",
    "    \n",
    "    report_path = os.path.join(report_folder, report_filename)\n",
    "    labels_path = os.path.join(report_folder, labels_filename)\n",
    "    \n",
    "    if not os.path.exists(report_path) and not os.path.exists(labels_path):\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "report_df.to_excel(report_path, index_label='Label')\n",
    "\n",
    "mapped_labels_df = pd.DataFrame({'true_label': mapped_true_labels, 'predicted_label': mapped_predicted_labels})\n",
    "mapped_labels_df.to_excel(labels_path, index=False)\n",
    "\n",
    "add_log_msg(f\"report path: {report_path}\")\n",
    "add_log_msg(f\"label path: {labels_path}\")\n",
    "\n",
    "mapped_report = classification_report(mapped_true_labels, mapped_predicted_labels)\n",
    "add_log_msg(f\"mapped_report:\\n{mapped_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workdir/home/euni/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.001_35d92515122effdd73801c6ac3021da7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.002_5a484b65c247675e3b7ada4ba648d376</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.002_7fa4ea18694f2552547b65e23952cabb</th>\n",
       "      <td>0.998668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.003_9f73269695e54311dd61dc68940fb3e1</th>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1574.011_72249c1e9ffe7d8f30243d838e0791ca</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>134563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.971463</td>\n",
       "      <td>0.971463</td>\n",
       "      <td>0.971463</td>\n",
       "      <td>0.971463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596490</td>\n",
       "      <td>0.598077</td>\n",
       "      <td>0.594237</td>\n",
       "      <td>310263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.970626</td>\n",
       "      <td>0.971463</td>\n",
       "      <td>0.970567</td>\n",
       "      <td>310263.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                precision    recall  f1-score  \\\n",
       "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554   1.000000  1.000000  1.000000   \n",
       "T1003.001_35d92515122effdd73801c6ac3021da7       1.000000  1.000000  1.000000   \n",
       "T1003.002_5a484b65c247675e3b7ada4ba648d376       1.000000  1.000000  1.000000   \n",
       "T1003.002_7fa4ea18694f2552547b65e23952cabb       0.998668  1.000000  0.999334   \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1       0.013423  0.020000  0.016064   \n",
       "...                                                   ...       ...       ...   \n",
       "T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.000000  1.000000  1.000000   \n",
       "benign                                           1.000000  0.999993  0.999996   \n",
       "accuracy                                         0.971463  0.971463  0.971463   \n",
       "macro avg                                        0.596490  0.598077  0.594237   \n",
       "weighted avg                                     0.970626  0.971463  0.970567   \n",
       "\n",
       "                                                      support  \n",
       "T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554    6400.000000  \n",
       "T1003.001_35d92515122effdd73801c6ac3021da7         600.000000  \n",
       "T1003.002_5a484b65c247675e3b7ada4ba648d376         500.000000  \n",
       "T1003.002_7fa4ea18694f2552547b65e23952cabb        1500.000000  \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1         100.000000  \n",
       "...                                                       ...  \n",
       "T1574.011_72249c1e9ffe7d8f30243d838e0791ca         600.000000  \n",
       "benign                                          134563.000000  \n",
       "accuracy                                             0.971463  \n",
       "macro avg                                       310263.000000  \n",
       "weighted avg                                    310263.000000  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_data = classification_report(mapped_true_labels, mapped_predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T1003.001_35d92515122effdd73801c6ac3021da7',\n",
       " 1: 'T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517',\n",
       " 2: 'T1047_ac2764f7a67a9ce92b54e8e59b361838',\n",
       " 3: 'T1059.001_6efbccc1869e8cd618c0d3ecda407d5f',\n",
       " 4: 'T1078.001_d0ca00832890baa1d42322cf70fcab1a',\n",
       " 5: 'T1112_257313a3c93e3bb7dfb60d6753b09e34',\n",
       " 6: 'T1119_344e7eaf650763e0d3e9f02e62c1cf4b',\n",
       " 7: 'T1219_7dabcbecab0334b115feefab1630f84a',\n",
       " 8: 'T1562.004_280003641a5cddf916c4f2bf605a71d3',\n",
       " 9: 'T1497.001_1258b063-27d6-489b-a677-4807faacf868',\n",
       " 10: 'T1547.001_4b71ebb2f6f6a01235ba240fa40ce978',\n",
       " 11: 'T1018_a44bb43474728496276d5d73aa14588f',\n",
       " 12: 'T1047_b0255b5120cbabc062d8d4510a142c3b',\n",
       " 13: 'T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2',\n",
       " 14: 'T1082_29451844-9b76-4e16-a9ee-d6feab4b24db',\n",
       " 15: 'T1112_34041639e6e501856ecaf5969ee29c76',\n",
       " 16: 'T1119_7121cdf93b951311be9d7078c602efdc',\n",
       " 17: 'T1219_af8cb2bf9b436aae5c106a0a9c207e14',\n",
       " 18: 'T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81',\n",
       " 19: 'T1003.002_5a484b65c247675e3b7ada4ba648d376',\n",
       " 20: 'T1547.001_777043894e42d2aae3881e63f6c76d33',\n",
       " 21: 'T1562.004_41627f71f968225b9f162cb76d16bd9d',\n",
       " 156: 'T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554',\n",
       " 23: 'T1547.001_d3ef4145e4144fd694514b1c5cc17350',\n",
       " 24: 'T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0',\n",
       " 25: 'T1219_f1b3fca18d7465cd10e5a7477a3bf97d',\n",
       " 26: 'T1120_7b9c7afaefa59aab759b49af0d699ac1',\n",
       " 27: 'T1112_35c0360d226cf38104f300d9d57ce60e',\n",
       " 28: 'T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8',\n",
       " 29: 'T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031',\n",
       " 30: 'T1047_ed736a123da6fb2aab22cfd4f437e8b5',\n",
       " 31: 'T1018_ac20e592bc912bddff4d6b88289095f0',\n",
       " 32: 'T1003.002_7fa4ea18694f2552547b65e23952cabb',\n",
       " 33: 'T1562.004_5b93df032e230056c21a3e57334f77d1',\n",
       " 34: 'T1003.003_9f73269695e54311dd61dc68940fb3e1',\n",
       " 35: 'T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89',\n",
       " 36: 'T1047_f4b0b4129560ea66f9751275e82f6bab',\n",
       " 37: 'T1059.001_ccdb8caf-c69e-424b-b930-551969450c57',\n",
       " 38: 'T1083_6e1a53c0-7352-4899-be35-fa7f364d5722',\n",
       " 39: 'T1112_4bfb5f265a5ce07af6bf10da113af7db',\n",
       " 40: 'T1123_372e6f46fca18e4f1b43209c20ffafa2',\n",
       " 41: 'T1482_6131397e-7765-424e-a594-3d7fb2d93a6a',\n",
       " 42: 'T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731',\n",
       " 43: 'T1547.004_0856714c9810ac55b53e9964d02958a0',\n",
       " 44: 'T1562.004_8d0a4585e7c4646185a912b14cd9cb46',\n",
       " 45: 'T1562.004_8fe59e288f10a486dc8b44bc872019ff',\n",
       " 46: 'T1547.004_aa147165f6c116cb0b0f944abe1db8ce',\n",
       " 47: 'T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba',\n",
       " 48: 'T1482_cfb61005899996469ae3023796792ca5',\n",
       " 49: 'T1124_fa6e8607-e0b1-425d-8924-9b894da5a002',\n",
       " 50: 'T1112_7fe6a66d03f4dbfc022609ba311c2b11',\n",
       " 51: 'T1087.001_6334877e8e3ba48f7835d4856d90a282',\n",
       " 52: 'T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d',\n",
       " 53: 'T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8',\n",
       " 54: 'T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989',\n",
       " 55: 'T1003.003_f049b89533298c2d6cd37a940248b219',\n",
       " 56: 'T1003_18f31c311ac208802e88ab8d5af8603e',\n",
       " 57: 'T1087.001_feaced8f-f43f-452a-9500-a5219488abb8',\n",
       " 58: 'T1059.003_6c318ef0339d74d909ad556681b6493e',\n",
       " 59: 'T1049_a14392d713dffba6a397682ff83259a0',\n",
       " 60: 'T1033_c0da588f-79f0-4263-8998-7496b1a40596',\n",
       " 61: 'T1112_ba6f6214dbd17c54001e0a163b60f151',\n",
       " 62: 'T1125_da86001b5081fcf773d8e62f22cf2b00',\n",
       " 63: 'T1486_d82ceb9939d3d920ee550187ad8235c8',\n",
       " 64: 'T1518.001_33a24ff44719e6ac0614b58f8c9a7c72',\n",
       " 65: 'benign',\n",
       " 66: 'T1547.009_501af516bd8b24fee0c7c650ae5cc861',\n",
       " 67: 'T1564.001_66a5fd5f244819181f074dd082a28905',\n",
       " 68: 'T1053.005_5db2884b6ca3ab932848f295a3896dc0',\n",
       " 69: 'T1007_9d03c91bdae5a80f17f89c987942b5a8',\n",
       " 70: 'T1036.003_04e8d83e7badf098d50800d6aa1dd487',\n",
       " 71: 'T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8',\n",
       " 72: 'T1090.001_ba343199a4f15ed6b57eb52412f62e4e',\n",
       " 73: 'T1112_cab7b85611a290c0769546bfa9d6f962',\n",
       " 74: 'T1135_530e47c6-8592-42bf-91df-c59ffbd8541b',\n",
       " 75: 'T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d',\n",
       " 76: 'T1518.001_b8453a5fe06b24aea12b27592d5c3d3a',\n",
       " 77: 'T1547.009_b6e5c895c6709fe289352ee23f062229',\n",
       " 78: 'T1564.001_dce51e632abdfe5392c7c1f942ac9273',\n",
       " 79: 'T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc',\n",
       " 80: 'T1547.010_4593d72a5145e3f494421ac772d37464',\n",
       " 81: 'T1007_c6607391-d02c-44b5-9b13-d3492ca58599',\n",
       " 82: 'T1036.003_f5ef8466e5ebcd2ae03f338d9416069c',\n",
       " 83: 'T1053.005_ee454be9197890de62705ce6255933fd',\n",
       " 84: 'T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2',\n",
       " 85: 'T1105_0856c235a1d26113d4f2d92e39c9a9f8',\n",
       " 86: 'T1112_cd8be0e6b873919da25530a2c7ea6750',\n",
       " 87: 'T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e',\n",
       " 88: 'T1490_8467c994685ccf178db166964bd80fab',\n",
       " 89: 'T1518_8ddfaf982ab359cda13626b870ccb339',\n",
       " 90: 'T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a',\n",
       " 91: 'T1007_d6bb2a19da7246731ed9c44831b135f8',\n",
       " 92: 'T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c',\n",
       " 93: 'T1069.001_a1f48fa3ddee658b29b414523c9a295b',\n",
       " 94: 'T1105_1095434782a00c8a4772a11e625bcf5d',\n",
       " 95: 'T1112_e74d2fb4ef5fa6c766a4151554033697',\n",
       " 96: 'T1137.002_e2af3c3ab1b0f659c874b8af58c49759',\n",
       " 97: 'T1490_9e5e4c0655fd1b5be88bd40b8251175f',\n",
       " 98: 'T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c',\n",
       " 99: 'T1547_fe9eeee9a7b339089e5fa634b08522c1',\n",
       " 100: 'T1564.004_28862487a99f5f89bc0d68c87396c7e9',\n",
       " 101: 'T1564.004_76b6066fe170d38215251102e42be973',\n",
       " 102: 'T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c',\n",
       " 103: 'T1531_aa6b15485a5f50ced34d87fda177b758',\n",
       " 104: 'T1490_c156ac5c9fa67080365268d95f29053d',\n",
       " 105: 'T1137_12ad9edefc86af07700fbf49bfdac6ba',\n",
       " 106: 'T1112_e7a987cbef27263e666e5b096488dc55',\n",
       " 107: 'T1105_4f683658f161ccdc51337c470d32bab9',\n",
       " 108: 'T1069.002_6103e503cb444bc7b4187704f2035708',\n",
       " 109: 'T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81',\n",
       " 110: 'T1036.004_7de3d7b4922a7b996d8df36fb22bb118',\n",
       " 111: 'T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17',\n",
       " 112: 'T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a',\n",
       " 113: 'T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc',\n",
       " 114: 'T1531_b25ae80dad74142fafb510e9c1949ace',\n",
       " 115: 'T1490_c8f329d2847ede593b6cb4a1ec6120fb',\n",
       " 116: 'T1201_38f6f0e50a6b196140ec40d3dc9cc9e6',\n",
       " 117: 'T1112_fa4ba6a06b4a5cd955ea5a60fae24281',\n",
       " 118: 'T1105_60f63260-39bb-4136-87a0-b6c2dca799fc',\n",
       " 119: 'T1016_71b3d2945679566b9d94d8cb11df4b70',\n",
       " 120: 'T1070.005_1f91076e2be2014cc7b4f1296de02fd6',\n",
       " 121: 'T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65',\n",
       " 122: 'T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7',\n",
       " 123: 'T1546.013_f9a968af61d36983448c74cca5464e17',\n",
       " 124: 'T1490_e90756bb6dcd21462dc4cc452661df91',\n",
       " 125: 'T1201_57296a2ddbeb7423c05feef2fe972111',\n",
       " 126: 'T1112_fd992e8ecfdac9b56dd6868904044827',\n",
       " 127: 'T1105_c521e0a70b243a0cf9217907ca3c6d27',\n",
       " 128: 'T1071.001_24c3b7b004401d839a5c337201da3484',\n",
       " 129: 'T1057_8adf02e8-6e71-4244-886c-98c402857404',\n",
       " 130: 'T1040_6881a4589710d53f0c146e91db513f01',\n",
       " 131: 'T1016_7d8ee68f0e9731db82964f558f614608',\n",
       " 132: 'T1560_a1ee301b0508747b468d578a14e5c1a5',\n",
       " 133: 'T1566.001_1afaec09315ab71fdfb167175e8a019a',\n",
       " 134: 'T1574.001_63bbedafba2f541552ac3579e9e3737b',\n",
       " 135: 'T1562.001_43e3334362b140924f001b256b229ee5',\n",
       " 136: 'T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac',\n",
       " 137: 'T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9',\n",
       " 138: 'T1204.002_522f3f35cd013e63830fa555495a0081',\n",
       " 139: 'T1113_316251ed-6a28-4013-812b-ddf5b5b007f8',\n",
       " 140: 'T1105_c76968acda4aa1673dadcd67f3ab7664',\n",
       " 141: 'T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e',\n",
       " 142: 'T1057_b2a1e430ca6d36eb5af2fe666e769847',\n",
       " 143: 'T1047_09e0f9cf2eb803a1c35deeecf3665fad',\n",
       " 144: 'T1016_921055f4-5970-4707-909e-62f594234d91',\n",
       " 145: 'T1574.011_72249c1e9ffe7d8f30243d838e0791ca',\n",
       " 146: 'T1562.002_6a8d25d65a7d481dc479f89c62af1e6a',\n",
       " 147: 'T1547.001_163b023f43aba758d36f524d146cb8ea',\n",
       " 148: 'T1491_68235976-2404-42a8-9105-68230cfef562',\n",
       " 149: 'T1115_70795de7cbb842edb029b3378c27c008',\n",
       " 150: 'T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69',\n",
       " 151: 'T1047_6935e41353aa781bb723462d26114c44',\n",
       " 152: 'T1057_f8de05d1741dcc468f772ab0ff4dac72',\n",
       " 153: 'T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89',\n",
       " 154: 'T1105_e6715e61f5df646692c624b3499384c4',\n",
       " 155: 'T1217_69bbe2183fa09c00ccaac62d48e214f8',\n",
       " 157: 'T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa',\n",
       " 158: 'T1047_ac122553ab4426ea3362bb4a97d31bfd',\n",
       " 159: 'T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4',\n",
       " 160: 'T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e',\n",
       " 161: 'T1105_eb814e03-811a-467a-bc6d-dcd453750fa2',\n",
       " 162: 'T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2',\n",
       " 163: 'T1217_f7a0f7d704aa52a764d9d1bee81e65d6',\n",
       " 164: 'T1562.002_94f51bf01a7036fe02d07b4c18967669',\n",
       " 165: 'T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4',\n",
       " 166: 'T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support=100: 54\n",
      "Number of support=100 and f1-score<=0.2: 53\n",
      "Number of support=100 and f1-score=0: 18\n",
      "Number of support=200 and f1-score=0: 10\n",
      "Number of support>200 and f1-score=0: 3\n"
     ]
    }
   ],
   "source": [
    "# # threshold = 0\n",
    "# # filtered_report = report_df[report_df['f1-score'] == threshold]\n",
    "# # print(\"Number of rows:\", filtered_report.shape[0])\n",
    "\n",
    "filtered_report = report_df[(report_df['support'] == 100)]\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of support=100:\", num_rows)\n",
    "\n",
    "filtered_report = report_df[(report_df['f1-score'] <= 0.2) & (report_df['support'] == 100)]\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of support=100 and f1-score<=0.2:\", num_rows)\n",
    "\n",
    "filtered_report = report_df[(report_df['f1-score'] == 0) & (report_df['support'] == 100)]\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of support=100 and f1-score=0:\", num_rows)\n",
    "\n",
    "filtered_report = report_df[(report_df['f1-score'] == 0) & (report_df['support'] == 200)]\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of support=200 and f1-score=0:\", num_rows)\n",
    "\n",
    "filtered_report = report_df[(report_df['f1-score'] == 0) & (report_df['support'] > 200)]\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of support>200 and f1-score=0:\", num_rows)\n",
    "\n",
    "threshold = 0 \n",
    "filtered_report = report_df[report_df['f1-score'] == threshold]\n",
    "# print(\"Number of rows:\", filtered_report.shape[0])\n",
    "\n",
    "\n",
    "# filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1003.003_9f73269695e54311dd61dc68940fb3e1</th>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1003.003_f049b89533298c2d6cd37a940248b219</th>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1007_c6607391-d02c-44b5-9b13-d3492ca58599</th>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1007_d6bb2a19da7246731ed9c44831b135f8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.002_94f51bf01a7036fe02d07b4c18967669</th>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_280003641a5cddf916c4f2bf605a71d3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_5b93df032e230056c21a3e57334f77d1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_8d0a4585e7c4646185a912b14cd9cb46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision  recall  f1-score  \\\n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1   0.013423    0.02  0.016064   \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219   0.028037    0.03  0.028986   \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599   0.005682    0.01  0.007246   \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8       0.000000    0.00  0.000000   \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17   0.000000    0.00  0.000000   \n",
       "...                                               ...     ...       ...   \n",
       "T1562.002_94f51bf01a7036fe02d07b4c18967669   0.027397    0.02  0.023121   \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3   0.000000    0.00  0.000000   \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1   0.000000    0.00  0.000000   \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46   0.000000    0.00  0.000000   \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.000000    0.00  0.000000   \n",
       "\n",
       "                                            support  \n",
       "T1003.003_9f73269695e54311dd61dc68940fb3e1    100.0  \n",
       "T1003.003_f049b89533298c2d6cd37a940248b219    100.0  \n",
       "T1007_c6607391-d02c-44b5-9b13-d3492ca58599    100.0  \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8        300.0  \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17    100.0  \n",
       "...                                             ...  \n",
       "T1562.002_94f51bf01a7036fe02d07b4c18967669    100.0  \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3    200.0  \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1    100.0  \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46    100.0  \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a        100.0  \n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.2\n",
    "filtered_report = report_df[report_df['f1-score'] <= threshold]\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_921055f4-5970-4707-909e-62f594234d91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_6935e41353aa781bb723462d26114c44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_ac2764f7a67a9ce92b54e8e59b361838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_ed736a123da6fb2aab22cfd4f437e8b5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047_f4b0b4129560ea66f9751275e82f6bab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1053.005_ee454be9197890de62705ce6255933fd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1201_38f6f0e50a6b196140ec40d3dc9cc9e6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1201_57296a2ddbeb7423c05feef2fe972111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_9e5e4c0655fd1b5be88bd40b8251175f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_c156ac5c9fa67080365268d95f29053d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_5b93df032e230056c21a3e57334f77d1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_8d0a4585e7c4646185a912b14cd9cb46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                precision  recall  f1-score  \\\n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17            0.0     0.0       0.0   \n",
       "T1016_921055f4-5970-4707-909e-62f594234d91            0.0     0.0       0.0   \n",
       "T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa            0.0     0.0       0.0   \n",
       "T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517            0.0     0.0       0.0   \n",
       "T1047_6935e41353aa781bb723462d26114c44                0.0     0.0       0.0   \n",
       "T1047_ac2764f7a67a9ce92b54e8e59b361838                0.0     0.0       0.0   \n",
       "T1047_ed736a123da6fb2aab22cfd4f437e8b5                0.0     0.0       0.0   \n",
       "T1047_f4b0b4129560ea66f9751275e82f6bab                0.0     0.0       0.0   \n",
       "T1053.005_ee454be9197890de62705ce6255933fd            0.0     0.0       0.0   \n",
       "T1201_38f6f0e50a6b196140ec40d3dc9cc9e6                0.0     0.0       0.0   \n",
       "T1201_57296a2ddbeb7423c05feef2fe972111                0.0     0.0       0.0   \n",
       "T1490_9e5e4c0655fd1b5be88bd40b8251175f                0.0     0.0       0.0   \n",
       "T1490_c156ac5c9fa67080365268d95f29053d                0.0     0.0       0.0   \n",
       "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0        0.0     0.0       0.0   \n",
       "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba        0.0     0.0       0.0   \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1            0.0     0.0       0.0   \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46            0.0     0.0       0.0   \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a                0.0     0.0       0.0   \n",
       "\n",
       "                                                support  \n",
       "T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17        100.0  \n",
       "T1016_921055f4-5970-4707-909e-62f594234d91        100.0  \n",
       "T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa        100.0  \n",
       "T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517        100.0  \n",
       "T1047_6935e41353aa781bb723462d26114c44            100.0  \n",
       "T1047_ac2764f7a67a9ce92b54e8e59b361838            100.0  \n",
       "T1047_ed736a123da6fb2aab22cfd4f437e8b5            100.0  \n",
       "T1047_f4b0b4129560ea66f9751275e82f6bab            100.0  \n",
       "T1053.005_ee454be9197890de62705ce6255933fd        100.0  \n",
       "T1201_38f6f0e50a6b196140ec40d3dc9cc9e6            100.0  \n",
       "T1201_57296a2ddbeb7423c05feef2fe972111            100.0  \n",
       "T1490_9e5e4c0655fd1b5be88bd40b8251175f            100.0  \n",
       "T1490_c156ac5c9fa67080365268d95f29053d            100.0  \n",
       "T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0    100.0  \n",
       "T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba    100.0  \n",
       "T1562.004_5b93df032e230056c21a3e57334f77d1        100.0  \n",
       "T1562.004_8d0a4585e7c4646185a912b14cd9cb46        100.0  \n",
       "T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a            100.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] == 0) & (report_df['support'] == 100)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# labels_indices = filtered_report.index.tolist()\n",
    "# # Print to check if the indices are what we expect\n",
    "# print(\"Filtered Report Indices:\", labels_indices)\n",
    "\n",
    "# mapped_labels = [key for label in labels_indices for key, value in label_mapping.items() if value == label]\n",
    "\n",
    "# with open('triplets_1.txt', 'w') as f:\n",
    "#     for label in mapped_labels:\n",
    "#         f.write(f'{label}\\n')\n",
    "\n",
    "# print(f'{len(labels_indices)} labels have been written to filtered_labels.txt')\n",
    "\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1036.004_7de3d7b4922a7b996d8df36fb22bb118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1053.005_5db2884b6ca3ab932848f295a3896dc0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1069.001_a1f48fa3ddee658b29b414523c9a295b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1490_8467c994685ccf178db166964bd80fab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1518.001_33a24ff44719e6ac0614b58f8c9a7c72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1531_aa6b15485a5f50ced34d87fda177b758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1531_b25ae80dad74142fafb510e9c1949ace</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1562.004_280003641a5cddf916c4f2bf605a71d3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision  recall  f1-score  \\\n",
       "T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a        0.0     0.0       0.0   \n",
       "T1036.004_7de3d7b4922a7b996d8df36fb22bb118        0.0     0.0       0.0   \n",
       "T1053.005_5db2884b6ca3ab932848f295a3896dc0        0.0     0.0       0.0   \n",
       "T1069.001_a1f48fa3ddee658b29b414523c9a295b        0.0     0.0       0.0   \n",
       "T1490_8467c994685ccf178db166964bd80fab            0.0     0.0       0.0   \n",
       "T1518.001_33a24ff44719e6ac0614b58f8c9a7c72        0.0     0.0       0.0   \n",
       "T1531_aa6b15485a5f50ced34d87fda177b758            0.0     0.0       0.0   \n",
       "T1531_b25ae80dad74142fafb510e9c1949ace            0.0     0.0       0.0   \n",
       "T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc        0.0     0.0       0.0   \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3        0.0     0.0       0.0   \n",
       "\n",
       "                                            support  \n",
       "T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a    200.0  \n",
       "T1036.004_7de3d7b4922a7b996d8df36fb22bb118    200.0  \n",
       "T1053.005_5db2884b6ca3ab932848f295a3896dc0    200.0  \n",
       "T1069.001_a1f48fa3ddee658b29b414523c9a295b    200.0  \n",
       "T1490_8467c994685ccf178db166964bd80fab        200.0  \n",
       "T1518.001_33a24ff44719e6ac0614b58f8c9a7c72    200.0  \n",
       "T1531_aa6b15485a5f50ced34d87fda177b758        200.0  \n",
       "T1531_b25ae80dad74142fafb510e9c1949ace        200.0  \n",
       "T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc    200.0  \n",
       "T1562.004_280003641a5cddf916c4f2bf605a71d3    200.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] <= 0.2) & (report_df['support'] == 200)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# labels_indices = filtered_report.index.tolist()\n",
    "# print(\"Filtered Report Indices:\", labels_indices)\n",
    "\n",
    "# mapped_labels = [key for label in labels_indices for key, value in label_mapping.items() if value == label]\n",
    "# print(mapped_labels)\n",
    "\n",
    "# with open('triplets_2.txt', 'w') as f:\n",
    "#     for label in mapped_labels:\n",
    "#         f.write(f'{label}\\n')\n",
    "\n",
    "# print(f'{len(labels_indices)} labels have been written to filtered_labels.txt')\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1007_d6bb2a19da7246731ed9c44831b135f8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1049_a14392d713dffba6a397682ff83259a0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1069.002_6103e503cb444bc7b4187704f2035708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision  recall  f1-score  \\\n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8            0.0     0.0       0.0   \n",
       "T1049_a14392d713dffba6a397682ff83259a0            0.0     0.0       0.0   \n",
       "T1069.002_6103e503cb444bc7b4187704f2035708        0.0     0.0       0.0   \n",
       "\n",
       "                                            support  \n",
       "T1007_d6bb2a19da7246731ed9c44831b135f8        300.0  \n",
       "T1049_a14392d713dffba6a397682ff83259a0        300.0  \n",
       "T1069.002_6103e503cb444bc7b4187704f2035708    400.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_report = report_df[(report_df['f1-score'] <= 0.2) & (report_df['support'] > 200)]\n",
    "\n",
    "num_rows = filtered_report.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "\n",
    "filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filtered_report[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize = (12,8))\n",
    "filtered_report[['f1-score']].plot(kind='bar', figsize = (16,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
