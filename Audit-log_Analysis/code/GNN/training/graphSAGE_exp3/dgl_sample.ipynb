{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1a6fac",
   "metadata": {},
   "source": [
    "# Smaple of the official dgl website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "301aab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch as th\n",
    "\n",
    "# 1~100生成500個nodes\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "\n",
    "\n",
    "# make it symmetric\n",
    "# edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
    "edge_pred_graph = dgl.graph((src, dst))\n",
    "    \n",
    "# synthetic node and edge features, as well as edge labels\n",
    "edge_pred_graph.ndata['feature'] = torch.randn(100, 10).float()\n",
    "\n",
    "edge_pred_graph.edata['feature'] = torch.randn(500, 10).float()\n",
    "# edge_pred_graph.edata['label'] = torch.randn(500)\n",
    "edge_pred_graph.edata['label'] = torch.randint(0, 100, (500,)).long()\n",
    "# edge_pred_graph.edata['label'] = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "\n",
    "# synthetic train-test splits, which is about 3:2(not exactly)\n",
    "# edge_pred_graph.edata['train_mask'] = torch.zeros(500, dtype=torch.bool).bernoulli(0.6)\n",
    "\n",
    "num_edges = 500\n",
    "train_ratio = 0.6\n",
    "num_train = int(num_edges * train_ratio)\n",
    "\n",
    "# 隨機排列的索引\n",
    "permuted_idxs = torch.randperm(num_edges)\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "valid_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "\n",
    "train_mask[permuted_idxs[:num_train]] = True\n",
    "valid_mask[permuted_idxs[num_train:]] = True\n",
    "\n",
    "edge_pred_graph.edata['train_mask'] = train_mask\n",
    "edge_pred_graph.edata['valid_mask'] = valid_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc2ca2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=100, num_edges=500,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'valid_mask': Scheme(shape=(), dtype=torch.bool)})\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "699ebf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58045a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[54 19 88 41 40 63 96 14  7 33 14 95 78 38 89 28 59 92 27  3 37 81 12 79\n",
      "  9 55 50 15 83 55 66 79 64 31 85 71 78  4 92 21 19 45 81 95 30 67 25 14\n",
      " 80 68 89 17 28 30 83 85 14 10 19 75 70 60 72 36 10 25 42 84 20 87 66 50\n",
      " 99 42 43 63 65 43 10 64 80 31 29 92 84 57 15 86 51 72 25 40 52 51 65  6\n",
      " 95 95 90 17 12  1 78 29 28 68 98 76 30 29 18 71 18 82 68 52 77 48 65 92\n",
      " 30  6 30 49 33 76 25 30 25 77 36 29 16 29 95 70 65 33 25 82 30 72 89 42\n",
      " 13 25 67 52 67 17 51 96 10 69 79  6 52 22 31 85 85 80 64 55 33 17 20 30\n",
      " 42 85 91 24 28 95 38 75 91 16 71  3 46  1 51  7 28 93 43 36 89 55  6  0\n",
      " 16 47 40  6 44 97 85 86 29 38 28 66 56 65 91 34 29  9  1 12 66 81 13 78\n",
      " 10 20 43 61 24 94 78 77 14  6 27 22  6 43 29  9 75  4 40 98 57 32 40 19\n",
      " 61 32 83 40 32 46 34 97 74  0 40 27 82 71 53 24 16 36 91 41 63 86 14 63\n",
      " 73 39 78 93 91 48 32 97 85 76 57  9  0 48 54  0 74 48  4 26 45  4 93 73\n",
      " 98 67 82 27 28 47 56  3 85 46 84 38 76 31 43  9 29 45 24 31  9 61 42 80\n",
      " 37 28 26 94  3 78 34 45  6 72 83 55  0 74 58 33 20 10 88 66 55 76 22 10\n",
      " 66 57 74 53 18 34  7 70 99 42 83 48 44 26 87 55 75 47 13 63 40 48 42 50\n",
      " 64 16 28  9 55 46 50 72 34  5 65  2 31 74 26 29 40 75 68 57 94 20 39 75\n",
      " 13  6 28 24  6 45 72 65 74 38 38 98 77 57 62 49 82 91 42 16 36 10 84 58\n",
      " 41  8 74 90 81 84 90 69 76 79  3 24 21 22 25 69 58 39 56 90 46 87 59 73\n",
      " 42 41 61 87 77 78 52 84  6 57 36 70 13 55 61 22 25 22 61 68  2  9  2 73\n",
      "  1 53 28 64 78 78 89 36 13 66 94 11 91 76 71 16 89 31 10 55 59 32 25 63\n",
      " 63  8 77 91  7 79 34 33 86 54 23 57 37 38  7 58  1 34 92 98]\n"
     ]
    }
   ],
   "source": [
    "print(src.shape)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94952595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([500, 10])\n"
     ]
    }
   ],
   "source": [
    "print(edge_pred_graph.ndata['feature'].shape)\n",
    "print(edge_pred_graph.edata['feature'].shape)\n",
    "# print(edge_pred_graph.ndata['feature'])\n",
    "# print(edge_pred_graph.edata['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53b80682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, dropout_prob = 0.25):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='pool')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='pool')\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(graph, h)\n",
    "#         print(\"weight: \", self.conv1.fc_self.weight)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a9e1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12d2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes)\n",
    "      \n",
    "    def forward(self, g, x, return_logits=False):\n",
    "        h = self.sage(g, x)\n",
    "        logits = self.pred(g, h)\n",
    "        \n",
    "        if return_logits:\n",
    "            return logits\n",
    "\n",
    "        output = torch.softmax(logits, dim=1)\n",
    "        predicted_classes = torch.argmax(output, dim=1)\n",
    "        return predicted_classes.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "815fdae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46142b846a3e4432830f439a9fd5b97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 5.971440315246582, Training Accuracy: 2.67%\n",
      "\n",
      "\n",
      "Epoch: 200, Loss: 0.3132559061050415, Training Accuracy: 88.33%\n",
      "\n",
      "\n",
      "Epoch: 400, Loss: 0.12932245433330536, Training Accuracy: 95.67%\n",
      "\n",
      "\n",
      "Epoch: 600, Loss: 0.11643753200769424, Training Accuracy: 93.33%\n",
      "\n",
      "\n",
      "Epoch: 800, Loss: 0.10570906102657318, Training Accuracy: 91.33%\n",
      "\n",
      "\n",
      "Epoch: 1000, Loss: 0.11307023465633392, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 1200, Loss: 0.07636285573244095, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 1400, Loss: 0.19097991287708282, Training Accuracy: 94.00%\n",
      "\n",
      "\n",
      "Epoch: 1600, Loss: 0.1270306557416916, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 1800, Loss: 0.08733554184436798, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 2000, Loss: 0.12367800623178482, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 2200, Loss: 0.10462213307619095, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 2400, Loss: 0.06537387520074844, Training Accuracy: 93.67%\n",
      "\n",
      "\n",
      "Epoch: 2600, Loss: 0.15967105329036713, Training Accuracy: 94.00%\n",
      "\n",
      "\n",
      "Epoch: 2800, Loss: 0.07520807534456253, Training Accuracy: 95.67%\n",
      "\n",
      "\n",
      "Epoch: 3000, Loss: 0.06287979334592819, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 3200, Loss: 0.05443360656499863, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 3400, Loss: 0.08926611393690109, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 3600, Loss: 0.06578923761844635, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 3800, Loss: 0.06562625616788864, Training Accuracy: 95.67%\n",
      "\n",
      "\n",
      "Epoch: 4000, Loss: 0.09078343212604523, Training Accuracy: 95.33%\n",
      "\n",
      "\n",
      "Epoch: 4200, Loss: 0.09116896241903305, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 4400, Loss: 0.056326985359191895, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "Epoch: 4600, Loss: 0.0945911630988121, Training Accuracy: 95.33%\n",
      "\n",
      "\n",
      "Epoch: 4800, Loss: 0.08316060155630112, Training Accuracy: 94.67%\n",
      "\n",
      "\n",
      "Epoch: 5000, Loss: 0.07568762451410294, Training Accuracy: 94.00%\n",
      "\n",
      "\n",
      "Epoch: 5200, Loss: 0.062239278107881546, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 5400, Loss: 0.04917166754603386, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 5600, Loss: 0.0813971608877182, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 5800, Loss: 0.0994461178779602, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 6000, Loss: 0.06361398100852966, Training Accuracy: 97.33%\n",
      "\n",
      "\n",
      "Epoch: 6200, Loss: 0.09011305868625641, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 6400, Loss: 0.06651448458433151, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "Epoch: 6600, Loss: 0.05204322561621666, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 6800, Loss: 0.08101106435060501, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 7000, Loss: 0.08633042871952057, Training Accuracy: 97.33%\n",
      "\n",
      "\n",
      "Epoch: 7200, Loss: 0.05451862886548042, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "Epoch: 7400, Loss: 0.05009080097079277, Training Accuracy: 97.33%\n",
      "\n",
      "\n",
      "Epoch: 7600, Loss: 0.06539911031723022, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 7800, Loss: 0.0811132863163948, Training Accuracy: 95.00%\n",
      "\n",
      "\n",
      "Epoch: 8000, Loss: 0.052332766354084015, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 8200, Loss: 0.05841818451881409, Training Accuracy: 96.00%\n",
      "\n",
      "\n",
      "Epoch: 8400, Loss: 0.08732490241527557, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 8600, Loss: 0.05711507052183151, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "Epoch: 8800, Loss: 0.06071852520108223, Training Accuracy: 96.67%\n",
      "\n",
      "\n",
      "Epoch: 9000, Loss: 0.05129994451999664, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "Epoch: 9200, Loss: 0.09135367721319199, Training Accuracy: 96.33%\n",
      "\n",
      "\n",
      "Epoch: 9400, Loss: 0.07783491909503937, Training Accuracy: 97.33%\n",
      "\n",
      "\n",
      "Epoch: 9600, Loss: 0.05553264543414116, Training Accuracy: 95.33%\n",
      "\n",
      "\n",
      "Epoch: 9800, Loss: 0.05229349061846733, Training Accuracy: 97.00%\n",
      "\n",
      "\n",
      "====================================================================================\n",
      "Validation Loss: 30.14349937438965, Validation Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "\n",
    "# the true label, which should be float()\n",
    "edge_label = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "\n",
    "model = Model(in_features=10, hidden_features=20, out_features=50, num_classes=100)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 10000\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(total_steps), desc=\"Training\", position=0, leave=True):\n",
    "    model.train()\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    score = scores[train_mask]\n",
    "    true_label = edge_label[train_mask].long()  # CrossEntropyLoss expects Long type for labels\n",
    "\n",
    "    loss = criterion(score, true_label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    with torch.no_grad():\n",
    "        preds_label = model(edge_pred_graph, node_features)\n",
    "        accuracy = (preds_label[train_mask] == true_label.float()).float().mean()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "#         print(\"training pred: \", prediction)\n",
    "#         print(\"training label: \", true_label)\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Training Accuracy: {accuracy.item() * 100:.2f}%\\n\\n\")\n",
    "\n",
    "# Validation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    val_score = scores[valid_mask]\n",
    "    val_label = edge_label[valid_mask].long()\n",
    "\n",
    "    val_loss = criterion(val_score, val_label)\n",
    "\n",
    "    val_preds_label = torch.argmax(val_score, dim=1)\n",
    "    val_accuracy = (val_preds_label == val_label).float().mean()\n",
    "\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed406012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fa492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d25a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01900107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0506cf82c184f408cd7fad2036322ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 6.121854782104492, Training Accuracy: 1.33%\n",
      "\n",
      "\n",
      "====================================================================================\n",
      "Validation Loss: 10.762978553771973, Validation Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch as th\n",
    "\n",
    "# 1~100生成500個nodes\n",
    "src = np.random.randint(0, 100, 500)\n",
    "dst = np.random.randint(0, 100, 500)\n",
    "\n",
    "\n",
    "# make it symmetric\n",
    "# edge_pred_graph = dgl.graph((np.concatenate([src, dst]), np.concatenate([dst, src])))\n",
    "edge_pred_graph = dgl.graph((src, dst))\n",
    "    \n",
    "# synthetic node and edge features, as well as edge labels\n",
    "edge_pred_graph.ndata['feature'] = torch.randn(100, 10).float()\n",
    "\n",
    "edge_pred_graph.edata['feature'] = torch.randn(500, 10).float()\n",
    "# edge_pred_graph.edata['label'] = torch.randn(500)\n",
    "edge_pred_graph.edata['label'] = torch.randint(0, 100, (500,)).long()\n",
    "# edge_pred_graph.edata['label'] = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "\n",
    "# synthetic train-test splits, which is about 3:2(not exactly)\n",
    "# edge_pred_graph.edata['train_mask'] = torch.zeros(500, dtype=torch.bool).bernoulli(0.6)\n",
    "\n",
    "num_edges = 500\n",
    "train_ratio = 0.6\n",
    "num_train = int(num_edges * train_ratio)\n",
    "\n",
    "# 隨機排列的索引\n",
    "permuted_idxs = torch.randperm(num_edges)\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "valid_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "\n",
    "train_mask[permuted_idxs[:num_train]] = True\n",
    "valid_mask[permuted_idxs[num_train:]] = True\n",
    "\n",
    "edge_pred_graph.edata['train_mask'] = train_mask\n",
    "edge_pred_graph.edata['valid_mask'] = valid_mask\n",
    "\n",
    "\n",
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, dropout_prob = 0.25):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='pool')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='pool')\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(graph, h)\n",
    "#         print(\"weight: \", self.conv1.fc_self.weight)\n",
    "        return h\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, out_feats, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(out_feats*2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(torch.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = MLPPredictor(out_features, num_classes)\n",
    "      \n",
    "    def forward(self, g, x, return_logits=False):\n",
    "        h = self.sage(g, x)\n",
    "        logits = self.pred(g, h)\n",
    "        \n",
    "        if return_logits:\n",
    "            return logits\n",
    "\n",
    "        output = torch.softmax(logits, dim=1)\n",
    "        predicted_classes = torch.argmax(output, dim=1)\n",
    "        return predicted_classes.float()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "\n",
    "# the true label, which should be float()\n",
    "edge_label = edge_pred_graph.edata['label'].float()\n",
    "\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "\n",
    "model = Model(in_features=10, hidden_features=20, out_features=50, num_classes=100)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 100\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(total_steps), desc=\"Training\", position=0, leave=True):\n",
    "    model.train()\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    score = scores[train_mask]\n",
    "    true_label = edge_label[train_mask].long()  # CrossEntropyLoss expects Long type for labels\n",
    "\n",
    "    loss = criterion(score, true_label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    with torch.no_grad():\n",
    "        preds_label = model(edge_pred_graph, node_features)\n",
    "        accuracy = (preds_label[train_mask] == true_label.float()).float().mean()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "#         print(\"training pred: \", prediction)\n",
    "#         print(\"training label: \", true_label)\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Training Accuracy: {accuracy.item() * 100:.2f}%\\n\\n\")\n",
    "\n",
    "# Validation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    scores = model(edge_pred_graph, node_features, return_logits=True)\n",
    "    \n",
    "    val_score = scores[valid_mask]\n",
    "    val_label = edge_label[valid_mask].long()\n",
    "\n",
    "    val_loss = criterion(val_score, val_label)\n",
    "\n",
    "    val_preds_label = torch.argmax(val_score, dim=1)\n",
    "    val_accuracy = (val_preds_label == val_label).float().mean()\n",
    "\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710b86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
