10/19/2023, 02:57:56# labels of 50000: tensor([ 76, 157,  75,  55, 116, 119,  81, 142,  24,  54, 124,  11, 157, 150,
        111, 158,  48, 152,  54, 157, 104,   9,  47,  18,   1,  11,  75,  44,
        121,  24,  48, 162, 152, 144,  92, 142,  48,  97, 121,  11, 151, 151,
        112,  76, 144,  54,  76,  38,  12, 124,  74, 142, 112,  42, 151,  83,
        116,   1,  57, 157,  83,  24, 109, 111], device='cuda:0') torch.Size([64])
10/19/2023, 02:57:56# predicted of 50000: tensor([ 76,  30,  18,  14, 116,  87,  75,  81,  24,  54,  34, 109, 157, 164,
        112, 158,  48,  14,  54,  42, 104,   9,  12,  24,   1,  11,  75,  92,
         14,  24,  54,  24, 152, 143, 157, 142, 144, 116,  49, 109, 151, 164,
        111,  76, 144,  97,  76,  38,  81,  42,  47, 104, 112,  12,   9, 104,
        116,   1, 124, 157, 125, 116, 109, 112], device='cuda:0') torch.Size([64])
10/19/2023, 03:26:17# labels of 100000: tensor([144, 144,  36,  34,  31, 163, 164, 143,   1, 163, 164, 125, 144,  49,
        162,  33,  48,  47, 111, 125, 157,  47,  53, 121,  92, 124,  42,  57,
          9,   1,  18, 158,   2,   1, 150,  24, 152,  18,  49, 158,  14, 125,
        150,  11,  24,   2, 164,  30,  24, 158,  83,  14,  18, 143, 164,  30,
         12, 111, 158, 150, 144, 164,   1, 142], device='cuda:0') torch.Size([64])
10/19/2023, 03:26:17# predicted of 100000: tensor([144, 144,  36,  34,  31, 163, 164, 143,   1, 163,  47,   1, 144,  49,
         44,  33,  48,  47, 111, 112, 157,  34,  53, 121,  54, 124,  42,  57,
          9,   1,  18, 158,   2,  44, 150, 163,   1,  18,  54, 158,  14, 125,
         54,  11,  57,   2, 164,  30,  24,  53,  54,  14, 116, 143, 164,  57,
         12, 111, 158,  54, 144, 164,   1, 142], device='cuda:0') torch.Size([64])
10/19/2023, 03:52:49# labels of 150000: tensor([ 92, 164, 151,   4, 163, 143,  30,  49,   9,  74,  48,  12, 112, 119,
         55,   4, 116,  42,  48,  48,  14,  76, 158, 143,  11,  83, 116, 119,
         83,  74,  36, 119, 144,  49,  24,  44, 143,  76,  11, 158,  87, 143,
          1, 125, 158,  18,  97, 111,  31, 152,  48,  33, 116,  42,  31,  57,
         87,  36, 109,  60, 151, 121,  31,  75], device='cuda:0') torch.Size([64])
10/19/2023, 03:52:49# predicted of 150000: tensor([ 92, 164, 151,   4, 163, 143,  30,  49,   9,  74,  48,  12, 112, 119,
         55,   4, 116,  42,  48,  48,  14,  76, 158,  49,  11,  83, 116, 119,
         47,  74,  36, 119, 144,  49,  33,  44, 143,  76,  33, 158,  87, 143,
          1, 125, 158,   4,  97, 111,  31, 152,  48,  33, 116,  42,  31,  57,
         87,  36, 109,  60, 151,  18,  31,  75], device='cuda:0') torch.Size([64])
10/19/2023, 04:19:22# labels of 200000: tensor([ 36,  31,  75,  92, 112, 142,   2,  74,  18,  60,  44,  74, 151,  48,
        143, 158, 143, 151,  97,   1, 151,  57,  76, 151, 142, 112, 109,  55,
          9, 144,   2,  54,  18, 163,  12,   4, 125, 162, 152, 116,  14,  48,
          4, 104,  38,  30, 151,  87,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7, 111,  33,  75, 157,  42, 124,  74, 158, 125, 158,  87,
        144,  60,  53, 112], device='cuda:0') torch.Size([130])
10/19/2023, 04:19:22# predicted of 200000: tensor([ 36,  31,  55,  92, 112, 142,  97,  74,  18,  60,  44, 116, 151,  48,
        143,   2, 143, 151,  97,   1, 151,  47,  76,  44, 142, 112, 109,  55,
          9, 112,   2,  54,  18, 163,  12,   4, 125, 162, 152, 116,  14,  48,
          4, 104,  38,  30,  12,  87,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7, 111,  33,  75, 157,  48, 124,  74, 158, 125, 158,  87,
        144,  60,  53, 112], device='cuda:0') torch.Size([130])
10/19/2023, 04:26:19# total batches: 213400
10/19/2023, 04:26:19# Epoch 0 | Train Loss: 1.2926 | Train Accuracy: 0.6715
10/19/2023, 04:26:19# labels of Validation: tensor([129, 129, 129, 129, 129, 129, 129,  92,  38,  75,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16, 111,  58,  58,  58,  58,  58,  58,  58,  73,  73,  73, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127,  46,  46, 152, 158,   0,   0,   0,   0,   0,
          0,  12, 110, 110,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85, 129, 129, 129, 129, 129, 129, 129,  42,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  10,  10,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128,  39,  39,  39, 126, 126, 126, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161,  14,  80,  80,  80,  80,  80,  80,  98, 143,  14, 164,
         97,  96,  96,  96,  96,  96,  96, 120, 120, 120, 120, 120, 120, 111,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 111, 110, 110,  56,  56,  56,  56,  56,
         56,  61,  61,  61,   0,   0,   0,   0,   0,   0, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140,  23,  23,  23,  23,  23,
         10,  10,  68,  68, 131, 131, 131, 131, 131,  80,  80,  80,  80,  80,
         80,  88,  88, 109, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         10,  10, 158,  91,  91,  91, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161,  35,  35,  35,  35,  35,  35,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 110, 110,
         12,  36, 103, 103,   8,   8, 166, 166, 166, 166, 166, 166,  66,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  89,  89], device='cuda:0') torch.Size([626])
10/19/2023, 04:26:19# predicted of Validation: tensor([129, 129, 129, 129, 129, 129, 129, 152,  49, 143,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16, 162,  58,  58,  58,  58,  58,  58,  58,  73,  73,  73, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127,  46,  46,  92,  87,   0,   0,   0,   0,   0,
          0,  38,  34,  34,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85, 129, 129, 129, 129, 129, 129, 129, 143,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  10,  10,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128,  39,  39,  39, 126, 126, 126, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 164,  80,  80,  80,  80,  80,  80,  98,  33,  60, 162,
         18,  96,  96,  96,  96,  96,  96, 120, 120, 120, 120, 120, 120,  36,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128,  87,  12,  12,  56,  56,  56,  56,  56,
         56,  61,  61,  61,   0,   0,   0,   0,   0,   0, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140,  23,  23,  23,  23,  23,
         10,  10,  60, 121, 151, 151, 151,  14,  14,  80,  80,  80,  80,  80,
         80,  42,  42,   2, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         10,  10,  44, 150,   4,   4, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161,  35,  35,  35,  35,  35,  35,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 112, 112,
         49,  92, 150, 150, 116, 116, 166, 166, 166, 166, 166, 166,  66,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  89,  89], device='cuda:0') torch.Size([626])
10/19/2023, 04:26:19# labels of 0: tensor([129, 129, 129, 129, 129, 129, 129,  92,  38,  75,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16, 111,  58,  58,  58,  58,  58,  58,  58,  73,  73,  73, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127,  46,  46, 152, 158,   0,   0,   0,   0,   0,
          0,  12, 110, 110,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85, 129, 129, 129, 129, 129, 129, 129,  42,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  10,  10,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128,  39,  39,  39, 126, 126, 126, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161,  14,  80,  80,  80,  80,  80,  80,  98, 143,  14, 164,
         97,  96,  96,  96,  96,  96,  96, 120, 120, 120, 120, 120, 120, 111,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 111, 110, 110,  56,  56,  56,  56,  56,
         56,  61,  61,  61,   0,   0,   0,   0,   0,   0, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140,  23,  23,  23,  23,  23,
         10,  10,  68,  68, 131, 131, 131, 131, 131,  80,  80,  80,  80,  80,
         80,  88,  88, 109, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         10,  10, 158,  91,  91,  91, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161,  35,  35,  35,  35,  35,  35,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 110, 110,
         12,  36, 103, 103,   8,   8, 166, 166, 166, 166, 166, 166,  66,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  89,  89], device='cuda:0') torch.Size([626])
10/19/2023, 04:26:19# predicted of 0: tensor([129, 129, 129, 129, 129, 129, 129, 152,  49, 143,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16, 162,  58,  58,  58,  58,  58,  58,  58,  73,  73,  73, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127,  46,  46,  92,  87,   0,   0,   0,   0,   0,
          0,  38,  34,  34,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85, 129, 129, 129, 129, 129, 129, 129, 143,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  10,  10,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128,  39,  39,  39, 126, 126, 126, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 164,  80,  80,  80,  80,  80,  80,  98,  33,  60, 162,
         18,  96,  96,  96,  96,  96,  96, 120, 120, 120, 120, 120, 120,  36,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128,  87,  12,  12,  56,  56,  56,  56,  56,
         56,  61,  61,  61,   0,   0,   0,   0,   0,   0, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140,  23,  23,  23,  23,  23,
         10,  10,  60, 121, 151, 151, 151,  14,  14,  80,  80,  80,  80,  80,
         80,  42,  42,   2, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         10,  10,  44, 150,   4,   4, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161,  35,  35,  35,  35,  35,  35,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 112, 112,
         49,  92, 150, 150, 116, 116, 166, 166, 166, 166, 166, 166,  66,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  89,  89], device='cuda:0') torch.Size([626])
10/19/2023, 04:26:28# Validation Loss: 0.4805 | Validation Accuracy: 0.9582

10/19/2023, 04:26:28# Find a better model!!
10/19/2023, 04:54:50# labels of 50000: tensor([121, 121,  47,  36,  38, 151,   9, 144, 162, 111,  74,  81, 150,  87,
          9,  14, 162,  83, 125,  12, 111,   9,  87,  75,  30, 142,  24,   4,
         31,   1,  76, 109,  60, 109,  60,  48,   1, 109, 162,  83,   1, 143,
         83, 142,  14, 142,  47,  97,  42,  53,  18,  34,  18,  34, 125,  87,
         36, 164,   9,  54,  31,  38,  49,  34], device='cuda:0') torch.Size([64])
10/19/2023, 04:54:50# predicted of 50000: tensor([121, 121,  47,  36,  38, 151,   9, 144, 162, 111,  74,  81, 150,  87,
          9,  14, 162,  83, 125,  12, 111,   9,  87,  75,  30, 142,  24,   4,
         31,   1,  76, 109,  60, 109,  60,  48,   1, 109, 162,  83,   1, 143,
         83, 142,  14, 142,  47,  97,  42, 143,  18,  34, 121,  34,  24,  87,
         36, 164,   9,  54,  31,  38,  49,  34], device='cuda:0') torch.Size([64])
10/19/2023, 05:24:02# labels of 100000: tensor([ 38, 150, 157, 152,  24,  49,  38,  49,  48, 158,  11, 121, 116, 112,
         87,  92,  12,  92,  18,  42, 151,  47, 124, 143,  14,  57,  53,  36,
        121,  38,  54,  97,  42,  87,  53,  38,  31, 121,  38,  30, 125,  38,
         60,  54,  83, 119,  81, 125, 112, 121,  55,  76, 121, 144,  18, 119,
         18,  81,  97,  57,   4,  38,  75, 158], device='cuda:0') torch.Size([64])
10/19/2023, 05:24:02# predicted of 100000: tensor([ 38, 150, 157, 152,  24,  49,  38,  49,  48, 158,  11, 121, 116, 112,
         87,  92,  12,  92,  18,  42, 151,  47, 124, 143,  14,  57,  53,  36,
        151,  38,  54,  97,  42,  87,  53,  38,  31, 121,  38,  30, 125,  38,
         60,  54,  83, 119,  81, 125, 112,   9,  55,  76, 121, 144,  18, 119,
         24, 124,  97,  57,   4,  38,  75, 158], device='cuda:0') torch.Size([64])
10/19/2023, 05:50:56# labels of 150000: tensor([143,  47,  81,  54, 111,  54,  55,  47,  18,  49,  49,  75,  18, 104,
        142, 151,   9, 150, 143, 151,  49,  11, 152, 151, 164,  76, 111,  97,
         48,  74,  44,  24,  48,  47,  92, 150, 111,  76, 104, 109, 124, 119,
        152, 111,  14,  92, 151,  11, 152, 125, 121,  57,   9, 111, 150, 162,
         60, 151, 157,  60,  14,  60, 116,  92], device='cuda:0') torch.Size([64])
10/19/2023, 05:50:56# predicted of 150000: tensor([143,  47,  81,  54, 111,  54,  55,  47,  18,  49,  49,  75,  18, 104,
        142, 151,   9, 150, 143, 151,  49,  11, 152, 151, 164,  76, 111,  97,
         48,  74,  44,  24,  76,  47,  92, 150, 111,  76, 104, 109, 124, 119,
        152, 111,  14,  92, 151,  11, 152, 125, 121,  57,   9, 111, 150, 162,
         60, 151, 157,  60,  14,  60, 116,  92], device='cuda:0') torch.Size([64])
10/19/2023, 06:17:32# labels of 200000: tensor([151, 121,  38,  18, 111, 121,  44,  83, 164,   9, 116,  38, 142,  74,
         14, 109, 121, 124, 152,  24,  30,   4,  87,  83,  48,  38, 162, 162,
        164, 109,  53,  30,  92, 152,  53, 152,  81, 152, 112,  57, 124, 119,
         47,  53,  12, 124,   4,   9,  81,  57,   9, 162,   1,  75,  92,  54,
        121, 112,  75,  33,  75, 121,  42, 142], device='cuda:0') torch.Size([64])
10/19/2023, 06:17:32# predicted of 200000: tensor([151, 121,  38,  18, 111, 121,  44,  83, 164,   9, 116,  38, 142,  74,
         14, 109, 121, 124, 152,  24,  30,   4,  87,  83,  48,  38, 162, 162,
        164, 109,  53,  30,  92, 152,  53, 152,  81, 152, 112,  57, 124, 119,
         47, 152,  12,  55,  57,   9,  81,  57,   9, 162,   1,  75,  92,  54,
        121, 112,  75,  33,  75, 121,  42, 142], device='cuda:0') torch.Size([64])
10/19/2023, 06:24:27# total batches: 213400
10/19/2023, 06:24:27# Epoch 1 | Train Loss: 0.2101 | Train Accuracy: 0.9507
10/19/2023, 06:24:27# labels of Validation: tensor([ 58,  58,  58,  58,  58,  58,  58,  36,  11,  61,  61,  61,  39,  39,
         39,  87, 129, 129, 129, 129, 129, 129, 129, 157, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165,  71,  71,  71,  71,  71,  71,
         49,  10,  10,  53,  44, 103, 103,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  31, 112,  65,  65,
         65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 150,   2, 150,  35,  35,  35,  35,  35,
         35, 158,  59,  59,  59,  56,  56,  56,  56,  56,  56,  88,  88, 104,
         48, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,   1,  88,  88,  98, 133, 133, 133, 133, 133, 133, 133,
        133,  59,  59,  59,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,   1,  65,
         46,  46, 110, 110, 147,  65,  65,  65, 147, 147, 147, 147,  73,  73,
         73, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 112,  80,  80,  80,  80,
         80,  80, 166, 166, 166, 166, 166, 166, 148, 148, 148, 148, 148, 148,
        148,  94,  94,  91,  91,  91,  93,  93,  54,  77,  77,  77,  77,  77,
         77,  77,  77, 158,  64,  64, 125,  60,  33, 121, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138,  43,  43, 157,  72,  72,  75, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101],
       device='cuda:0') torch.Size([644])
10/19/2023, 06:24:27# predicted of Validation: tensor([ 58,  58,  58,  58,  58,  58,  58, 119,  36,  61,  61,  61,  39,  39,
         39,   2, 129, 129, 129, 129, 129, 129, 129,  87, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165,  71,  71,  71,  71,  71,  71,
         87,  10,  10,  60,  11,  76,  76,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  92,  11,  65,  65,
         65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149,   2,   2,  38,  35,  35,  35,  35,  35,
         35, 116,  14,  14,  14,  56,  56,  56,  56,  56,  56, 151, 151, 125,
         24, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  11,  74,  74,  98, 133, 133, 133, 133, 133, 133, 133,
        133, 152, 152, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  87,  65,
         46,  46, 121, 121, 147,  65,  65,  65, 147, 147, 147, 147,  73,  73,
         73, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  55,  80,  80,  80,  80,
         80,  80, 166, 166, 166, 166, 166, 166, 148, 148, 148, 148, 148, 148,
        148,  94,  94, 119, 119,  38,  60,  60,  81,  77,  77,  77,  77,  77,
         77,  77,  77,  75,  83, 111,  87, 121,   2, 150, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138,  43,  43, 150,  72,  54,   4, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101],
       device='cuda:0') torch.Size([644])
10/19/2023, 06:24:27# labels of 0: tensor([ 58,  58,  58,  58,  58,  58,  58,  36,  11,  61,  61,  61,  39,  39,
         39,  87, 129, 129, 129, 129, 129, 129, 129, 157, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165,  71,  71,  71,  71,  71,  71,
         49,  10,  10,  53,  44, 103, 103,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  31, 112,  65,  65,
         65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 150,   2, 150,  35,  35,  35,  35,  35,
         35, 158,  59,  59,  59,  56,  56,  56,  56,  56,  56,  88,  88, 104,
         48, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,   1,  88,  88,  98, 133, 133, 133, 133, 133, 133, 133,
        133,  59,  59,  59,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,   1,  65,
         46,  46, 110, 110, 147,  65,  65,  65, 147, 147, 147, 147,  73,  73,
         73, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 112,  80,  80,  80,  80,
         80,  80, 166, 166, 166, 166, 166, 166, 148, 148, 148, 148, 148, 148,
        148,  94,  94,  91,  91,  91,  93,  93,  54,  77,  77,  77,  77,  77,
         77,  77,  77, 158,  64,  64, 125,  60,  33, 121, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138,  43,  43, 157,  72,  72,  75, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101],
       device='cuda:0') torch.Size([644])
10/19/2023, 06:24:27# predicted of 0: tensor([ 58,  58,  58,  58,  58,  58,  58, 119,  36,  61,  61,  61,  39,  39,
         39,   2, 129, 129, 129, 129, 129, 129, 129,  87, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165,  71,  71,  71,  71,  71,  71,
         87,  10,  10,  60,  11,  76,  76,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  92,  11,  65,  65,
         65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149,   2,   2,  38,  35,  35,  35,  35,  35,
         35, 116,  14,  14,  14,  56,  56,  56,  56,  56,  56, 151, 151, 125,
         24, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  11,  74,  74,  98, 133, 133, 133, 133, 133, 133, 133,
        133, 152, 152, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  87,  65,
         46,  46, 121, 121, 147,  65,  65,  65, 147, 147, 147, 147,  73,  73,
         73, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65,  65, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  55,  80,  80,  80,  80,
         80,  80, 166, 166, 166, 166, 166, 166, 148, 148, 148, 148, 148, 148,
        148,  94,  94, 119, 119,  38,  60,  60,  81,  77,  77,  77,  77,  77,
         77,  77,  77,  75,  83, 111,  87, 121,   2, 150, 138, 138, 138, 138,
        138, 138, 138, 138, 138, 138,  43,  43, 150,  72,  54,   4, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101],
       device='cuda:0') torch.Size([644])
10/19/2023, 06:24:36# Validation Loss: 0.4894 | Validation Accuracy: 0.9559

10/19/2023, 06:53:43# labels of 50000: tensor([ 49,   2,  76, 162,  33, 121,  81, 162, 152,  47, 125,  47, 162, 119,
         44, 150,  30,  55,  47,  87, 157, 142,  53,  42,  36,  38,  12,  92,
        142,  74, 119, 125,  12, 125,   4,  81,  34,   4, 109,  24, 116, 125,
        104,  87,   4,  55, 162, 116, 164, 158,   9, 151,   9, 144,  57, 104,
        158, 104,  83, 104,  55,  75, 104, 124], device='cuda:0') torch.Size([64])
10/19/2023, 06:53:43# predicted of 50000: tensor([ 49,   2,  76, 162,  33, 121,  81, 162, 152,  47, 125,  47, 162, 119,
         44, 150,  30,  55,  47,  87, 157,  76,  53,  42,  36,  38,  12,  92,
        142,  74, 119, 125,  12, 125,   4, 116,  34, 116, 109,  24, 116, 125,
        104,  87,   4,  55, 162, 116, 164, 158,   9, 151,   9, 144,  57, 104,
        158, 104,  83, 104,  55,  75, 104, 124], device='cuda:0') torch.Size([64])
10/19/2023, 07:22:51# labels of 100000: tensor([119,  47, 124, 151, 124, 152,  33,  31,  33, 111, 121,  83, 121,  31,
         75, 142, 163,  36,  12, 109,  14, 163,  74,  36, 116,  75,  18, 104,
         53,  54, 164, 142,  12,  97,  81, 164,  47,   2,  75, 158, 162,  81,
        163,  34,  42, 112,   2,  81,  44,  48,  44,  55,  18,  30,  57,   4,
         74, 116, 112,  12,  92,  53,  59,  59,  59,  81], device='cuda:0') torch.Size([66])
10/19/2023, 07:22:51# predicted of 100000: tensor([119,  47, 124, 151, 124, 152,  33,  31,  33, 111, 121,  83, 121,  31,
         75, 142, 163,  36,  12, 109,  14, 163,  74,  36, 116,  75,  18, 104,
         53,  54, 164, 142,  12,  97,  81, 164,  47,   2,  75, 158, 162,  81,
        163,  34,  42, 112,   2,  81,  44,  48,  44,  55,  18,  30,  57,   4,
         74, 116, 112,  12,  92,  53,  14,  14,  14,  81], device='cuda:0') torch.Size([66])
10/19/2023, 07:49:53# labels of 150000: tensor([ 92,  63,  63,  63,  63,  36,   4,  31, 164,  42,  34,  81, 143, 119,
         49,  60,  49, 152,  55,  30,  42,  18, 142,  24,  87, 116, 121,  83,
         47,  57,  33, 104,  55, 125,  31,  33,  42,  83, 143,  18, 111,  55,
        163, 143,  31,  38,  31, 119, 111,  54,  12, 162, 144,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7, 158,  30,  55, 116,  55, 157,
         83,  76, 142,  38, 109, 119,  87], device='cuda:0') torch.Size([133])
10/19/2023, 07:49:53# predicted of 150000: tensor([ 92,  63,  63,  63,  63,  36,   4,  31, 164,  42,  34,  81, 143, 119,
         49,  60,  49, 152, 104,  30,  42, 157, 142,  24,  87, 116, 121,  83,
         47,  57,  33, 104,  55, 125,  31,  33,  42,  83, 143,  18, 111,  55,
        163, 143,  31,  38,  31, 119, 111,  54,  12, 162, 144,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7, 158,  30,  55, 116,  55, 157,
         83,  76, 142,  38, 109, 119,  87], device='cuda:0') torch.Size([133])
10/19/2023, 08:16:18# labels of 200000: tensor([ 83, 119, 163, 164,  53,  18,  44,  30, 158,  74,  81, 125,  34,  97,
        124,  55,  74,  34, 109, 151,  81,  92,  42, 163,  76, 142,  47, 119,
        158,  92, 109,  30,  54, 119,  75, 158, 142,  14, 142,   9,  36,  97,
         30, 104,  14,   9, 151, 111,  75, 109, 104,  14, 144,  60,  97,  42,
        109, 116, 109, 119, 116,  42,  38,  42], device='cuda:0') torch.Size([64])
10/19/2023, 08:16:18# predicted of 200000: tensor([ 83, 119, 163, 164,  53,  18,  44,  30, 158,  74,  81, 125,  34,  97,
        124,  55,  74,  34, 109, 151,  81,  92,  42, 125,  76, 142,  47, 119,
        158,  92, 109,  30,  54, 119,  75, 158, 142,  14, 142,   9,  36,  97,
         30, 104,  14,   9, 151, 111,  75, 109, 104,  14, 144,  60,  97,  42,
        109, 116, 109, 119, 116,  42,  38,  42], device='cuda:0') torch.Size([64])
10/19/2023, 08:23:35# total batches: 213400
10/19/2023, 08:23:35# Epoch 2 | Train Loss: 0.1695 | Train Accuracy: 0.9625
10/19/2023, 08:23:36# labels of Validation: tensor([110, 110,   0,   0,   0,   0,   0,   0,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  67,  67,  67,  67,
         67,   2, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  40,
         40,  40,  40,  40,  40,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  76,   1,  97,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  34,  68,  68,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 119,  79,  79, 136, 136, 136, 136, 136, 136, 136, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  30,  50,  50,  50,  90,  90,
         19,  19,  19,  19,  19, 155,  65,  65, 155, 155, 155,  78,  78,  78,
         78,  78, 125,  42,  94,  94,  92,   1,  81,  88,  88,  65, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 109,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101,  89,  89,  42,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 137, 137, 137,
        137, 137,  65,  65, 135, 135,  20,  20, 139, 139, 139, 139, 139,  83,
        116, 148, 148, 148, 148, 148, 148, 148, 142, 115, 115, 115, 115, 115,
        115, 115, 115, 115, 115,  98,  73,  73,  73, 113, 113,  11,  24, 133,
        133, 133, 133, 133, 133, 133, 133,  19,  19,  19,  19,  19,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 153, 153, 153,  86,  86,
         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  34, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  74,  92, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123],
       device='cuda:0') torch.Size([502])
10/19/2023, 08:23:36# predicted of Validation: tensor([116, 116,   0,   0,   0,   0,   0,   0,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  78,  78,  78,  78,
         78,  83, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  40,
         40,  40,  40,  40,  40,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 157, 152,  31,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  34,  57,  49,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 158,  44,  79, 136, 136, 136, 136, 136, 136, 136, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  14,  50,  50,  50,  12,  12,
         19,  19,  19,  19,  19, 155,  65,  65, 155, 155, 155,  78,  78,  78,
         78,  78,  48,  38,  94,  94,  14, 125,  60, 157,  75,  65, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  47,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101,  89,  89, 104,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 137, 137, 137,
        137, 137,  65,  65, 135, 135,  20,  20, 139, 139, 139, 139, 139, 162,
        116, 148, 148, 148, 148, 148, 148, 148,  54, 115, 115, 115, 115, 115,
        115, 115, 115, 115, 115,  98,  73,  73,  73,  59,  59,   1,  36, 133,
        133, 133, 133, 133, 133, 133, 133,  19,  19,  19,  19,  19,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 153, 153, 153,  86,  86,
         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 109, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  30,   2, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123],
       device='cuda:0') torch.Size([502])
10/19/2023, 08:23:36# labels of 0: tensor([110, 110,   0,   0,   0,   0,   0,   0,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  67,  67,  67,  67,
         67,   2, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  40,
         40,  40,  40,  40,  40,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  76,   1,  97,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  34,  68,  68,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 119,  79,  79, 136, 136, 136, 136, 136, 136, 136, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  30,  50,  50,  50,  90,  90,
         19,  19,  19,  19,  19, 155,  65,  65, 155, 155, 155,  78,  78,  78,
         78,  78, 125,  42,  94,  94,  92,   1,  81,  88,  88,  65, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 109,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101,  89,  89,  42,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 137, 137, 137,
        137, 137,  65,  65, 135, 135,  20,  20, 139, 139, 139, 139, 139,  83,
        116, 148, 148, 148, 148, 148, 148, 148, 142, 115, 115, 115, 115, 115,
        115, 115, 115, 115, 115,  98,  73,  73,  73, 113, 113,  11,  24, 133,
        133, 133, 133, 133, 133, 133, 133,  19,  19,  19,  19,  19,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 153, 153, 153,  86,  86,
         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  34, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  74,  92, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123],
       device='cuda:0') torch.Size([502])
10/19/2023, 08:23:36# predicted of 0: tensor([116, 116,   0,   0,   0,   0,   0,   0,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  78,  78,  78,  78,
         78,  83, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,  40,
         40,  40,  40,  40,  40,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 157, 152,  31,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  34,  57,  49,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 158,  44,  79, 136, 136, 136, 136, 136, 136, 136, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  14,  50,  50,  50,  12,  12,
         19,  19,  19,  19,  19, 155,  65,  65, 155, 155, 155,  78,  78,  78,
         78,  78,  48,  38,  94,  94,  14, 125,  60, 157,  75,  65, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  47,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101,  89,  89, 104,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, 137, 137, 137,
        137, 137,  65,  65, 135, 135,  20,  20, 139, 139, 139, 139, 139, 162,
        116, 148, 148, 148, 148, 148, 148, 148,  54, 115, 115, 115, 115, 115,
        115, 115, 115, 115, 115,  98,  73,  73,  73,  59,  59,   1,  36, 133,
        133, 133, 133, 133, 133, 133, 133,  19,  19,  19,  19,  19,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 153, 153, 153,  86,  86,
         21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21, 109, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 115,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  30,   2, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123],
       device='cuda:0') torch.Size([502])
10/19/2023, 08:23:44# Validation Loss: 0.4770 | Validation Accuracy: 0.9565

10/19/2023, 08:23:44# Find a better model!!
10/19/2023, 08:52:45# labels of 50000: tensor([ 92, 158,   1,  81, 160, 160, 160, 160, 160, 160, 160, 160, 111, 119,
         81,  81,  81,  81, 162, 151,  38,  57,  74,  49, 150,  42,  87,  87,
         60, 143,  31,  30,  53,  83,   4,  92, 157,  38,  74,  92,  33,  75,
         76,   9,  87,  55,  53, 151, 164,  14,  47, 152,  11, 163,   1, 158,
        142,  75,  14,  18,  18,  18, 124,  74, 143,  38,  92,   4, 157,  75,
        150], device='cuda:0') torch.Size([71])
10/19/2023, 08:52:45# predicted of 50000: tensor([ 92, 158,   1,  81, 160, 160, 160, 160, 160, 160, 160, 160, 111, 119,
         81,  81,  81,  81, 162, 151,  38,  57,  74,  49, 150,  42,  87,  87,
         60, 143,  31,  30,  53,  83,   4,  92, 157,  38,  74,  92,  33,  75,
         76,   9,  87,  55,  53, 151, 164, 151,  47, 152,  11, 163,   1, 158,
        142,  75,  14,  18,  18,  18, 124,  74, 143,  38,  92,   4, 157,  75,
        150], device='cuda:0') torch.Size([71])
10/19/2023, 09:21:48# labels of 100000: tensor([121,  75, 116, 121, 151,  81,   4,  92,  92,  31,  18,  47,  87,  48,
         97, 116,  47,  24, 111, 109, 150,  14,   2,  42,   9,  12, 163,  76,
         54,  48,  18,  33, 104,  38,  92,  81,  42,  87,  36,  53,   9,  81,
        109, 109,  97,  31, 164,  54, 164,  54,  12,   1,  36, 121, 119, 162,
         36,  49, 104,  44, 125,  83,  36, 144], device='cuda:0') torch.Size([64])
10/19/2023, 09:21:48# predicted of 100000: tensor([121,  75, 116, 121, 151,  81,   4,  92,  92,  31,  18,  47,  87,  48,
         97, 116,  47,  24, 111, 109, 150,  14,   2,  42,   9,  12, 163,  76,
         54,  48,  18,  33, 104,  38,  92,  81,  42,  87,  36,  53,   9,  81,
        109, 109,  97,  31, 164,  54,  18,  54,  12,   1,  36, 121, 119, 162,
         36,  49, 104,  44, 125,  83,  36, 144], device='cuda:0') torch.Size([64])
10/19/2023, 09:48:58# labels of 150000: tensor([ 14,  11, 104, 116,   9,  14,  53, 112, 158,   1,  97,  14,   4, 144,
         49, 112,  38,  44, 104,  55,  47, 152,  38, 109,  49,  44,  44,  49,
        125,   4, 112, 109,   9, 158, 157, 124,  48,   2, 143,  12, 125, 150,
        124,  87,  44,  15,  15,  15,   9, 151, 144, 104,  74,  14,   4,  44,
        163,  74, 109, 143,  47,  48,  31, 158,  34,   1], device='cuda:0') torch.Size([66])
10/19/2023, 09:48:58# predicted of 150000: tensor([ 74,  11, 104, 116,   9,  14,  53, 112, 158,   1,  97,  14,   4, 144,
         49, 112,  38,  44, 104,  55,  47, 152,  38, 109,  49,  44,  44,  49,
        125,   4, 112, 109,   9, 158, 157, 124,   2,   2, 143,  12, 125, 150,
        124,  87,  44,  15,  15,  15,   9, 151, 144, 104,  74,  14,   4,  44,
        163,  74, 109,  60,  47,  48,  31, 158,  34,   1], device='cuda:0') torch.Size([66])
10/19/2023, 10:15:55# labels of 200000: tensor([ 57, 121,  97, 157,  18,   1,   4, 143, 158,  75,   9,  48, 162, 157,
        152,  38, 142,  33, 112,  36,  33, 162,  34, 111, 104,  11, 104,  87,
        111,   2, 112,  83, 111,  76,   1,  18,  44, 150,  53,  38, 157,   1,
         36, 158, 111,  76, 157,  14,  55, 142, 111,  53, 121,  54,  47, 112,
          2,  30, 109,  53,  36,   1,  24,  30], device='cuda:0') torch.Size([64])
10/19/2023, 10:15:55# predicted of 200000: tensor([ 57, 121,  97, 157,  18,   1,   4, 143, 158,  75,   9,  48, 162, 157,
        152,  38, 142,  33, 112,  36,  33, 162,  34, 111, 104,  11, 104,  87,
        111,   2, 112,  83, 111,  76,   1,  24,  44, 150,  53,  38, 157,   1,
         36, 158, 111,  76, 157,  14,  55, 142, 111,  53, 121,  54,  47, 112,
          2,  30, 109,  53,  36,   1,  24,  30], device='cuda:0') torch.Size([64])
10/19/2023, 10:23:12# total batches: 213400
10/19/2023, 10:23:12# Epoch 3 | Train Loss: 0.1414 | Train Accuracy: 0.9679
10/19/2023, 10:23:12# labels of Validation: tensor([120, 120, 120, 120, 120, 120,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
        106, 106, 106, 106, 106,  12,  93,  93,   2, 125,  97, 115, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 109, 151, 130, 130, 130, 130, 130,
        119, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  75, 110, 110,
        110, 110, 157, 153, 153, 153,  65,  65,  65, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,  56,  56,  56,
         56,  56,  56,  64,  64,  30,  73,  73,  73, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 146, 146, 146, 146, 146, 146,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  31, 113, 113,  15,  15,  15,
        124,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  90,  90, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
          4,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,  24,  60, 145, 145, 145, 145, 145, 145,  49, 146, 146, 146,
        146, 146, 146,   1, 109,  69,  69,  69,  69,  69,  69,   4, 125,  73,
         73,  73, 133, 133, 133, 133, 133, 133, 133, 133,  26,  26,  26,  26,
         26,  26, 163, 130, 130, 130, 130, 130,  34,  57,  35,  35,  65,  35,
         35,  35,  35, 120, 120, 120, 120, 120, 120, 157, 150,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,   0,   0,   0,   0,   0,   0,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,
         82,  82,  82,  82,  82,  82,  82,  82,  82, 144,   2],
       device='cuda:0') torch.Size([501])
10/19/2023, 10:23:12# predicted of Validation: tensor([120, 120, 120, 120, 120, 120,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 154, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
        106, 106, 106, 106, 106,  75,  14,  14, 124, 162, 121, 115, 115, 115,
        115, 115, 115, 115, 115, 115, 115,  76,  42, 130, 130, 130, 130, 130,
         38, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  76, 111, 111,
        162, 144,  14, 153, 153, 153,  65,  65,  65, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,  56,  56,  56,
         56,  56,  56, 162, 162, 143,  73,  73,  73, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 146, 146, 146, 146, 146, 146,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  49,  81,  81,  15,  15,  15,
         57,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  14,  14, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
        162,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,  54, 164, 145, 145, 145, 145, 145, 145,  60, 146, 146, 146,
        146, 146, 146,  14,  12,  69,  69,  69,  69,  69,  69,  60, 124,  73,
         73,  73, 133, 133, 133, 133, 133, 133, 133, 133,  26,  26,  26,  26,
         26,  26,  74, 130, 130, 130, 130, 130, 125,  48,  35,  35,  65,  35,
         35,  35,  35, 120, 120, 120, 120, 120, 120,  53,  49,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,   0,   0,   0,   0,   0,   0,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,
         82,  82,  82,  82,  82,  82,  82,  82,  82, 152, 142],
       device='cuda:0') torch.Size([501])
10/19/2023, 10:23:12# labels of 0: tensor([120, 120, 120, 120, 120, 120,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
        106, 106, 106, 106, 106,  12,  93,  93,   2, 125,  97, 115, 115, 115,
        115, 115, 115, 115, 115, 115, 115, 109, 151, 130, 130, 130, 130, 130,
        119, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  75, 110, 110,
        110, 110, 157, 153, 153, 153,  65,  65,  65, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,  56,  56,  56,
         56,  56,  56,  64,  64,  30,  73,  73,  73, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 146, 146, 146, 146, 146, 146,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  31, 113, 113,  15,  15,  15,
        124,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  90,  90, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
          4,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,  24,  60, 145, 145, 145, 145, 145, 145,  49, 146, 146, 146,
        146, 146, 146,   1, 109,  69,  69,  69,  69,  69,  69,   4, 125,  73,
         73,  73, 133, 133, 133, 133, 133, 133, 133, 133,  26,  26,  26,  26,
         26,  26, 163, 130, 130, 130, 130, 130,  34,  57,  35,  35,  65,  35,
         35,  35,  35, 120, 120, 120, 120, 120, 120, 157, 150,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,   0,   0,   0,   0,   0,   0,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,
         82,  82,  82,  82,  82,  82,  82,  82,  82, 144,   2],
       device='cuda:0') torch.Size([501])
10/19/2023, 10:23:12# predicted of 0: tensor([120, 120, 120, 120, 120, 120,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 154, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
        106, 106, 106, 106, 106,  75,  14,  14, 124, 162, 121, 115, 115, 115,
        115, 115, 115, 115, 115, 115, 115,  76,  42, 130, 130, 130, 130, 130,
         38, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  76, 111, 111,
        162, 144,  14, 153, 153, 153,  65,  65,  65, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,  56,  56,  56,
         56,  56,  56, 162, 162, 143,  73,  73,  73, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 146, 146, 146, 146, 146, 146,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  49,  81,  81,  15,  15,  15,
         57,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  14,  14, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156,  65,  65, 156, 156, 156, 156, 156, 156, 156, 156,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
        162,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,  54, 164, 145, 145, 145, 145, 145, 145,  60, 146, 146, 146,
        146, 146, 146,  14,  12,  69,  69,  69,  69,  69,  69,  60, 124,  73,
         73,  73, 133, 133, 133, 133, 133, 133, 133, 133,  26,  26,  26,  26,
         26,  26,  74, 130, 130, 130, 130, 130, 125,  48,  35,  35,  65,  35,
         35,  35,  35, 120, 120, 120, 120, 120, 120,  53,  49,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,   0,   0,   0,   0,   0,   0,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,
         82,  82,  82,  82,  82,  82,  82,  82,  82, 152, 142],
       device='cuda:0') torch.Size([501])
10/19/2023, 10:23:22# Validation Loss: 0.4858 | Validation Accuracy: 0.9580

10/19/2023, 10:52:44# labels of 50000: tensor([119, 111,   1,   2,  92,  57,  18, 151, 158, 162,  11,  55, 163,  18,
        157,  74,  49,  34, 111, 109, 163,  30, 143, 150,  14,  92, 151,  49,
         74, 112,  12,  48,  74,  34,  42, 164,  18, 152,  38,  83,  36, 157,
         33,  74, 152, 143,  76,  47,  47,   9,  11,  14,  49,  83,  33, 151,
         47,   9, 104,  57,   1,  47,  34,  55], device='cuda:0') torch.Size([64])
10/19/2023, 10:52:44# predicted of 50000: tensor([119, 111,   1,   2,  92,  57,  18, 151, 158, 162,  11, 125, 163,  18,
        157,  74,  49,  34, 111, 109, 163,  30, 143, 150,  14,  92, 151,  49,
         74,  60,  12,  48,  74,  34,  42, 164,  18, 152,  38,  83,  36, 157,
         33,  74, 152, 143,  57,  47,  47,   9,  11,  14,  49,  83,  33, 151,
         47,   9, 104,  57,   1,  47,  34,  55], device='cuda:0') torch.Size([64])
10/19/2023, 11:18:38# labels of 100000: tensor([ 60,  33, 157,  57,  74, 124,  48, 151,  47,  44, 158, 157, 125,  12,
         92, 112, 144, 121,   4, 121,  87, 124,  54,  92,  54,  42,  34,  36,
         44,  11,  36, 157,  74, 111, 142, 144,  54,  92,   2, 152,  18,  18,
        152,  48, 145, 145, 145, 145, 145, 145,  44,   2,  74,   4, 163,  74,
        164,  75, 104,  61,  61,  61, 144, 164,   2,  42,  76, 151,  30,  55,
        143], device='cuda:0') torch.Size([71])
10/19/2023, 11:18:38# predicted of 100000: tensor([ 60,  33, 157,  57,  74, 124,  48, 151,  47,  44, 158, 157, 125,  12,
         92, 112, 144, 121,   4, 121,  87, 124,  54,  92,  54,  42,  34,  36,
         44,  11,  36, 157,  74, 111, 142, 144,  54,  92,   2, 152,  18,  18,
        152,  48, 145, 145, 145, 145, 145, 145,  44,   2,  74,   4, 163, 162,
        164,  75, 104,  61,  61,  61, 144, 164,   2,  42,  76, 151,  30,  55,
        143], device='cuda:0') torch.Size([71])
10/19/2023, 11:46:55# labels of 150000: tensor([151, 111,  97, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 157, 143,  74, 112, 111, 119,  76, 152, 163,  18,  81,  42,  11,
        164, 119, 150, 112, 142, 143,  54,  14, 150,  75, 152, 112,  53,  11,
        124,  53,  55,  75, 157,  12,  18,  33,  76, 104,  74, 143,  57, 111,
         34,  60, 119, 157,  11,  42,   9,  24,  75,  30,  49,   2,  33,  18,
         53,   4, 124,  53,  49], device='cuda:0') torch.Size([145])
10/19/2023, 11:46:55# predicted of 150000: tensor([151, 111,  97, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 157, 143,  74, 112, 111, 119,  76, 152, 163,   9,  81,  42,  11,
        164, 119, 150, 112, 142, 143,  54,  14, 150,  75, 152, 112,  53,  11,
        124,  53,  55,  75, 157,  12,  18,  33,  76, 104,  74, 143,  57, 111,
         34,  60, 119, 157,  11,  42,   9,  24,  36,  30,  49,   2,  33,  18,
         53,   4, 124,  53,  49], device='cuda:0') torch.Size([145])
10/19/2023, 12:13:13# labels of 200000: tensor([ 87, 152, 151,  31,  92,  24,  57, 150, 121,  11,  31, 121,  75,  75,
         14,  60,  34, 142, 125,  54,  75,  30,  12,  11,  24,  87, 121,  12,
         38, 150, 158,  12,  31, 124, 112,  57, 151, 162,  57, 143,  38,  36,
        111,  57, 116,  76,  87,  31, 124, 124,  31,  87,  34, 142, 109,  83,
        116,  33,   9, 151,   1,  33,  33, 112], device='cuda:0') torch.Size([64])
10/19/2023, 12:13:13# predicted of 200000: tensor([ 87, 152, 151,  31,  92,  24,  57, 150, 121,  11,  31, 121,  75,  75,
         14,  60,  34, 142, 125,  54,  75,  30,  12,  11,  24,  87, 121,  12,
         38, 150, 158,  12,  31, 124, 112,  57, 151, 162,  57, 143,  38,  36,
        111,  57, 116,  76,  87,  31, 124, 124,  31,  87,  34, 142, 109,  83,
        116,  33,  49, 151,   1,  33,  33, 112], device='cuda:0') torch.Size([64])
10/19/2023, 12:20:06# total batches: 213400
10/19/2023, 12:20:06# Epoch 4 | Train Loss: 0.1428 | Train Accuracy: 0.9695
10/19/2023, 12:20:06# labels of Validation: tensor([142, 113, 113,  ...,  85,  85,  85], device='cuda:0') torch.Size([1675])
10/19/2023, 12:20:06# predicted of Validation: tensor([150,  60, 131,  ...,  85,  85,  85], device='cuda:0') torch.Size([1675])
10/19/2023, 12:20:06# labels of 0: tensor([142, 113, 113,  ...,  85,  85,  85], device='cuda:0') torch.Size([1675])
10/19/2023, 12:20:06# predicted of 0: tensor([150,  60, 131,  ...,  85,  85,  85], device='cuda:0') torch.Size([1675])
10/19/2023, 12:20:15# Validation Loss: 0.6460 | Validation Accuracy: 0.9554

10/19/2023, 12:48:03# labels of 50000: tensor([ 55,  87, 104, 142,  57, 125,   9,  12,  30,  87,  24, 157, 112, 104,
         24, 124,  24,  34,   1,  97,  24,  36, 157, 150, 104, 121,  18,  76,
         47,  14, 164, 104, 144,  47,  31,  42, 124, 125,  58,  58,  58,  58,
         58,  58,  58,   1,  31,  81, 158, 158,   2, 119, 151, 150, 111, 143,
         18,  31,  60,   9,  36,   9,  31, 150,   2, 124, 150,  92, 124, 111],
       device='cuda:0') torch.Size([70])
10/19/2023, 12:48:03# predicted of 50000: tensor([ 47,  87, 104, 142,  57, 125,   9,  12,  30,  87,  24, 157, 112, 104,
         24, 124,  24,  34,   1,  97,  24,  36, 157, 150, 104,  18,  18,  76,
         47,  14, 164, 104, 144,  47,  31,  42, 124, 125,  58,  58,  58,  58,
         58,  58,  58,   1,  31,  81, 158, 158,   2, 119, 151, 150, 111, 143,
         18,  31,  60,   9,  36,   9,  31, 150,   2, 124, 150,  92, 124, 111],
       device='cuda:0') torch.Size([70])
10/19/2023, 14:40:28# Train Classification Report at Epoch 5:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00     51200
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00      4800
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00      4000
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00     12000
    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.94      0.96      0.95    256000
    T1003.003_f049b89533298c2d6cd37a940248b219       0.98      0.90      0.94    256000
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00      4800
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00      4800
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.93      0.94      0.93    256000
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.13      0.06      0.08      2400
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.98      0.93      0.95    256000
        T1016_71b3d2945679566b9d94d8cb11df4b70       0.92      0.97      0.95    256000
        T1016_7d8ee68f0e9731db82964f558f614608       0.48      0.32      0.38      4000
    T1016_921055f4-5970-4707-909e-62f594234d91       0.95      0.95      0.95    256000
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.97      0.93      0.95    256000
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.93      0.98      0.96    256000
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.94      0.95      0.95    256000
        T1018_a44bb43474728496276d5d73aa14588f       0.93      0.98      0.96    256000
        T1018_ac20e592bc912bddff4d6b88289095f0       0.92      0.96      0.94    256000
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00      4800
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.91      0.98      0.94    256000
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.91      0.94      0.92    256000
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00     18400
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00     21600
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.67      0.00      0.00      1600
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.20      0.01      0.01      1600
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00      5600
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00      4000
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.95      0.97      0.96    256000
        T1047_6935e41353aa781bb723462d26114c44       0.94      0.96      0.95    256000
        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.91      0.97      0.94    256000
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.96      0.95      0.96    256000
        T1047_b0255b5120cbabc062d8d4510a142c3b       0.93      0.97      0.95    256000
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.94      0.98      0.96    256000
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.94      0.97      0.95    256000
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.98      0.93      0.95    256000
        T1049_a14392d713dffba6a397682ff83259a0       0.11      0.07      0.09      2400
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00      1600
    T1053.005_ee454be9197890de62705ce6255933fd       0.96      0.97      0.97    256000
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.96      0.96      0.96    256000
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.96      0.95      0.96    256000
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.95      0.92      0.93    256000
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00      5600
        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.97      0.95      0.96    256000
        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.98      0.96      0.97    256000
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      8000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00     12000
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00      4000
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      0.99      1.00      8000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00      4000
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00    109600
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00      5600
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00      4800
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00      7200
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.22      0.00      0.01      1600
    T1069.002_6103e503cb444bc7b4187704f2035708       0.36      0.03      0.06      3200
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00      4800
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00     16000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      8000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00      2400
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00      6400
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.94      0.96      0.95    256000
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.91      0.95      0.93    256000
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      9600
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.95      0.89      0.92    256000
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00      4000
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.92      0.95      0.93    256000
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.77      0.74      0.75      1600
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      8800
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.99      1.00      1600
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00      6400
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00     16800
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00     16000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      0.99      1.00     10400
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00     45600
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00    120000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00      2400
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00      2400
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00      2400
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00      2400
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       1.00      1.00      1.00      2400
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00      2400
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00      2400
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00      1600
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00      2400
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00     14400
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00      2400
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00      2400
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00      4000
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00     12800
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.94      0.92      0.93    256000
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00     15200
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00     16000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00      4800
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00      4800
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.87      0.97      0.92    256000
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00      4800
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.91      0.95      0.93    256000
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.96      0.96      0.96    256000
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00      4800
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00     10400
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.98      0.91      0.95    256000
        T1201_57296a2ddbeb7423c05feef2fe972111       0.99      0.91      0.95    256000
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      8000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00      3200
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.94      0.97      0.95    256000
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00     53600
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     83200
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00     40000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00      4000
        T1482_cfb61005899996469ae3023796792ca5       0.97      0.96      0.96    256000
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00      3200
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.97      0.93      0.95    256000
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00      1600
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.98      0.93      0.96    256000
        T1490_c156ac5c9fa67080365268d95f29053d       0.94      0.98      0.96    256000
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      8000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.96      0.91      0.93    256000
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00      4000
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00      5600
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00     65600
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.96      0.90      0.93    256000
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.93      0.92      0.92    256000
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.95      0.91      0.93    256000
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.97      0.92      0.95    256000
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.97      0.96      0.97    256000
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00      1600
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.93      0.94      0.93    256000
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      0.99      1.00      1600
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       0.99      1.00      1.00       800
        T1531_aa6b15485a5f50ced34d87fda177b758       0.33      0.00      0.00      1600
        T1531_b25ae80dad74142fafb510e9c1949ace       0.43      0.00      0.00      1600
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00     12000
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00      5600
    T1547.001_163b023f43aba758d36f524d146cb8ea       1.00      1.00      1.00      4000
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00      4800
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00      1600
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00      1600
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00      4000
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00      1600
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00      1600
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      8000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00      6400
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00      4800
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00     17600
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00      1600
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00      1600
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00    172800
    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00      1600
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      0.98      0.99      4800
    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.90      0.99      0.94    256000
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.71      0.00      0.01      1600
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      8800
    T1562.004_5b93df032e230056c21a3e57334f77d1       0.98      0.93      0.95    256000
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.90      0.98      0.94    256000
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00      2400
    T1564.001_66a5fd5f244819181f074dd082a28905       0.51      0.05      0.08      4000
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.94      0.65      4000
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.55      0.32      0.40      1600
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00      4800
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00     12800
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.97      0.91      0.94    256000
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00      6400
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00     49600
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00      4800
                                        benign       1.00      1.00      1.00   1077033

                                      accuracy                           0.95  16008233
                                     macro avg       0.91      0.89      0.89  16008233
                                  weighted avg       0.95      0.95      0.95  16008233

10/19/2023, 14:54:59# labels of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:54:59# predicted of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:54:59# labels of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:54:59# predicted of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:54:59# labels: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:54:59# predicted: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/19/2023, 14:55:09# Test Accuracy: 97.02188143607198 %



10/19/2023, 14:55:40# report path: classification_report/classification_report-transE_50-graphSAGE-2.xlsx
10/19/2023, 14:55:40# label path: classification_report/mapped_true_predicted_labels-transE_50-graphSAGE-2.xlsx
10/19/2023, 14:55:52# mapped_report:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00      6400
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00       600
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00       500
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00      1500
    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.02      0.04      0.03       100
    T1003.003_f049b89533298c2d6cd37a940248b219       0.02      0.02      0.02       100
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00       600
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00       600
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.02      0.03      0.02       100
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.10      0.03      0.05       300
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.03      0.03      0.03       100
        T1016_71b3d2945679566b9d94d8cb11df4b70       0.04      0.06      0.04       100
        T1016_7d8ee68f0e9731db82964f558f614608       0.57      0.29      0.38       500
    T1016_921055f4-5970-4707-909e-62f594234d91       0.01      0.01      0.01       100
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.01      0.01      0.01       100
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.02      0.04      0.03       100
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.02      0.03      0.02       100
        T1018_a44bb43474728496276d5d73aa14588f       0.01      0.02      0.02       100
        T1018_ac20e592bc912bddff4d6b88289095f0       0.03      0.06      0.04       100
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00       600
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.01      0.02      0.01       100
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.01      0.03      0.02       100
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00      2300
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00      2700
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00       200
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00       200
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00       700
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00       500
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.01      0.01      0.01       100
        T1047_6935e41353aa781bb723462d26114c44       0.01      0.02      0.02       100
        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.01      0.03      0.02       100
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.02      0.03      0.02       100
        T1047_b0255b5120cbabc062d8d4510a142c3b       0.04      0.07      0.05       100
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.01      0.02      0.01       100
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.03      0.05      0.04       100
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.05      0.05      0.05       100
        T1049_a14392d713dffba6a397682ff83259a0       0.09      0.03      0.05       300
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00       200
    T1053.005_ee454be9197890de62705ce6255933fd       0.01      0.01      0.01       100
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.02      0.02      0.02       100
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.00      0.00      0.00       100
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.02      0.03      0.02       100
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00       700
        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.04      0.05      0.04       100
        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.05      0.06      0.06       100
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      0.99      1.00      1000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00      1500
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00       500
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      0.99      0.99      1000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00       500
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00     13700
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00       700
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00       600
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      0.99      0.99       900
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00       200
    T1069.002_6103e503cb444bc7b4187704f2035708       0.07      0.01      0.01       400
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00       600
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00      2000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      1000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00       300
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00       800
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.02      0.03      0.02       100
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.02      0.04      0.03       100
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      1200
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.01      0.02      0.02       100
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00       500
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.01      0.02      0.01       100
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.95      0.74      0.83       200
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      1100
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.99      0.99       200
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00       800
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00      2100
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00      2000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00      1300
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00      5700
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00     15000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00       300
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00       300
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00       300
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00       300
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       1.00      1.00      1.00       300
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      0.99      1.00       300
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00       300
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00       200
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00       300
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00      1800
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00       300
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00       300
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00       500
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00      1600
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.01      0.01      0.01       100
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00      1900
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00      2000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00       600
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00       600
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.02      0.05      0.03       100
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00       600
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.01      0.02      0.01       100
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.01      0.01      0.01       100
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00       600
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00      1300
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.01      0.01      0.01       100
        T1201_57296a2ddbeb7423c05feef2fe972111       0.05      0.04      0.05       100
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      1000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00       400
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.01      0.02      0.02       100
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00      6700
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     10400
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00      5000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00       500
        T1482_cfb61005899996469ae3023796792ca5       0.02      0.02      0.02       100
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00       400
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.06      0.06      0.06       100
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00       200
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.00      0.00      0.00       100
        T1490_c156ac5c9fa67080365268d95f29053d       0.02      0.04      0.03       100
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      1000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.03      0.04      0.03       100
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00       500
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00       700
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00      8200
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.01      0.01      0.01       100
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.02      0.03      0.02       100
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.04      0.07      0.05       100
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.04      0.04      0.04       100
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.04      0.05      0.04       100
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00       200
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.02      0.03      0.02       100
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00       200
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       100
        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00       200
        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00       200
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00      1500
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00       700
    T1547.001_163b023f43aba758d36f524d146cb8ea       1.00      1.00      1.00       500
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00       600
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00       200
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00       200
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00       500
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00       200
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00       200
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      1000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00       800
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00       600
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00      2200
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00       200
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00       200
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00     21600
    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00       200
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      0.98      0.99       600
    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.01      0.03      0.02       100
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00       200
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      1100
    T1562.004_5b93df032e230056c21a3e57334f77d1       0.05      0.06      0.06       100
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.00      0.01      0.01       100
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00       300
    T1564.001_66a5fd5f244819181f074dd082a28905       0.49      0.06      0.10       500
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.92      0.65       500
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.71      0.28      0.40       200
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00       600
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00      1600
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.02      0.02      0.02       100
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00       800
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00      6200
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00       600
                                        benign       1.00      1.00      1.00    134563

                                      accuracy                           0.97    310263
                                     macro avg       0.60      0.60      0.59    310263
                                  weighted avg       0.97      0.97      0.97    310263

10/20/2023, 01:53:02# labels of 50000: tensor([ 55, 157,   9, 150, 112,  60, 116,  30,  34, 143, 125,  18,  48,  83,
        164, 163,  47, 163, 121, 142,  30, 151, 143, 124,  74, 111,  47,  34,
        119, 142,   2,  83, 125,  48,  31,  53,  57,  36,  74,  60,  76, 164,
         14, 112,   1, 121,   2,  53, 125, 152, 124,  92,  81,  81,  97,  34,
         97,  30,  87,  57,   2,  81,  58,  58,  58,  58,  58,  58,  58, 163],
       device='cuda:0') torch.Size([70])
10/20/2023, 01:53:02# predicted of 50000: tensor([ 55, 144, 162, 163, 112, 112, 124,  81,  34, 104, 143, 144,  53,  11,
        164,  33, 104,   1,  38, 142,  38, 151,  30, 124, 162, 109,  44, 124,
        143, 124,  18, 164, 144,  54,  81,  34,  57,  36,  33,  60,  12, 112,
         38,  49, 152, 162,  53,  48, 112,  33, 162, 112,  36,  14,  18, 152,
        144,  30,  47,  12,  55,  81,  58,  58,  58,  58,  58,  58,  58,  54],
       device='cuda:0') torch.Size([70])
10/20/2023, 02:21:19# labels of 100000: tensor([112, 144,  87, 151,   9, 143,  55,   2,  47,  34,  11,  76,  42, 124,
          2,  11, 104,  49,  60,  38,  92, 104, 104,  60,  81,  53, 125, 104,
         83,  48,  33, 112,  44, 116,  36,   1, 163,  75, 115, 115, 115, 115,
        115, 115, 115, 115, 115, 115,  48, 143,  83,  60,   9,  87,  24,  75,
         47,  92,  18, 158, 111,  97, 116,   1, 163, 104,  87,  36, 150,  33,
          2,  36,  47], device='cuda:0') torch.Size([73])
10/20/2023, 02:21:19# predicted of 100000: tensor([ 53,  87, 142,   2,   9,  49,  38,   2,  47,  34, 116,  47, 109,   9,
         53,  42, 104,  49,   9,  38,  92, 104,  36,  60,  87, 104, 112, 158,
        143,  36,  38, 112,  44,  11, 157,   1, 142,  53, 115, 115, 115, 115,
        115, 115, 115, 115, 115, 115,  11,  11,  34,  31,   9,  87, 125,  83,
         47, 144,  18, 158,  47,  97, 116,   1, 163, 104,  87, 143,  83,  54,
          2,  74,  47], device='cuda:0') torch.Size([73])
10/20/2023, 02:49:45# labels of 150000: tensor([ 24,  48, 164, 150,  14,  75, 157,  55,  31,  18, 143,  47,  42, 124,
        124, 125,  75,  34, 158,  92, 142, 124,  33, 119,  14, 109, 116,   4,
         38, 152, 121, 121,  18, 142,  14,  44,  60, 112,  14, 158,  87,  74,
        151,  42,  11,  30,  55,  97,  87,  24, 150,  54,  55,  48,  40,  40,
         40,  40,  40,  40, 116,  11,  18,  76,  92, 150, 151, 143,  49],
       device='cuda:0') torch.Size([69])
10/20/2023, 02:49:45# predicted of 150000: tensor([ 24,  83,  55, 112,  76,  55, 157,  55,  31, 162, 143,  47,  42, 124,
        124, 125,  75,  34, 158,  92, 142, 104,  33, 119,  14, 109, 116,   4,
         38, 152, 121, 121,  83,  48,  14, 121, 109,  14, 112, 158,  34,  74,
        157,  42,  11,  53,  44,  54,  87,  24, 143,  54,  55, 125,  40,  40,
         40,  40,  40,  40, 111,  11,  18,  53,  24, 150, 151, 143, 121],
       device='cuda:0') torch.Size([69])
10/20/2023, 03:16:15# labels of 200000: tensor([  4,  54, 124, 109, 119, 111,   4, 119, 121, 109,  47,  24,  36, 163,
         18, 152, 143,  30,  53, 158, 124,  12, 144, 152,  76, 124, 164,  34,
         76, 157,  49,  33,  12, 142,  76, 158,   2, 143,   1,  47, 112, 152,
         87,  76, 116, 158,  54,  97,  83,  31,  30,  33, 112, 109,  44,  11,
        112,  49, 157, 121,  30,   9, 119, 158], device='cuda:0') torch.Size([64])
10/20/2023, 03:16:15# predicted of 200000: tensor([ 44,  92,  53,  75,   1,  14, 119, 119,  76,  12,  47,  24,  36, 163,
        112, 152, 143,  30,  97, 143, 158,  87, 144, 152,  76, 124,  54,  34,
         76, 151,  49,  54,  12, 142, 125, 158,  54, 119,   1,  47, 144, 152,
         87, 162, 116, 158, 143,  97, 109,  31,  30,  33, 143, 109,  44,  11,
        112,  36,  97, 121, 119,   9, 119, 104], device='cuda:0') torch.Size([64])
10/20/2023, 03:23:19# total batches: 213400
10/20/2023, 03:23:19# Epoch 0 | Train Loss: 2.1929 | Train Accuracy: 0.4184
10/20/2023, 03:23:19# labels of Validation: tensor([  9, 143,  27,  27,  27,  41,  41,  41,  41,  41, 116, 150, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  60, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0,  74,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  81,  88,  88,  92,  62,  62,
         62,  62,  62,  62,  75,   1,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 162, 152, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         59,  59,  59,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  14,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 114, 114, 150, 153, 153, 153,  89,  89, 162, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  53,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  83], device='cuda:0') torch.Size([690])
10/20/2023, 03:23:19# predicted of Validation: tensor([ 14,  53,  27,  27,  27,  41,  41,  41,  41,  41,  53,  87, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  48, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0, 144,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  87,  30,  30,  97,  62,  62,
         62,  62,  62,  62, 111,  31,  33, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165,  38,  60, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         42,  49,  42,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126, 112,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 158, 158, 104, 153, 153, 153,  89,  89,  42, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  38,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,   2], device='cuda:0') torch.Size([690])
10/20/2023, 03:23:19# labels of 0: tensor([  9, 143,  27,  27,  27,  41,  41,  41,  41,  41, 116, 150, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  60, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0,  74,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  81,  88,  88,  92,  62,  62,
         62,  62,  62,  62,  75,   1,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 162, 152, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         59,  59,  59,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  14,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 114, 114, 150, 153, 153, 153,  89,  89, 162, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  53,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  83], device='cuda:0') torch.Size([690])
10/20/2023, 03:23:19# predicted of 0: tensor([ 14,  53,  27,  27,  27,  41,  41,  41,  41,  41,  53,  87, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  48, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0, 144,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  87,  30,  30,  97,  62,  62,
         62,  62,  62,  62, 111,  31,  33, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165,  38,  60, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         42,  49,  42,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126, 112,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 158, 158, 104, 153, 153, 153,  89,  89,  42, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  38,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,   2], device='cuda:0') torch.Size([690])
10/20/2023, 03:23:28# Validation Loss: 0.3975 | Validation Accuracy: 0.9465

10/20/2023, 03:23:28# Find a better model!!
10/20/2023, 03:50:35# labels of 50000: tensor([111, 111,  11,  33,  38, 150, 151,  55,  24,  12, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118,  55,   2, 163,  44,   1,  74,  47,  92, 121,  30,  33,
         14,   4,  75, 144, 109,  74,  81, 158, 116,  55,  92,  12,  54, 144,
         57, 150, 121,  30, 124,   1,   2, 124,   1,  57,  11,  30,   9,  92,
         31,  33,   1,  74,  38,  11,  75,  24, 125,  76,  11, 143, 124, 144],
       device='cuda:0') torch.Size([84])
10/20/2023, 03:50:35# predicted of 50000: tensor([111,  81,  11,  33,  38, 150, 151,  55,  24,  42, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118,  33,   2,  31,  57,   1,  30,  48,  36, 121,  75,  33,
         57,   4, 125, 144, 109,  74,  81, 158,  87,  55,  92,  12,  54, 144,
         57,  49, 121,  38, 124,   1,   2, 124,   1,  57,  11,  30,   9,  92,
         31,  36,   1,  74,  34,  11, 143,  36, 125,  76,  11, 143, 124, 144],
       device='cuda:0') torch.Size([84])
10/20/2023, 04:19:02# labels of 100000: tensor([ 30,  18,  30,  33, 157,  14, 143, 164,  11, 109, 109, 125, 162,  48,
         92,  60, 144,  92, 109,  33,  87,  53,  76, 104, 157,  53, 112,  18,
         36, 109,  34,  60,  18, 151,  34, 162,  53,   2, 109,   2,  33, 150,
         42,  38,   9, 111, 125, 164,  38,  12, 151, 163,   4,  33, 124, 125,
          1, 162,   9,  92,  44,  31,  31, 119], device='cuda:0') torch.Size([64])
10/20/2023, 04:19:02# predicted of 100000: tensor([ 30,  18,  30,  30, 157,  11, 112, 164, 143, 109, 109, 125,  92,  38,
         92,   2, 119,  81, 109,  33,  87,  53, 158, 104, 157,  53,  92,  18,
         36, 109,  34,  60,  18, 151,  34, 162,  53,   2, 116, 104,  33, 150,
        109,  57,   9, 111, 125, 164,  38,  12, 151, 163,  18,  33, 124, 125,
          1, 162,   9,  92,  36, 119,  31, 119], device='cuda:0') torch.Size([64])
10/20/2023, 04:46:09# labels of 150000: tensor([ 55,   2,  12,  53, 164, 142,   1, 152, 111, 116, 158, 151,  38, 157,
        152,  11, 104, 162,  48,  47,  81,  76,   9,   2, 157,  44, 163, 109,
         57, 163,  11,  81,   4,  54,  54, 164,  57, 104,  57,  57, 112,  54,
        142,  38,  11, 125,  97, 164,  38,   2,  97,  31,  49,  74,   4, 152,
         47,  48,   2,  92,  42,   4, 157,   2], device='cuda:0') torch.Size([64])
10/20/2023, 04:46:09# predicted of 150000: tensor([ 55,  81,  12,  53,  30,  30,   1, 152,  49, 116, 158, 151,  38, 157,
        152,  11,  60, 163,  48,  47,  81,  76,   9,   2, 157,  44, 144, 109,
         57, 163,   1, 112,   4,  54, 104, 125,  57, 104,  57,  57, 112,  54,
        142,  38,  11, 125,  97, 164,  38,   2,  97,  31,  49,  74,   4, 152,
         47,  48,   2,  92,  42,   4, 157,   9], device='cuda:0') torch.Size([64])
10/20/2023, 05:14:34# labels of 200000: tensor([143, 109,  42,  11,  36,  11,  49, 124,  75,  60,  12, 163,  47,   4,
        119,  57,  24,  44,  76,  60,  38,  54,  87,  49,   4,   9, 143,  18,
        144, 157,  92,  33,  74,  44, 158, 143,  75, 157,  55,  31,  53, 124,
        144, 111, 112,  11,  87,  48,  44, 144, 152,  31, 158,  38,  81,  49,
         44,  92,  11,  42,  60,  92,   1,  83], device='cuda:0') torch.Size([64])
10/20/2023, 05:14:34# predicted of 200000: tensor([143, 109,  42,  11,  36,  11,  49, 124,  75,  60,  12, 163,  47,   4,
        119,  57,  47,  44,  42,  60,  38,  31,  87,  49,   4,   9, 143, 151,
        144, 157, 144,  92,  74,  44, 158, 143,  75, 157,  55,  31,  53,  42,
        144, 111,   4,  11,  44,   2,  44, 144, 152,  31,  75,  38,  81,  49,
         44,  92,  11,  42,  60,  92,   1,  14], device='cuda:0') torch.Size([64])
10/20/2023, 05:22:01# total batches: 213400
10/20/2023, 05:22:01# Epoch 1 | Train Loss: 0.8337 | Train Accuracy: 0.7540
10/20/2023, 05:22:01# labels of Validation: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 151,  95,  95,  95,  97,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 131, 131, 131, 131, 131,   8,   8,
        152, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  33,   8,
          8,  93,  93,  79,  79,   2,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  74,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  87, 158,  11,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 150,  51,  65,  51,  51,  51,  51,  18,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  55,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  81, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 113, 113,  64,  64,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,  83, 126, 126, 126, 144, 157, 109,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  88,  88, 142, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  76, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,  59,
         59,  59], device='cuda:0') torch.Size([576])
10/20/2023, 05:22:01# predicted of Validation: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154,  87,  95,  95,  95, 111,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118,  34, 121, 121, 121, 121,  11,  83,
         87, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  38,  75,
         75,  74,  74,  49,  47,  30,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  14,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  38,  42, 151,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  36,  51,  65,  51,  51,  51,  51,  87,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139, 144,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  36, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89,  18,  18, 125, 125,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,   2, 126, 126, 126, 158,  44, 144,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  24,  47, 152, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,   4, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,   9,
          9,   9], device='cuda:0') torch.Size([576])
10/20/2023, 05:22:01# labels of 0: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 151,  95,  95,  95,  97,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 131, 131, 131, 131, 131,   8,   8,
        152, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  33,   8,
          8,  93,  93,  79,  79,   2,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  74,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  87, 158,  11,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 150,  51,  65,  51,  51,  51,  51,  18,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  55,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  81, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 113, 113,  64,  64,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,  83, 126, 126, 126, 144, 157, 109,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  88,  88, 142, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  76, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,  59,
         59,  59], device='cuda:0') torch.Size([576])
10/20/2023, 05:22:01# predicted of 0: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154,  87,  95,  95,  95, 111,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118,  34, 121, 121, 121, 121,  11,  83,
         87, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  38,  75,
         75,  74,  74,  49,  47,  30,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  14,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  38,  42, 151,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  36,  51,  65,  51,  51,  51,  51,  87,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139, 144,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  36, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89,  18,  18, 125, 125,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,   2, 126, 126, 126, 158,  44, 144,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  24,  47, 152, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,   4, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,   9,
          9,   9], device='cuda:0') torch.Size([576])
10/20/2023, 05:22:09# Validation Loss: 0.2886 | Validation Accuracy: 0.9597

10/20/2023, 05:22:09# Find a better model!!
10/20/2023, 05:49:04# labels of 50000: tensor([ 12, 163, 121, 124,  87,  54, 143, 119,  81, 142, 158, 144,   4, 116,
          2,  36,   2, 124,  53, 163, 142,  36, 104, 163,  30, 142, 150, 151,
         92, 125,  14,  18,  57, 111,  55, 142, 109,  34,  12,  30, 152, 151,
        158, 121,  49, 111,  33,   1, 109,   1,  47,  55, 116,  76, 119, 164,
         48,  47,  97,  53, 111,  34,  97, 112], device='cuda:0') torch.Size([64])
10/20/2023, 05:49:04# predicted of 50000: tensor([ 12, 163, 121, 124,  87,  54, 143, 119,  54, 142, 158, 144, 163, 116,
          2,  44,   2, 124,  53, 163, 142, 151, 104, 163,  30, 142, 124, 151,
         92, 125,  57,  18,  57, 151,  55, 142, 109,  53,  36,  30,  60, 151,
        158, 121,  49, 111,  33,   1, 109, 116,  53,  55,  47,  76, 119, 164,
         48,  47,  97,  53, 111,  34, 157, 112], device='cuda:0') torch.Size([64])
10/20/2023, 06:15:44# labels of 100000: tensor([ 14,  87, 104,  12, 157, 119,  87,  24, 119, 142,  38,  31, 109,   9,
        158,  60, 163, 116, 150,   9,  81, 163, 163,  60, 162,  31,  55, 112,
        142,   2,   1,  38, 142, 157,  55,   2,  24, 157,  36, 150,  31, 119,
         87,  60,  18, 150,  92,  42, 157, 119,  47,  97,  14,  55,  18,  18,
         33, 152, 111, 150, 104,  81,  14, 111], device='cuda:0') torch.Size([64])
10/20/2023, 06:15:44# predicted of 100000: tensor([ 24,  87, 104,  12, 163, 119,  87,  24,  18, 142,  38,  31, 164,   9,
        158,  60, 163,   2, 150,   9,  81, 163, 144,  60, 162,  31,  55, 112,
        142,  12,   1,  38, 142, 157,  55, 121,  75, 157,  36, 150,  33, 119,
         87,  60,  18, 150,  92,  42, 157, 119,  47,  97,  14,  55,  55,  18,
         33, 152, 111, 150, 104,  81,  42, 111], device='cuda:0') torch.Size([64])
10/20/2023, 06:45:25# labels of 150000: tensor([ 18,  34,  30,  14,  33,  81, 157, 152,   9,  44,  49, 124,  74,  87,
         60,  36,  53,  60,  47,  47,  48, 104,   9,  31,  30,  76,  18,  57,
        124,   2,  47,  57,   4,  54, 111,  11, 124,  33,  75,  11,  31,  76,
         31, 152, 157,  31,  31, 150,  42,  18,  83, 104,  14, 125,   2,  76,
         55,  18,  87, 121, 111,  54,  97, 150], device='cuda:0') torch.Size([64])
10/20/2023, 06:45:25# predicted of 150000: tensor([ 18,  34,  30,  97,  33,  81, 157,  92,  38, 109,  49, 124,  74,  87,
         60,  36,  53,  60,  47,  30,  48, 104,   9,  31,  30,  76,  18, 162,
        124,   2,  47,  57,   4,  54, 111,  11, 124,  33,  55,  11, 151,  76,
         31,  30, 157,  31,  31, 150, 142, 142,  83,  75,  14,   1,   2,  34,
         55,  81,  87, 121, 111,  54,  97, 150], device='cuda:0') torch.Size([64])
10/20/2023, 07:12:38# labels of 200000: tensor([125,  76, 152,  55, 121,  81,  14,  60,   2, 109,  49, 142, 112, 119,
        152,  48,  12,  54,  30,  87,  87,  42,  81,  47,  49,  31, 109,  54,
         11,  75,  83,  12,  12, 104,  38, 158,  49, 109,  36,  44, 125,  57,
        125,  38, 151,  33,  31, 121,  60, 109,  34,  81, 111,   4, 163, 119,
        164,  30, 157,  97,  55,  47, 151,  92], device='cuda:0') torch.Size([64])
10/20/2023, 07:12:38# predicted of 200000: tensor([125,  76, 152,  55, 121,  81,  49, 109,   2, 109,  49, 142,  33, 119,
        125,  48,  12,  54,  30,  87,   4,  34,  81,  47,  49,  31, 109,  54,
         11,  75,  31,  55,  12,   2,  38, 158,  49, 151,  36,  44, 125,  57,
        125,  38, 151,  33,  31, 121,  60, 109,  34,  81, 111,   4, 158, 119,
        164,  30, 157,  97,  55,  47, 151,  92], device='cuda:0') torch.Size([64])
10/20/2023, 07:19:50# total batches: 213400
10/20/2023, 07:19:50# Epoch 2 | Train Loss: 0.7030 | Train Accuracy: 0.7930
10/20/2023, 07:19:50# labels of Validation: tensor([ 42, 137, 137, 137, 137, 137,  92,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  47,
        136, 136, 136, 136, 136, 136, 136,  18,  14,  92,  11,  45,  65,  45,
         45,   4,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 150,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 108, 108, 108, 108,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 119, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  83,  80,  80,  80,  80,  80,  80, 116,  14,  72,
         72, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  83,  53, 117, 117, 117,  56,  56,
         56,  56,  56,  56,   9, 157,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 111,
         95,  95,  95,   5,   5,   5,  14, 143, 146, 146, 146, 146, 146, 146,
         49,  41,  41,  41,  41,  41,  93,  93, 113, 113,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  64,  64,  74,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 07:19:50# predicted of Validation: tensor([ 11, 137, 137, 137, 137, 137,  38,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  42,
        136, 136, 136, 136, 136, 136, 136,  92,  55, 104,  36,  45,  65,  45,
         45, 111,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 109,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149,  81, 131, 162,  81,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148,  60, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  87,  80,  80,  80,  80,  80,  80,  24,  47, 104,
         75, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  18,  14, 117, 117, 117,  56,  56,
         56,  56,  56,  56,  38,  44,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  12,
         95,  95,  95,   5,   5,   5,  47, 152, 146, 146, 146, 146, 146, 146,
         92,  41,  41,  41,  41,  41, 157, 157,  18,  18,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  24,  47,   9,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 07:19:50# labels of 0: tensor([ 42, 137, 137, 137, 137, 137,  92,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  47,
        136, 136, 136, 136, 136, 136, 136,  18,  14,  92,  11,  45,  65,  45,
         45,   4,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 150,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 108, 108, 108, 108,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 119, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  83,  80,  80,  80,  80,  80,  80, 116,  14,  72,
         72, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  83,  53, 117, 117, 117,  56,  56,
         56,  56,  56,  56,   9, 157,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 111,
         95,  95,  95,   5,   5,   5,  14, 143, 146, 146, 146, 146, 146, 146,
         49,  41,  41,  41,  41,  41,  93,  93, 113, 113,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  64,  64,  74,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 07:19:50# predicted of 0: tensor([ 11, 137, 137, 137, 137, 137,  38,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  42,
        136, 136, 136, 136, 136, 136, 136,  92,  55, 104,  36,  45,  65,  45,
         45, 111,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 109,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149,  81, 131, 162,  81,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148,  60, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  87,  80,  80,  80,  80,  80,  80,  24,  47, 104,
         75, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  18,  14, 117, 117, 117,  56,  56,
         56,  56,  56,  56,  38,  44,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  12,
         95,  95,  95,   5,   5,   5,  47, 152, 146, 146, 146, 146, 146, 146,
         92,  41,  41,  41,  41,  41, 157, 157,  18,  18,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  24,  47,   9,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 07:20:00# Validation Loss: 0.3086 | Validation Accuracy: 0.9571

10/20/2023, 07:48:52# labels of 50000: tensor([ 24,   4,  74, 164,  11,  92, 162,  14, 163, 119, 112, 163,  33, 124,
         57,  14,   9,   2, 125,  54, 152,  87,  81,   4,   9, 111,  74,  18,
         44, 151,  18, 119,  14,   2, 121,  49,  97,  74, 151, 163, 112,  83,
         34, 142,  74, 112,  97, 109, 124,   9,  34,  83, 111,  57,  76, 150,
        150,  48,  53,  11, 142,  18,   2,  44], device='cuda:0') torch.Size([64])
10/20/2023, 07:48:52# predicted of 50000: tensor([ 24,   4,  55, 164,  11,  92, 162,   1, 163, 119, 112, 163, 151, 124,
         57,  14,   9, 164, 125,  54,  75,  87,  75,   4,   9, 111,   9,  18,
         44,  18,  18, 119,  76,  47, 143,  49,  97, 152, 151, 163, 112,  83,
         34, 142,  74, 112,  97, 109, 124,   9,  34,  83, 111,  57,  14, 150,
        150,  48,  53,  11, 142,  18,   2,  44], device='cuda:0') torch.Size([64])
10/20/2023, 08:18:00# labels of 100000: tensor([104, 151, 119,   4,  33,  18,  57,  11,  48, 158,  81,  97,  14,  34,
         83,  12,  14,  55, 119,  54, 142, 151,  31,  14,  55,   2, 125,  47,
         30, 158,  54, 112, 124, 151,  55,  81,   1,  12, 158, 111,  31,  75,
        151,   1,  48, 163,  81,  74,  48,  14,  11,  53,  30,  54,  54,   1,
         24, 142,  54,  11,  14,  33,  24,  11], device='cuda:0') torch.Size([64])
10/20/2023, 08:18:00# predicted of 100000: tensor([104, 151, 119,   2,  33,  18,  57,  11,  48, 158,  81,  97,  14,  34,
          2,  12,  49,  55, 119, 125, 142,  55,  31,  14,  55,   2, 125,  48,
         14, 158,  54, 112, 124, 151,  55,  81,   1,  12, 158, 111,  31,  75,
        151,   1,  48, 163,  81,  74,  48,  14,  11,  53,  30,  54,  54,   2,
         24, 142,  54,  11,  14,  48,  24,  11], device='cuda:0') torch.Size([64])
10/20/2023, 08:45:37# labels of 150000: tensor([ 74,  55,   4, 158, 142,  57,  33, 150,  30, 116,  24,  38, 163,  18,
        111,  18,  55, 116,  36,  44,  36,  24,   2,  11,   1,   4, 164,  14,
         60,  75,  14,  97,  74,  83,  24,  75,  36, 104,  54, 121,   2, 152,
          2,  83, 152, 121,  11,  54,   1,  60, 163,   9,  54, 124, 150, 152,
        119,  18,  30, 119,  36,  87,  48,  48], device='cuda:0') torch.Size([64])
10/20/2023, 08:45:37# predicted of 150000: tensor([ 74,  55,   4, 158, 142,  57,  33, 150,  30, 116,  24, 158, 163,  18,
         44,  18,  55, 111, 125,  44, 151,  31,   2,  11,   1,   4, 164,  14,
        142,  75,  47,  97,  74,  83,  24,  75,  18, 104, 158, 158,   2, 152,
          2,  83, 152, 121,  11,  54,   1,  60, 163,   9,  54, 162, 150,  33,
        109, 152,   1, 111,  36,  87,  48,  48], device='cuda:0') torch.Size([64])
10/20/2023, 09:12:29# labels of 200000: tensor([ 33,  44,   9,  18,  31, 151,  81,  53, 121, 143,  76,  11,   9,  81,
         49, 151,  92,  31, 104,  48, 119, 125,  36,  30,  33, 111,   4, 112,
        124, 104,  44,  53, 144,  18,  31,  48,  75,  76,  76, 125, 112,  75,
         31,  60,  33,  47, 143,  92,  75, 112,   1,  87,  81,  75, 125,  38,
         87, 121, 152, 112,  34,  18,  49,  42], device='cuda:0') torch.Size([64])
10/20/2023, 09:12:29# predicted of 200000: tensor([  4,  44, 162,  18,  83, 151,  81,  53, 121, 158,  76,  11,   9,  81,
         49, 151,  92,  53, 104,  48,  81, 125,  36,  30, 112, 111,   4, 112,
         18, 104,  44,  53,  33,  18,  31,  42,  92,  76,  76, 125, 112,  75,
         31,  60,  33,  47, 143,  92,  75, 112,   1,  87,  81,  75, 125,  38,
         87, 121, 152, 112,  34,  18,  49,  42], device='cuda:0') torch.Size([64])
10/20/2023, 09:19:43# total batches: 213400
10/20/2023, 09:19:43# Epoch 3 | Train Loss: 0.6432 | Train Accuracy: 0.8101
10/20/2023, 09:19:43# labels of Validation: tensor([152,  28,  28,  ...,  95,  95,  95], device='cuda:0') torch.Size([1216])
10/20/2023, 09:19:43# predicted of Validation: tensor([42, 28, 28,  ..., 95, 95, 95], device='cuda:0') torch.Size([1216])
10/20/2023, 09:19:43# labels of 0: tensor([152,  28,  28,  ...,  95,  95,  95], device='cuda:0') torch.Size([1216])
10/20/2023, 09:19:43# predicted of 0: tensor([42, 28, 28,  ..., 95, 95, 95], device='cuda:0') torch.Size([1216])
10/20/2023, 09:19:52# Validation Loss: 0.3095 | Validation Accuracy: 0.9566

10/20/2023, 09:48:31# labels of 50000: tensor([ 75, 163,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  75,  75,  49,
         38, 143, 112,  33,  92,  87,  34,  31, 144,   2, 116, 112,  74,  31,
        121, 152,  34,  36,   4,  31,  42,  14, 124,  81,  34,  33,  54,  87,
        125,  48,  75,  44,  92, 121,  42, 124, 150,  11, 112,   4,  41,  41,
         41,  41,  41,  76, 116,  33,  38,  38, 152, 152,  55, 125,  60,  87,
         18, 157, 152,  87,  34,  11], device='cuda:0') torch.Size([90])
10/20/2023, 09:48:31# predicted of 50000: tensor([ 75, 163,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  75,  75,   9,
         38, 143, 112,  83,  92,  87,  48,  31, 144,   2, 116,  44,  74,  31,
        121, 152, 150,  36,  57,  31,  42, 162, 158,  81,  34,  33,  54,  87,
        125,  48,  75,  44,  92, 121,  42, 124, 150,  33, 104,   4,  41,  41,
         41,  41,  41,  76, 116,  74,  38,  57, 152, 152,  55, 125,  92,  87,
         18, 157, 152,  34,  60,  11], device='cuda:0') torch.Size([90])
10/20/2023, 10:17:56# labels of 100000: tensor([ 92,  30, 144,  54, 158,  49, 158, 162,  75,  24, 162,  36,  92,  60,
        112,  87, 142,   2, 152, 121,  74,   1, 158, 158,  18, 163,  18,  87,
         48,  36,   2,  18, 157,  55,  57,   1,  83, 142, 150,  36,  48, 112,
        119,  74,  12, 164,  54, 111,  42,  12,  75,  49,  49, 157,  31,  54,
        119,  36, 119,  14,  30,  31, 144, 112], device='cuda:0') torch.Size([64])
10/20/2023, 10:17:56# predicted of 100000: tensor([ 92, 164, 144,  54,  60,  49, 158, 162,  75,  24, 162,  36,  92,  60,
          9,  87, 142,   2, 152, 121, 142,   1, 158, 158,  18, 163,  18,  38,
         48, 152,   2,  18, 150,  55,  57,   1,  83, 142,  54,  36,  48, 112,
        119,  74,  18, 164,  55, 111,  42, 164,  75, 151,   9, 157,  31,  54,
        119,  36, 119,   9,  30,  12, 144, 112], device='cuda:0') torch.Size([64])
10/20/2023, 10:45:10# labels of 150000: tensor([ 24,   2, 144, 142,  83,  11, 152, 143, 163, 124, 116,  76,  33,  87,
        116,   2,  18,  60,  31,  76, 143,  49, 162, 119,  97,  31, 125,  12,
        111,  75,  74, 121, 119,   1,  48, 111,  75,  48,  76,  60, 144,  14,
        151, 163, 109, 164,  12, 158,  36,  34, 104,  60, 164, 157,  53,  87,
          2, 116,  47,  97, 119,  75,  49,  75], device='cuda:0') torch.Size([64])
10/20/2023, 10:45:10# predicted of 150000: tensor([ 24,   2, 144, 142, 144,  11,  49, 143, 163, 124, 116,  76,  33,  34,
        116,   2, 121,  60,  31,  76,  44,  49, 162, 119,  33,  31, 125,  12,
        111,  55,  74, 121, 119,   1,  48, 111,  75,  48,  76,  60, 144, 142,
        151,  24, 109, 164,  12, 119,  36,  34, 104,  60, 164, 157,  53,  87,
          2, 142,  18,  97, 119,  53,  33,  75], device='cuda:0') torch.Size([64])
10/20/2023, 11:12:38# labels of 200000: tensor([ 92, 162,  18,  74, 111,  11,   2,  92, 109,  30,  75, 124,  18, 158,
         53,  48,  60, 164, 158, 112,  76, 111,  81, 143,  57,  81,   9,  11,
        163,  83,  11,  97,   1, 143, 112, 112,  11,  83, 143,  12, 112,  18,
         11,  34,  24,  44,  75,   1,  12,  60,  30,  12,  36,  44,  44,  12,
         18, 111,  81, 152, 152,   1,  57,  12], device='cuda:0') torch.Size([64])
10/20/2023, 11:12:38# predicted of 200000: tensor([ 92, 162,  18,  74,  24,  97,   2,  92, 109,  30,  75, 109,  36,  87,
         53,  48,  60, 164, 158,  34,  76, 111,  81, 143,  57,  81,   9,  11,
        163,  83,  11,  97,   1, 143, 112, 112,  11,  83, 143,   2, 112, 150,
         11,  34,  24,  44,  75,   1, 111,  60,  30,   9,  36,  44,  44,  12,
         18,  48,  34, 152, 152,   1,  60,  12], device='cuda:0') torch.Size([64])
10/20/2023, 11:20:07# total batches: 213400
10/20/2023, 11:20:07# Epoch 4 | Train Loss: 0.7512 | Train Accuracy: 0.7781
10/20/2023, 11:20:07# labels of Validation: tensor([ 87, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/20/2023, 11:20:07# predicted of Validation: tensor([143, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/20/2023, 11:20:07# labels of 0: tensor([ 87, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/20/2023, 11:20:07# predicted of 0: tensor([143, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/20/2023, 11:20:17# Validation Loss: 0.3087 | Validation Accuracy: 0.9573

10/20/2023, 11:49:40# labels of 50000: tensor([ 38,  33,  48,  55,  75, 124, 121, 121, 164, 112, 116,  74, 164,  83,
        152,  24, 119, 151, 104,  30,  38,  33, 121, 121,  49, 157, 143,   9,
         87,  14,  24,  60, 163,  24,  54,  81,  44,  12, 111,  76, 104,  61,
         61,  61,  33, 119,  57,  18,  87,  24, 144,  47,  87, 112,  83,  47,
        164,  47,  60,  44, 109,  47, 124,  57,  55, 150], device='cuda:0') torch.Size([66])
10/20/2023, 11:49:40# predicted of 50000: tensor([ 38,  33,  48,  55,  75, 150, 121, 121, 164, 112, 116,  75, 164,  83,
        152,  24, 119, 151, 104,  30,  38,  33, 121, 121,  49, 157, 143,   9,
         87,  14,  47,  60, 163,  24,  48,  81,  31,  12, 111,  76, 104,  61,
         61,  61,  33, 119,  57,  18,   9,  24, 144,  47,  87, 112,  83, 163,
        164,  47,  60,  44, 109,  47, 124, 124,  55, 150], device='cuda:0') torch.Size([66])
10/20/2023, 12:18:28# labels of 100000: tensor([ 81, 158, 142,   4, 144, 162, 112, 163, 119,  92,  76, 125,  24, 109,
         55,  42,  76,  42,  75,  57,  60,   4,   1, 121,  81,  12,  76,   4,
         57,  48,  33,   2,  87,  48, 152, 104,  12,  83,  49,  34,  87,  47,
         47,  44, 162,  12,  44,  31, 152, 143, 143,  83,  36,  33, 119,   1,
         34,  44,   9, 109, 116,  76, 143,  76], device='cuda:0') torch.Size([64])
10/20/2023, 12:18:28# predicted of 100000: tensor([ 81, 158, 142,   4, 144,  74, 112, 163, 119, 143,  76, 125,  24, 109,
         55,  42,  76,  42,  75,  74,  60,  75,   1,   9,  81,  12,  76,   4,
         57,  48,  33,   2,  87,  48, 152, 104,  12,  83,  49,  34,  87,  47,
         47,  53, 162,  12,  44,  31, 152, 143, 143, 119,  36,  33, 119,   1,
         34,  44,   9,  81, 116,  76, 143,  87], device='cuda:0') torch.Size([64])
10/20/2023, 12:45:54# labels of 150000: tensor([ 42,  76, 121,  11,  57,  60,  83, 158,  42, 143,  83, 151, 150,  44,
         44,   9,  92,  24,  11, 158, 150,  38, 143,  57,  36, 163, 157, 111,
         42,  49, 116,  49,  33, 163, 164,  54, 124,  87, 124,  97,  38, 111,
         31,  81,  74,  33, 164, 157,  48,   1,  75, 162, 163,  42,  31,  60,
        157,  81, 157,  97, 152,  55, 125, 112], device='cuda:0') torch.Size([64])
10/20/2023, 12:45:54# predicted of 150000: tensor([ 42,  76, 121,  11,  57,  60,  83, 158,  42, 143,  83, 151,  44,  44,
         44,   9,  92,  24, 142, 158, 150,  38, 143,  57,  36, 163, 124, 111,
         42,  49, 116,  49,  33, 163, 164,  54, 124,  87, 124,  97,  38, 111,
         31,  81,  74,  33, 151, 157,  48,   1,  75, 162,  53,  42,  31,  60,
        157,  81, 157,  97, 152,  55, 125, 112], device='cuda:0') torch.Size([64])
10/20/2023, 13:13:27# labels of 200000: tensor([ 49,  42,  76,  18,  38,  48,  53,  47, 158, 109,  33,  30, 124, 164,
        164, 157,  87, 112, 121, 125,  92,  47,   1,  31,  14,  34, 104, 119,
         92,  54,   9, 121, 111, 163, 157,  11, 162,   1,  75, 121,  11, 157,
         60,  11, 142,  34, 121, 163,  97, 157, 124,  54, 158,  87, 124,  76,
          1, 116,  76,  53,   4, 125, 121, 125], device='cuda:0') torch.Size([64])
10/20/2023, 13:13:27# predicted of 200000: tensor([ 49,  42,  76,  55, 162,  60,  53, 112, 158, 109,  33,  30,  81, 164,
        164,   1,  87, 112, 121, 125,  92,  47,  42,  31,  14,  34,  75, 119,
         92,  54,   9, 121, 111, 163,  33,  11, 162,   1,  75,  36,  11, 157,
         60,  11, 142, 125, 121, 163,  97, 157, 124,  54, 158,  87, 124,  76,
          1, 116,  76,  53, 125, 125, 121, 125], device='cuda:0') torch.Size([64])
10/20/2023, 13:20:44# total batches: 213400
10/20/2023, 13:20:44# Epoch 5 | Train Loss: 0.4668 | Train Accuracy: 0.8632
10/20/2023, 13:20:44# labels of Validation: tensor([ 11, 150, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  31,
         68,  68, 152,  55,  47,  37,  37,  37,  37,  37,   2, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  59,  59,  59,  26,  26,  26,  26,  26,  26,  90,  90, 153, 153,
        153, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  44, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 116,  76,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  33,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  64,  64,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99, 157,  30,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  93,
         93, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  59,  59,  59,   9,  42,
         91,  91,  91, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   2,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  60, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108,
        103, 103], device='cuda:0') torch.Size([632])
10/20/2023, 13:20:44# predicted of Validation: tensor([ 83, 142, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  54,
         24,  24,  97, 119,  44,  37,  37,  37,  37,  37,  47, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 119,  97,  97,  26,  26,  26,  26,  26,  26,  57,  57, 153, 153,
        153, 144,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  33, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 142, 125,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,   9,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82, 158,  97,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  31,  57,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 162,
         38, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  33,  33,  33,  11,  33,
        116, 116, 116, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   4,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  49, 107, 107, 107, 107, 107, 107, 107, 107,  81,  36,  81,  81,
        121, 121], device='cuda:0') torch.Size([632])
10/20/2023, 13:20:44# labels of 0: tensor([ 11, 150, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  31,
         68,  68, 152,  55,  47,  37,  37,  37,  37,  37,   2, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  59,  59,  59,  26,  26,  26,  26,  26,  26,  90,  90, 153, 153,
        153, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  44, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 116,  76,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  33,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  64,  64,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99, 157,  30,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  93,
         93, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  59,  59,  59,   9,  42,
         91,  91,  91, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   2,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  60, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108,
        103, 103], device='cuda:0') torch.Size([632])
10/20/2023, 13:20:44# predicted of 0: tensor([ 83, 142, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  54,
         24,  24,  97, 119,  44,  37,  37,  37,  37,  37,  47, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 119,  97,  97,  26,  26,  26,  26,  26,  26,  57,  57, 153, 153,
        153, 144,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  33, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 142, 125,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,   9,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82, 158,  97,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  31,  57,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 162,
         38, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  33,  33,  33,  11,  33,
        116, 116, 116, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   4,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  49, 107, 107, 107, 107, 107, 107, 107, 107,  81,  36,  81,  81,
        121, 121], device='cuda:0') torch.Size([632])
10/20/2023, 13:20:53# Validation Loss: 0.3167 | Validation Accuracy: 0.9562

10/20/2023, 15:13:09# Train Classification Report at Epoch 5:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00     51200
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00      4800
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00      4000
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00     12000
    T1003.003_9f73269695e54311dd61dc68940fb3e1       1.00      0.99      0.99    256000
    T1003.003_f049b89533298c2d6cd37a940248b219       0.98      1.00      0.99    256000
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00      4800
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00      4800
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.95      0.95      0.95    256000
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.33      0.00      0.00      2400
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.99      0.99      0.99    256000
        T1016_71b3d2945679566b9d94d8cb11df4b70       0.99      0.99      0.99    256000
        T1016_7d8ee68f0e9731db82964f558f614608       0.59      0.29      0.39      4000
    T1016_921055f4-5970-4707-909e-62f594234d91       0.99      1.00      1.00    256000
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       1.00      0.99      0.99    256000
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       1.00      1.00      1.00    256000
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.99      0.99      0.99    256000
        T1018_a44bb43474728496276d5d73aa14588f       0.99      0.99      0.99    256000
        T1018_ac20e592bc912bddff4d6b88289095f0       1.00      0.99      1.00    256000
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00      4800
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.99      0.99      0.99    256000
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.93      0.97      0.95    256000
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00     18400
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00     21600
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00      1600
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00      1600
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00      5600
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00      4000
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.99      0.99      0.99    256000
        T1047_6935e41353aa781bb723462d26114c44       0.99      1.00      0.99    256000
        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.99      1.00      0.99    256000
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.99      1.00      0.99    256000
        T1047_b0255b5120cbabc062d8d4510a142c3b       1.00      1.00      1.00    256000
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.99      1.00      0.99    256000
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.99      0.99      0.99    256000
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       1.00      0.99      0.99    256000
        T1049_a14392d713dffba6a397682ff83259a0       0.00      0.00      0.00      2400
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00      1600
    T1053.005_ee454be9197890de62705ce6255933fd       0.99      1.00      0.99    256000
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       1.00      0.99      0.99    256000
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.99      0.99      0.99    256000
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.95      0.94      0.95    256000
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00      5600
        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.99      1.00      0.99    256000
        T1057_f8de05d1741dcc468f772ab0ff4dac72       1.00      1.00      1.00    256000
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      8000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00     12000
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00      4000
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      1.00      1.00      8000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00      4000
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00    109600
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00      5600
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00      4800
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00      7200
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00      1600
    T1069.002_6103e503cb444bc7b4187704f2035708       0.42      0.06      0.11      3200
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00      4800
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00     16000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      8000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00      2400
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00      6400
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.99      1.00      0.99    256000
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.97      0.94      0.95    256000
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      9600
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.94      0.96      0.95    256000
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00      4000
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.93      0.96      0.95    256000
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.99      0.47      0.64      1600
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      8800
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.99      0.99      1600
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00      6400
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00     16800
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00     16000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00     10400
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00     45600
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00    120000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00      2400
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00      2400
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00      2400
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00      2400
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       1.00      1.00      1.00      2400
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00      2400
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00      2400
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00      1600
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00      2400
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00     14400
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00      2400
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00      2400
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00      4000
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00     12800
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.95      0.94      0.95    256000
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00     15200
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00     16000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00      4800
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00      4800
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.96      0.94      0.95    256000
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00      4800
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.96      0.95      0.95    256000
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.99      0.99      0.99    256000
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00      4800
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00     10400
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       1.00      0.99      1.00    256000
        T1201_57296a2ddbeb7423c05feef2fe972111       0.99      1.00      1.00    256000
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      8000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00      3200
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       1.00      0.99      0.99    256000
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00     53600
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     83200
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00     40000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00      4000
        T1482_cfb61005899996469ae3023796792ca5       0.99      0.99      0.99    256000
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00      3200
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.99      1.00      0.99    256000
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00      1600
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.99      1.00      0.99    256000
        T1490_c156ac5c9fa67080365268d95f29053d       1.00      1.00      1.00    256000
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      8000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.96      0.96      0.96    256000
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00      4000
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00      5600
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00     65600
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.94      0.96      0.95    256000
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.96      0.94      0.95    256000
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.95      0.96      0.96    256000
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.98      1.00      0.99    256000
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.98      1.00      0.99    256000
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00      1600
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.97      0.96      0.97    256000
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00      1600
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       800
        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00      1600
        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00      1600
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00     12000
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00      5600
    T1547.001_163b023f43aba758d36f524d146cb8ea       0.99      1.00      1.00      4000
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00      4800
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00      1600
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00      1600
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00      4000
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00      1600
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00      1600
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      8000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00      6400
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00      4800
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00     17600
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00      1600
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00      1600
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00    172800
    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00      1600
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      1.00      1.00      4800
    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.99      1.00      0.99    256000
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00      1600
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      8800
    T1562.004_5b93df032e230056c21a3e57334f77d1       1.00      0.99      1.00    256000
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.99      0.99      0.99    256000
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00      2400
    T1564.001_66a5fd5f244819181f074dd082a28905       0.54      0.01      0.01      4000
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.99      0.67      4000
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.87      0.10      0.17      1600
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00      4800
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00     12800
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.99      1.00      0.99    256000
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00      6400
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00     49600
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00      4800
                                        benign       1.00      1.00      1.00   1077033

                                      accuracy                           0.98  16008233
                                     macro avg       0.91      0.90      0.90  16008233
                                  weighted avg       0.98      0.98      0.98  16008233

10/20/2023, 15:13:09# ============================== Early stopping ==================================
10/20/2023, 15:13:11# labels of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:11# predicted of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:11# labels of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:11# predicted of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:11# labels: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:11# predicted: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/20/2023, 15:13:22# Test Accuracy: 97.00898914791645 %



10/20/2023, 15:13:51# report path: classification_report/classification_report-transE_50-graphSAGE-3.xlsx
10/20/2023, 15:13:51# label path: classification_report/mapped_true_predicted_labels-transE_50-graphSAGE-3.xlsx
10/20/2023, 15:14:04# mapped_report:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00      6400
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00       600
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00       500
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00      1500
    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.01      0.01      0.01       100
    T1003.003_f049b89533298c2d6cd37a940248b219       0.02      0.04      0.02       100
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00       600
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00       600
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.00      0.01      0.01       100
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.00      0.00      0.00       300
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.01      0.02      0.02       100
        T1016_71b3d2945679566b9d94d8cb11df4b70       0.03      0.04      0.04       100
        T1016_7d8ee68f0e9731db82964f558f614608       0.63      0.32      0.43       500
    T1016_921055f4-5970-4707-909e-62f594234d91       0.00      0.00      0.00       100
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.01      0.01      0.01       100
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.04      0.07      0.05       100
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.04      0.05      0.05       100
        T1018_a44bb43474728496276d5d73aa14588f       0.02      0.04      0.03       100
        T1018_ac20e592bc912bddff4d6b88289095f0       0.02      0.03      0.03       100
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00       600
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.03      0.05      0.04       100
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.01      0.02      0.01       100
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00      2300
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00      2700
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00       200
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00       200
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00       700
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00       500
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.03      0.03      0.03       100
        T1047_6935e41353aa781bb723462d26114c44       0.01      0.02      0.01       100
        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.01      0.01      0.01       100
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.02      0.03      0.02       100
        T1047_b0255b5120cbabc062d8d4510a142c3b       0.05      0.07      0.06       100
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.02      0.03      0.03       100
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.03      0.04      0.04       100
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.02      0.02      0.02       100
        T1049_a14392d713dffba6a397682ff83259a0       0.00      0.00      0.00       300
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00       200
    T1053.005_ee454be9197890de62705ce6255933fd       0.01      0.02      0.02       100
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.00      0.00      0.00       100
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.00      0.00      0.00       100
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.01      0.03      0.02       100
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00       700
        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.01      0.02      0.02       100
        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.04      0.05      0.04       100
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      1000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00      1500
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00       500
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      1.00      1.00      1000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00       500
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00     13700
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00       700
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00       600
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00       900
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00       200
    T1069.002_6103e503cb444bc7b4187704f2035708       0.10      0.01      0.02       400
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00       600
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00      2000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      1000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00       300
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00       800
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.03      0.04      0.03       100
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.03      0.06      0.04       100
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      1200
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.00      0.00      0.00       100
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00       500
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.01      0.03      0.02       100
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.96      0.47      0.63       200
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      1100
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.98      0.99       200
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00       800
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00      2100
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00      2000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00      1300
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00      5700
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00     15000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00       300
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00       300
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00       300
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00       300
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       0.97      1.00      0.99       300
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00       300
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00       300
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00       200
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00       300
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00      1800
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00       300
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00       300
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00       500
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00      1600
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.02      0.03      0.02       100
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00      1900
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00      2000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00       600
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00       600
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.03      0.06      0.04       100
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00       600
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.01      0.01      0.01       100
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.03      0.04      0.03       100
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00       600
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00      1300
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.01      0.02      0.01       100
        T1201_57296a2ddbeb7423c05feef2fe972111       0.02      0.03      0.02       100
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      1000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      0.99      0.99       400
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.02      0.03      0.02       100
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00      6700
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     10400
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00      5000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00       500
        T1482_cfb61005899996469ae3023796792ca5       0.01      0.01      0.01       100
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00       400
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.02      0.04      0.03       100
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00       200
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.04      0.05      0.04       100
        T1490_c156ac5c9fa67080365268d95f29053d       0.00      0.00      0.00       100
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      1000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.03      0.05      0.03       100
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00       500
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00       700
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00      8200
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.00      0.01      0.01       100
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.01      0.01      0.01       100
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.02      0.05      0.03       100
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.05      0.08      0.06       100
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.01      0.03      0.02       100
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00       200
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.03      0.04      0.03       100
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00       200
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       100
        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00       200
        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00       200
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00      1500
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00       700
    T1547.001_163b023f43aba758d36f524d146cb8ea       0.99      1.00      1.00       500
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00       600
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00       200
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00       200
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00       500
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00       200
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00       200
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      1000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00       800
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00       600
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00      2200
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00       200
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00       200
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00     21600
    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00       200
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      1.00      1.00       600
    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.03      0.06      0.04       100
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00       200
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      1100
    T1562.004_5b93df032e230056c21a3e57334f77d1       0.04      0.04      0.04       100
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.02      0.03      0.02       100
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00       300
    T1564.001_66a5fd5f244819181f074dd082a28905       0.33      0.01      0.01       500
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.98      0.66       500
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.93      0.14      0.24       200
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00       600
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00      1600
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.02      0.04      0.03       100
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00       800
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00      6200
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00       600
                                        benign       1.00      1.00      1.00    134563

                                      accuracy                           0.97    310263
                                     macro avg       0.60      0.59      0.59    310263
                                  weighted avg       0.97      0.97      0.97    310263

10/20/2023, 17:19:25# labels of 50000: tensor([ 55, 157,   9, 150, 112,  60, 116,  30,  34, 143, 125,  18,  48,  83,
        164, 163,  47, 163, 121, 142,  30, 151, 143, 124,  74, 111,  47,  34,
        119, 142,   2,  83, 125,  48,  31,  53,  57,  36,  74,  60,  76, 164,
         14, 112,   1, 121,   2,  53, 125, 152, 124,  92,  81,  81,  97,  34,
         97,  30,  87,  57,   2,  81,  58,  58,  58,  58,  58,  58,  58, 163],
       device='cuda:0') torch.Size([70])
10/20/2023, 17:19:25# predicted of 50000: tensor([ 36, 164, 162, 124, 112,  87,  54,  57, 151,  33, 119, 152,  49,  30,
         44,  49,  11,  31,  38, 142,  11, 109,  30,  54, 124,  30,  33, 124,
        119,  54, 162,  49, 124,  11, 157, 124,  57,  36, 119,  54,  87, 111,
         38,  33, 150,  83, 162, 162, 124,  57, 124,  30, 125,  12,  54,  14,
        157,  81,  74, 112,  83,  54,  58,  58,  58,  58,  58,  58,  58,  30],
       device='cuda:0') torch.Size([70])
10/20/2023, 17:47:03# labels of 100000: tensor([112, 144,  87, 151,   9, 143,  55,   2,  47,  34,  11,  76,  42, 124,
          2,  11, 104,  49,  60,  38,  92, 104, 104,  60,  81,  53, 125, 104,
         83,  48,  33, 112,  44, 116,  36,   1, 163,  75, 115, 115, 115, 115,
        115, 115, 115, 115, 115, 115,  48, 143,  83,  60,   9,  87,  24,  75,
         47,  92,  18, 158, 111,  97, 116,   1, 163, 104,  87,  36, 150,  33,
          2,  36,  47], device='cuda:0') torch.Size([73])
10/20/2023, 17:47:03# predicted of 100000: tensor([112, 157,  87, 150,  49, 143,   2,  34,  47, 112, 125, 116,  24, 124,
          2,  38, 104,  57,  81, 121,  92, 104,  12,  60,  31, 158,  12, 104,
         83,   4,  44,  42,  44, 116,  24,   1, 104,  75, 115, 115, 115, 115,
        115, 115, 115, 115, 115, 115, 152,  83,  83,  74, 157,  87,  24,  54,
         31,  97,  18, 158,  47,  97, 162,   1, 157, 104,  87,   4, 150,  33,
        142, 144,  47], device='cuda:0') torch.Size([73])
10/20/2023, 18:16:17# labels of 150000: tensor([ 24,  48, 164, 150,  14,  75, 157,  55,  31,  18, 143,  47,  42, 124,
        124, 125,  75,  34, 158,  92, 142, 124,  33, 119,  14, 109, 116,   4,
         38, 152, 121, 121,  18, 142,  14,  44,  60, 112,  14, 158,  87,  74,
        151,  42,  11,  30,  55,  97,  87,  24, 150,  54,  55,  48,  40,  40,
         40,  40,  40,  40, 116,  11,  18,  76,  92, 150, 151, 143,  49],
       device='cuda:0') torch.Size([69])
10/20/2023, 18:16:17# predicted of 150000: tensor([ 24,  47, 151, 150,  14,  75,  76,  92, 163, 116, 143,  47,  24, 124,
        125, 125,  75,  97,  87,  92, 142, 124,  33,  36,  14, 109,  97, 111,
        152, 152,  14, 121,  31, 142,  97,   4,  83,  87, 144, 158,  87,  74,
        144, 142,  12,  30, 125,  97, 119,  81, 150,  47,  55,  48,  40,  40,
         40,  40,  40,  40, 116,  11,  47,  24, 112,  48, 151,  48, 162],
       device='cuda:0') torch.Size([69])
10/20/2023, 18:44:07# labels of 200000: tensor([  4,  54, 124, 109, 119, 111,   4, 119, 121, 109,  47,  24,  36, 163,
         18, 152, 143,  30,  53, 158, 124,  12, 144, 152,  76, 124, 164,  34,
         76, 157,  49,  33,  12, 142,  76, 158,   2, 143,   1,  47, 112, 152,
         87,  76, 116, 158,  54,  97,  83,  31,  30,  33, 112, 109,  44,  11,
        112,  49, 157, 121,  30,   9, 119, 158], device='cuda:0') torch.Size([64])
10/20/2023, 18:44:07# predicted of 200000: tensor([119,   2, 124,  31,   1,   4,   4, 119, 121,   4,  47,  24,  36, 163,
        142,  18, 143,  30,  53, 158, 124, 124, 144, 152,  76, 124, 151,  34,
         76,  87,  49,  33,  54, 142, 144, 158,   2,  81,   1,  47, 142, 152,
         87,  12,  87, 158, 164,  97,  83, 152,  57, 158, 121, 109, 157,  11,
        112,  81,  48, 111,  30,   9, 119,  87], device='cuda:0') torch.Size([64])
10/20/2023, 18:53:10# total batches: 213400
10/20/2023, 18:53:10# Epoch 0 | Train Loss: 2.2282 | Train Accuracy: 0.4102
10/20/2023, 18:53:10# labels of Validation: tensor([  9, 143,  27,  27,  27,  41,  41,  41,  41,  41, 116, 150, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  60, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0,  74,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  81,  88,  88,  92,  62,  62,
         62,  62,  62,  62,  75,   1,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 162, 152, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         59,  59,  59,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  14,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 114, 114, 150, 153, 153, 153,  89,  89, 162, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  53,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  83], device='cuda:0') torch.Size([690])
10/20/2023, 18:53:10# predicted of Validation: tensor([  2,  36,  27,  27,  27,  41,  41,  41,  41,  41,  44, 112, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  54, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 124, 124, 124, 124, 124,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0, 150,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99, 157,  92,  92,  48,  62,  62,
         62,  62,  62,  62,  18, 158,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165,  75, 142, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        150, 150, 158,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  81,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 116, 116,  60, 153, 153, 153,  89,  89,  44, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  24,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  34], device='cuda:0') torch.Size([690])
10/20/2023, 18:53:10# labels of 0: tensor([  9, 143,  27,  27,  27,  41,  41,  41,  41,  41, 116, 150, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  60, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 131, 131, 131, 131, 131,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0,  74,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  81,  88,  88,  92,  62,  62,
         62,  62,  62,  62,  75,   1,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 162, 152, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         59,  59,  59,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  14,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 114, 114, 150, 153, 153, 153,  89,  89, 162, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  53,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  83], device='cuda:0') torch.Size([690])
10/20/2023, 18:53:10# predicted of 0: tensor([  2,  36,  27,  27,  27,  41,  41,  41,  41,  41,  44, 112, 130, 130,
        130, 130, 130,  35,  35,  35,  35,  35,  35,  89,  89,  37,  37,  37,
         37,  37,  54, 139, 139, 139, 139, 139,  29,  29,  29,  29,  29,  29,
         29,  29,  29,  29, 129, 129, 129, 129, 129, 129, 129,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52, 136, 136, 136, 136, 136,
        136, 136, 136, 136, 136, 136, 136, 136, 136, 124, 124, 124, 124, 124,
          6,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,  19,  19,  19,  19,  19, 147,
         65, 147, 147, 147, 147,   0,   0,   0,   0,   0,   0, 150,  58,  58,
         58,  58,  58,  58,  58, 133, 133, 133, 133, 133, 133, 133, 133,  69,
         69,  69,  69,  69,  69,  94,  94,   0,   0,   0,   0,   0,   0,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99, 157,  92,  92,  48,  62,  62,
         62,  62,  62,  62,  18, 158,  53, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165,  75, 142, 148, 148, 148, 148, 148, 148, 148,
         95,  95,  95, 139, 139, 139, 139, 139, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        150, 150, 158,  10,  10,  89,  89, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 136, 136, 136, 136, 136, 136, 136, 126, 126, 126,  81,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  62,  62,  62,  62,  62,
         62, 116, 116,  60, 153, 153, 153,  89,  89,  44, 137, 137, 137, 137,
        137, 146, 146, 146, 146, 146, 146,  24,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,  45,  45,  45,  23,  23,
         23,  23,  23,  34], device='cuda:0') torch.Size([690])
10/20/2023, 18:53:20# Validation Loss: 0.4664 | Validation Accuracy: 0.9455

10/20/2023, 18:53:20# Find a better model!!
10/20/2023, 19:21:21# labels of 50000: tensor([111, 111,  11,  33,  38, 150, 151,  55,  24,  12, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118,  55,   2, 163,  44,   1,  74,  47,  92, 121,  30,  33,
         14,   4,  75, 144, 109,  74,  81, 158, 116,  55,  92,  12,  54, 144,
         57, 150, 121,  30, 124,   1,   2, 124,   1,  57,  11,  30,   9,  92,
         31,  33,   1,  74,  38,  11,  75,  24, 125,  76,  11, 143, 124, 144],
       device='cuda:0') torch.Size([84])
10/20/2023, 19:21:21# predicted of 50000: tensor([111, 111,  11, 152,  38, 150,  83,  55,  24,  12, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118,  55,   2, 163,  44,   1,  74,  48,  92, 119,  30,  49,
         14,  33,  75, 144, 142,  74,  57, 144, 116,  75,  92, 152,  54, 144,
         57, 150, 121,  30, 124,   1,  36,  30,   1,  57,   9,  53,   9, 125,
        143,  33,   1,  49, 119,  11,  75,  24, 125,  76,  11, 144, 124, 144],
       device='cuda:0') torch.Size([84])
10/20/2023, 19:48:53# labels of 100000: tensor([ 30,  18,  30,  33, 157,  14, 143, 164,  11, 109, 109, 125, 162,  48,
         92,  60, 144,  92, 109,  33,  87,  53,  76, 104, 157,  53, 112,  18,
         36, 109,  34,  60,  18, 151,  34, 162,  53,   2, 109,   2,  33, 150,
         42,  38,   9, 111, 125, 164,  38,  12, 151, 163,   4,  33, 124, 125,
          1, 162,   9,  92,  44,  31,  31, 119], device='cuda:0') torch.Size([64])
10/20/2023, 19:48:53# predicted of 100000: tensor([ 30,  87, 109,  33, 157,  14,  30, 164, 164,  47, 109, 125,  38, 151,
         92, 112, 125,  92, 109,  33,  87,  53,  76, 104, 157,  53, 142,  18,
         36, 109,  34,  11,  18, 151, 150, 162,  53,   2, 109,   2,  33, 109,
          9,  38,  97, 111,  47, 164,  38,  12, 151, 163, 150, 104, 124, 125,
         12, 162,   9,  92,  44,  31,  31, 121], device='cuda:0') torch.Size([64])
10/20/2023, 20:16:25# labels of 150000: tensor([ 55,   2,  12,  53, 164, 142,   1, 152, 111, 116, 158, 151,  38, 157,
        152,  11, 104, 162,  48,  47,  81,  76,   9,   2, 157,  44, 163, 109,
         57, 163,  11,  81,   4,  54,  54, 164,  57, 104,  57,  57, 112,  54,
        142,  38,  11, 125,  97, 164,  38,   2,  97,  31,  49,  74,   4, 152,
         47,  48,   2,  92,  42,   4, 157,   2], device='cuda:0') torch.Size([64])
10/20/2023, 20:16:25# predicted of 150000: tensor([ 55,   2,  12,  31, 164,  31,   1, 152, 111, 116, 158, 151,  38, 150,
         30,  11, 104, 164,   2,  47,  81,  76,   9, 119, 157,  44, 163, 109,
         57, 150,   4,  47,   4, 119,  54, 164,  57, 104,  57,  57, 112,  54,
        142,  76,  11, 125,  97, 164,  38,  33,  97,  31,  49, 125, 116, 152,
         47,  48,   2,  48, 119,   4, 150,   2], device='cuda:0') torch.Size([64])
10/20/2023, 20:45:46# labels of 200000: tensor([143, 109,  42,  11,  36,  11,  49, 124,  75,  60,  12, 163,  47,   4,
        119,  57,  24,  44,  76,  60,  38,  54,  87,  49,   4,   9, 143,  18,
        144, 157,  92,  33,  74,  44, 158, 143,  75, 157,  55,  31,  53, 124,
        144, 111, 112,  11,  87,  48,  44, 144, 152,  31, 158,  38,  81,  49,
         44,  92,  11,  42,  60,  92,   1,  83], device='cuda:0') torch.Size([64])
10/20/2023, 20:45:46# predicted of 200000: tensor([143, 109,  55,  11,  36,  60,  47, 116,  75,  60,  87, 158,  47,   4,
        119,  57,  24,  44,  75,  55,  74,  54,  87,  60,   4,  83, 111,  18,
        144,  55,  92,  33,  74,  44, 158, 143,  75, 157,  76,  31,  53, 124,
        144, 111, 112, 143,  87,  44,  44,   2, 152,  31, 158,  38,  81,  49,
         44,  92,  11,  42,  60,  92,   1,  83], device='cuda:0') torch.Size([64])
10/20/2023, 20:53:30# total batches: 213400
10/20/2023, 20:53:30# Epoch 1 | Train Loss: 0.8664 | Train Accuracy: 0.7450
10/20/2023, 20:53:30# labels of Validation: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 151,  95,  95,  95,  97,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 131, 131, 131, 131, 131,   8,   8,
        152, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  33,   8,
          8,  93,  93,  79,  79,   2,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  74,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  87, 158,  11,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 150,  51,  65,  51,  51,  51,  51,  18,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  55,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  81, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 113, 113,  64,  64,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,  83, 126, 126, 126, 144, 157, 109,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  88,  88, 142, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  76, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,  59,
         59,  59], device='cuda:0') torch.Size([576])
10/20/2023, 20:53:30# predicted of Validation: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154,  60,  95,  95,  95, 144,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118,  81,  38,  81,  38,  81, 142, 142,
        143, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  55,  53,
         53,  60,  60,  97,  97, 143,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 104,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21, 111,  42,   4,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  60,  51,  65,  51,  51,  51,  51,  48,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  74,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  12, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 124, 124, 163, 163,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137, 124, 126, 126, 126, 109,  49,  11,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 144,  30,  24, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 162, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50, 162,
        162, 162], device='cuda:0') torch.Size([576])
10/20/2023, 20:53:30# labels of 0: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 151,  95,  95,  95,  97,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 131, 131, 131, 131, 131,   8,   8,
        152, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  33,   8,
          8,  93,  93,  79,  79,   2,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  74,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  87, 158,  11,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 150,  51,  65,  51,  51,  51,  51,  18,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  55,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  81, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 113, 113,  64,  64,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137,  83, 126, 126, 126, 144, 157, 109,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149,  88,  88, 142, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,  76, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50,  59,
         59,  59], device='cuda:0') torch.Size([576])
10/20/2023, 20:53:30# predicted of 0: tensor([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154,  60,  95,  95,  95, 144,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118,  81,  38,  81,  38,  81, 142, 142,
        143, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  95,  95,  95,  55,  53,
         53,  60,  60,  97,  97, 143,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,   0,   0,
          0,   0,   0,   0, 102, 102,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 104,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21, 111,  42,   4,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  60,  51,  65,  51,  51,  51,  51,  48,  50,
         50,  50,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 139, 139, 139, 139,
        139,  74,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  12, 147,  65,
         65,  65,  65,  65, 147, 147, 147, 147,  89,  89, 124, 124, 163, 163,
        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 155,  65,  65,  65,
         65, 155, 155, 155,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,  28,  28,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28, 148, 148, 148, 148, 148,
        148, 148, 137, 137, 137, 137, 137, 124, 126, 126, 126, 109,  49,  11,
        148, 148, 148, 148, 148, 148, 148,  23,  23,  23,  23,  23,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  96,  96,  96,  96,  96,  96,  51,  65,
         51,  51,  51,  51,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 144,  30,  24, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 162, 137, 137, 137,
        137, 137,  20,  20,  40,  40,  40,  40,  40,  40,  50,  50,  50, 162,
        162, 162], device='cuda:0') torch.Size([576])
10/20/2023, 20:53:40# Validation Loss: 0.2921 | Validation Accuracy: 0.9594

10/20/2023, 20:53:40# Find a better model!!
10/20/2023, 21:22:50# labels of 50000: tensor([ 12, 163, 121, 124,  87,  54, 143, 119,  81, 142, 158, 144,   4, 116,
          2,  36,   2, 124,  53, 163, 142,  36, 104, 163,  30, 142, 150, 151,
         92, 125,  14,  18,  57, 111,  55, 142, 109,  34,  12,  30, 152, 151,
        158, 121,  49, 111,  33,   1, 109,   1,  47,  55, 116,  76, 119, 164,
         48,  47,  97,  53, 111,  34,  97, 112], device='cuda:0') torch.Size([64])
10/20/2023, 21:22:50# predicted of 50000: tensor([ 12, 163, 121, 124,  87,  54, 143, 119,  81, 142, 158,   4, 125, 116,
          2,  36,  18, 151,  53, 163, 142,  36, 104, 163,  30,  12, 150, 151,
         92,  24,  14,  18,  57, 111,  55, 142, 109,  55,  12,  30, 152, 157,
        158, 121,  49, 111,  33,   1, 109,   1,  47,  55, 116,  76, 119, 164,
         48,  47,  24,  53, 111,  76,  97, 112], device='cuda:0') torch.Size([64])
10/20/2023, 21:50:32# labels of 100000: tensor([ 14,  87, 104,  12, 157, 119,  87,  24, 119, 142,  38,  31, 109,   9,
        158,  60, 163, 116, 150,   9,  81, 163, 163,  60, 162,  31,  55, 112,
        142,   2,   1,  38, 142, 157,  55,   2,  24, 157,  36, 150,  31, 119,
         87,  60,  18, 150,  92,  42, 157, 119,  47,  97,  14,  55,  18,  18,
         33, 152, 111, 150, 104,  81,  14, 111], device='cuda:0') torch.Size([64])
10/20/2023, 21:50:32# predicted of 100000: tensor([ 57,  87, 104,  83, 157, 119,  87,  24, 119, 142,  38,  31, 109,   9,
        158,  18, 163, 116, 150,   9,  81, 163, 163,  87,  30,  31,  55,  60,
        111,   2,   1,  38, 142, 157,  55,  60,  24, 157,  36, 150,  31,  60,
         87,  60,  18, 121,  92,  36, 157,  36,  47,  97,   2,  55, 142,  18,
         33, 152, 111, 150, 104,  81,  60, 111], device='cuda:0') torch.Size([64])
10/20/2023, 22:18:18# labels of 150000: tensor([ 18,  34,  30,  14,  33,  81, 157, 152,   9,  44,  49, 124,  74,  87,
         60,  36,  53,  60,  47,  47,  48, 104,   9,  31,  30,  76,  18,  57,
        124,   2,  47,  57,   4,  54, 111,  11, 124,  33,  75,  11,  31,  76,
         31, 152, 157,  31,  31, 150,  42,  18,  83, 104,  14, 125,   2,  76,
         55,  18,  87, 121, 111,  54,  97, 150], device='cuda:0') torch.Size([64])
10/20/2023, 22:18:18# predicted of 150000: tensor([ 18,  34,  30,  14,  33,  81, 157,   4,   9,  44,  54, 124,  24,  87,
         60,  36,  53, 151,  47,  47, 111, 104,   9,  31,  83,  76,  18,  57,
        124,   2,  47,  57,   4,  54, 111,  11, 124,  33,  75, 158,  31,  76,
         31, 152, 157,  31,  97, 150,  42,  18,  83, 104,  14, 150,   2,  76,
         55,  87,  87, 121, 111,  54, 162, 112], device='cuda:0') torch.Size([64])
10/20/2023, 22:46:27# labels of 200000: tensor([125,  76, 152,  55, 121,  81,  14,  60,   2, 109,  49, 142, 112, 119,
        152,  48,  12,  54,  30,  87,  87,  42,  81,  47,  49,  31, 109,  54,
         11,  75,  83,  12,  12, 104,  38, 158,  49, 109,  36,  44, 125,  57,
        125,  38, 151,  33,  31, 121,  60, 109,  34,  81, 111,   4, 163, 119,
        164,  30, 157,  97,  55,  47, 151,  92], device='cuda:0') torch.Size([64])
10/20/2023, 22:46:27# predicted of 200000: tensor([125,  76, 152,  55,  74,   9,  14,  55,   2,  81,  49, 142, 112, 119,
        152,  48,  12,  54,  30,  87, 144,  42,  57,  47,  49,  54, 109,  54,
         11,  49,  83,  12,  12, 104,  38,  53,  18, 109,  36,  12, 125,  57,
        125,  38, 151,  33,  14, 121,  60, 109,  34,  81, 111,   4, 144, 119,
        164,  30, 157,  97,  55,  47, 151,  92], device='cuda:0') torch.Size([64])
10/20/2023, 22:55:40# total batches: 213400
10/20/2023, 22:55:40# Epoch 2 | Train Loss: 0.7120 | Train Accuracy: 0.7904
10/20/2023, 22:55:40# labels of Validation: tensor([ 42, 137, 137, 137, 137, 137,  92,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  47,
        136, 136, 136, 136, 136, 136, 136,  18,  14,  92,  11,  45,  65,  45,
         45,   4,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 150,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 108, 108, 108, 108,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 119, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  83,  80,  80,  80,  80,  80,  80, 116,  14,  72,
         72, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  83,  53, 117, 117, 117,  56,  56,
         56,  56,  56,  56,   9, 157,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 111,
         95,  95,  95,   5,   5,   5,  14, 143, 146, 146, 146, 146, 146, 146,
         49,  41,  41,  41,  41,  41,  93,  93, 113, 113,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  64,  64,  74,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 22:55:40# predicted of Validation: tensor([ 33, 137, 137, 137, 137, 137,  31,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62, 152,
        136, 136, 136, 136, 136, 136, 136, 144, 143,  11,  97,  45,  65,  45,
         45, 157,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 124,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149,  34,  34,  34,  34,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 150, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  44,  80,  80,  80,  80,  80,  80, 151, 111,  38,
         74, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,   9,   4, 117, 117, 117,  56,  56,
         56,  56,  56,  56,  36,  49,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 109,
         95,  95,  95,   5,   5,   5,  83, 151, 146, 146, 146, 146, 146, 146,
         24,  41,  41,  41,  41,  41, 111,  11, 124, 124,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  60,  60,   9,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 22:55:40# labels of 0: tensor([ 42, 137, 137, 137, 137, 137,  92,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62,  47,
        136, 136, 136, 136, 136, 136, 136,  18,  14,  92,  11,  45,  65,  45,
         45,   4,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 150,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 108, 108, 108, 108,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 119, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  83,  80,  80,  80,  80,  80,  80, 116,  14,  72,
         72, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,  83,  53, 117, 117, 117,  56,  56,
         56,  56,  56,  56,   9, 157,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 111,
         95,  95,  95,   5,   5,   5,  14, 143, 146, 146, 146, 146, 146, 146,
         49,  41,  41,  41,  41,  41,  93,  93, 113, 113,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  64,  64,  74,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 22:55:40# predicted of 0: tensor([ 33, 137, 137, 137, 137, 137,  31,  65,  65,  65,  65,  65,  65,  65,
         65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  62,  62,  62,  62,  62,  62, 152,
        136, 136, 136, 136, 136, 136, 136, 144, 143,  11,  97,  45,  65,  45,
         45, 157,  27,  27,  27,  62,  62,  62,  62,  62,  62,  71,  71,  71,
         71,  71,  71, 124,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149,  34,  34,  34,  34,  28,
         28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  65,  65,  65,
         65,  65,  65,  65,  65, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149, 149, 149, 149, 149, 149, 149,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32, 147,  65,  65,  65,  65,  65,
         65,  65,  65, 147, 147, 147, 147,  96,  96,  96,  96,  96,  96, 148,
        148, 148, 148, 148, 148, 148, 150, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134,  73,  73,  73,  44,  80,  80,  80,  80,  80,  80, 151, 111,  38,
         74, 146, 146, 146, 146, 146, 146, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165,   9,   4, 117, 117, 117,  56,  56,
         56,  56,  56,  56,  36,  49,  13,  13,  13,  13,  13, 146, 146, 146,
        146, 146, 146, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 109,
         95,  95,  95,   5,   5,   5,  83, 151, 146, 146, 146, 146, 146, 146,
         24,  41,  41,  41,  41,  41, 111,  11, 124, 124,  37,  37,  37,  37,
         37, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128,  60,  60,   9,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161],
       device='cuda:0') torch.Size([798])
10/20/2023, 22:55:50# Validation Loss: 0.3107 | Validation Accuracy: 0.9567

10/20/2023, 23:24:02# labels of 50000: tensor([ 24,   4,  74, 164,  11,  92, 162,  14, 163, 119, 112, 163,  33, 124,
         57,  14,   9,   2, 125,  54, 152,  87,  81,   4,   9, 111,  74,  18,
         44, 151,  18, 119,  14,   2, 121,  49,  97,  74, 151, 163, 112,  83,
         34, 142,  74, 112,  97, 109, 124,   9,  34,  83, 111,  57,  76, 150,
        150,  48,  53,  11, 142,  18,   2,  44], device='cuda:0') torch.Size([64])
10/20/2023, 23:24:02# predicted of 50000: tensor([ 24,   4, 158,  76,  11,  92, 162,  14, 163, 119, 112, 163,  38, 124,
         57,  14,   9, 164, 125, 164, 152,  87,  81,   4,   9, 111,  74,  55,
         44, 151,  36, 119,  76,   2, 121,  49,  97,  74, 151,  92, 112,  83,
         34, 142,  87,  75,  55, 109,  60,   9,  34,  83, 111,  57,  76, 150,
        150,  48,  53,  11, 142,  18,   2,  44], device='cuda:0') torch.Size([64])
10/20/2023, 23:53:36# labels of 100000: tensor([104, 151, 119,   4,  33,  18,  57,  11,  48, 158,  81,  97,  14,  34,
         83,  12,  14,  55, 119,  54, 142, 151,  31,  14,  55,   2, 125,  47,
         30, 158,  54, 112, 124, 151,  55,  81,   1,  12, 158, 111,  31,  75,
        151,   1,  48, 163,  81,  74,  48,  14,  11,  53,  30,  54,  54,   1,
         24, 142,  54,  11,  14,  33,  24,  11], device='cuda:0') torch.Size([64])
10/20/2023, 23:53:36# predicted of 100000: tensor([104, 151, 119,   4,  33,  18,  57,  11,  48,   4,  81, 116,  11,  34,
        152,  12,  14,  55, 119,  18, 142, 151,  31,  14,  92,   2, 125,  47,
         30, 158,  54, 112, 124,  53,  74,  81,   1,  12, 158, 111,  31,  75,
        151, 163,  48, 163,  81,  74,  48,  14,  11,  48,  30,  54,  54,   1,
         24, 142,  54,  74,  14,  33,  24,  11], device='cuda:0') torch.Size([64])
10/21/2023, 00:21:55# labels of 150000: tensor([ 74,  55,   4, 158, 142,  57,  33, 150,  30, 116,  24,  38, 163,  18,
        111,  18,  55, 116,  36,  44,  36,  24,   2,  11,   1,   4, 164,  14,
         60,  75,  14,  97,  74,  83,  24,  75,  36, 104,  54, 121,   2, 152,
          2,  83, 152, 121,  11,  54,   1,  60, 163,   9,  54, 124, 150, 152,
        119,  18,  30, 119,  36,  87,  48,  48], device='cuda:0') torch.Size([64])
10/21/2023, 00:21:55# predicted of 150000: tensor([ 74,  55,   4,  49, 142,  57,  33, 150,  30, 116,  24,  38, 163,  18,
        111,  18,  55, 112,  36,  44,  36,  24, 111,  11,   1,  38, 164,  14,
         60,  75,  14,  97,  74,  24,  24,  42,  36, 104,  54, 121,   2,  87,
          2,  83, 152, 121,  11,  12,   1,  60, 163,   9,  54, 162, 150, 152,
        119,  18,   1, 119,  36,  83,  48,  48], device='cuda:0') torch.Size([64])
10/21/2023, 00:51:35# labels of 200000: tensor([ 33,  44,   9,  18,  31, 151,  81,  53, 121, 143,  76,  11,   9,  81,
         49, 151,  92,  31, 104,  48, 119, 125,  36,  30,  33, 111,   4, 112,
        124, 104,  44,  53, 144,  18,  31,  48,  75,  76,  76, 125, 112,  75,
         31,  60,  33,  47, 143,  92,  75, 112,   1,  87,  81,  75, 125,  38,
         87, 121, 152, 112,  34,  18,  49,  42], device='cuda:0') torch.Size([64])
10/21/2023, 00:51:35# predicted of 200000: tensor([ 33,  44,   9,  18,  31, 151,  81,  53, 121, 143,  76,  11,   9,  81,
         49, 151,  44,  31, 104, 112, 119, 125, 125,  30,  33, 111,   4, 112,
        124, 104,  44,  53, 144,  18,  31, 157,  75,  76,   9, 125, 112,  75,
         31,  60,  33,  47, 143,  33, 109,  42,   1,  87,   1,  75, 125,  38,
         87, 121, 152, 112,  34,  18,  49,  42], device='cuda:0') torch.Size([64])
10/21/2023, 00:58:56# total batches: 213400
10/21/2023, 00:58:56# Epoch 3 | Train Loss: 0.6627 | Train Accuracy: 0.8046
10/21/2023, 00:58:56# labels of Validation: tensor([152,  28,  28,  ...,  95,  95,  95], device='cuda:0') torch.Size([1216])
10/21/2023, 00:58:56# predicted of Validation: tensor([18, 28, 28,  ..., 95, 95, 95], device='cuda:0') torch.Size([1216])
10/21/2023, 00:58:56# labels of 0: tensor([152,  28,  28,  ...,  95,  95,  95], device='cuda:0') torch.Size([1216])
10/21/2023, 00:58:56# predicted of 0: tensor([18, 28, 28,  ..., 95, 95, 95], device='cuda:0') torch.Size([1216])
10/21/2023, 00:59:05# Validation Loss: 0.3123 | Validation Accuracy: 0.9565

10/21/2023, 01:27:31# labels of 50000: tensor([ 75, 163,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  75,  75,  49,
         38, 143, 112,  33,  92,  87,  34,  31, 144,   2, 116, 112,  74,  31,
        121, 152,  34,  36,   4,  31,  42,  14, 124,  81,  34,  33,  54,  87,
        125,  48,  75,  44,  92, 121,  42, 124, 150,  11, 112,   4,  41,  41,
         41,  41,  41,  76, 116,  33,  38,  38, 152, 152,  55, 125,  60,  87,
         18, 157, 152,  87,  34,  11], device='cuda:0') torch.Size([90])
10/21/2023, 01:27:31# predicted of 50000: tensor([ 47, 163,  99,  99,  99,  99,  99,  99,  99,  99,  99,  65, 147,  99,
        147,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  75,  75,  49,
         53,  60, 164, 119,  92,  87,  34, 158, 144,   2, 116, 112,  74,  31,
        150, 152,  34,  36,   4,  31,  42, 119, 124,  81,  34,  33,  54,  87,
         24, 104,  75,  87,  49,  30,  42, 124, 150,  11,  75, 144,  41,  41,
         41,  41,  41,  76, 116, 163,   4,  38, 152, 152, 158, 125,  60,  87,
         18, 157, 152,  87,  34,  11], device='cuda:0') torch.Size([90])
10/21/2023, 01:56:59# labels of 100000: tensor([ 92,  30, 144,  54, 158,  49, 158, 162,  75,  24, 162,  36,  92,  60,
        112,  87, 142,   2, 152, 121,  74,   1, 158, 158,  18, 163,  18,  87,
         48,  36,   2,  18, 157,  55,  57,   1,  83, 142, 150,  36,  48, 112,
        119,  74,  12, 164,  54, 111,  42,  12,  75,  49,  49, 157,  31,  54,
        119,  36, 119,  14,  30,  31, 144, 112], device='cuda:0') torch.Size([64])
10/21/2023, 01:56:59# predicted of 100000: tensor([ 92,  36, 144,  57, 158,  49, 158, 162,  75,  24, 164,  36,  92,  60,
        112,  87, 142,   2, 121, 121,  74,   1,  87, 158,  44, 163, 162,  87,
         48,  36,   2,  18, 157,  55,  18,   1,  83, 142, 150,  36,  48, 112,
        104,  74, 104, 164,  54, 111,  42,  12,  75,  49,  49, 157,  31,  54,
        119,  36, 112,  14,  30,  31, 144, 112], device='cuda:0') torch.Size([64])
10/21/2023, 02:27:00# labels of 150000: tensor([ 24,   2, 144, 142,  83,  11, 152, 143, 163, 124, 116,  76,  33,  87,
        116,   2,  18,  60,  31,  76, 143,  49, 162, 119,  97,  31, 125,  12,
        111,  75,  74, 121, 119,   1,  48, 111,  75,  48,  76,  60, 144,  14,
        151, 163, 109, 164,  12, 158,  36,  34, 104,  60, 164, 157,  53,  87,
          2, 116,  47,  97, 119,  75,  49,  75], device='cuda:0') torch.Size([64])
10/21/2023, 02:27:00# predicted of 150000: tensor([ 24,   2, 144, 142,  83,  11, 152, 143, 163, 124, 116,  24, 109,  87,
        116, 116,  31,  60,  60,  76, 143,  49, 162, 119,  97,  31, 125,  12,
        111, 164,  74, 121, 119,   1,  48, 111,  75,  48,  76,  60, 144,  14,
         53, 163, 109, 164,  12, 158,  36,  34, 151, 104, 164, 157,  53,  87,
          2, 116,  47,  97, 144,  75,  49, 157], device='cuda:0') torch.Size([64])
10/21/2023, 02:55:26# labels of 200000: tensor([ 92, 162,  18,  74, 111,  11,   2,  92, 109,  30,  75, 124,  18, 158,
         53,  48,  60, 164, 158, 112,  76, 111,  81, 143,  57,  81,   9,  11,
        163,  83,  11,  97,   1, 143, 112, 112,  11,  83, 143,  12, 112,  18,
         11,  34,  24,  44,  75,   1,  12,  60,  30,  12,  36,  44,  44,  12,
         18, 111,  81, 152, 152,   1,  57,  12], device='cuda:0') torch.Size([64])
10/21/2023, 02:55:26# predicted of 200000: tensor([  1, 162,  18, 163, 152,  11,   2,  92, 109,  30,  74, 124,  18,   4,
         83,  48,  60, 164, 158, 112,  76, 111,  81, 143,  57, 112,   9,   2,
        152, 157,  11,  97,   1, 143, 112,  75,  38,  83, 143,  12, 112,  18,
         11,  34,  24,  44,  75,   1,  12,  60,  30,  53, 116,  44,  44,  12,
         18, 111,  81, 152, 152,   1,  60, 152], device='cuda:0') torch.Size([64])
10/21/2023, 03:03:07# total batches: 213400
10/21/2023, 03:03:07# Epoch 4 | Train Loss: 0.7755 | Train Accuracy: 0.7710
10/21/2023, 03:03:07# labels of Validation: tensor([ 87, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/21/2023, 03:03:07# predicted of Validation: tensor([ 47, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/21/2023, 03:03:07# labels of 0: tensor([ 87, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/21/2023, 03:03:07# predicted of 0: tensor([ 47, 126, 126,  ..., 106, 106, 106], device='cuda:0') torch.Size([1970])
10/21/2023, 03:03:17# Validation Loss: 0.3163 | Validation Accuracy: 0.9550

10/21/2023, 03:31:34# labels of 50000: tensor([ 38,  33,  48,  55,  75, 124, 121, 121, 164, 112, 116,  74, 164,  83,
        152,  24, 119, 151, 104,  30,  38,  33, 121, 121,  49, 157, 143,   9,
         87,  14,  24,  60, 163,  24,  54,  81,  44,  12, 111,  76, 104,  61,
         61,  61,  33, 119,  57,  18,  87,  24, 144,  47,  87, 112,  83,  47,
        164,  47,  60,  44, 109,  47, 124,  57,  55, 150], device='cuda:0') torch.Size([66])
10/21/2023, 03:31:34# predicted of 50000: tensor([ 81,  33,  48,  55, 151, 124, 121,  60, 164,  42, 116,  30, 164, 157,
        152,  24, 119, 151, 104,  30,  38,  33, 121, 121,  14, 157, 143,   9,
         87,  14,  24,  60, 163,  24,  53,  81,  44,  12,  83,  76, 104,  61,
         61,  61,  33, 119,  57,  18,  31,  24, 144,  47,  87, 112,  83,  47,
        164,  47,  54,  44, 109,  47, 124,  57,  55, 150], device='cuda:0') torch.Size([66])
10/21/2023, 04:01:18# labels of 100000: tensor([ 81, 158, 142,   4, 144, 162, 112, 163, 119,  92,  76, 125,  24, 109,
         55,  42,  76,  42,  75,  57,  60,   4,   1, 121,  81,  12,  76,   4,
         57,  48,  33,   2,  87,  48, 152, 104,  12,  83,  49,  34,  87,  47,
         47,  44, 162,  12,  44,  31, 152, 143, 143,  83,  36,  33, 119,   1,
         34,  44,   9, 109, 116,  76, 143,  76], device='cuda:0') torch.Size([64])
10/21/2023, 04:01:18# predicted of 100000: tensor([ 81, 158, 142, 150, 144,  18, 112, 163, 119,  92,  76, 125,  24, 109,
         55,  33,  76,  42,  75,  57,  60, 116,   1, 121,  81,  12,  76,   4,
         57,  48,  33,   2,  87,  31, 152, 104,  12,  83,  49,  34,  87,  75,
         47,  44, 162,  12,  44,  31, 152, 143, 143,  83,  36,  33, 119,   1,
         34,  44,   4,   9, 116,  76,  30,  81], device='cuda:0') torch.Size([64])
10/21/2023, 04:31:23# labels of 150000: tensor([ 42,  76, 121,  11,  57,  60,  83, 158,  42, 143,  83, 151, 150,  44,
         44,   9,  92,  24,  11, 158, 150,  38, 143,  57,  36, 163, 157, 111,
         42,  49, 116,  49,  33, 163, 164,  54, 124,  87, 124,  97,  38, 111,
         31,  81,  74,  33, 164, 157,  48,   1,  75, 162, 163,  42,  31,  60,
        157,  81, 157,  97, 152,  55, 125, 112], device='cuda:0') torch.Size([64])
10/21/2023, 04:31:23# predicted of 150000: tensor([ 38,  76, 121,  11,  57,  60,  83, 158,  42, 143,  83, 151, 150,  12,
        164,   9,  92,  24,  30, 158, 150,  38, 143,  57,  36, 163, 157, 111,
         42,  49,  92,  49,  33,   2, 164,  54, 124,  87, 124,  97,  38, 111,
         47,  81,  74,  33, 164, 157,  48,   1,  75, 162, 163,  42,  31,  60,
        157,  81, 157,  97, 152,  55, 125, 112], device='cuda:0') torch.Size([64])
10/21/2023, 04:59:35# labels of 200000: tensor([ 49,  42,  76,  18,  38,  48,  53,  47, 158, 109,  33,  30, 124, 164,
        164, 157,  87, 112, 121, 125,  92,  47,   1,  31,  14,  34, 104, 119,
         92,  54,   9, 121, 111, 163, 157,  11, 162,   1,  75, 121,  11, 157,
         60,  11, 142,  34, 121, 163,  97, 157, 124,  54, 158,  87, 124,  76,
          1, 116,  76,  53,   4, 125, 121, 125], device='cuda:0') torch.Size([64])
10/21/2023, 04:59:35# predicted of 200000: tensor([ 49,  42,  76,  18,  38,  48,  53,  47, 158, 109,  33,  30, 124, 164,
        164,  24,  87, 112, 121, 125,  92,  47,   1,  31,  14,  49, 162, 119,
         92,  54,   9, 121, 111, 163, 157,  11, 162,   1,  75, 121,  11, 157,
         60,  11, 142,  34, 121, 162,  97, 157, 124,  54, 158,  87, 124,  76,
          1, 116,  76,  53,   4, 125, 121, 125], device='cuda:0') torch.Size([64])
10/21/2023, 05:07:05# total batches: 213400
10/21/2023, 05:07:05# Epoch 5 | Train Loss: 0.4850 | Train Accuracy: 0.8580
10/21/2023, 05:07:05# labels of Validation: tensor([ 11, 150, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  31,
         68,  68, 152,  55,  47,  37,  37,  37,  37,  37,   2, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  59,  59,  59,  26,  26,  26,  26,  26,  26,  90,  90, 153, 153,
        153, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  44, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 116,  76,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  33,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  64,  64,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99, 157,  30,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  93,
         93, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  59,  59,  59,   9,  42,
         91,  91,  91, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   2,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  60, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108,
        103, 103], device='cuda:0') torch.Size([632])
10/21/2023, 05:07:05# predicted of Validation: tensor([  9, 142, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69, 104,
         55,  55,  97,   4, 143,  37,  37,  37,  37,  37,   1, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,   9,   9,  60,  26,  26,  26,  26,  26,  26, 152, 152, 153, 153,
        153,  60,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,   9, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117,  76, 104,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  11,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82, 109, 109,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  57,  54,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  55,
         55, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  75,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66, 121, 121, 121,  12, 112,
         18,  18,  60, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84, 157,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  49, 107, 107, 107, 107, 107, 107, 107, 107,  36,  36,  36,  36,
         54,  54], device='cuda:0') torch.Size([632])
10/21/2023, 05:07:05# labels of 0: tensor([ 11, 150, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69,  31,
         68,  68, 152,  55,  47,  37,  37,  37,  37,  37,   2, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,  59,  59,  59,  26,  26,  26,  26,  26,  26,  90,  90, 153, 153,
        153, 152,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,  44, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117, 116,  76,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  33,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  64,  64,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99, 157,  30,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  93,
         93, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  53,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  59,  59,  59,   9,  42,
         91,  91,  91, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84,   2,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  60, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108,
        103, 103], device='cuda:0') torch.Size([632])
10/21/2023, 05:07:05# predicted of 0: tensor([  9, 142, 137, 137, 137, 137, 137,  69,  69,  69,  69,  69,  69, 104,
         55,  55,  97,   4, 143,  37,  37,  37,  37,  37,   1, 107, 107, 107,
        107, 107, 107, 107, 107,  65,  65,  65,  65,  65,  65,  65,  65, 149,
        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
        149,   9,   9,  60,  26,  26,  26,  26,  26,  26, 152, 152, 153, 153,
        153,  60,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  21,  21,  21,  21,
         21,  21,  21,  21,  21,  21,  21,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27,   9, 133, 133,
        133, 133, 133, 133, 133, 133, 117, 117, 117,  76, 104,  39,  39,  39,
          0,   0,   0,   0,   0,   0,  35,  35,  35,  35,  35,  35,  77,  77,
         77,  77,  77,  77,  77,  77,  11,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,
         82,  82,  82,  82,  82,  82,  82, 109, 109,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  65, 102, 102,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  65,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  57,  54,   0,   0,   0,
          0,   0,   0, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  55,
         55, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 139, 139, 139, 139, 139,  75,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66, 121, 121, 121,  12, 112,
         18,  18,  60, 147,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65, 147, 147, 147, 147,  20,  20, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,
         84,  84,  84,  84,  84,  84,  84,  84,  84, 157,  94,  94,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 145, 145, 145, 145, 145,
        145,  49, 107, 107, 107, 107, 107, 107, 107, 107,  36,  36,  36,  36,
         54,  54], device='cuda:0') torch.Size([632])
10/21/2023, 05:07:15# Validation Loss: 0.3216 | Validation Accuracy: 0.9564

10/21/2023, 05:37:31# labels of 50000: tensor([ 24,  97,  12,  42,  60, 162,  87,  92,   2,  30,   4,  53, 124,  75,
         36,   9, 158,  83,  53,   1,  55,   4,  47, 144, 116,  31,  54, 143,
        112,  31, 157, 150, 152,   2,  11, 104,  60, 144,  38, 143,  44, 157,
         24,  31,  87,  74,  42,  49, 150,  33,  54,  18, 152, 158,   4,  54,
         57, 152, 150,  44, 109,  54, 158, 109], device='cuda:0') torch.Size([64])
10/21/2023, 05:37:31# predicted of 50000: tensor([ 24,  97,  12,  42, 109, 162,  87,  92,   2,  49,   4,  53, 124,  75,
         36,   9, 158,  83,  53,   1,  36,   4,  47, 144, 116,  31,  54, 143,
        112,  31, 157, 150, 152,  83,  11,  83,  60, 144,  38, 143,  44, 157,
         24,  31,  87,  74,  42,  49, 150,  33,  54,  18, 152, 158,   4,  54,
         57, 152, 150,  44,  30,  54, 158, 109], device='cuda:0') torch.Size([64])
10/21/2023, 06:05:51# labels of 100000: tensor([ 47,  38, 152, 104,  48,  18,  54, 162,  97,  33,  54,  36,  83,  55,
        152, 158,  74,  55,  36, 163,  49, 109, 158,  97,  54,  76, 116,   9,
          9, 163,   9,  53, 157,   1,  42, 109,  44,  49, 158, 144, 125, 112,
         36,  11,  34,  48, 119,   2,   9,  55,  30, 109,   2,  38,  11,  55,
        104,  14,  74,  87, 164,  53,   9,  33], device='cuda:0') torch.Size([64])
10/21/2023, 06:05:51# predicted of 100000: tensor([ 42,  38, 152, 104,  48,  18,  54, 162,  97,  33,  54,  36,  83,  55,
        152, 158,  74,  55,   4, 163,  49, 109,  54,  97,  54, 150, 116,  55,
          9, 163,   9,  53, 157,   1,  42, 109,  44,  49, 158, 144, 125, 112,
         36,  11, 124,  48, 119,   2,   9,  87,  30,  55,   2,  60,  34,  55,
        104,  14,  74,  87, 164,  53,   9,  33], device='cuda:0') torch.Size([64])
10/21/2023, 06:36:03# labels of 150000: tensor([  9,  31,  53, 143,  12,  34, 125,  97,  30,  48,  97,  34, 124,  15,
         15,  15, 112,  18,  11, 163,  87,  38,  33,  54,  11,  77,  77,  77,
         77,  77,  77,  77,  77, 119,  42,  81,  11, 162,  60, 143,  31,  76,
         74, 158, 163,  74,  54, 124,  87, 111,  12, 164,  81,  54,  48,  53,
         74, 111,  49,  75, 119, 112,  75,   1,  42, 143,  30, 143, 112,  30,
        152, 125,  87], device='cuda:0') torch.Size([73])
10/21/2023, 06:36:03# predicted of 150000: tensor([  9,  31,  53, 143,  12,  24, 125,  97,  30,  48,  97,  34, 124,  15,
         15,  15, 112,  18,  11, 163,  87,  38,  33,  54,   9,  77,  77,  77,
         77,  77,  77,  77,  77, 119,  42,  81,  11, 162,  18, 143,  31,  76,
         48, 158,  34,  74,  54, 124,  87, 111,  53, 164,  81,  54,  48,  53,
         74, 111,  49,  75,   2, 112,   9,   1,  42,  97,  30, 143, 112,  30,
        152, 125,  87], device='cuda:0') torch.Size([73])
10/21/2023, 07:04:10# labels of 200000: tensor([163,   1, 162,  87,  74,   2,  48, 116, 150, 125,  57,  87, 157,  60,
         12,  76, 162,  24,  14,  83, 158,  42,  75,  11,  44,  60, 150,   2,
         44,  81,  81, 124, 104, 157,  49, 112, 124,  24,  14, 124, 152, 111,
         12,  34,  92,  18, 109, 116,   2, 125, 104,  76, 150,  60,  53, 104,
        116,  31,   9,   9, 143,   1, 164, 164], device='cuda:0') torch.Size([64])
10/21/2023, 07:04:10# predicted of 200000: tensor([163,   1, 162,  87,  74, 109,  24, 116,   1, 125,  57,  87, 157,  60,
         12,   1, 162,  24,  14,  83, 158,  42,  75,  11,  44,  60, 150,   2,
         44,  81,  81, 124, 104, 157,  49, 112, 124,  24,  14, 124, 152, 111,
         74,  34,   9,  18, 109, 116,   2, 125, 104,  76,  97,  60,  30, 104,
        116,  31,   9,  81, 143,   1, 164, 164], device='cuda:0') torch.Size([64])
10/21/2023, 07:11:53# total batches: 213400
10/21/2023, 07:11:53# Epoch 6 | Train Loss: 0.4625 | Train Accuracy: 0.8646
10/21/2023, 07:11:53# labels of Validation: tensor([119,  91,  91,  ...,  23,  23,  23], device='cuda:0') torch.Size([2172])
10/21/2023, 07:11:53# predicted of Validation: tensor([11, 49, 49,  ..., 23, 23, 23], device='cuda:0') torch.Size([2172])
10/21/2023, 07:11:53# labels of 0: tensor([119,  91,  91,  ...,  23,  23,  23], device='cuda:0') torch.Size([2172])
10/21/2023, 07:11:53# predicted of 0: tensor([11, 49, 49,  ..., 23, 23, 23], device='cuda:0') torch.Size([2172])
10/21/2023, 07:12:03# Validation Loss: 0.3090 | Validation Accuracy: 0.9581

10/21/2023, 07:42:17# labels of 50000: tensor([ 30, 112, 158,  34,  42,  53, 152, 111, 162,  54, 143,   9, 157, 111,
         83,   1, 163,  83,  38,  74, 152,  53,  44, 151, 150, 124, 116,  34,
         36, 164, 111, 124,  38, 119,  87, 109, 144, 119,  48, 152, 125,  83,
        157,  54,  55,   4,  76, 163,  18,  33,  74, 152, 150, 121,  33, 151,
        121,  24, 163,   2,   1, 152,  57,  14], device='cuda:0') torch.Size([64])
10/21/2023, 07:42:17# predicted of 50000: tensor([ 30, 112, 158,  34,  42,  53, 152, 162,   1,  54, 143,   9, 157, 111,
         83,   1, 163,  83,  38,  74, 152,  53,  44, 151, 150, 124, 116,  34,
         36, 164, 111, 124,  38, 116, 157, 109, 144, 119,  48, 152, 125,  83,
        157,  54,  55,   4, 151, 163,  18,  33,  74,  12, 150, 121,  33, 151,
        121,  24, 121,   2,   1, 152,  57,  14], device='cuda:0') torch.Size([64])
10/21/2023, 08:11:12# labels of 100000: tensor([  9,  97,  87,  42, 112, 157, 157,  14,  92, 119, 109,  92,  76, 157,
        158, 152, 119,  14,  57,  24, 163,  54, 143,  87,  49,  44, 124,  76,
         48, 119, 163,  57,  34,  42, 164,  49, 121,   2,  48, 163,   1, 116,
        111,  12,  81,  57,  34,  87,  33, 142, 124,  38, 112,  92,  74,  87,
         11,  24, 157,   1,  14, 162, 119,  60], device='cuda:0') torch.Size([64])
10/21/2023, 08:11:12# predicted of 100000: tensor([124,  97,  87,  42, 112, 157, 157,  14,  11, 119, 109,  92,  76, 152,
        158, 152, 119,  14,  57,  24, 163,  54, 143, 116,  49,  44, 124,  76,
         48, 119, 163,  57, 124,  42, 164,  49,  14,   2,  48, 144,   1, 116,
        111,  12, 150,  74,  34,  87,  33, 142, 124,  38, 112,  92,  74,  87,
         11,  24, 157, 116,  14, 162, 119,  49], device='cuda:0') torch.Size([64])
10/21/2023, 08:40:57# labels of 150000: tensor([ 31,  76,  38, 142,  38, 112, 164, 124,  44, 144, 109, 124, 144, 111,
        111,  97, 142,  30,  11,  12,  31,  11,  42, 125,  11, 112,  75,  36,
        104, 158, 163,  33,  92, 144, 151,   4, 116,  30,   2, 151, 125,  74,
         54,   9, 119, 162, 142,  53, 144,  38,  30,  57,  33, 142, 111,  14,
        111,  33, 112, 163,  11,  81, 162,  76], device='cuda:0') torch.Size([64])
10/21/2023, 08:40:57# predicted of 150000: tensor([ 31,  76,  38, 109,  38, 112, 164, 124,  44, 144, 109, 124, 144,  47,
        111,  97, 142,  30,  11,  12,  31,  11,  42, 125,  11, 112,  75,  36,
        157, 158, 163,  33,  92, 144, 151,   4, 116,  30,   2, 151, 125,  74,
          4,  34, 119,  14, 142, 163,  92,  38,  30,  57,  33, 142, 111,  14,
        111,  33, 112, 163,  11,  47, 162,  76], device='cuda:0') torch.Size([64])
10/21/2023, 09:08:58# labels of 200000: tensor([ 60,  11,  60,  36,  54, 150,  97,  92,  83, 157, 144, 152,  47,  47,
         83, 158,  83,  36,  12, 164,  30,  34,   4, 125, 121,  34, 163, 157,
         57,  54,  36, 162,  81, 162, 119, 157,  87,  42, 121,  53,  76,  48,
         97, 124,  75,  30,  81,  76,   1, 125,  60, 121,  87,  38,  31,  30,
         14,  57,  14, 109,  92, 112,  24, 142], device='cuda:0') torch.Size([64])
10/21/2023, 09:08:58# predicted of 200000: tensor([ 60,  11,  60,  83,  54, 150,  97,  44,  83, 157, 144,  87,  47,  47,
         83, 158,  83,  36,  12, 164,  30,  34,   4, 125,  74,  34, 163, 157,
         57,  54,  36, 162,  81, 162, 119, 157,  87,  42, 121,  53,  76, 124,
         97, 124,  75,  30,  81,  76,   1, 125, 152, 121,  87,  38,  31,  30,
         14,  57,  14, 109,  92, 112,  24, 144], device='cuda:0') torch.Size([64])
10/21/2023, 09:16:27# total batches: 213400
10/21/2023, 09:16:27# Epoch 7 | Train Loss: 0.4619 | Train Accuracy: 0.8644
10/21/2023, 09:16:27# labels of Validation: tensor([ 34,  43,  43,  75,  60, 136, 136, 136, 136, 136, 136, 136, 166, 166,
        166, 166, 166, 166,  92,  26,  26,  26,  26,  26,  26, 155,  65,  65,
         65, 155, 155, 155,  92, 112,   0,   0,   0,   0,   0,   0, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  45,  65,  45,  45, 146, 146, 146, 146,
        146, 146,  37,  37,  37,  37,  37, 155,  65, 155, 155, 155,  50,  50,
         50,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  48,  50,
         50,  50, 110, 110,  49,  71,  71,  71,  71,  71,  71, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52, 119,  31,  61,  61,  61,  65, 123, 123, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 155,  65, 155, 155, 155,  83,
         78,  78,  78,  78,  78,  87,  61,  61,  61,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  37,  37,  37,  37,  37,  68,  68,  62,  62,  62,  62,  62,  62,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,   2,
         92, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154,  41,  41,  41,  41,  41,  49,  50,
         50,  50,  15,  15,  15,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 110, 110, 136, 136, 136, 136, 136, 136, 136,
        114, 114,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,
         86,  86, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 117, 117,
        117, 122, 122, 122, 122, 122, 122, 122, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132,  93,  93, 163, 131, 131, 131, 131, 131, 144,  56,  56,  56,  56,
         56,  56,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17], device='cuda:0') torch.Size([960])
10/21/2023, 09:16:27# predicted of Validation: tensor([ 44,  43,  43, 143,  48, 136, 136, 136, 136, 136, 136, 136, 166, 166,
        166, 166, 166, 166,  87,  26,  26,  26,  26,  26,  26, 155,  65,  65,
         65, 155, 155, 155,   2, 144,   0,   0,   0,   0,   0,   0, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  45,  65,  45,  45, 146, 146, 146, 146,
        146, 146,  37,  37,  37,  37,  37, 155,  65, 155, 155, 155,  50,  50,
         50,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,   9,  50,
         50,  50, 116, 116, 124,  71,  71,  71,  71,  71,  71, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52, 116, 150,  61,  61,  61,  65, 123, 123, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 155,  65, 155, 155, 155, 158,
         67,  78,  78,  78,  78,  11,  61,  61,  61,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  37,  37,  37,  37,  37,  33,  33,  62,  62,  62,  62,  62,  62,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,  60,
        163, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154,  41,  41,  41,  41,  41,  34,  50,
         50,  50,  15,  15,  15,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  92,  81, 136, 136, 136, 136, 136, 136, 136,
        157, 157,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,
         86,  86, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 117, 117,
        117, 122, 122, 122, 122, 122, 122, 122, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 124, 124,  74,  18,  18,  18,  18,  18,  76,  56,  56,  56,  56,
         56,  56,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  55,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17], device='cuda:0') torch.Size([960])
10/21/2023, 09:16:27# labels of 0: tensor([ 34,  43,  43,  75,  60, 136, 136, 136, 136, 136, 136, 136, 166, 166,
        166, 166, 166, 166,  92,  26,  26,  26,  26,  26,  26, 155,  65,  65,
         65, 155, 155, 155,  92, 112,   0,   0,   0,   0,   0,   0, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  45,  65,  45,  45, 146, 146, 146, 146,
        146, 146,  37,  37,  37,  37,  37, 155,  65, 155, 155, 155,  50,  50,
         50,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  48,  50,
         50,  50, 110, 110,  49,  71,  71,  71,  71,  71,  71, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52, 119,  31,  61,  61,  61,  65, 123, 123, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 155,  65, 155, 155, 155,  83,
         78,  78,  78,  78,  78,  87,  61,  61,  61,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  37,  37,  37,  37,  37,  68,  68,  62,  62,  62,  62,  62,  62,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,   2,
         92, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154,  41,  41,  41,  41,  41,  49,  50,
         50,  50,  15,  15,  15,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82, 110, 110, 136, 136, 136, 136, 136, 136, 136,
        114, 114,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,
         86,  86, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 117, 117,
        117, 122, 122, 122, 122, 122, 122, 122, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132,  93,  93, 163, 131, 131, 131, 131, 131, 144,  56,  56,  56,  56,
         56,  56,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17], device='cuda:0') torch.Size([960])
10/21/2023, 09:16:27# predicted of 0: tensor([ 44,  43,  43, 143,  48, 136, 136, 136, 136, 136, 136, 136, 166, 166,
        166, 166, 166, 166,  87,  26,  26,  26,  26,  26,  26, 155,  65,  65,
         65, 155, 155, 155,   2, 144,   0,   0,   0,   0,   0,   0, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
         65,  65, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  45,  65,  45,  45, 146, 146, 146, 146,
        146, 146,  37,  37,  37,  37,  37, 155,  65, 155, 155, 155,  50,  50,
         50,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,   9,  50,
         50,  50, 116, 116, 124,  71,  71,  71,  71,  71,  71, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52, 116, 150,  61,  61,  61,  65, 123, 123, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 155,  65, 155, 155, 155, 158,
         67,  78,  78,  78,  78,  11,  61,  61,  61,  16,  16,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  37,  37,  37,  37,  37,  33,  33,  62,  62,  62,  62,  62,  62,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,  60,
        163, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
        154,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65, 154, 154, 154, 154, 154, 154, 154, 154,
        154, 154, 154, 154, 154, 154, 154,  41,  41,  41,  41,  41,  34,  50,
         50,  50,  15,  15,  15,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  92,  81, 136, 136, 136, 136, 136, 136, 136,
        157, 157,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,
         86,  86, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 117, 117,
        117, 122, 122, 122, 122, 122, 122, 122, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132,  65, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 124, 124,  74,  18,  18,  18,  18,  18,  76,  56,  56,  56,  56,
         56,  56,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  55,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17], device='cuda:0') torch.Size([960])
10/21/2023, 09:16:36# Validation Loss: 0.3097 | Validation Accuracy: 0.9572

10/21/2023, 09:45:31# labels of 50000: tensor([143,  48,  49,  31,  81, 125,  55,  92,  18,  92,  54,  83, 158,  54,
         11,  74, 152,  44,  81, 143,  11,  54, 152,  12, 104, 162, 121,  92,
         34,  44, 125,  14, 150, 144,  30, 142,  60, 121, 121,   4,  75,   2,
         36,  24,  54,  30, 158,  75,  18, 121, 158, 109,  97,  31,  34, 112,
         11,  55,  74, 142,  11,  31, 124,  49], device='cuda:0') torch.Size([64])
10/21/2023, 09:45:31# predicted of 50000: tensor([143,  48,  49,  31,  24, 158,  55,  92,  18,  92,  54,  83, 158,  54,
         11, 112, 152, 112,  81, 143,  11,  54, 152,  12, 104, 162, 121,  18,
         34,  44, 162,  14, 150, 144,  30, 142,  60, 121, 121,   4,  75,   2,
         36,  24,  54,  54, 158,  75,  18, 121, 158, 109,  97,  31,  34, 112,
         11,  55,  74,  12,  11,  31, 124,  49], device='cuda:0') torch.Size([64])
10/21/2023, 10:15:12# labels of 100000: tensor([ 57,  12,  81,  18,   1, 121,  47,  48,  47,  34,  83,  33,  75, 116,
          1,  33, 116,  54,  44,  24,  34,  30, 157,   4,   9, 119, 125,  34,
        162,  60,  44,  97,  42, 125,  14,  76,  57,  42,  87,  53,  14, 158,
        104,  76,  53, 144, 121,  11,  76,  60,  54,  48,  12, 163, 133, 133,
        133, 133, 133, 133, 133, 133, 142,  87, 143,  11,  12,  38,  53,  38,
         76], device='cuda:0') torch.Size([71])
10/21/2023, 10:15:12# predicted of 100000: tensor([ 57,  53,  81,  18,   1, 121,  14,  48, 104,  34,  83,  38,  75, 116,
         60,  33, 116, 157,  44, 158,  34,  30, 157, 121,   9, 119, 125,  34,
        162, 124,  44,  97,  42, 125,  14,  76,  57,  42,  87, 152,  14, 158,
        104,  76,  53, 144,  74,  11,  76,  60,  54,  48,  12,  75, 133, 133,
        133, 133, 133, 133, 133, 133, 142,  87, 143,  11,  12,  38,  53,  38,
         76], device='cuda:0') torch.Size([71])
10/21/2023, 10:43:42# labels of 150000: tensor([ 33, 104,  60,  57, 109,  12, 119,  83, 151,  83,   4,  97, 151, 162,
        111, 119,   4,  76, 162, 158,  30,  92,  55, 104,  72,  72, 164, 111,
         33, 112,  31, 125,  24,  36,  18,  55,  11,  75,  12, 150,  55, 158,
         60,   2, 112,  44, 125, 150, 111,   2,  42, 163, 152, 158, 142,  42,
        124, 144, 112, 164,  76, 163, 124,  55,   1], device='cuda:0') torch.Size([65])
10/21/2023, 10:43:42# predicted of 150000: tensor([ 33, 104,  76,  57, 109,  12,  47,  83, 151,  83,  76,  97, 151, 162,
        111,  47,   4,  76, 162, 111,  30,  33,  55, 104,  59, 111, 164, 111,
         33, 112,  31,  83,  14, 112,  18, 164,  11,  75,  42, 150,  76, 158,
         83,   2, 112,  44, 125,  12, 143,   2,  92, 163, 152,  42, 142,  42,
        124,  11, 112, 164,  76, 163,  57,  55,   1], device='cuda:0') torch.Size([65])
10/21/2023, 11:13:43# labels of 200000: tensor([124,  38,  42,   1, 151,  34,  92,  44, 112,  49,  18,  76,  87,  75,
         76,  11, 158,  48,  76, 157, 162,  75,   4,   4,  11,  42,  83, 111,
         87, 121,  14,  36, 109,  14,   2,   2, 157, 119, 158, 124, 151, 109,
         87,   1,  36, 163,  81, 125,  48,  14,  74, 157, 124,  24, 142, 121,
         48,  83,  53,  53, 142, 121,  11, 152], device='cuda:0') torch.Size([64])
10/21/2023, 11:13:43# predicted of 200000: tensor([124, 119,  42,   1, 151,  34,  92,  44, 112,  49,  18,  76,  87,  75,
         76,  87, 158,  48,  76, 157, 124,  75,   4,   4,  11, 142,  83, 111,
         55, 121,  14,  36, 109,  14,   2,   2, 157, 119, 158, 124,  57, 109,
         33,   1, 104, 163,  81, 125,  48,  14,  74, 157, 124,  24, 142,  36,
        143,  33,  53,  53,  47, 121,  11, 152], device='cuda:0') torch.Size([64])
10/21/2023, 11:21:08# total batches: 213400
10/21/2023, 11:21:08# Epoch 8 | Train Loss: 0.6476 | Train Accuracy: 0.8090
10/21/2023, 11:21:08# labels of Validation: tensor([ 57, 130, 130, 130, 130, 130,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  72,  72,  72,  72, 117, 117, 117,  95,  95,  95,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 166, 166, 166, 166, 166, 166,  65,  65, 102, 102,  87,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  88,  88, 130, 130, 130,
        130, 130, 124,  38,  61,  61,  61,  57, 159, 159, 159, 159, 159, 159,
        159, 159, 159, 159,  11, 160, 160, 160, 160, 160, 160, 160, 160,  96,
         96,  96,  96,  96,  96,  50,  50,  50,  40,  40,  40,  40,  40,  40,
        130, 130, 130, 130, 130, 108, 108, 108, 108, 136, 136, 136, 136, 136,
        136, 136,  96,  96,  96,  96,  96,  96,  37,  37,  37,  37,  37, 153,
        153, 153, 131, 131, 131, 131, 131,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 104, 148, 148, 148, 148, 148, 148, 148, 160, 160, 160, 160,
        160, 160, 160, 160,  41,  41,  41,  41,  41, 136, 136, 136, 136, 136,
        136, 136,  73,  73,  73,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  69,  69,  69,  69,  69,  69, 116, 157,
         53,  92,  88,  88, 129, 129, 129, 129, 129, 129, 129,  83,  37,  37,
         37,  37,  37,  58,  58,  58,  58,  58,  58,  58, 110, 110, 139, 139,
        139, 139, 139,  49, 133, 133, 133, 133, 133, 133, 133, 133,  88,  88,
          2, 108, 108, 108, 108,   1,  94,  94,  58,  58,  58,  58,  58,  58,
         58, 107, 107, 107, 107, 107, 107, 107, 107,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  13,  13,  13,  13,  13],
       device='cuda:0') torch.Size([529])
10/21/2023, 11:21:08# predicted of Validation: tensor([ 74, 130, 130, 130, 130, 130,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  72,  72, 112, 119, 117, 117, 117,  95,  95,  95,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 166, 166, 166, 166, 166, 166,  65,  65, 102, 102,  14,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66, 163, 163, 130, 130, 130,
        130, 130, 124,  83,  61,  61,  61,  14, 159, 159, 159, 159, 159, 159,
        159, 159, 159, 159,  76, 160, 160, 160, 160, 160, 160, 160, 160,  96,
         96,  96,  96,  96,  96,  50,  50,  50,  40,  40,  40,  40,  40,  40,
        130, 130, 130, 130, 130, 151, 151, 151, 151, 136, 136, 136, 136, 136,
        136, 136,  96,  96,  96,  96,  96,  96,  37,  37,  37,  37,  37, 153,
        153, 153, 131, 131, 131, 131, 131,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 104, 148, 148, 148, 148, 148, 148, 148, 160, 160, 160, 160,
        160, 160, 160, 160,  41,  41,  41,  41,  41, 136, 136, 136, 136, 136,
        136, 136,  73,  73,  73,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  69,  69,  69,  69,  69,  69,  92,  54,
         24,   2,  11,  11, 129, 129, 129, 129, 129, 129, 129, 109,  37,  37,
         37,  37,  37,  58,  58,  58,  58,  58,  58,  58,  33,  33, 139, 139,
        139, 139, 139,  38, 133, 133, 133, 133, 133, 133, 133, 133,  74,  74,
         14,  31,  31,  31,  31, 152,  94,  94,  58,  58,  58,  58,  58,  58,
         58, 107, 107, 107, 107, 107, 107, 107, 107,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  13,  13,  13,  13,  13],
       device='cuda:0') torch.Size([529])
10/21/2023, 11:21:08# labels of 0: tensor([ 57, 130, 130, 130, 130, 130,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  72,  72,  72,  72, 117, 117, 117,  95,  95,  95,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 166, 166, 166, 166, 166, 166,  65,  65, 102, 102,  87,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66,  88,  88, 130, 130, 130,
        130, 130, 124,  38,  61,  61,  61,  57, 159, 159, 159, 159, 159, 159,
        159, 159, 159, 159,  11, 160, 160, 160, 160, 160, 160, 160, 160,  96,
         96,  96,  96,  96,  96,  50,  50,  50,  40,  40,  40,  40,  40,  40,
        130, 130, 130, 130, 130, 108, 108, 108, 108, 136, 136, 136, 136, 136,
        136, 136,  96,  96,  96,  96,  96,  96,  37,  37,  37,  37,  37, 153,
        153, 153, 131, 131, 131, 131, 131,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 104, 148, 148, 148, 148, 148, 148, 148, 160, 160, 160, 160,
        160, 160, 160, 160,  41,  41,  41,  41,  41, 136, 136, 136, 136, 136,
        136, 136,  73,  73,  73,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  69,  69,  69,  69,  69,  69, 116, 157,
         53,  92,  88,  88, 129, 129, 129, 129, 129, 129, 129,  83,  37,  37,
         37,  37,  37,  58,  58,  58,  58,  58,  58,  58, 110, 110, 139, 139,
        139, 139, 139,  49, 133, 133, 133, 133, 133, 133, 133, 133,  88,  88,
          2, 108, 108, 108, 108,   1,  94,  94,  58,  58,  58,  58,  58,  58,
         58, 107, 107, 107, 107, 107, 107, 107, 107,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  13,  13,  13,  13,  13],
       device='cuda:0') torch.Size([529])
10/21/2023, 11:21:08# predicted of 0: tensor([ 74, 130, 130, 130, 130, 130,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  72,  72, 112, 119, 117, 117, 117,  95,  95,  95,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 166, 166, 166, 166, 166, 166,  65,  65, 102, 102,  14,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66, 163, 163, 130, 130, 130,
        130, 130, 124,  83,  61,  61,  61,  14, 159, 159, 159, 159, 159, 159,
        159, 159, 159, 159,  76, 160, 160, 160, 160, 160, 160, 160, 160,  96,
         96,  96,  96,  96,  96,  50,  50,  50,  40,  40,  40,  40,  40,  40,
        130, 130, 130, 130, 130, 151, 151, 151, 151, 136, 136, 136, 136, 136,
        136, 136,  96,  96,  96,  96,  96,  96,  37,  37,  37,  37,  37, 153,
        153, 153, 131, 131, 131, 131, 131,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 104, 148, 148, 148, 148, 148, 148, 148, 160, 160, 160, 160,
        160, 160, 160, 160,  41,  41,  41,  41,  41, 136, 136, 136, 136, 136,
        136, 136,  73,  73,  73,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  69,  69,  69,  69,  69,  69,  92,  54,
         24,   2,  11,  11, 129, 129, 129, 129, 129, 129, 129, 109,  37,  37,
         37,  37,  37,  58,  58,  58,  58,  58,  58,  58,  33,  33, 139, 139,
        139, 139, 139,  38, 133, 133, 133, 133, 133, 133, 133, 133,  74,  74,
         14,  31,  31,  31,  31, 152,  94,  94,  58,  58,  58,  58,  58,  58,
         58, 107, 107, 107, 107, 107, 107, 107, 107,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  13,  13,  13,  13,  13],
       device='cuda:0') torch.Size([529])
10/21/2023, 11:21:17# Validation Loss: 0.3177 | Validation Accuracy: 0.9569

10/21/2023, 11:49:33# labels of 50000: tensor([112,  48, 104,  81,  76, 143, 150,  53,  33,  60,  55,  42,  31,  55,
        109, 164, 121, 111,  60, 121,  42, 158,   9,  76,  12,  34,  74,  48,
         18,  47,   9,  42,  12, 121,  74, 158,  48,  97,  81, 109, 116,  33,
         87,  76,  31,  55,   2, 163, 104, 124, 112, 158,  38,  47, 142,   4,
         33,  48,  87, 111,  57,  48, 104, 111], device='cuda:0') torch.Size([64])
10/21/2023, 11:49:33# predicted of 50000: tensor([112,  48, 143,  81,  76, 143, 150,  53,  33,  60,  55,  42,  31,  55,
        109, 164, 121,  47,  60, 121,  42, 158,  14,  76,  12,  34,  74,  48,
         18,  47,   9,  42,  12, 121,  74, 158,  48,  97,  76, 109, 163,  33,
         87,  76,  31,  55,   2, 163,  34, 116, 112, 158,  38,  47, 142,   4,
         24,  48,  36, 111,  57,  31, 104, 111], device='cuda:0') torch.Size([64])
10/21/2023, 12:19:41# labels of 100000: tensor([111,  14, 158,  44,  30, 121, 152,   9, 111,   4,  34,  34,  24, 116,
        158, 116,  30, 158,  38, 152, 121,  24, 150, 104, 121, 125,  33, 157,
         34, 125,  30,  14,  49, 150, 104, 124,  36,  92,  74, 144,  55,   2,
        157,  48, 142,   6,  65,  65,  65,  65,  65,  65,  65,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,  36,  11,  38, 164, 164,  97,  83,  53, 164, 104,   9, 125,   9,
         53,  76,  14,   9,  31], device='cuda:0') torch.Size([89])
10/21/2023, 12:19:41# predicted of 100000: tensor([111,  14, 158,  44,  30, 121, 152,   9, 111,   4,  34,  34,  24, 116,
        158, 116,  30, 158,  38, 152, 121,  24, 150, 104, 121, 125,  33, 157,
         92, 125, 124,  14,  49, 150, 104, 124,  36,  92,  74, 144,  55,   2,
        157,  48,  42,   6,  65,  65,  65,  65,  65,  65,  65,   6,   6,   6,
          6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,
          6,  36,  11,  54, 164, 164,  97,  83,  53, 164, 104,   9,  33,   9,
         53,  76,  14,   9,  31], device='cuda:0') torch.Size([89])
10/21/2023, 12:48:13# labels of 150000: tensor([ 48,  76, 124, 125, 152,  57,  54, 157, 143, 164, 119,  14, 109,  83,
        150,   1, 125,   4,  81, 164,  11,  87, 166, 166, 166, 166, 166, 166,
         12, 144,  57,  36,  87,  47,  83,  81,  33,  83,   1,  76,  11, 157,
         24,  76, 144,  87,  75,  12,  53,  76,   4,   4, 124,  83, 109,  42,
         14,  18,  87,  34,  74,  24, 158,  74,   4, 143,  31,  44, 125],
       device='cuda:0') torch.Size([69])
10/21/2023, 12:48:13# predicted of 150000: tensor([111,  76, 124, 125, 152,  57,  54, 157, 143, 164, 119,  14, 109,  83,
        150,   1, 125,   4,  81, 164, 111,  87, 166, 166, 166, 166, 166, 166,
         12, 144, 157,  36,  42,  47,  83,  81,  33,  83,   1,  76,  11, 157,
         24,  76, 144,  87, 157,  12,  53,  76, 157, 124, 124,  83, 109,  42,
         14,  18,  87,  34,  74,  24, 158,  74,  83, 143,  31,  44, 125],
       device='cuda:0') torch.Size([69])
10/21/2023, 13:18:22# labels of 200000: tensor([119, 142, 157,  87,  76, 104,  57,  75,  83, 124, 125,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 150,  75,  33, 143,
         60,  81,  38,  49,  97, 112,  24,  49,   1, 144,  60,  31, 152, 157,
         18, 144,   9, 157,  11, 158,  97,   1,  34,  57,  18,  34, 151,   4,
         75,  53,  76,  31, 116,  54, 158,  38, 109,  14, 152,  44, 143, 119,
        152, 152,  42,  34, 116, 119], device='cuda:0') torch.Size([90])
10/21/2023, 13:18:22# predicted of 200000: tensor([119, 142, 157,  87,  76, 104,  57,  75,  83, 124, 125,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  82,  82,  82, 150,  75,  33, 143,
         60,  81,  38,  49,  97, 112,  24,  49,   1, 144,  60,  31, 152, 157,
         18, 144,   9, 157,  11, 158,  97,   1,  34,  42,  18,  60, 151,   4,
         75,  53,  76,  31, 116,  54, 158, 144, 109,  14, 152,  44, 143, 119,
        152, 152,  42, 150, 116, 119], device='cuda:0') torch.Size([90])
10/21/2023, 13:25:52# total batches: 213400
10/21/2023, 13:25:52# Epoch 9 | Train Loss: 0.4092 | Train Accuracy: 0.8804
10/21/2023, 13:25:52# labels of Validation: tensor([ 83, 151,   5,   5,   5,  91,  91,  91, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 121,  35,  35,  35,  35,  35,  35,
         42,  98,  81,  59,  59,  59,  10,  10,  67,  67,  67,  67,  67, 136,
        136, 136, 136, 136, 136, 136,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32, 109, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,   5,   5,   5, 131, 131, 131, 131,
        131,  61,  61,  61, 103, 103,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  48,  11, 131, 131, 131, 131, 131, 112,  41,  41,  41,
         41,  41, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127,  20,  20,  79,  79, 122, 122,
        122, 122, 122, 122, 122,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  85,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  94,
         94,   0,   0,   0,   0,   0,   0,  38,  88,  88, 160, 160, 160, 160,
        160, 160, 160, 160, 157,  10,  10,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 163,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
        110, 110,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  63,  63,  63,  63,  85,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  43,  43,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  65,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52, 130, 130, 130, 130, 130,  56,  56,  56,  56,
         56,  56,  68,  68, 119,  83,  53,  45,  65,  45,  45,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70, 139, 139, 139, 139, 139,  43,  43, 143,  93,  93,  28,  28,  28,
         28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  29,  29,  29,  29,
         29,  29,  29,  29,  29,  29], device='cuda:0') torch.Size([720])
10/21/2023, 13:25:52# predicted of Validation: tensor([143,  48,   5,   5,   5,  74,  74,   9, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,  24,  35,  35,  35,  35,  35,  35,
         97,  98,  38,  49,  49,  49,  10,  10,  78,  78,  78,  78,  78, 136,
        136, 136, 136, 136, 136, 136,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32, 121, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,   5,   5,   5, 131, 131, 131, 131,
        131,  61,  61,  61,  11,  11,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7, 152, 124,  74,  74,  74,  74,  74, 119,  41,  41,  41,
         41,  41, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127,  20,  20, 162,  79, 122, 122,
        122, 122, 122, 122, 122,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  85,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  94,
         94,   0,   0,   0,   0,   0,   0, 152,  55,  55, 160, 160, 160, 160,
        160, 160, 160, 160, 109,  10,  10,  84,  84,  84,  84,  84,  84,  84,
         84,  84,  31,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
        162, 162,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  63,  63,  63,  63,  85,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  43,  43,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  65,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52, 130, 130, 130, 130, 130,  56,  56,  56,  56,
         56,  56, 116, 116, 142,  44,  38,  45,  65,  45,  45,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70, 139, 139, 139, 139, 139,  43,  43,  83,  42,  42,  28,  28,  28,
         28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  29,  29,  29,  29,
         29,  29,  29,  29,  29,  29], device='cuda:0') torch.Size([720])
10/21/2023, 13:25:52# labels of 0: tensor([ 83, 151,   5,   5,   5,  91,  91,  91, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 121,  35,  35,  35,  35,  35,  35,
         42,  98,  81,  59,  59,  59,  10,  10,  67,  67,  67,  67,  67, 136,
        136, 136, 136, 136, 136, 136,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32, 109, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,   5,   5,   5, 131, 131, 131, 131,
        131,  61,  61,  61, 103, 103,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  48,  11, 131, 131, 131, 131, 131, 112,  41,  41,  41,
         41,  41, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127,  20,  20,  79,  79, 122, 122,
        122, 122, 122, 122, 122,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  85,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  94,
         94,   0,   0,   0,   0,   0,   0,  38,  88,  88, 160, 160, 160, 160,
        160, 160, 160, 160, 157,  10,  10,  84,  84,  84,  84,  84,  84,  84,
         84,  84, 163,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
        110, 110,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  63,  63,  63,  63,  85,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  43,  43,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  65,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52, 130, 130, 130, 130, 130,  56,  56,  56,  56,
         56,  56,  68,  68, 119,  83,  53,  45,  65,  45,  45,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70, 139, 139, 139, 139, 139,  43,  43, 143,  93,  93,  28,  28,  28,
         28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  29,  29,  29,  29,
         29,  29,  29,  29,  29,  29], device='cuda:0') torch.Size([720])
10/21/2023, 13:25:52# predicted of 0: tensor([143,  48,   5,   5,   5,  74,  74,   9, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,  24,  35,  35,  35,  35,  35,  35,
         97,  98,  38,  49,  49,  49,  10,  10,  78,  78,  78,  78,  78, 136,
        136, 136, 136, 136, 136, 136,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32, 121, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,   5,   5,   5, 131, 131, 131, 131,
        131,  61,  61,  61,  11,  11,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7, 152, 124,  74,  74,  74,  74,  74, 119,  41,  41,  41,
         41,  41, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127,  20,  20, 162,  79, 122, 122,
        122, 122, 122, 122, 122,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  85,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  94,
         94,   0,   0,   0,   0,   0,   0, 152,  55,  55, 160, 160, 160, 160,
        160, 160, 160, 160, 109,  10,  10,  84,  84,  84,  84,  84,  84,  84,
         84,  84,  31,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
        162, 162,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  63,  63,  63,  63,  85,  85,  85,  85,  85,  85,
         85,  85,  85,  85,  85,  43,  43,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  65,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52, 130, 130, 130, 130, 130,  56,  56,  56,  56,
         56,  56, 116, 116, 142,  44,  38,  45,  65,  45,  45,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70, 139, 139, 139, 139, 139,  43,  43,  83,  42,  42,  28,  28,  28,
         28,  28,  65,  28,  28,  28,  28,  28,  28,  28,  29,  29,  29,  29,
         29,  29,  29,  29,  29,  29], device='cuda:0') torch.Size([720])
10/21/2023, 13:26:01# Validation Loss: 0.3057 | Validation Accuracy: 0.9583

10/21/2023, 13:56:44# labels of 50000: tensor([144,  75,  54, 142,  18,  44,  36, 142,   4,  53,  49, 158,  30, 143,
        163, 158, 119,  48, 144,  34, 109,  30,  97,  75, 150, 151,  57, 109,
         31,  38, 163, 109, 142,  81,  24, 109, 142,  38,   1,  36, 150,  18,
        119,  38,  42,  92,  36, 150,  81,  76, 124,   1,   1, 143,  31, 143,
         44, 112,  76,  97, 119,   1,  18,  18], device='cuda:0') torch.Size([64])
10/21/2023, 13:56:44# predicted of 50000: tensor([144,  75,  54, 142,  18,  44,  36, 142,   4,  53,  49,   1,  30, 143,
        163, 157, 119,  44, 144,  34, 109,  30,  97,  75,  24, 151,  57,  74,
         31,  38, 163, 109, 142,  81,  24, 109, 142,  38,   1,  36, 150,  18,
        157,  38,  42,  92, 116, 150,  81, 124,  24,   1,   1, 143,  31, 150,
         44, 112,  76,  97, 119,   1,  14,  18], device='cuda:0') torch.Size([64])
10/21/2023, 14:24:55# labels of 100000: tensor([ 83,  33,   9, 111,  12,  55,  54, 124, 158, 163,  48,  33,  55,  57,
         87,  12,  33, 144,  12,  14,  60,  78,  78,  78,  78,  78,  30,  92,
          9,  57, 144,  33, 158, 111, 104, 109,  36, 125,  92,  53, 152,  60,
         81,  74,  74,  87, 157,   2,  49,  55, 143,  55, 124,  44,   9,  76,
         80,  80,  80,  80,  80,  80,  48,  53,  36, 125,  18,   4, 109, 109,
         34,  24,  57], device='cuda:0') torch.Size([73])
10/21/2023, 14:24:55# predicted of 100000: tensor([ 83,  81,   9, 157,  12,  55,  54, 124, 158, 163,  48,  33,  55,  57,
         87,  12,  33, 144,  12,  14,  60,  78,  78,  78,  78,  78,  30, 164,
          9,  57, 144,  33, 158, 111, 104, 109,  36, 125,  92,  53, 152,  60,
         81, 158,  74,  87, 157,   2,  49,  55, 143,  55, 124,  44,   9,  76,
         80,  80,  80,  80,  80,  80,  48,  53,  36, 125,  18, 164, 109, 109,
         38,  24,  57], device='cuda:0') torch.Size([73])
10/21/2023, 14:53:38# labels of 150000: tensor([121,  87,  42,   9,  75,  30,  34, 143, 158, 157,  11,  97,  83,  48,
        152,  24, 111,  75,  33,   9,  24,  74,  36,  48,  60, 164,  24,  30,
        164,  12,  11,  55, 150,   9, 142, 121,   1, 109, 162,  34, 157,  97,
         54,  38,  76, 158,  33,  33, 158,  18, 112,  12,  38, 112, 152,   1,
         81,   1, 109,  34,   2,  38,  49, 109], device='cuda:0') torch.Size([64])
10/21/2023, 14:53:38# predicted of 150000: tensor([121,  87,  42, 116,  75,  30,  34, 143, 158,  74, 112,  97,  83,  48,
        152,  24, 111,  75,  33,  30,  24,  74,  36,  48,  60, 164,  24,  30,
        164,  12,  11,  55, 150,   9, 142, 121,   1, 109, 162,  34, 157,  97,
         54,  38,  55, 158,  33,  33, 158,  42, 112,  12,  38, 112, 152,   1,
        162,  33, 109,  34,   2,  49,  49, 109], device='cuda:0') torch.Size([64])
10/21/2023, 15:24:02# labels of 200000: tensor([144,  34, 119,  42,  53,  57, 162, 163,  44, 111, 162,  76, 142, 158,
        143,  36,  57, 119, 158, 112,   1,   1,  30,  57, 144,  30, 109,  14,
        158,  87, 111, 162, 112, 158,   4,  74, 157,   9,  47,  97, 143,  38,
        152,  74, 164, 151, 116,  14, 150,  53,  74,  34,  49,   1, 157,  87,
         53, 124, 119, 163, 111, 142,  55, 143], device='cuda:0') torch.Size([64])
10/21/2023, 15:24:02# predicted of 200000: tensor([144,  34, 119,  42,  53,  57, 162, 163,  44, 111, 162,  76, 142, 158,
         76,  36,  57, 119, 158, 112,   1,   1,  30,  57, 144,  30, 109,  14,
        158, 163, 111,  18, 112, 158,   4,  74, 157,   9,  47,  97, 143,  38,
        152,  74, 164,   1, 116,  14, 150,  53,  74, 109,  49,   1, 157,  87,
         53, 124, 119, 163, 111, 142,  75, 143], device='cuda:0') torch.Size([64])
10/21/2023, 15:31:53# total batches: 213400
10/21/2023, 15:31:53# Epoch 10 | Train Loss: 0.3919 | Train Accuracy: 0.8862
10/21/2023, 15:31:53# labels of Validation: tensor([111,   1,  33,  42, 116, 155,  65, 155, 155, 155, 108, 108, 108, 108,
        158,  13,  13,  13,  13,  13,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  21,  50,  50,  50, 117, 117, 117,  94,  94, 160, 160, 160,
        160, 160, 160, 160, 160,  59,  59,  59, 157,  97,  79,  79,  83, 143,
         74,  50,  50,  50, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
        152, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 164,  76,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 107, 107,
        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         31, 137, 137, 137, 137, 137, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115,   5,   5,   5,  43,  43, 162,   1,  48, 163,  69,  69,  69,
         69,  69,  69,  65,  65,  65,  65,  65, 135, 135,  67,  67,  67,  67,
         67,  26,  26,  26,  26,  26,  26, 166, 166, 166, 166, 166, 166,  72,
         72,  86,  86, 144,  87,  44,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  67,  67,  67,  67,  67, 116,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32, 113, 113,  35,  35,
         35,  35,  35,  35, 122, 122, 122, 122, 122, 122, 122,  94,  94, 122,
        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,  96,
         96,  96,  96,  96,  96, 166, 166, 166, 166, 166, 166],
       device='cuda:0') torch.Size([375])
10/21/2023, 15:31:53# predicted of Validation: tensor([150, 143,  74, 164,  97, 155,  65, 155, 155, 155, 131, 131, 131, 131,
         30,  13,  13,  13,  13,  13,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  21,  50,  50,  50, 117, 117, 117,  94,  94, 160, 160, 160,
        160, 160, 160, 160, 160, 162, 162, 162, 119, 143,  87, 143,  31, 152,
         81,  50,  50,  50, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
        142, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127,  75,  33,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 107, 107,
        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         18, 137, 137, 137, 137, 137, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115,   5,   5,   5,  43,  43, 151, 144,  47, 143,  69,  69,  69,
         69,  69,  69,  65,  65,  65,  65,  65, 135, 135,  78,  78,  78,  78,
         78,  26,  26,  26,  26,  26,  26, 166, 166, 166, 166, 166, 166,  81,
         72,  86,  86,  49, 121,  57,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  78,  78,  78,  78,  78, 158,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  24,  24,  35,  35,
         35,  35,  35,  35, 122, 122, 122, 122, 122, 122, 122,  94,  94, 122,
        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,  96,
         96,  96,  96,  96,  96, 166, 166, 166, 166, 166, 166],
       device='cuda:0') torch.Size([375])
10/21/2023, 15:31:54# labels of 0: tensor([111,   1,  33,  42, 116, 155,  65, 155, 155, 155, 108, 108, 108, 108,
        158,  13,  13,  13,  13,  13,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  21,  50,  50,  50, 117, 117, 117,  94,  94, 160, 160, 160,
        160, 160, 160, 160, 160,  59,  59,  59, 157,  97,  79,  79,  83, 143,
         74,  50,  50,  50, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
        152, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 164,  76,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 107, 107,
        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         31, 137, 137, 137, 137, 137, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115,   5,   5,   5,  43,  43, 162,   1,  48, 163,  69,  69,  69,
         69,  69,  69,  65,  65,  65,  65,  65, 135, 135,  67,  67,  67,  67,
         67,  26,  26,  26,  26,  26,  26, 166, 166, 166, 166, 166, 166,  72,
         72,  86,  86, 144,  87,  44,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  67,  67,  67,  67,  67, 116,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32, 113, 113,  35,  35,
         35,  35,  35,  35, 122, 122, 122, 122, 122, 122, 122,  94,  94, 122,
        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,  96,
         96,  96,  96,  96,  96, 166, 166, 166, 166, 166, 166],
       device='cuda:0') torch.Size([375])
10/21/2023, 15:31:54# predicted of 0: tensor([150, 143,  74, 164,  97, 155,  65, 155, 155, 155, 131, 131, 131, 131,
         30,  13,  13,  13,  13,  13,  21,  21,  21,  21,  21,  21,  21,  21,
         21,  21,  21,  50,  50,  50, 117, 117, 117,  94,  94, 160, 160, 160,
        160, 160, 160, 160, 160, 162, 162, 162, 119, 143,  87, 143,  31, 152,
         81,  50,  50,  50, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
        142, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127,  75,  33,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  27,  27,  27, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 107, 107,
        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         18, 137, 137, 137, 137, 137, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115,   5,   5,   5,  43,  43, 151, 144,  47, 143,  69,  69,  69,
         69,  69,  69,  65,  65,  65,  65,  65, 135, 135,  78,  78,  78,  78,
         78,  26,  26,  26,  26,  26,  26, 166, 166, 166, 166, 166, 166,  81,
         72,  86,  86,  49, 121,  57,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  78,  78,  78,  78,  78, 158,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65, 141,
        141, 141, 141, 141, 141, 141, 141, 141, 141,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  24,  24,  35,  35,
         35,  35,  35,  35, 122, 122, 122, 122, 122, 122, 122,  94,  94, 122,
        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,  96,
         96,  96,  96,  96,  96, 166, 166, 166, 166, 166, 166],
       device='cuda:0') torch.Size([375])
10/21/2023, 15:32:03# Validation Loss: 0.3115 | Validation Accuracy: 0.9573

10/21/2023, 16:03:07# labels of 50000: tensor([ 87,  76,  11,  36,  36,   1,   2,  14,   1, 143,  38, 121, 152,  81,
         53,  14,   9,  60,  74,  34,  30,  36,  34,  76,  75, 163, 164,  57,
        104,  31, 121,  33, 150,  11,  75,  49, 163,  31,  68,  68, 144,  81,
        152, 163, 163,  38,  34,  75, 121, 109, 143,  44,  57,  34,  31, 150,
         42,  54, 152,  11,  44,  18,  81, 142,  38], device='cuda:0') torch.Size([65])
10/21/2023, 16:03:07# predicted of 50000: tensor([ 87,  76,  53,  36,  36,   1,   2,  14,   1, 143,  38, 121, 152,  81,
         53,  14,   9,  60,  74,  34,  30,  36,  34,  76,  75, 125,  54,  57,
        104,  31, 121,  33, 150,  11,  75,  49, 163,  31, 158, 158, 144, 158,
          1, 163, 158,  75,  34,  75, 121, 109, 143,  44,  57,  30,  31, 150,
         42,  54, 152,  11,  44,  18,  81, 109,  38], device='cuda:0') torch.Size([65])
10/21/2023, 16:31:52# labels of 100000: tensor([ 97,  60, 111, 143,  54, 158,  14,  53,  75,  33, 144, 142,  75, 164,
         38, 104,  36,  87,  14, 111,  53,  97,  34,  48, 119, 164,   4,  74,
         55,  31, 121, 162,  44,  11, 150,  74,  97,  38, 162,  60,  34,  11,
        142,  87,  49,  57,  60,  12,  83, 142, 125, 164,  38, 121, 144, 125,
         42,  11,  97,  49,   1,  11,  31,  48], device='cuda:0') torch.Size([64])
10/21/2023, 16:31:52# predicted of 100000: tensor([ 76,  60, 111, 143,  54, 158,  14,  53,  75,  33, 144, 142,  75,   9,
         38, 104,  36,  87,  14,  75,  53,  97,  34,  48, 119, 164,   4,  74,
         55,  31, 121, 162,  44,  11, 150,  74,  97,  38, 162,  60,  74,  11,
        142,  87,  49, 162,  60,  12,  83, 142, 125, 164,  38, 121, 144, 125,
         42,  60,  97,  49,   1,  11,  31,  48], device='cuda:0') torch.Size([64])
10/21/2023, 17:00:10# labels of 150000: tensor([125,   2,   2,   2, 164,  44,  36, 151,  57,  54, 121, 144,  54, 157,
         55,  42, 151,  97, 124, 104,  38, 158,  11,  47,  38, 143,  74, 152,
          4, 144,   9, 158,  57,  53, 144,  74, 163,   9,  34, 121,  60,  14,
         55, 142,   2,  54, 144,  49,  30, 104, 109, 112, 151,  30,  11,   9,
        143, 116,  44,  55, 152, 157,  24, 104], device='cuda:0') torch.Size([64])
10/21/2023, 17:00:10# predicted of 150000: tensor([ 31,   9,   2,   2, 164,  44,  60, 151,  57,  54, 121, 144,  54, 157,
         55,  42, 151,  97, 124, 104, 109, 158,  11,  47,  38, 143,  87, 152,
          4, 144,   9, 158,  57,  53, 144,  74,  81,   9,  34, 121,  60,  14,
         55, 142,   2,  54, 144,  49,  30, 104, 109, 112, 151,  30,  11,   9,
        143, 116,  44,  76, 152, 157,  24, 104], device='cuda:0') torch.Size([64])
10/21/2023, 17:28:16# labels of 200000: tensor([ 75,  38,  60,  74, 119, 157, 125,  81, 164,  34,  83, 143, 143, 158,
        158, 151,  18,   2,   2,  74,  92, 144,  33,  44,  33,  36,  57,   9,
         42,   9, 109,   1,  36, 162,  92, 116,  12, 109,  83, 152,   9,  74,
        152,  74, 157,  49,  14,  74, 124, 143, 163,  44,  34,  14,  81,  12,
         76,  18,  36,  53, 157,   9,  31,  55], device='cuda:0') torch.Size([64])
10/21/2023, 17:28:16# predicted of 200000: tensor([ 75,  38,  60,  18, 119, 121, 125,  81, 164,  34,   2, 143, 143, 158,
        158, 151,  18,  53,   2,  74,  92, 144,  33,  44,  33,  36,  11,   9,
         42,   9, 109,   1,  36, 162,  92, 116,  12, 109,  83, 152,  49,  74,
        152,  47, 157,  49,  14,  74, 124, 143, 163,  44,  34,  14,  55,  12,
         76,  18,  36,  53, 157,   9, 150,  55], device='cuda:0') torch.Size([64])
10/21/2023, 17:35:48# total batches: 213400
10/21/2023, 17:35:48# Epoch 11 | Train Loss: 0.4036 | Train Accuracy: 0.8821
10/21/2023, 17:35:48# labels of Validation: tensor([ 61,  61,  61,  10,  10,  46,  46, 129, 129, 129, 129, 129, 129, 129,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  94,  94, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128,  53, 112, 116,  48,  10,  10,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 148, 148, 148, 148, 148,
        148, 148,  73,  73,  73, 166, 166, 166, 166, 166, 166,  12,  87,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,   4,  46,  46,  59,
         59,  59,  39,  39,  39, 126, 126, 126,  41,  41,  41,  41,  41,  26,
         26,  26,  26,  26,  26,  75, 150,  15,  15,  15,  30, 102, 102,  93,
         93,  78,  78,  78,  78,  78,  54, 148, 148, 148, 148, 148, 148, 148,
        129, 129, 129, 129, 129, 129, 129,  34, 112,  86,  86, 164, 113, 113,
        151, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        146, 146, 146, 146, 146, 146,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165,  90,  90,   4, 144,  24,   0,   0,   0,   0,   0,   0,  74,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 114, 114, 113, 113, 119,  73,  73,  73,
         63,  63,  63,  63, 163, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132],
       device='cuda:0') torch.Size([697])
10/21/2023, 17:35:48# predicted of Validation: tensor([ 61,  61,  61,  10,  10,  46,  46, 129, 129, 129, 129, 129, 129, 129,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  94,  94, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128,  54, 151,  54,  44,  10,  10,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 148, 148, 148, 148, 148,
        148, 148,  73,  73,  73, 166, 166, 166, 166, 166, 166, 131,  49,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 143,  46,  46,  81,
         81,  81,  39,  39,  39, 126, 126, 126,  41,  41,  41,  41,  41,  26,
         26,  26,  26,  26,  26, 162,   9,  15,  15,  15, 164, 102, 102,  48,
        125,  67,  67,  67,  67,  67, 150, 148, 148, 148, 148, 148, 148, 148,
        129, 129, 129, 129, 129, 129, 129,  18, 124,  86,  86,   2,  18,  18,
        162, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        146, 146, 146, 146, 146, 146,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165,  18,  57,   9,  55,  55,   0,   0,   0,   0,   0,   0, 109,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118,  44,  44,  87,  87, 142,  73,  73,  73,
         63,  63,  63,  63,  11, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132],
       device='cuda:0') torch.Size([697])
10/21/2023, 17:35:48# labels of 0: tensor([ 61,  61,  61,  10,  10,  46,  46, 129, 129, 129, 129, 129, 129, 129,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  94,  94, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128,  53, 112, 116,  48,  10,  10,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 148, 148, 148, 148, 148,
        148, 148,  73,  73,  73, 166, 166, 166, 166, 166, 166,  12,  87,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,   4,  46,  46,  59,
         59,  59,  39,  39,  39, 126, 126, 126,  41,  41,  41,  41,  41,  26,
         26,  26,  26,  26,  26,  75, 150,  15,  15,  15,  30, 102, 102,  93,
         93,  78,  78,  78,  78,  78,  54, 148, 148, 148, 148, 148, 148, 148,
        129, 129, 129, 129, 129, 129, 129,  34, 112,  86,  86, 164, 113, 113,
        151, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        146, 146, 146, 146, 146, 146,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165,  90,  90,   4, 144,  24,   0,   0,   0,   0,   0,   0,  74,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 114, 114, 113, 113, 119,  73,  73,  73,
         63,  63,  63,  63, 163, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132],
       device='cuda:0') torch.Size([697])
10/21/2023, 17:35:48# predicted of 0: tensor([ 61,  61,  61,  10,  10,  46,  46, 129, 129, 129, 129, 129, 129, 129,
         85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,  94,  94, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128,  54, 151,  54,  44,  10,  10,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  85, 148, 148, 148, 148, 148,
        148, 148,  73,  73,  73, 166, 166, 166, 166, 166, 166, 131,  49,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,
         65,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70, 143,  46,  46,  81,
         81,  81,  39,  39,  39, 126, 126, 126,  41,  41,  41,  41,  41,  26,
         26,  26,  26,  26,  26, 162,   9,  15,  15,  15, 164, 102, 102,  48,
        125,  67,  67,  67,  67,  67, 150, 148, 148, 148, 148, 148, 148, 148,
        129, 129, 129, 129, 129, 129, 129,  18, 124,  86,  86,   2,  18,  18,
        162, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        146, 146, 146, 146, 146, 146,  28,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134,  65, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  65,  65,  65,
         65,  65,  65,  65,  65,  65,  65,  65,  65,  70,  70,  70,  70,  70,
         70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,  70,
         70,  70,  70,  70, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
        165, 165,  18,  57,   9,  55,  55,   0,   0,   0,   0,   0,   0, 109,
        105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118,  44,  44,  87,  87, 142,  73,  73,  73,
         63,  63,  63,  63,  11, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132],
       device='cuda:0') torch.Size([697])
10/21/2023, 17:35:57# Validation Loss: 0.3029 | Validation Accuracy: 0.9586

10/21/2023, 18:05:26# labels of 50000: tensor([ 74,  54, 112, 109,  74,  60,  18,  74, 143, 143,  54, 143, 150,  47,
         54, 121, 162,  42, 125, 125,   2, 104, 163, 144, 142, 150,   9, 119,
         60,  75,  81, 164, 142,  81,  75, 116,  48,  57, 157, 111, 163,  74,
         33, 112, 112, 163, 152, 104, 124, 150, 121,  30,   4, 111,  44,  44,
         60, 111,  12, 164,  83,  48,  76,  38], device='cuda:0') torch.Size([64])
10/21/2023, 18:05:26# predicted of 50000: tensor([ 74,  54, 112,  34,  74,  60,  31,  74, 143, 143,  54, 143, 150,  47,
         54, 121, 162,  57, 125, 125,   2, 104, 163, 144, 142, 150,  44,  48,
         60, 104,  81, 164,  12,  81,  75, 116,  48,  57, 157,   4, 163,  74,
         97, 112, 112, 163,   9, 104, 124, 150, 121,  30,   4, 143,  44,   1,
         60, 111,  47, 164,  83,  48,  76,  38], device='cuda:0') torch.Size([64])
10/21/2023, 18:33:54# labels of 100000: tensor([ 31,   4, 104,  14,  11,  53,  33, 111,  48,  42,  30,  49, 142,   2,
          9, 104,  34,  75, 151,  74,  83,  83, 158, 150,  49,   9,  42,  31,
         87,  42,  36, 157,  55,  60, 144, 151, 142,  33,  76,  83,  76, 163,
         74,  31,  54,  11,  74, 142,  34,   2,  81, 162,  92, 150,  60,  75,
        151,  75, 163,  47, 152,  12, 119, 116], device='cuda:0') torch.Size([64])
10/21/2023, 18:33:54# predicted of 100000: tensor([ 31,   4, 104,  14,  11,  53,  33, 111,  55,  42,  30,  49, 142,   2,
          9, 104,  34,  75, 151,  74,  83,  83, 158, 150,  49,   9,  42,  31,
        144,  42,  36, 157, 144, 116, 144, 151,   9,  33,  76,  83,  76, 163,
         74,  31, 163, 163,  74, 142,  34,   2,  81, 162, 151, 150, 112,  75,
        151,  75, 163, 111, 152,  12, 119, 116], device='cuda:0') torch.Size([64])
10/21/2023, 19:04:00# labels of 150000: tensor([ 14,  47,  55,  83,  92,   9,  12, 158, 109, 111,  44,  30,  36,  12,
        142, 124, 111,  30,  81,  44,  36,  18, 109,  57,  97,  53,   9,  81,
        125,  57, 163,  44, 164, 158, 111, 119,   2,  92, 124,  33,  36,  81,
          4,  33,  36,  53,  75,  24,   2,  97,  33, 158, 109,  97,  30, 112,
        111,  38,  97,  87,  92, 116,  34,  36], device='cuda:0') torch.Size([64])
10/21/2023, 19:04:00# predicted of 150000: tensor([ 14,  47,  55, 119,  92,   9,  57, 158,  97,  83,  44,  30,  36,  12,
         44, 124,  44,  30, 104,  44,  87,  18, 163,  57,  97,  53,   9,  81,
        125,  57, 163,  44, 164, 158,  24,  18,  48,  92, 125,   4,  36,  81,
          4,  24,  36,  53,  75,  47,   2,  48,  33, 158, 152, 144,  30, 112,
        111,  38, 163,  87,  92, 116,  34,  36], device='cuda:0') torch.Size([64])
10/21/2023, 19:33:46# labels of 200000: tensor([ 31, 112,  34, 144,   2, 104,  44,  49,  54,  18,  34,  30, 112,  31,
         74, 151,  36,  44, 116, 107, 107, 107, 107, 107, 107, 107, 107,  36,
         54, 164, 121,  75,  34, 157, 164,  83,  92,  31, 151,  49,  87,  36,
        124,  47,  76, 162,  76,  49, 163,  48,  12, 163, 144, 112, 144, 163,
         44,   9, 125,   1, 109,  30,  57,  36,  11,  54,  83,  81,  87, 112,
         34], device='cuda:0') torch.Size([71])
10/21/2023, 19:33:46# predicted of 200000: tensor([ 31, 112,  34, 144,   2, 104, 158,  49,  54,  18,  34,  30, 112,  31,
         74, 151, 158,  44, 104, 107, 107, 107, 107, 107, 107, 107, 107,  36,
         54, 164, 121, 142,  34, 157,  44,  83,  92,  31, 151,  49,  60,  48,
        124,  47, 109,  18,  76,  49, 163,  48,  12, 163, 144, 112, 144, 163,
         44,   9, 125,   1, 109,  30,  57,  36,  11,  48,  83,  81,  60, 112,
         34], device='cuda:0') torch.Size([71])
10/21/2023, 19:41:12# total batches: 213400
10/21/2023, 19:41:12# Epoch 12 | Train Loss: 0.5843 | Train Accuracy: 0.8261
10/21/2023, 19:41:12# labels of Validation: tensor([  8,   8,  20,  20, 147,  65, 147, 147, 147, 147, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  86,  86,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 100, 100, 100, 100, 100, 100, 142,
        120, 120, 120, 120, 120, 120, 162,  76,  10,  10,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  12,  76, 104,
         40,  40,  40,  40,  40,  40,  23,  23,  23,  23,  23,  55,  27,  27,
         27, 150, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  18,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  33,  13,  13,  13,  13,  13,  57,   0,
          0,   0,   0,   0,   0,  69,  69,  69,  69,  69,  69,   1,  36,  95,
         95,  95,  64,  64,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  55,  39,  39,  39, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  40,  40,  40,  40,  40,  40,   0,   0,   0,
          0,   0,   0, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140,  27,  27,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,  87,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 143,  96,  96,  96,  96,
         96,  96, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105, 105,  39,  39,  39,  44,  43,
         43,  31,  20,  20, 120, 120, 120, 120, 120, 120, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 159, 159, 159, 159, 159,
        159, 159, 159, 159, 159, 139, 139, 139, 139, 139,  80,  80,  80,  80,
         80,  80,  35,  35,  65,  35,  35,  35,  35, 105, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105,  74], device='cuda:0') torch.Size([849])
10/21/2023, 19:41:12# predicted of Validation: tensor([152, 152,  20,  20, 147,  65, 147, 147, 147, 147, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  86,  86,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 100, 100, 100, 100, 100, 100,  83,
        120, 120, 120, 120, 120, 120, 158,  11,  10,  10,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 116,  57, 119,
         40,  40,  40,  40,  40,  40,  23,  23,  23,  23,  23, 152,  27,  27,
         27,  55, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25, 124,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3, 151,  13,  13,  13,  13,  13, 142,   0,
          0,   0,   0,   0,   0,  69,  69,  69,  69,  69,  69, 150,  57,  95,
         95,  95, 163, 163,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  30,  39,  39,  39, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  40,  40,  40,  40,  40,  40,   0,   0,   0,
          0,   0,   0, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140,  27,  27,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,  38,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 158,  96,  96,  96,  96,
         96,  96, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105, 105,  39,  39,  39,  36,  43,
         43,  47,  20,  20, 120, 120, 120, 120, 120, 120, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 159, 159, 159, 159, 159,
        159, 159, 159, 159, 159, 139, 139, 139, 139, 139,  80,  80,  80,  80,
         80,  80,  35,  35,  65,  35,  35,  35,  35, 105, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105,  47], device='cuda:0') torch.Size([849])
10/21/2023, 19:41:12# labels of 0: tensor([  8,   8,  20,  20, 147,  65, 147, 147, 147, 147, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  86,  86,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 100, 100, 100, 100, 100, 100, 142,
        120, 120, 120, 120, 120, 120, 162,  76,  10,  10,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  12,  76, 104,
         40,  40,  40,  40,  40,  40,  23,  23,  23,  23,  23,  55,  27,  27,
         27, 150, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  18,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,  33,  13,  13,  13,  13,  13,  57,   0,
          0,   0,   0,   0,   0,  69,  69,  69,  69,  69,  69,   1,  36,  95,
         95,  95,  64,  64,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  55,  39,  39,  39, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  40,  40,  40,  40,  40,  40,   0,   0,   0,
          0,   0,   0, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140,  27,  27,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,  87,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 143,  96,  96,  96,  96,
         96,  96, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105, 105,  39,  39,  39,  44,  43,
         43,  31,  20,  20, 120, 120, 120, 120, 120, 120, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 159, 159, 159, 159, 159,
        159, 159, 159, 159, 159, 139, 139, 139, 139, 139,  80,  80,  80,  80,
         80,  80,  35,  35,  65,  35,  35,  35,  35, 105, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105,  74], device='cuda:0') torch.Size([849])
10/21/2023, 19:41:12# predicted of 0: tensor([152, 152,  20,  20, 147,  65, 147, 147, 147, 147, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  86,  86,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 100, 100, 100, 100, 100, 100,  83,
        120, 120, 120, 120, 120, 120, 158,  11,  10,  10,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3, 116,  57, 119,
         40,  40,  40,  40,  40,  40,  23,  23,  23,  23,  23, 152,  27,  27,
         27,  55, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134,  65,  65, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,
         25,  25,  25,  25, 124,   3,   3,   3,   3,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3, 151,  13,  13,  13,  13,  13, 142,   0,
          0,   0,   0,   0,   0,  69,  69,  69,  69,  69,  69, 150,  57,  95,
         95,  95, 163, 163,  85,  85,  85,  85,  85,  85,  85,  85,  85,  85,
         85,  30,  39,  39,  39, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
        134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  65,  65, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132,  40,  40,  40,  40,  40,  40,   0,   0,   0,
          0,   0,   0, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140,  27,  27,  27, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,  38,  21,  21,
         21,  21,  21,  21,  21,  21,  21,  21,  21, 158,  96,  96,  96,  96,
         96,  96, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  65,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,  52,
         52,  52,  52,  52,  52,  52,  52,  52,  52,  52, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105, 105,  39,  39,  39,  36,  43,
         43,  47,  20,  20, 120, 120, 120, 120, 120, 120, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 159, 159, 159, 159, 159,
        159, 159, 159, 159, 159, 139, 139, 139, 139, 139,  80,  80,  80,  80,
         80,  80,  35,  35,  65,  35,  35,  35,  35, 105, 105, 105, 105, 105,
        105, 105, 105, 105, 105, 105, 105, 105,  47], device='cuda:0') torch.Size([849])
10/21/2023, 19:41:22# Validation Loss: 0.3115 | Validation Accuracy: 0.9578

10/21/2023, 20:09:56# labels of 50000: tensor([ 38,  75, 112,  43,  43, 109,  36,  31,  81, 151,  36,  38,  76, 164,
         30,  33, 142,  60,  33,  75,  74,  11, 151,  38, 152,  53, 144, 104,
         81, 157, 125,  97,  87, 164,  60,  38,  49,  30, 157,  55, 116,   1,
         74, 152, 142,  54,  53,  92, 151, 162, 151,   2,  44, 104, 152,  60,
        157, 158,  57,   4,  11,   9, 111,   2,  97], device='cuda:0') torch.Size([65])
10/21/2023, 20:09:56# predicted of 50000: tensor([104,  75, 112,  43,  43, 109,  36,  31,  81, 151,  36,  38,  76, 164,
         30,  33, 142,  60,  33,  75,  18,  11, 151,  38, 152,  53, 144, 104,
         81,  76, 125,  97,  87, 164,  60,  38,  49,  30, 157,  55, 116,   1,
         74, 152, 142,  54,  53,  92, 151, 162, 151,   2,  76, 104, 152, 144,
        111, 104,  33,   4,  11,   9,  97,   2,  97], device='cuda:0') torch.Size([65])
10/21/2023, 20:38:32# labels of 100000: tensor([ 49, 152,  38, 104,  60,   9, 158,  14, 163, 124,  53, 157,  55, 121,
         60,  97, 158, 104,  14,  49,  33, 119,  87, 112,  47,  49,  34, 150,
        158,  55, 152,  60, 150,   2,  75,  14, 116,  74, 152,  38,  12,  75,
        163, 157,  48,  97,   1, 151, 144, 125, 124,   2, 109,  49, 116,   4,
         54, 104,  36,  97,  76,  44,  30, 124], device='cuda:0') torch.Size([64])
10/21/2023, 20:38:32# predicted of 100000: tensor([ 49, 152,  75, 104,  60,   9, 158,  53, 163, 124,  53, 157,  55, 121,
         60,  97, 158, 104, 150,  49,  33, 119,  87, 112,  47,  49,  34, 150,
        158,  55, 152,  60, 150,   2,  75,  14,  14,  74, 152,  44,  12,  75,
        163,  12,  48,  97,   1, 151, 144, 125, 124,   2, 109,  49, 116,   4,
         33, 104, 109,  97,  76,  76,  30, 124], device='cuda:0') torch.Size([64])
10/21/2023, 21:08:23# labels of 150000: tensor([ 38, 143,   1,  38,  36, 111, 111,  36, 111,  83,  24,  42,  11, 157,
         42,  60,  92,  57,  53,  18,  83, 157,  34,  34,  30,  47,  49, 152,
          9,  44, 116, 164, 163,  75, 112,  81,  57,  47,  57,  57,  97,   4,
        109,  83,  42, 158,  53,  36,  42, 125,  54,  36,  57, 112,  75,  14,
        124,  30, 111, 150,  55,   4, 116, 164], device='cuda:0') torch.Size([64])
10/21/2023, 21:08:23# predicted of 150000: tensor([111, 143,   1,  38,  36, 111, 111,  36, 111,  83,  24,  42,  14, 157,
         42,  60,  92,  57,  53,  18,   2, 162,  34,  54,  30,  47,  49, 152,
          9,  44, 116, 164, 163,  75, 112,   1,  57,  47,  57,  57,  12,   4,
        109,  83,  42, 158,  53, 163,  42, 125,  54,  36,  57, 112,  75,  14,
        124,   1, 111, 150,  55,  31, 116, 164], device='cuda:0') torch.Size([64])
10/21/2023, 21:36:51# labels of 200000: tensor([ 55,  18, 125,  31, 104,  36,  30,  48,  75, 121,  97, 144,  75, 143,
          4, 152,   4,  18,  83,  74, 111,  75, 116,  54, 144, 150,  24, 162,
        152,  83,  38,  44,  31, 143,  47,  34,  33, 151, 104, 116,  87,  55,
         34, 119,  18,  31,  83,  76, 162,  47,  60,  57,  24, 111,   4,  76,
        152,  14,  48,  54, 158,  48,  48, 142], device='cuda:0') torch.Size([64])
10/21/2023, 21:36:51# predicted of 200000: tensor([ 55,  38, 125,  31, 104,  36,  30,  48,  75, 121,  97, 144,  75, 143,
          4, 152,   4,  18,  83,  74, 111,  75, 116,  54, 144, 150,  30, 162,
        152,  83,  38,  44,  31, 143,  47,  34,  33, 151, 104, 116,  87,  55,
         34, 119,  81,  31,  83,  76, 162,  47,  60,  57,  24, 111, 152,  76,
        152,  14,  48,  54, 144,  48,  48, 142], device='cuda:0') torch.Size([64])
10/21/2023, 21:44:34# total batches: 213400
10/21/2023, 21:44:34# Epoch 13 | Train Loss: 0.3738 | Train Accuracy: 0.8912
10/21/2023, 21:44:34# labels of Validation: tensor([ 78,  78,  78,  ..., 118,  42,  24], device='cuda:0') torch.Size([2036])
10/21/2023, 21:44:34# predicted of Validation: tensor([ 67,  67,  67,  ..., 118,  97, 164], device='cuda:0') torch.Size([2036])
10/21/2023, 21:44:34# labels of 0: tensor([ 78,  78,  78,  ..., 118,  42,  24], device='cuda:0') torch.Size([2036])
10/21/2023, 21:44:34# predicted of 0: tensor([ 67,  67,  67,  ..., 118,  97, 164], device='cuda:0') torch.Size([2036])
10/21/2023, 21:44:43# Validation Loss: 0.3052 | Validation Accuracy: 0.9578

10/21/2023, 22:14:18# labels of 50000: tensor([121,  75, 125, 143,  34,  60,  34,  83, 121,  11,  57, 121,  42,  47,
         53,   9,   4,  74, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 150,  18,  75,  81,
        116, 121,  11, 144,   2,  54,  36,  42, 164,  87, 104,  55,  57,  60,
         34,  54, 150,  76, 152,  24,  38,  74,  42,  81,  44, 125, 142,  18,
        150, 121,  44,  49, 125,  36,  24,  36,  92,  83, 151,  24,  12],
       device='cuda:0') torch.Size([83])
10/21/2023, 22:14:18# predicted of 50000: tensor([121,  75, 125, 143,  34,  60, 112,  83, 121,  11,  57, 121,  42,  47,
         53,   9,   4,  74, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 150,  57,  75,  81,
         74, 121,  11, 144,   2,  54,  36,  42, 164,  97, 104,  55,  57,  60,
         34,  54, 150,  76,   9,  24,  38,  74,  42,  81,  44, 125, 142,  18,
        150, 121,  18,  49, 125,  36,  24,  36,  92,  83, 151,  24,  12],
       device='cuda:0') torch.Size([83])
10/21/2023, 22:42:32# labels of 100000: tensor([ 87,  74,  92, 164, 163,  57, 151, 150,   1,  53,  31,  57,  31, 112,
         49,  74,  49, 143,  57,  18, 104,  11,  60,  44,  53,  11,  76, 144,
         38, 142,  33,  11, 163,  75,  60,  57,  14, 163,  54,  74, 109, 152,
         57, 152, 151, 164,  74, 104, 124,  97,  30,  97, 157, 151,  97,  55,
         54, 143,   2,  87, 121,  74,  31, 142], device='cuda:0') torch.Size([64])
10/21/2023, 22:42:32# predicted of 100000: tensor([158,  74,  92, 164,  47,  57, 151, 150, 116,  53,  31,  57,  31, 112,
         49,  74,  49, 143,  57,  18, 104,  11,  60,  44,  53,  11,  76, 144,
        121, 142,  33,  11, 163,  75, 151,  57,  14, 163,  54,  74, 109,  57,
         57, 152, 151, 164,  74, 104, 124,  97,  30,  97, 157, 151,  97,  55,
         54, 143,   2,  87, 121, 109,  48, 142], device='cuda:0') torch.Size([64])
10/21/2023, 23:11:09# labels of 150000: tensor([ 53, 162, 119,  74, 144,  30, 121,  81, 116,  48,  48,  76,  74,  83,
        142,  74,  34, 104,  75, 142, 162,  31, 125, 157,   2, 150,  31,  11,
        164,  18,  44,  36,  38, 121,  36, 164, 116,  76,  49, 109,  24,  33,
         30,  42,  14, 163, 119,   2,  18, 152, 164,  54, 162, 152,  75, 151,
         76,  11,  24,  33,  36,  36,   1,   4], device='cuda:0') torch.Size([64])
10/21/2023, 23:11:09# predicted of 150000: tensor([ 53, 162, 119,  74, 144,  30,  24, 143, 116,  48,  48,  76,  74,  83,
        164,  74,  34, 104,  75,  76,   9,  31, 125, 157,   2, 150,  31,  11,
        164,  18,  44,  36,  38, 121,  36, 164, 116,  76,  49, 109,  24,  33,
         92,  42,  14, 144, 119,   2,  18, 152, 164,  54, 162, 152,  75, 151,
         76,  11,  24,  33,  36,  36,   1,   4], device='cuda:0') torch.Size([64])
10/21/2023, 23:41:29# labels of 200000: tensor([109,  49, 157,  33,  60,  83,  30,  33,  34, 109,  44,  18, 104, 119,
         24,  74,  92, 142, 151, 112,  47, 151,  18, 104,  55, 111,  87,  34,
         97,  76, 152,  55, 151, 121, 142, 116,  57,  31,  47,  18, 158, 158,
         92,  24,  31,  30, 151, 109,  60, 143,  11,  49, 109, 152,  57,  60,
        151,  44, 109,  31, 109, 143, 142, 157], device='cuda:0') torch.Size([64])
10/21/2023, 23:41:29# predicted of 200000: tensor([109,  49, 157,  33,  60,  83,  30,  33,  34, 109,  44,  18, 104,  38,
         24, 163,  92, 142, 151, 112,  47, 151,  18, 142,  55, 111,  87,  34,
         97,  76, 152,  55, 151, 121, 142, 116,  57,  31,  47,  18, 158, 158,
         92,  24,  31,  30, 151,  12,  60, 143,  11,  49, 109, 152,  57,  60,
        151,  44, 109,  31, 109, 143, 142,  92], device='cuda:0') torch.Size([64])
10/21/2023, 23:49:21# total batches: 213400
10/21/2023, 23:49:21# Epoch 14 | Train Loss: 0.3620 | Train Accuracy: 0.8948
10/21/2023, 23:49:21# labels of Validation: tensor([100, 100, 100, 100, 100, 100, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115, 155,  65,  65,  65,  65, 155, 155, 155, 125,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  81, 145, 145, 145, 145, 145, 145, 114, 114,  81,  97,
         64,  64,  95,  95,  95, 153, 153, 153,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  66,  66,  66,  66,  66,  66,  66,  66,  66,
         66,  83, 111,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         14,  80,  80,  80,  80,  80,  80, 144, 142,  96,  96,  96,  96,  96,
         96, 136, 136, 136, 136, 136, 136, 136, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        164,  36,  24, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156,  65,  65,  65,  65,  65,  65,  65, 156, 156, 156, 156, 156, 156,
        156, 156,  27,  27,  27, 119,  68,  68,  66,  66,  66,  66,  66,  66,
         66,  66,  66,  66,  81,  36,  13,  13,  13,  13,  13,  54,  95,  95,
         95, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
         47, 164, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,  38,  71,
         71,  71,  71,  71,  71, 124,  51,  65,  65,  65,  51,  51,  51,  51,
         59,  59,  59, 104, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        125,  10,  10,  75,  27,  27,  27,  75,  76,  89,  89,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  83,  69,  69,  69,  69,  69,
         69], device='cuda:0') torch.Size([729])
10/21/2023, 23:49:21# predicted of Validation: tensor([100, 100, 100, 100, 100, 100, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115, 155,  65,  65,  65,  65, 155, 155, 155,   2,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  55, 145, 145, 145, 145, 145, 145,  30,  30,  54,   4,
        109, 124,  95,  95,  95, 153, 153, 153,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  66,  66,  66,  66,  66,  66,  66,  66,  66,
         66, 121, 116,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
        158,  80,  80,  80,  80,  80,  80, 158,   1,  96,  96,  96,  96,  96,
         96, 136, 136, 136, 136, 136, 136, 136, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
         76,  83,  12, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156,  65,  65,  65,  65,  65,  65,  65, 156, 156, 156, 156, 156, 156,
        156, 156,  27,  27,  27,  44,  14,  14,  66,  66,  66,  66,  66,  66,
         66,  66,  66,  66,  53,   9,  13,  13,  13,  13,  13,  14,  95,  95,
         95, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
        112,  36, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 104,  71,
         71,  71,  71,  71,  71,  30,  51,  65,  65,  65,  51,  51,  51,  51,
         81,  81,  81,  18, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
         76,  10,  10, 158,  27,  27,  27,  92,  12,  89,  98,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  24,  69,  69,  69,  69,  69,
         69], device='cuda:0') torch.Size([729])
10/21/2023, 23:49:21# labels of 0: tensor([100, 100, 100, 100, 100, 100, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115, 155,  65,  65,  65,  65, 155, 155, 155, 125,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  81, 145, 145, 145, 145, 145, 145, 114, 114,  81,  97,
         64,  64,  95,  95,  95, 153, 153, 153,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  66,  66,  66,  66,  66,  66,  66,  66,  66,
         66,  83, 111,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         14,  80,  80,  80,  80,  80,  80, 144, 142,  96,  96,  96,  96,  96,
         96, 136, 136, 136, 136, 136, 136, 136, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        164,  36,  24, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156,  65,  65,  65,  65,  65,  65,  65, 156, 156, 156, 156, 156, 156,
        156, 156,  27,  27,  27, 119,  68,  68,  66,  66,  66,  66,  66,  66,
         66,  66,  66,  66,  81,  36,  13,  13,  13,  13,  13,  54,  95,  95,
         95, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
         47, 164, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,  38,  71,
         71,  71,  71,  71,  71, 124,  51,  65,  65,  65,  51,  51,  51,  51,
         59,  59,  59, 104, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        125,  10,  10,  75,  27,  27,  27,  75,  76,  89,  89,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  83,  69,  69,  69,  69,  69,
         69], device='cuda:0') torch.Size([729])
10/21/2023, 23:49:21# predicted of 0: tensor([100, 100, 100, 100, 100, 100, 115, 115, 115, 115, 115, 115, 115, 115,
        115, 115, 155,  65,  65,  65,  65, 155, 155, 155,   2,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,
         17,  17,  17,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,  55, 145, 145, 145, 145, 145, 145,  30,  30,  54,   4,
        109, 124,  95,  95,  95, 153, 153, 153,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  66,  66,  66,  66,  66,  66,  66,  66,  66,
         66, 121, 116,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
        158,  80,  80,  80,  80,  80,  80, 158,   1,  96,  96,  96,  96,  96,
         96, 136, 136, 136, 136, 136, 136, 136, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
         76,  83,  12, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,
        118, 118, 118, 118, 118, 118, 118, 118, 118, 118,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,
         21, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156,  65,  65,  65,  65,  65,  65,  65, 156, 156, 156, 156, 156, 156,
        156, 156,  27,  27,  27,  44,  14,  14,  66,  66,  66,  66,  66,  66,
         66,  66,  66,  66,  53,   9,  13,  13,  13,  13,  13,  14,  95,  95,
         95, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
        112,  36, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 104,  71,
         71,  71,  71,  71,  71,  30,  51,  65,  65,  65,  51,  51,  51,  51,
         81,  81,  81,  18, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
        161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
         76,  10,  10, 158,  27,  27,  27,  92,  12,  89,  98,  85,  85,  85,
         85,  85,  85,  85,  85,  85,  85,  85,  24,  69,  69,  69,  69,  69,
         69], device='cuda:0') torch.Size([729])
10/21/2023, 23:49:30# Validation Loss: 0.3083 | Validation Accuracy: 0.9573

10/22/2023, 00:18:34# labels of 50000: tensor([144,  75, 152,   4,   1,  36, 109,   2,  34, 112,  83,  42,  92,  57,
        162,  92,  53, 151,  48,  38,  87,  81, 163,  14,  18,   9,  60,  18,
         55,  92,  24, 144, 104,  48,   2,   1,   9, 124, 124,  48,  18,  11,
         49,  47, 112,  18,  83,  38,  44,  30,   2,  14,  60,  34, 119, 111,
          1,  97, 112, 121,  36,  12,  60, 143], device='cuda:0') torch.Size([64])
10/22/2023, 00:18:34# predicted of 50000: tensor([144,  75, 152,   4,  48,  36, 109,   2,  34, 112,  83,  55,  92,  57,
        162,  92,  53, 151,  48,  38,  87,  81, 163, 121,  18,   9,  60,  49,
         55,  92,  24, 144, 104,  48,   2,   1,   9, 124, 124,  48,  18,  11,
         49,  47, 112,  18,  83, 143,  60,  30,   2,  14,  60,  34, 119, 111,
          1,  97, 112, 121,  36,  12,  60, 143], device='cuda:0') torch.Size([64])
10/22/2023, 00:49:26# labels of 100000: tensor([163, 143, 116, 119,  83,  14,  30,  33,  97,  76,  44,  97,  54, 112,
         11, 112, 163,  31, 124, 121,  24,  34,  33,  74,  55, 111, 119, 164,
         14,   2,  31, 142,  48,  48,  87,  11,  97,  74, 125,  47,  24, 121,
          1, 125, 121,  76,  31, 112,  12,  14,  55, 163,   9,  54,  34,  83,
         34,  57, 150,  14,  47,  12,  83,  53], device='cuda:0') torch.Size([64])
10/22/2023, 00:49:26# predicted of 100000: tensor([163, 143, 116, 119,  83,  14,  30,  33,  97,  76,  44,  97,  54, 112,
         11, 112,  34,  31, 124, 121, 112,  34,  33,  74,  55, 111, 119, 164,
         14,   9,  31, 142,  48,  30, 158,  11,  97,  74, 125,  47,  24, 121,
          1, 125, 121,  76,  31, 112,  12,  14,  55, 163, 116,  54,  34,  83,
         34,  57, 150,  14,  47,  12,  83,  53], device='cuda:0') torch.Size([64])
10/22/2023, 01:19:56# labels of 150000: tensor([ 36,  49,  38,  24,  11, 112, 112,  36,  12, 151,  31,  38,   9,  60,
         60,  31,  44,   1,  57,  60, 125,  54,  75, 152, 121,  92,  97,  33,
         24,  36, 162,  87,  31, 124,  54,  97, 109,   9,  12,  47,  36,  92,
         38,  44,  76, 151,  74,  97,   4,   9,  44, 162,  76,  34, 125, 151,
        109,  92,   9,   1,  75, 112, 121,  31], device='cuda:0') torch.Size([64])
10/22/2023, 01:19:56# predicted of 150000: tensor([ 97,  49,  38,  24,  11, 112, 112,  36,  12,  34,  31,  38,   9,  60,
         60,  31,  92,   1,  34,  60, 125,  54,  75, 152,  87,  92,  97,  33,
         24,  36, 162,  87,  31, 124,  54,  97, 109,   9,  12,  47,  36, 144,
         38,  44,  76, 151,  74,  97, 112,   9,  44, 162,  76,  34, 125, 151,
        109,  14,   9,   1,  75,  30, 121,  31], device='cuda:0') torch.Size([64])
10/22/2023, 01:48:35# labels of 200000: tensor([125,  83,  60,  87,   9, 144,  42, 164,   2,  74, 112,  76, 124,  57,
         83,  24, 119,  11,   2, 116,   9,  42,  74,  30,  87, 143, 143, 104,
         33, 151,  12,  38, 111, 151,  44,  34,  34,  74,  87, 162,  81,  57,
         12,  74,  57, 163, 163, 109, 157, 143,  75,  87,  48,  75,   4, 164,
         38, 125,  30, 111, 104,  81,  74,  74], device='cuda:0') torch.Size([64])
10/22/2023, 01:48:35# predicted of 200000: tensor([125,  87,  60,  49,   9, 144,  42, 164,   2,  74,  42,  76, 124,  81,
         83,  24, 119,  11,   2, 116,   9,  42,  74,  30,  87, 143,  55, 104,
         33, 151,  12,  38, 111, 151,  31,  34,  34,  74,  87, 162,  81,  57,
         12,  74,  76, 163, 163, 109, 157, 112,  75,  87,  48,  75,   4, 164,
         38, 125,  30, 111, 104,  81,  74, 142], device='cuda:0') torch.Size([64])
10/22/2023, 01:56:14# total batches: 213400
10/22/2023, 01:56:14# Epoch 15 | Train Loss: 0.3754 | Train Accuracy: 0.8902
10/22/2023, 01:56:14# labels of Validation: tensor([160, 160, 160,  ...,  69,  69,   4], device='cuda:0') torch.Size([2155])
10/22/2023, 01:56:14# predicted of Validation: tensor([160, 160, 160,  ...,  69,  69, 124], device='cuda:0') torch.Size([2155])
10/22/2023, 01:56:14# labels of 0: tensor([160, 160, 160,  ...,  69,  69,   4], device='cuda:0') torch.Size([2155])
10/22/2023, 01:56:14# predicted of 0: tensor([160, 160, 160,  ...,  69,  69, 124], device='cuda:0') torch.Size([2155])
10/22/2023, 01:56:23# Validation Loss: 0.3198 | Validation Accuracy: 0.9567

10/22/2023, 02:24:44# labels of 50000: tensor([111,  81,  75,  54,  44,  24, 152, 111,  44, 157,  38,  30, 142, 111,
         53,  74,  18, 112,  44,  38, 104, 125,  42,  92,  55, 122, 122, 122,
        122, 122, 122, 122, 162,  87,  24, 116, 150,  18,  14,  30,  44,  47,
        164, 162,  53, 143,  57, 162,  44,  97,   9,  74,  38,   1,  92,  38,
          1, 144, 163,  14,  53, 163, 151,   2,  57,   9,  33, 152, 144,  30],
       device='cuda:0') torch.Size([70])
10/22/2023, 02:24:44# predicted of 50000: tensor([111,  11,  75,  54,  44,  24, 152, 111,  44, 157,  36,  30, 143, 111,
         76,   4,  18, 112,  44,  38, 104, 125,  42,  92,  55, 122, 122, 122,
        122, 122, 122, 122,  76,  87,  24, 116, 150,  18,  55,  30,  44,  47,
        164, 162,  53,  48,  57,  24,  44,  97,   9,  74,  38,  44,  92,  38,
          1, 144, 163,  14, 125, 163, 151,   2,  57,   9,  33, 152, 157,  30],
       device='cuda:0') torch.Size([70])
10/22/2023, 02:54:53# labels of 100000: tensor([ 74,  44,  76,  42, 121,  38,  55,  49, 143, 152,  48,  18,  30,  92,
        162,   4,  31,  76, 142, 144,  54,  11, 151,  12,   2,  34, 109, 164,
        143, 144,  18, 109,  76, 152,  44,   2, 104,  75,   4, 116, 116, 111,
         34,  24, 109,  75, 119,  81, 162,  75,  75,  81,  55,  14,  34,  48,
         81,  75,   4,  53,  33,  57, 144,  48], device='cuda:0') torch.Size([64])
10/22/2023, 02:54:53# predicted of 100000: tensor([ 74,  44, 158,  42, 121,  38,  55,  49, 143, 152,  48,  18,  30,  42,
          9,   4,  31,  76, 142, 144, 143, 164, 151,  12,   2,  34, 151, 164,
        143, 144,  18,  81,  76, 152,  44,   2, 104,  76,   4, 116, 116, 111,
         34,  24, 109,  75, 119,  81, 162,  75,  83,  81,  11,  14,  34,  48,
         81, 116,   4,  53,  33,   9, 144,  48], device='cuda:0') torch.Size([64])
10/22/2023, 03:25:12# labels of 150000: tensor([ 31,  48,  87, 111,   9, 162,  49, 151, 143, 142,  36,  34, 157, 111,
          4,  97, 163, 111,  34,  42,  31, 121,  75,  81,  31, 158,  11, 119,
        163, 109,  49,  44, 125,  11,  36,  36,  53,  75,  57, 104,  92,  36,
        124,  75, 109, 112,  33,  57, 125,   4,  74, 111, 112, 144,  60, 104,
        112,  97,   4, 125,  60,  60, 143,  36], device='cuda:0') torch.Size([64])
10/22/2023, 03:25:12# predicted of 150000: tensor([ 31,  36,  53, 111,  60,  33,  49, 151,  55, 142,  36,   2, 157, 111,
         24,  97, 163, 111,  34,  42,  31,  34,  75,  76, 143, 158, 142, 119,
        163, 109,  49,  44,  36,  11,  57,  36,  53,  75,  57, 104,  92, 111,
        124,  75, 109, 112,  33,  57, 125,   4,  74, 111,  75, 144, 121,   1,
        112,  97,  44, 125,  60,  60, 143, 112], device='cuda:0') torch.Size([64])
10/22/2023, 03:54:20# labels of 200000: tensor([158,  92,   4,   9, 104,   2, 150,  87,  44,  74,  75,  24,   4,   9,
        163,  11,  60, 151, 150, 121,  76,  36, 158,  34,   9,  54, 104,  75,
         92,  47,  14, 119,  87,  38,  33,  83, 112, 162,  49,  24, 124,  60,
        104, 150,  75, 125,  97,  81,  38, 144,  76, 112,   9, 104, 144,  92,
         38,  44,   4, 124,  33, 112,  12, 112], device='cuda:0') torch.Size([64])
10/22/2023, 03:54:20# predicted of 200000: tensor([158,  92, 116,   9, 104,   2,  49,  87,  44,  74,  75,  24,   4,   9,
        163,  11,  60, 151,  33, 121,  76,  36, 158,  34,   9,  54, 104,  75,
         92,  47,  14, 119,  87,   2,  42,  83, 112, 162,  49,  24,   2,  60,
         74, 150,  75, 125,  97,  18,  38,  49,  76, 112,   9, 158,  42,  92,
         38,  44,   4, 124,  33, 112,  12, 112], device='cuda:0') torch.Size([64])
10/22/2023, 04:01:59# total batches: 213400
10/22/2023, 04:01:59# Epoch 16 | Train Loss: 0.5603 | Train Accuracy: 0.8330
10/22/2023, 04:01:59# labels of Validation: tensor([ 65,  65,  65,  ..., 100, 100,  33], device='cuda:0') torch.Size([1802])
10/22/2023, 04:01:59# predicted of Validation: tensor([ 65,  65,  65,  ..., 100, 100,  57], device='cuda:0') torch.Size([1802])
10/22/2023, 04:01:59# labels of 0: tensor([ 65,  65,  65,  ..., 100, 100,  33], device='cuda:0') torch.Size([1802])
10/22/2023, 04:01:59# predicted of 0: tensor([ 65,  65,  65,  ..., 100, 100,  57], device='cuda:0') torch.Size([1802])
10/22/2023, 04:02:10# Validation Loss: 0.3085 | Validation Accuracy: 0.9579

10/22/2023, 04:33:25# labels of 50000: tensor([  1,   1, 125,   4,  42,  49, 151,  30,  83,  14, 104,   1,  74,  33,
        162,  31, 158, 121,   9, 111,  53,  36,  76,  12,  44,   1,   2,  47,
         24,  81, 125,  54, 124, 158, 151, 119,  81,  38,   1,  53,  87, 119,
        151,  14,  18,  74, 112,  83, 157,  87,   9,   4,  49, 119, 124, 152,
         55,  34,  54, 124,  44,  33, 144,  36], device='cuda:0') torch.Size([64])
10/22/2023, 04:33:25# predicted of 50000: tensor([  1,   1, 125, 116,  42,  49, 151,  30,  83,  14, 104,   1,  74,  33,
        162,  31, 158, 121,   9, 111,  53,  36,  76,  12,  76,   1,   2,  47,
         24,  81, 125,  49, 124, 158, 151, 119,  81,  38,   1,  30,  87, 119,
        151,  60,  18,  74, 112,  83, 157,  87,   9,   4,  49, 119, 124, 152,
         55,  34,  54, 124,  44,  33, 144,  36], device='cuda:0') torch.Size([64])
10/22/2023, 05:02:11# labels of 100000: tensor([ 18, 164,  42, 119,  47, 150,  30, 109, 125, 116, 112,  83,  44,  30,
        116, 152, 162, 124, 116,  36,  24,  31,  34,  31, 162,  76,  14,   2,
        157, 144,  97,  11, 104, 157, 142,  48,  53, 162, 111,  44,  42,  36,
        104, 142, 157,  57, 164,  12, 119, 124,   1,  76,  14, 150,  38,  42,
          9,  30,  11, 152,  83, 151,  48,  55], device='cuda:0') torch.Size([64])
10/22/2023, 05:02:11# predicted of 100000: tensor([ 18, 164,  42, 119,  47, 150,  30, 109, 125, 116, 112,  83,  44,  30,
        116, 152, 162, 124, 116,  36,  24,  31,  34,  11, 162,  76,  60,   2,
        157, 144,  97,  11,  87, 157, 142,  48,  53, 162, 111,  44,  42,  36,
        104, 142, 157,  57, 164,  12, 119, 124,   1,  76,  14, 150,  38,  42,
          9,  30, 164, 152,  83, 151,  48,  55], device='cuda:0') torch.Size([64])
10/22/2023, 05:32:28# labels of 150000: tensor([158,  60,  48,   1, 111, 121, 112,  75,  75,  34,  33,  54, 119, 124,
         33, 109,  49,  54, 151, 119,  34,  14, 124,  74, 111, 158,  87,  31,
        150, 125,   1,  47,  44, 158,  49, 158, 150,  34,  18,  18, 121, 164,
        151,  76, 162,  83,  18,   1, 143, 151, 162, 142,  57,  87,  83,   1,
         18,   4, 111,  54,  54,  30, 121,  42], device='cuda:0') torch.Size([64])
10/22/2023, 05:32:28# predicted of 150000: tensor([158,  60, 124,   1, 111, 121, 112,  75,  75,  34,  33,  54, 119,  47,
         33, 109,  49,  54, 151, 119,  34,  14, 124,  74, 111, 158,  87,  31,
        150, 125,   1,  47,  47, 158,  49,  54, 150,  34,  18,  18, 121, 164,
        151,  76, 162,  83,  18,   1, 143, 151,  14, 142,  57,  87,  83,  92,
         18,   4, 111,  54,  54,  30, 121,  42], device='cuda:0') torch.Size([64])
10/22/2023, 06:01:08# labels of 200000: tensor([ 34, 116,  38,  44, 164,  30,   9, 152,  11,  81,  49, 111, 143,  38,
         42, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        152,  83, 151,  47,  76, 111,  44, 150,   2,  14,  30, 151, 116, 124,
         55,  55,  12,   9,  47,  24,  33,  48,  44,   4, 109,  92,  75, 109,
         47,  54, 164,  57, 121, 124,  38,  30,  30, 158, 144,  75,  12,  76,
        151,  55,   4,  38,  54,  38], device='cuda:0') torch.Size([76])
10/22/2023, 06:01:08# predicted of 200000: tensor([ 57, 116,  38, 104, 119,  30, 125, 152,  11,  81,  49, 111, 143,  38,
         42, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        152,  83, 151,  47,  76, 111,  44,  31,   2,  14,  30, 151,  44, 124,
         55,  53,  12,   9,  47,  24,  33,  48,  44,   4, 109,  92,  75, 109,
         47,  54, 164,  57,   4, 124,  38,  30,  30, 158, 144,  75,  12,  76,
        151,  55,   4,  38,  54,  38], device='cuda:0') torch.Size([76])
10/22/2023, 06:08:39# total batches: 213400
10/22/2023, 06:08:39# Epoch 17 | Train Loss: 0.3581 | Train Accuracy: 0.8957
10/22/2023, 06:08:39# labels of Validation: tensor([ 11, 148, 148, 148, 148, 148, 148, 148,  75, 133, 133, 133, 133, 133,
        133, 133, 133,  87, 139, 139, 139, 139, 139, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127,  50,  50,  50,  12, 110, 110,  24,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  91,  91,  91,  83,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  36,  91,  91,  91,
         47,  78,  78,  78,  78,  78,   1, 162, 155,  65,  65,  65,  65, 155,
        155, 155,  60,  54,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,   8,   8, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65, 156, 156,
        156, 156, 156, 156, 156, 156,  40,  40,  40,  40,  40,  40,  80,  80,
         80,  80,  80,  80, 100, 100, 100, 100, 100, 100,  53,  23,  23,  23,
         23,  23,   8,   8,   1,  56,  56,  56,  56,  56,  56,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  73,  73,
         73,  18,  68,  68,  77,  77,  77,  77,  77,  77,  77,  77,  18, 150,
         83, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  38,  37,  37,  37,  37,  37, 126, 126, 126,  75,  93,
         93,  31,  14,  56,  56,  56,  56,  56,  56, 146, 146, 146, 146, 146,
        146, 162, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  80,  80,
         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  63,  63,  63,  63,
         78,  78,  78,  78,  78,  13,  13,  13,  13,  13], device='cuda:0') torch.Size([500])
10/22/2023, 06:08:39# predicted of Validation: tensor([  9, 148, 148, 148, 148, 148, 148, 148,  60, 133, 133, 133, 133, 133,
        133, 133, 133,  48, 139, 139, 139, 139, 139, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127,  50,  50,  50, 162, 162,  38,  76,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  44,  44,  44,  18,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  76, 143, 143, 143,
        158,  67,  67,  67,  67,  67,  76,  53, 155,  65,  65,  65,  65, 155,
        155, 155,  34,  44,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  24,  24, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65, 156, 156,
        156, 156, 156, 156, 156, 156,  40,  40,  40,  40,  40,  40,  80,  80,
         80,  80,  80,  80, 100, 100, 100, 100, 100, 100, 124,  23,  23,  23,
         23,  23,  14,  14,  18,  56,  56,  56,  56,  56,  56,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  73,  73,
         73,  81, 111,  11,  77,  77,  77,  77,  77,  77,  77,  77,  33,  14,
         55, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  38,  37,  37,  37,  37,  37, 126, 126, 126, 143,  14,
         14,  33, 142,  56,  56,  56,  56,  56,  56, 146, 146, 146, 146, 146,
        146,  76, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  80,  80,
         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  63,  63,  63,  63,
         67,  67,  67,  67,  67,  13,  13,  13,  13,  13], device='cuda:0') torch.Size([500])
10/22/2023, 06:08:39# labels of 0: tensor([ 11, 148, 148, 148, 148, 148, 148, 148,  75, 133, 133, 133, 133, 133,
        133, 133, 133,  87, 139, 139, 139, 139, 139, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127,  50,  50,  50,  12, 110, 110,  24,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  91,  91,  91,  83,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  36,  91,  91,  91,
         47,  78,  78,  78,  78,  78,   1, 162, 155,  65,  65,  65,  65, 155,
        155, 155,  60,  54,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,   8,   8, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65, 156, 156,
        156, 156, 156, 156, 156, 156,  40,  40,  40,  40,  40,  40,  80,  80,
         80,  80,  80,  80, 100, 100, 100, 100, 100, 100,  53,  23,  23,  23,
         23,  23,   8,   8,   1,  56,  56,  56,  56,  56,  56,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  73,  73,
         73,  18,  68,  68,  77,  77,  77,  77,  77,  77,  77,  77,  18, 150,
         83, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  38,  37,  37,  37,  37,  37, 126, 126, 126,  75,  93,
         93,  31,  14,  56,  56,  56,  56,  56,  56, 146, 146, 146, 146, 146,
        146, 162, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  80,  80,
         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  63,  63,  63,  63,
         78,  78,  78,  78,  78,  13,  13,  13,  13,  13], device='cuda:0') torch.Size([500])
10/22/2023, 06:08:39# predicted of 0: tensor([  9, 148, 148, 148, 148, 148, 148, 148,  60, 133, 133, 133, 133, 133,
        133, 133, 133,  48, 139, 139, 139, 139, 139, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127,  50,  50,  50, 162, 162,  38,  76,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,  44,  44,  44,  18,   3,   3,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  76, 143, 143, 143,
        158,  67,  67,  67,  67,  67,  76,  53, 155,  65,  65,  65,  65, 155,
        155, 155,  34,  44,  39,  39,  39,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,
          7,   7,   7,   7, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
         65,  65,  65,  65,  65,  65,  65,  65, 141, 141, 141, 141, 141, 141,
        141, 141, 141, 141,  24,  24, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
        156, 156, 156, 156, 156, 156,  65,  65,  65,  65,  65,  65, 156, 156,
        156, 156, 156, 156, 156, 156,  40,  40,  40,  40,  40,  40,  80,  80,
         80,  80,  80,  80, 100, 100, 100, 100, 100, 100, 124,  23,  23,  23,
         23,  23,  14,  14,  18,  56,  56,  56,  56,  56,  56,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  73,  73,
         73,  81, 111,  11,  77,  77,  77,  77,  77,  77,  77,  77,  33,  14,
         55, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
        101, 101, 101,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  82,  82,  82,  82,  65,  82,  82,  82,  82,  82,  82,
         82,  82,  82,  38,  37,  37,  37,  37,  37, 126, 126, 126, 143,  14,
         14,  33, 142,  56,  56,  56,  56,  56,  56, 146, 146, 146, 146, 146,
        146,  76, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,  80,  80,
         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  63,  63,  63,  63,
         67,  67,  67,  67,  67,  13,  13,  13,  13,  13], device='cuda:0') torch.Size([500])
10/22/2023, 06:08:49# Validation Loss: 0.3169 | Validation Accuracy: 0.9569

10/22/2023, 06:39:15# labels of 50000: tensor([ 55,  57, 121,  76,  92,  18, 164, 143, 143,   4,  54, 125,  97,  76,
        104,  36,   4, 112,  81,  33,  31, 142,  48,  18,  34,  97,  31,  55,
          1, 144,  54, 157, 142,  36, 144,  24,  11,  31, 125,  30, 111,  30,
         87,  42,  60,  36, 112,  47,  12,  38,  36, 116, 142, 116,  44,   9,
         53, 112,  54, 121, 143,  81,  11,  74], device='cuda:0') torch.Size([64])
10/22/2023, 06:39:15# predicted of 50000: tensor([ 55,  57, 121,  76,  92,  18, 164, 143, 143,   4,  54, 125,  97,  42,
         47,  36,   4, 112,  53,  48, 143, 111, 163,  18,  34,  97,  31,  55,
          1, 144,  54, 157, 142,  36,  36,  24,  11,  31, 125,  30, 111,  30,
         87,  42,  60,  36, 112,  47,  12,  38,  36, 116, 142, 116,  44,   9,
         53, 112,  54, 121, 143,  81,  11,  74], device='cuda:0') torch.Size([64])
10/22/2023, 07:07:51# labels of 100000: tensor([ 87, 109, 144,  74,  36, 119,  14, 104, 162, 163, 116,  24,  97,   2,
        116,   4, 150,  47,  48,  87,  36, 112, 111,  53,  60, 111,  53, 116,
         57,  12, 109, 109,  11,  76,  83,  33,  75, 119,  31, 109, 116, 163,
         34,  87,  87, 158, 111, 150,  44, 119,  42, 163,  47,  92, 164, 164,
         30,  30,  48, 152, 124,  48, 158,   4], device='cuda:0') torch.Size([64])
10/22/2023, 07:07:51# predicted of 100000: tensor([ 87, 109, 144,  74,  36,  33,  14, 104,  54, 163, 116,  24,  97,  18,
        116,   4, 150,  47,  48,  87,  36, 112, 111,  53,  60, 111,  53, 116,
         57,  18, 109, 109,  11,  76,  83,  33,  75, 158,  31, 125, 116, 163,
         34,  87,  87, 158, 111, 150,  44, 144,  42, 163,  47,  92, 164, 164,
        158,  30, 111, 152, 124,  48, 158,   4], device='cuda:0') torch.Size([64])
10/22/2023, 07:38:51# labels of 150000: tensor([164,  53, 121,   9,  33,  55,  76, 116, 163, 125,   9,   2,  38, 116,
        125,  49, 152,  75,  38,  31,  74, 142,   4, 158, 112,  92,   2,  11,
        104,  24,  83, 157,   4,  38, 164,  49, 125,  92, 112,  36,  36, 104,
         48,  31,   4,  54,  47,  24,  18, 104, 109, 158,  33,  47, 121,  42,
        116, 143,  83,  97,   9, 164,  12, 151], device='cuda:0') torch.Size([64])
10/22/2023, 07:38:51# predicted of 150000: tensor([164,  53, 121,   9,  33,  55,  49, 116, 163, 125,   9,   2,  38, 116,
        125,  12, 152,  75,  38, 142,  74, 142,   4, 158,  36,  92,   2,  11,
        104,  24,  83, 157,   4,  38, 164,  49, 125,  92, 112,  36,  36, 104,
         48,  31,   4,  54,  47,  24,  18, 104, 109, 158,  33,  47, 121,  42,
        116, 143,  83,  97,   9, 164,  24, 151], device='cuda:0') torch.Size([64])
10/22/2023, 08:07:42# labels of 200000: tensor([  9, 116,  38, 150, 124, 143,  83, 144, 111,  87, 121,  30,  12,  18,
        109, 142, 119,  49,   2, 142,  55, 116,  38,  36, 164,  48,  49,  57,
         47,  92,  31,  24, 164, 163,  53,  30, 116,  53,  57,  18,  30,  57,
        163,  30,  57, 163, 121,  31,  33,  31,  49, 158, 142,  47,  30,  42,
         30, 151,  11,  74,  34,  83,  18,  75], device='cuda:0') torch.Size([64])
10/22/2023, 08:07:42# predicted of 200000: tensor([  9, 116,  38, 150, 124, 143,  83, 144, 111,  87, 121,  30,  12,  18,
        109, 142, 119,  49,   2, 142,  55, 116,  57,  36, 164, 162,  49,  57,
         47,  92,  31,  74, 164, 163,  53, 152, 116,  24, 125,  18,  30,  57,
        163,  30,  53, 163, 121,  31,  33,  31,  53, 158, 142,  47,  30,  42,
         30, 151,  11,  74,  34,  83,  18,  75], device='cuda:0') torch.Size([64])
10/22/2023, 08:15:13# total batches: 213400
10/22/2023, 08:15:13# Epoch 18 | Train Loss: 0.3489 | Train Accuracy: 0.8983
10/22/2023, 08:15:13# labels of Validation: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  73,  73,  73, 158,  40,  40,  40,  40,  40,  40,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  36, 119, 146, 146, 146, 146, 146, 146,  69,  69,  69,
         69,  69,  69, 166, 166, 166, 166, 166, 166, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  10,  10,  93,
         93, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
         35,  35,  35,  35,  35,  35, 102, 102, 164,  37,  37,  37,  37,  37,
         59,  59,  59,  26,  26,  26,  26,  26,  26, 110, 110,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  15,  15,
         15,  33, 100, 100, 100, 100, 100, 100,  65, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  75,  65,  46,  46,
         36,   4, 133, 133, 133, 133, 133, 133, 133, 133, 126, 126, 126, 129,
        129, 129, 129, 129, 129, 129,  26,  26,  26,  26,  26,  26, 129, 129,
        129, 129, 129, 129, 129,  18,  86,  86, 151, 146, 146, 146, 146, 146,
        146, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 104, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  18,  56,  56,
         56,  56,  56,  56,  27,  27,  27,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  71,  71,  71,  71,  71,  71,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  28,  47,  14, 166, 166, 166, 166, 166, 166,  86,
         86,   8,   8,  51,  65,  65,  51,  51,  51,  51,  40,  40,  40,  40,
         40,  40,  87,  93,  93,  10,  10,  60,  31,  93,  93, 157,   4, 160,
        160, 160, 160, 160, 160, 160, 160], device='cuda:0') torch.Size([539])
10/22/2023, 08:15:13# predicted of Validation: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  73,  73,  73,  24,  40,  40,  40,  40,  40,  40,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16, 144, 162, 146, 146, 146, 146, 146, 146,  69,  69,  69,
         69,  69,  69, 166, 166, 166, 166, 166, 166, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  10,  10,  54,
        157, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
         35,  35,  35,  35,  35,  35, 102, 102,  57,  37,  37,  37,  37,  37,
        108, 108, 131,  26,  26,  26,  26,  26,  26,  60,  60,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  15,  15,
         15,  76, 100, 100, 100, 100, 100, 100,  65, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  49,  65,  46,  46,
         74,  24, 133, 133, 133, 133, 133, 133, 133, 133, 126, 126, 126, 129,
        129, 129, 129, 129, 129, 129,  26,  26,  26,  26,  26,  26, 129, 129,
        129, 129, 129, 129, 129,  83,  86,  86, 151, 146, 146, 146, 146, 146,
        146, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132,  76, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 151,  56,  56,
         56,  56,  56,  56,  27,  27,  27,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  71,  71,  71,  71,  71,  71,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  28, 164, 104, 166, 166, 166, 166, 166, 166,  86,
         86,  74,  74,  51,  65,  65,  51,  51,  51,  51,  40,  40,  40,  40,
         40,  40, 111,  33,  33,  10,  10, 111,  42,  14, 109,   9,  12, 160,
        160, 160, 160, 160, 160, 160, 160], device='cuda:0') torch.Size([539])
10/22/2023, 08:15:13# labels of 0: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  73,  73,  73, 158,  40,  40,  40,  40,  40,  40,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16,  36, 119, 146, 146, 146, 146, 146, 146,  69,  69,  69,
         69,  69,  69, 166, 166, 166, 166, 166, 166, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  10,  10,  93,
         93, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
         35,  35,  35,  35,  35,  35, 102, 102, 164,  37,  37,  37,  37,  37,
         59,  59,  59,  26,  26,  26,  26,  26,  26, 110, 110,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  15,  15,
         15,  33, 100, 100, 100, 100, 100, 100,  65, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  75,  65,  46,  46,
         36,   4, 133, 133, 133, 133, 133, 133, 133, 133, 126, 126, 126, 129,
        129, 129, 129, 129, 129, 129,  26,  26,  26,  26,  26,  26, 129, 129,
        129, 129, 129, 129, 129,  18,  86,  86, 151, 146, 146, 146, 146, 146,
        146, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 104, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  18,  56,  56,
         56,  56,  56,  56,  27,  27,  27,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  71,  71,  71,  71,  71,  71,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  28,  47,  14, 166, 166, 166, 166, 166, 166,  86,
         86,   8,   8,  51,  65,  65,  51,  51,  51,  51,  40,  40,  40,  40,
         40,  40,  87,  93,  93,  10,  10,  60,  31,  93,  93, 157,   4, 160,
        160, 160, 160, 160, 160, 160, 160], device='cuda:0') torch.Size([539])
10/22/2023, 08:15:13# predicted of 0: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  73,  73,  73,  24,  40,  40,  40,  40,  40,  40,  16,  16,  16,
         16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,
         16,  16,  16, 144, 162, 146, 146, 146, 146, 146, 146,  69,  69,  69,
         69,  69,  69, 166, 166, 166, 166, 166, 166, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,  10,  10,  54,
        157, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
         35,  35,  35,  35,  35,  35, 102, 102,  57,  37,  37,  37,  37,  37,
        108, 108, 131,  26,  26,  26,  26,  26,  26,  60,  60,   3,   3,   3,
          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,  15,  15,
         15,  76, 100, 100, 100, 100, 100, 100,  65, 123, 123, 123, 123, 123,
        123, 123, 123, 123, 123, 123, 123, 123, 123, 123,  49,  65,  46,  46,
         74,  24, 133, 133, 133, 133, 133, 133, 133, 133, 126, 126, 126, 129,
        129, 129, 129, 129, 129, 129,  26,  26,  26,  26,  26,  26, 129, 129,
        129, 129, 129, 129, 129,  83,  86,  86, 151, 146, 146, 146, 146, 146,
        146, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132,  65, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
        132, 132, 132, 132, 132, 132, 132, 132,  76, 101, 101, 101, 101, 101,
        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 151,  56,  56,
         56,  56,  56,  56,  27,  27,  27,  99,  99,  99,  99,  99,  99,  99,
         99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
         99,  71,  71,  71,  71,  71,  71,  28,  28,  28,  28,  28,  28,  28,
         28,  28,  28,  28,  28, 164, 104, 166, 166, 166, 166, 166, 166,  86,
         86,  74,  74,  51,  65,  65,  51,  51,  51,  51,  40,  40,  40,  40,
         40,  40, 111,  33,  33,  10,  10, 111,  42,  14, 109,   9,  12, 160,
        160, 160, 160, 160, 160, 160, 160], device='cuda:0') torch.Size([539])
10/22/2023, 08:15:22# Validation Loss: 0.3118 | Validation Accuracy: 0.9580

10/22/2023, 08:46:37# labels of 50000: tensor([164, 162, 112,  36, 157, 109,  48,  97,  31,  76,  18,  36,  24, 162,
        112,  30, 163,  47,  38, 116, 104,   9,  54, 116, 111, 125,   2,  55,
        119,  60,  74, 112, 116, 124, 157, 125,   2,  30,  60,  33,  18,  18,
        162,  34,  31,  53,  48, 109,  74, 150,  11,  76, 119, 163,  24, 152,
         48, 119,  31,   1, 164, 144, 157, 111], device='cuda:0') torch.Size([64])
10/22/2023, 08:46:37# predicted of 50000: tensor([164, 162, 121,  36,  60, 109,  48,  97,  31,  76,  18,  81,  24, 162,
        112,  30, 163,  47,  38, 116, 104,   9,  54, 116, 111, 125,   2,  55,
        119,  60,  74, 112, 116, 124, 157, 125,   2,  30,   1, 158,  18,  18,
        162,  34,  81,  53,  48, 109,  74, 150,  11,  76, 119, 163,  24, 152,
        150, 119,  31,   1, 164, 144, 157, 111], device='cuda:0') torch.Size([64])
10/22/2023, 09:16:22# labels of 100000: tensor([116,  11,  48, 124,  44,  92, 162, 109, 150,  36, 121,  97, 124, 164,
         50,  50,  50,  74, 116,  44, 157, 121,  49, 104,  44, 112, 121, 162,
        164, 109,  14,  83, 121, 163, 142,  49,  60,  24,   2,  97,  33,   4,
        124,  87, 143,  53, 124,  74,  87,  47,  47,  57,  34,  34,  87, 157,
         57,  92, 116,  31, 164,  92,  14,  11,  44,  48], device='cuda:0') torch.Size([66])
10/22/2023, 09:16:22# predicted of 100000: tensor([116,  11,  48, 124,  44,  92, 116, 109, 150,  36, 121,  97, 124, 164,
         50,  50,  50,  74, 116,  44, 157, 121,  49, 104,  44, 112, 121, 162,
         30, 109,  14,  18, 124, 163, 142,  49,  60,  24,   2,  97,  33,  44,
        124,  87, 143,  53, 124,  44,  87,  47,  47,  57,  34,  34,  87, 157,
        163,  92, 116,  31, 164,  92,  14,  11,  44,  48], device='cuda:0') torch.Size([66])
10/22/2023, 09:47:16# labels of 150000: tensor([  2,   9, 152,  18,  92, 116, 158,  14, 157, 142,   1, 124,  92,  48,
         49,  92,  18,  14, 124,  44, 144, 143, 144,  44,  76,  92,  44, 109,
        144, 150,  11, 125,  38, 164, 163, 121,  34,  11,  54, 125,  38,  54,
          9,  87,  12,  49, 162, 143,  54,  87, 125,  14,  42,   4,   1,  76,
        124,  76, 152, 144,  48,  55, 152, 152], device='cuda:0') torch.Size([64])
10/22/2023, 09:47:16# predicted of 150000: tensor([  2,   9, 152,  18,  55,  53, 158,  14, 157, 142,   1,  42,  92,  48,
         49,  92,  18,  14, 119,  42, 144, 143, 119,  44,  76,  92,  18, 109,
        144, 150,  11, 125,  38, 164, 163, 121, 143,  11,  54, 125,  38,  54,
          9,  87,  12,  49, 162, 143,  54,  87, 125,  97,  42,   4,   1,  76,
        124,  76, 152, 144,  48,  55, 152, 152], device='cuda:0') torch.Size([64])
10/22/2023, 10:16:04# labels of 200000: tensor([162, 112, 116,  48, 162,   4,  38,  74, 158, 119, 144, 112,  54,   9,
        111,  47, 144,  44,  24, 163, 164, 152, 124,  60,  47,  44,  75, 163,
        116, 158,  60,  34,  49,  48,  74,  74, 162,   4,  48,   4, 151, 150,
         14,   9, 111, 162,  30, 158,  48,  48, 163,  24, 151, 157,  44, 162,
         89,  89,  48,  36,  76,  54, 104,   2,  48], device='cuda:0') torch.Size([65])
10/22/2023, 10:16:04# predicted of 200000: tensor([162, 112, 116,  48, 162, 125,  33,  75, 158, 119, 144, 112,  92,   9,
        111,  47, 144,  44,  31, 163, 164, 152, 124,  60,  47,  44,  75,   2,
        116, 125,  60,  34,  49,  48,  74,  74, 162,   4,  48,   4, 151, 150,
         14,   9, 111, 162,  30, 158,  48,  18, 163,  24, 151, 157,  44, 162,
         89,  98,  48,  36,  76,  54, 104,   2,  48], device='cuda:0') torch.Size([65])
10/22/2023, 10:23:58# total batches: 213400
10/22/2023, 10:23:58# Epoch 19 | Train Loss: 0.3612 | Train Accuracy: 0.8944
10/22/2023, 10:23:58# labels of Validation: tensor([  9,  82,  82,  ..., 117, 117, 117], device='cuda:0') torch.Size([1271])
10/22/2023, 10:23:58# predicted of Validation: tensor([ 14,  82,  82,  ..., 117, 117, 117], device='cuda:0') torch.Size([1271])
10/22/2023, 10:23:58# labels of 0: tensor([  9,  82,  82,  ..., 117, 117, 117], device='cuda:0') torch.Size([1271])
10/22/2023, 10:23:58# predicted of 0: tensor([ 14,  82,  82,  ..., 117, 117, 117], device='cuda:0') torch.Size([1271])
10/22/2023, 10:24:08# Validation Loss: 0.3022 | Validation Accuracy: 0.9592

10/22/2023, 12:23:34# Train Classification Report at Epoch 19:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00     51200
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00      4800
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00      4000
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00     12000
    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.99      0.99      0.99    256000
    T1003.003_f049b89533298c2d6cd37a940248b219       0.99      1.00      0.99    256000
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00      4800
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00      4800
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.96      0.96      0.96    256000
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.00      0.00      0.00      2400
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.99      1.00      0.99    256000
        T1016_71b3d2945679566b9d94d8cb11df4b70       1.00      1.00      1.00    256000
        T1016_7d8ee68f0e9731db82964f558f614608       0.61      0.34      0.44      4000
    T1016_921055f4-5970-4707-909e-62f594234d91       0.99      1.00      1.00    256000
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       1.00      1.00      1.00    256000
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.99      1.00      1.00    256000
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       1.00      0.99      0.99    256000
        T1018_a44bb43474728496276d5d73aa14588f       1.00      0.99      0.99    256000
        T1018_ac20e592bc912bddff4d6b88289095f0       1.00      1.00      1.00    256000
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00      4800
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.99      1.00      0.99    256000
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.93      0.96      0.95    256000
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      0.99      1.00     18400
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00     21600
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00      1600
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00      1600
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00      5600
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00      4000
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.99      1.00      1.00    256000
        T1047_6935e41353aa781bb723462d26114c44       0.99      0.99      0.99    256000
        T1047_ac122553ab4426ea3362bb4a97d31bfd       1.00      0.99      1.00    256000
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.99      1.00      0.99    256000
        T1047_b0255b5120cbabc062d8d4510a142c3b       1.00      0.99      0.99    256000
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       1.00      1.00      1.00    256000
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.99      0.99      0.99    256000
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.99      0.99      0.99    256000
        T1049_a14392d713dffba6a397682ff83259a0       0.00      0.00      0.00      2400
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00      1600
    T1053.005_ee454be9197890de62705ce6255933fd       0.98      1.00      0.99    256000
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       1.00      0.99      1.00    256000
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       1.00      1.00      1.00    256000
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.95      0.94      0.95    256000
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00      5600
        T1057_b2a1e430ca6d36eb5af2fe666e769847       1.00      0.99      1.00    256000
        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.99      0.99      0.99    256000
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      8000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00     12000
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00      4000
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      1.00      1.00      8000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00      4000
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00    109600
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00      5600
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00      4800
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00      7200
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00      1600
    T1069.002_6103e503cb444bc7b4187704f2035708       0.42      0.05      0.08      3200
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00      4800
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00     16000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      8000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00      2400
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00      6400
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.99      0.98      0.99    256000
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.97      0.94      0.95    256000
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      9600
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.95      0.96      0.95    256000
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00      4000
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.94      0.95      0.95    256000
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.96      0.46      0.62      1600
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      8800
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.99      1.00      1600
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00      6400
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00     16800
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00     16000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00     10400
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00     45600
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00    120000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00      2400
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00      2400
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00      2400
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00      2400
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       1.00      1.00      1.00      2400
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00      2400
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00      2400
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00      1600
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00      2400
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00     14400
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00      2400
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00      2400
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00      4000
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00     12800
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.96      0.94      0.95    256000
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00     15200
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00     16000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00      4800
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00      4800
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.96      0.93      0.95    256000
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00      4800
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.95      0.97      0.96    256000
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.99      1.00      0.99    256000
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00      4800
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00     10400
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.99      0.99      0.99    256000
        T1201_57296a2ddbeb7423c05feef2fe972111       1.00      1.00      1.00    256000
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      8000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00      3200
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.99      0.99      0.99    256000
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00     53600
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     83200
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00     40000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00      4000
        T1482_cfb61005899996469ae3023796792ca5       1.00      1.00      1.00    256000
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00      3200
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.99      0.99      0.99    256000
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00      1600
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       1.00      0.98      0.99    256000
        T1490_c156ac5c9fa67080365268d95f29053d       0.99      0.99      0.99    256000
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      8000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.94      0.98      0.96    256000
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00      4000
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00      5600
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00     65600
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.96      0.95      0.96    256000
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.95      0.96      0.95    256000
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.94      0.97      0.95    256000
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       1.00      1.00      1.00    256000
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.99      0.99      0.99    256000
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00      1600
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.96      0.97      0.96    256000
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00      1600
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       800
        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00      1600
        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00      1600
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00     12000
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00      5600
    T1547.001_163b023f43aba758d36f524d146cb8ea       1.00      1.00      1.00      4000
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00      4800
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00      1600
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00      1600
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00      4000
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00      1600
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00      1600
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      8000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00      6400
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00      4800
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00     17600
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00      1600
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00      1600
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00    172800
    T1562.001_43e3334362b140924f001b256b229ee5       0.99      1.00      0.99      1600
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      1.00      1.00      4800
    T1562.002_94f51bf01a7036fe02d07b4c18967669       1.00      1.00      1.00    256000
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00      1600
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      8800
    T1562.004_5b93df032e230056c21a3e57334f77d1       0.99      1.00      1.00    256000
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.99      1.00      0.99    256000
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00      2400
    T1564.001_66a5fd5f244819181f074dd082a28905       0.50      0.20      0.29      4000
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.80      0.62      4000
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.88      0.09      0.16      1600
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00      4800
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00     12800
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.99      1.00      1.00    256000
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00      6400
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00     49600
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00      4800
                                        benign       1.00      1.00      1.00   1077033

                                      accuracy                           0.98  16008233
                                     macro avg       0.91      0.90      0.90  16008233
                                  weighted avg       0.98      0.98      0.98  16008233

10/22/2023, 12:23:36# labels of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:36# predicted of Test: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:36# labels of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:36# predicted of 0: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:36# labels: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:36# predicted: tensor([65, 65, 65,  ..., 70, 70, 70], device='cuda:0') torch.Size([2718])
10/22/2023, 12:23:47# Test Accuracy: 96.99222917331426 %



10/22/2023, 12:24:16# report path: classification_report/classification_report-transE_50-graphSAGE-4.xlsx
10/22/2023, 12:24:16# label path: classification_report/mapped_true_predicted_labels-transE_50-graphSAGE-4.xlsx
10/22/2023, 12:24:28# mapped_report:
                                                precision    recall  f1-score   support

T1003.001_0ef4cc7b-611c-4237-b20b-db36b6906554       1.00      1.00      1.00      6400
    T1003.001_35d92515122effdd73801c6ac3021da7       1.00      1.00      1.00       600
    T1003.002_5a484b65c247675e3b7ada4ba648d376       1.00      1.00      1.00       500
    T1003.002_7fa4ea18694f2552547b65e23952cabb       1.00      1.00      1.00      1500
    T1003.003_9f73269695e54311dd61dc68940fb3e1       0.01      0.01      0.01       100
    T1003.003_f049b89533298c2d6cd37a940248b219       0.01      0.04      0.02       100
        T1003_18f31c311ac208802e88ab8d5af8603e       1.00      1.00      1.00       600
        T1007_9d03c91bdae5a80f17f89c987942b5a8       1.00      1.00      1.00       600
    T1007_c6607391-d02c-44b5-9b13-d3492ca58599       0.01      0.01      0.01       100
        T1007_d6bb2a19da7246731ed9c44831b135f8       0.00      0.00      0.00       300
    T1016_14a21534-350f-4d83-9dd7-3c56b93a0c17       0.03      0.07      0.05       100
        T1016_71b3d2945679566b9d94d8cb11df4b70       0.03      0.04      0.03       100
        T1016_7d8ee68f0e9731db82964f558f614608       0.60      0.27      0.37       500
    T1016_921055f4-5970-4707-909e-62f594234d91       0.01      0.02      0.02       100
    T1016_a0676fe1-cd52-482e-8dde-349b73f9aa69       0.03      0.04      0.03       100
    T1016_e8017c46-acb8-400c-a4b5-b3362b5b5baa       0.02      0.03      0.02       100
    T1018_26c8b8b5-7b5b-4de1-a128-7d37fb14f517       0.02      0.02      0.02       100
        T1018_a44bb43474728496276d5d73aa14588f       0.01      0.02      0.02       100
        T1018_ac20e592bc912bddff4d6b88289095f0       0.03      0.04      0.04       100
    T1021.001_dd67068b052fa553ad4a0ac7d6a5ea89       1.00      1.00      1.00       600
    T1033_bd527b63-9f9e-46e0-9816-b8434d2b8989       0.03      0.04      0.04       100
    T1033_c0da588f-79f0-4263-8998-7496b1a40596       0.00      0.01      0.01       100
    T1036.003_04e8d83e7badf098d50800d6aa1dd487       1.00      1.00      1.00      2300
    T1036.003_f5ef8466e5ebcd2ae03f338d9416069c       1.00      1.00      1.00      2700
    T1036.004_1f0614ea5c4af6faf1b44570f5f22f8a       0.00      0.00      0.00       200
    T1036.004_7de3d7b4922a7b996d8df36fb22bb118       0.00      0.00      0.00       200
    T1037.001_62cfa90fb03a6bc1a6ebcce8a3ea81b7       1.00      1.00      1.00       700
        T1040_6881a4589710d53f0c146e91db513f01       1.00      1.00      1.00       500
        T1047_09e0f9cf2eb803a1c35deeecf3665fad       0.00      0.00      0.00       100
        T1047_6935e41353aa781bb723462d26114c44       0.01      0.01      0.01       100
        T1047_ac122553ab4426ea3362bb4a97d31bfd       0.01      0.01      0.01       100
        T1047_ac2764f7a67a9ce92b54e8e59b361838       0.01      0.01      0.01       100
        T1047_b0255b5120cbabc062d8d4510a142c3b       0.04      0.05      0.04       100
        T1047_ed736a123da6fb2aab22cfd4f437e8b5       0.01      0.03      0.02       100
        T1047_f4b0b4129560ea66f9751275e82f6bab       0.01      0.02      0.01       100
    T1049_638fb6bb-ba39-4285-93d1-7e4775b033a8       0.02      0.02      0.02       100
        T1049_a14392d713dffba6a397682ff83259a0       0.00      0.00      0.00       300
    T1053.005_5db2884b6ca3ab932848f295a3896dc0       0.00      0.00      0.00       200
    T1053.005_ee454be9197890de62705ce6255933fd       0.01      0.02      0.01       100
T1055.001_a74bc239-a196-4f7e-8d5c-fe8c0266071c       0.00      0.00      0.00       100
T1055.002_e5bcefee-262d-4568-a261-e8a20855ec81       0.00      0.00      0.00       100
    T1057_5a39d7ed-45c9-4a79-b581-e5fb99e24f65       0.01      0.02      0.01       100
    T1057_8adf02e8-6e71-4244-886c-98c402857404       1.00      1.00      1.00       700
        T1057_b2a1e430ca6d36eb5af2fe666e769847       0.03      0.04      0.04       100
        T1057_f8de05d1741dcc468f772ab0ff4dac72       0.03      0.04      0.03       100
T1059.001_55678719-e76e-4df9-92aa-10655bbd1cf4       1.00      1.00      1.00      1000
    T1059.001_6efbccc1869e8cd618c0d3ecda407d5f       1.00      1.00      1.00      1500
T1059.001_702bfdd2-9947-4eda-b551-c3a1ea9a59a2       1.00      1.00      1.00       500
T1059.001_bfff9006-d1fb-46ce-b173-92cb04e9a031       1.00      1.00      1.00      1000
T1059.001_ccdb8caf-c69e-424b-b930-551969450c57       1.00      1.00      1.00       500
T1059.001_e5f9de8f-3df1-4e78-ad92-a784e3f6770d       1.00      1.00      1.00     13700
    T1059.003_6c318ef0339d74d909ad556681b6493e       1.00      1.00      1.00       700
    T1059.003_f38e58deb7ad20b5538ca40db7b7b4f8       1.00      1.00      1.00       600
T1069.001_5c4dd985-89e3-4590-9b57-71fed66ff4e2       1.00      1.00      1.00       900
    T1069.001_a1f48fa3ddee658b29b414523c9a295b       0.00      0.00      0.00       200
    T1069.002_6103e503cb444bc7b4187704f2035708       0.27      0.02      0.04       400
    T1070.005_1f91076e2be2014cc7b4f1296de02fd6       1.00      1.00      1.00       600
    T1071.001_24c3b7b004401d839a5c337201da3484       1.00      1.00      1.00      2000
T1074.001_4e97e699-93d7-4040-b5a3-2e906a58199e       1.00      1.00      1.00      1000
T1074.001_6469befa-748a-4b9c-a96d-f191fde47d89       1.00      1.00      1.00       300
    T1074.001_e6dfc7e89359ac6fa6de84b0e1d5762e       1.00      1.00      1.00       800
    T1078.001_d0ca00832890baa1d42322cf70fcab1a       0.04      0.05      0.04       100
    T1082_29451844-9b76-4e16-a9ee-d6feab4b24db       0.03      0.04      0.03       100
    T1083_52177cc1-b9ab-4411-ac21-2eadc4b5d3b8       1.00      1.00      1.00      1200
    T1083_6e1a53c0-7352-4899-be35-fa7f364d5722       0.01      0.03      0.02       100
    T1087.001_6334877e8e3ba48f7835d4856d90a282       1.00      1.00      1.00       500
T1087.001_feaced8f-f43f-452a-9500-a5219488abb8       0.03      0.06      0.04       100
    T1090.001_ba343199a4f15ed6b57eb52412f62e4e       0.93      0.44      0.60       200
        T1105_0856c235a1d26113d4f2d92e39c9a9f8       1.00      1.00      1.00      1100
        T1105_1095434782a00c8a4772a11e625bcf5d       1.00      0.98      0.99       200
        T1105_4f683658f161ccdc51337c470d32bab9       1.00      1.00      1.00       800
    T1105_60f63260-39bb-4136-87a0-b6c2dca799fc       1.00      1.00      1.00      2100
        T1105_c521e0a70b243a0cf9217907ca3c6d27       1.00      1.00      1.00      2000
        T1105_c76968acda4aa1673dadcd67f3ab7664       1.00      1.00      1.00      1300
        T1105_e6715e61f5df646692c624b3499384c4       1.00      1.00      1.00      5700
    T1105_eb814e03-811a-467a-bc6d-dcd453750fa2       1.00      1.00      1.00     15000
        T1112_257313a3c93e3bb7dfb60d6753b09e34       1.00      1.00      1.00       300
        T1112_34041639e6e501856ecaf5969ee29c76       1.00      1.00      1.00       300
        T1112_35c0360d226cf38104f300d9d57ce60e       1.00      1.00      1.00       300
        T1112_4bfb5f265a5ce07af6bf10da113af7db       1.00      1.00      1.00       300
        T1112_7fe6a66d03f4dbfc022609ba311c2b11       1.00      1.00      1.00       300
        T1112_ba6f6214dbd17c54001e0a163b60f151       1.00      1.00      1.00       300
        T1112_cab7b85611a290c0769546bfa9d6f962       1.00      1.00      1.00       300
        T1112_cd8be0e6b873919da25530a2c7ea6750       1.00      1.00      1.00       200
        T1112_e74d2fb4ef5fa6c766a4151554033697       1.00      1.00      1.00       300
        T1112_e7a987cbef27263e666e5b096488dc55       1.00      1.00      1.00      1800
        T1112_fa4ba6a06b4a5cd955ea5a60fae24281       1.00      1.00      1.00       300
        T1112_fd992e8ecfdac9b56dd6868904044827       1.00      1.00      1.00       300
    T1113_316251ed-6a28-4013-812b-ddf5b5b007f8       1.00      1.00      1.00       500
        T1115_70795de7cbb842edb029b3378c27c008       1.00      1.00      1.00      1600
    T1115_b007fe0c-c6b0-4fda-915c-255bbc070de2       0.00      0.00      0.00       100
        T1119_344e7eaf650763e0d3e9f02e62c1cf4b       1.00      1.00      1.00      1900
        T1119_7121cdf93b951311be9d7078c602efdc       1.00      1.00      1.00      2000
        T1120_7b9c7afaefa59aab759b49af0d699ac1       1.00      1.00      1.00       600
        T1123_372e6f46fca18e4f1b43209c20ffafa2       1.00      1.00      1.00       600
    T1124_fa6e8607-e0b1-425d-8924-9b894da5a002       0.02      0.03      0.02       100
        T1125_da86001b5081fcf773d8e62f22cf2b00       1.00      1.00      1.00       600
    T1135_530e47c6-8592-42bf-91df-c59ffbd8541b       0.01      0.02      0.01       100
    T1135_deeac480-5c2a-42b5-90bb-41675ee53c7e       0.02      0.03      0.02       100
    T1137.002_e2af3c3ab1b0f659c874b8af58c49759       1.00      1.00      1.00       600
        T1137_12ad9edefc86af07700fbf49bfdac6ba       1.00      1.00      1.00      1300
        T1201_38f6f0e50a6b196140ec40d3dc9cc9e6       0.01      0.02      0.02       100
        T1201_57296a2ddbeb7423c05feef2fe972111       0.04      0.04      0.04       100
    T1204.002_522f3f35cd013e63830fa555495a0081       1.00      1.00      1.00      1000
        T1217_69bbe2183fa09c00ccaac62d48e214f8       1.00      1.00      1.00       400
        T1217_f7a0f7d704aa52a764d9d1bee81e65d6       0.01      0.02      0.02       100
        T1219_7dabcbecab0334b115feefab1630f84a       1.00      1.00      1.00      6700
        T1219_af8cb2bf9b436aae5c106a0a9c207e14       1.00      1.00      1.00     10400
        T1219_f1b3fca18d7465cd10e5a7477a3bf97d       1.00      1.00      1.00      5000
    T1482_6131397e-7765-424e-a594-3d7fb2d93a6a       1.00      1.00      1.00       500
        T1482_cfb61005899996469ae3023796792ca5       0.02      0.02      0.02       100
        T1486_d82ceb9939d3d920ee550187ad8235c8       1.00      1.00      1.00       400
        T1490_2d53d6fabd39bf9c70b0dfcdfbbc926d       0.04      0.06      0.05       100
        T1490_8467c994685ccf178db166964bd80fab       0.00      0.00      0.00       200
        T1490_9e5e4c0655fd1b5be88bd40b8251175f       0.04      0.05      0.05       100
        T1490_c156ac5c9fa67080365268d95f29053d       0.00      0.00      0.00       100
        T1490_c8f329d2847ede593b6cb4a1ec6120fb       1.00      1.00      1.00      1000
        T1490_e90756bb6dcd21462dc4cc452661df91       0.01      0.02      0.01       100
    T1491_47d08617-5ce1-424a-8cc5-c9c978ce6bf9       1.00      1.00      1.00       500
    T1491_68235976-2404-42a8-9105-68230cfef562       1.00      1.00      1.00       700
    T1496_46da2385-cf37-49cb-ba4b-a739c7a19de4       1.00      1.00      1.00      8200
T1497.001_1258b063-27d6-489b-a677-4807faacf868       0.00      0.00      0.00       100
T1497.001_5dc841fd-28ad-40e2-b10e-fb007fe09e81       0.01      0.02      0.01       100
T1497.001_7a6ba833-de40-466a-8969-5c37b13603e0       0.02      0.05      0.03       100
    T1499_2fe2d5e6-7b06-4fc0-bf71-6966a1226731       0.02      0.04      0.03       100
T1518.001_2dece965-37a0-4f70-a391-0f30e3331aba       0.02      0.04      0.03       100
    T1518.001_33a24ff44719e6ac0614b58f8c9a7c72       0.00      0.00      0.00       200
    T1518.001_b8453a5fe06b24aea12b27592d5c3d3a       0.01      0.01      0.01       100
        T1518_8ddfaf982ab359cda13626b870ccb339       1.00      1.00      1.00       200
    T1518_c9be8043-a445-4cbf-b77b-ed7bb007fc7c       1.00      1.00      1.00       100
        T1531_aa6b15485a5f50ced34d87fda177b758       0.00      0.00      0.00       200
        T1531_b25ae80dad74142fafb510e9c1949ace       0.00      0.00      0.00       200
    T1546.013_f9a968af61d36983448c74cca5464e17       1.00      1.00      1.00      1500
    T1547.001_0dbdf1a2a87e718a6ac8a8e3415a7fac       1.00      1.00      1.00       700
    T1547.001_163b023f43aba758d36f524d146cb8ea       1.00      1.00      1.00       500
    T1547.001_1f15ab22c39a9b6bb2bb0d77276dfcb3       1.00      1.00      1.00       600
    T1547.001_4b71ebb2f6f6a01235ba240fa40ce978       1.00      1.00      1.00       200
    T1547.001_777043894e42d2aae3881e63f6c76d33       1.00      1.00      1.00       200
    T1547.001_d3ef4145e4144fd694514b1c5cc17350       1.00      1.00      1.00       500
    T1547.004_0856714c9810ac55b53e9964d02958a0       1.00      1.00      1.00       200
    T1547.004_aa147165f6c116cb0b0f944abe1db8ce       1.00      1.00      1.00       200
    T1547.009_501af516bd8b24fee0c7c650ae5cc861       1.00      1.00      1.00      1000
    T1547.009_b6e5c895c6709fe289352ee23f062229       1.00      1.00      1.00       800
    T1547.010_4593d72a5145e3f494421ac772d37464       1.00      1.00      1.00       600
        T1547_fe9eeee9a7b339089e5fa634b08522c1       1.00      1.00      1.00      2200
T1548.002_665432a4-42e7-4ee1-af19-a9a8c9455d0c       1.00      1.00      1.00       200
    T1552.002_3e5b04b8ee0a1a4950da8f35d95e65fc       0.00      0.00      0.00       200
        T1560_a1ee301b0508747b468d578a14e5c1a5       1.00      1.00      1.00     21600
    T1562.001_43e3334362b140924f001b256b229ee5       1.00      1.00      1.00       200
    T1562.002_6a8d25d65a7d481dc479f89c62af1e6a       1.00      1.00      1.00       600
    T1562.002_94f51bf01a7036fe02d07b4c18967669       0.02      0.02      0.02       100
    T1562.004_280003641a5cddf916c4f2bf605a71d3       0.00      0.00      0.00       200
    T1562.004_41627f71f968225b9f162cb76d16bd9d       1.00      1.00      1.00      1100
    T1562.004_5b93df032e230056c21a3e57334f77d1       0.04      0.06      0.05       100
    T1562.004_8d0a4585e7c4646185a912b14cd9cb46       0.03      0.05      0.04       100
    T1562.004_8fe59e288f10a486dc8b44bc872019ff       1.00      1.00      1.00       300
    T1564.001_66a5fd5f244819181f074dd082a28905       0.50      0.20      0.29       500
    T1564.001_dce51e632abdfe5392c7c1f942ac9273       0.50      0.80      0.62       500
    T1564.003_9a2edad4053a2b59fb9167a9bc29e7dc       0.90      0.10      0.17       200
    T1564.004_28862487a99f5f89bc0d68c87396c7e9       1.00      1.00      1.00       600
    T1564.004_76b6066fe170d38215251102e42be973       1.00      1.00      1.00      1600
        T1564_dedfa0a54c9c13ce5714a0dc2e1f5d1a       0.00      0.00      0.00       100
    T1566.001_1afaec09315ab71fdfb167175e8a019a       1.00      1.00      1.00       800
    T1574.001_63bbedafba2f541552ac3579e9e3737b       1.00      1.00      1.00      6200
    T1574.011_72249c1e9ffe7d8f30243d838e0791ca       1.00      1.00      1.00       600
                                        benign       1.00      1.00      1.00    134563

                                      accuracy                           0.97    310263
                                     macro avg       0.60      0.59      0.59    310263
                                  weighted avg       0.97      0.97      0.97    310263

