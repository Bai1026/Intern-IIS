{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GAT\n",
    "- use DGL\n",
    "- predict `graphs`\n",
    "- test: 0~99\n",
    "- validation: 100~199\n",
    "- train: 200~999\n",
    "- larger lr with scheduler\n",
    "- try the sklearn report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm  # 使用 notebook 版本的 tqdm\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the GPU and assign the GPU by the best memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_free_gpu():\n",
    "    try:\n",
    "        # Run nvidia-smi command to get GPU details\n",
    "        _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "        command = \"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\"\n",
    "        memory_free_info = _output_to_list(subprocess.check_output(command.split())) \n",
    "        memory_free_values = [int(x) for i, x in enumerate(memory_free_info)]\n",
    "        \n",
    "        # Get the GPU with the maximum free memory\n",
    "        best_gpu_id = memory_free_values.index(max(memory_free_values))\n",
    "        return best_gpu_id\n",
    "    except:\n",
    "        # If any exception occurs, default to GPU 0 (this handles cases where nvidia-smi isn't installed)\n",
    "        return 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the best GPU ID based on free memory and set it\n",
    "    best_gpu_id = get_free_gpu()\n",
    "    device = torch.device(f\"cuda:{best_gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"there's no available GPU\")\n",
    "\n",
    "# device = torch.device(f\"cuda:1\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed = 8787):\n",
    "    torch.manual_seed(seed)\n",
    "    # random.seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "\n",
    "        g = dgl.graph((th.tensor(data[\"edge_index\"][0]), th.tensor(data[\"edge_index\"][1])), num_nodes=data[\"num_nodes\"]).to(self.device)\n",
    "\n",
    "        g.ndata['feat'] = th.tensor(data[\"node_feat\"]).to(self.device)\n",
    "        g.edata['feat'] = th.tensor(data[\"edge_attr\"]).to(self.device)  # Add edge features to graph\n",
    "\n",
    "        return g, th.tensor(data[\"label\"]).to(self.device)\n",
    "\n",
    "\n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be26de3f40594f21904c3d1dcf823347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp1-2/training_data/exp_2/transR_50/train.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935c0e82b84d44d58a029db88ec4240f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp1-2/training_data/exp_2/transR_50/valid.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc74a3d851b148b2b9f7107ce2404dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data_new/exp1-2/training_data/exp_2/transR_50/test.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45e2dc8fbbf465aba587cc58ec54f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "datasets = ['train', 'valid', 'test']\n",
    "# datasets = ['test']\n",
    "dataset_data = {}\n",
    "\n",
    "for dataset_name in tqdm(datasets):\n",
    "#     file_path = f\"../../data_processing/dgl/data/test_graph/repeated_{dataset_name}.jsonl\"\n",
    "    file_path = f\"../../data_processing/dgl/data_new/exp1-2/training_data/exp_2/transR_50/{dataset_name}.jsonl\"\n",
    "    \n",
    "    print(file_path)\n",
    "    with open(file_path) as f:\n",
    "        data_list = [json.loads(line) for line in tqdm(f, position=0, leave=True)]\n",
    "    \n",
    "    dataset_data[dataset_name] = GraphDataset(data_list, device)\n",
    "\n",
    "print(\"Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "def create_dataloaders(batch_size, shuffle=True):\n",
    "    dataloaders = {}\n",
    "    for dataset_name, dataset in dataset_data.items():\n",
    "        # do not shuffle the testing dataset\n",
    "        if dataset_name == \"test\":\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)    \n",
    "        else:\n",
    "            dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate)\n",
    "    return dataloaders\n",
    "\n",
    "# dataloaders = create_dataloaders(4)\n",
    "dataloaders = create_dataloaders(16)\n",
    "\n",
    "\n",
    "if (len(dataloaders['test'].dataset) + len(dataloaders['valid'].dataset) + len(dataloaders['train'].dataset)) % 166 != 0: print(\"Error data!!\")\n",
    "else: print(\"OK!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turn the print message to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Graph(num_nodes=10, num_edges=19,\n",
      "      ndata_schemes={'feat': Scheme(shape=(50,), dtype=torch.float32)}\n",
      "      edata_schemes={'feat': Scheme(shape=(50,), dtype=torch.float32)}), tensor(6, device='cuda:2'))\n",
      "16600\n",
      "16600\n",
      "132800\n",
      "166000\n"
     ]
    }
   ],
   "source": [
    "# print(dataloaders['test'][5])\n",
    "sample = dataset_data['train'][5000]\n",
    "print(sample)\n",
    "\n",
    "print(len(dataloaders['test'].dataset))\n",
    "print(len(dataloaders['valid'].dataset))\n",
    "print(len(dataloaders['train'].dataset))\n",
    "print(len(dataloaders['test'].dataset) + len(dataloaders['valid'].dataset) + len(dataloaders['train'].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log_message/0910_21:23_GAT_transR_50.log\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "formatted_time = now.strftime(\"%m%d_%H:%M\")\n",
    "\n",
    "log_file_path = f\"../log_message/{formatted_time}_GAT_transR_50.log\"\n",
    "\n",
    "def add_log_msg(msg, log_file_path=log_file_path):\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}\\n')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}')\n",
    "\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads, dropout_prob=0.25):\n",
    "        super(GAT, self).__init__()\n",
    "        \n",
    "        # do not check the zero in_degree since we have all the complete graph\n",
    "        self.layer1 = GATConv(in_dim, hidden_dim, num_heads=num_heads, activation=F.relu, allow_zero_in_degree=True)\n",
    "#         self.layer1 = GATConv(in_dim, hidden_dim*num_heads, num_heads=num_heads, activation=F.relu, allow_zero_in_degree=True)\n",
    "        self.layer2 = GATConv(hidden_dim * num_heads, out_dim, num_heads=num_heads, allow_zero_in_degree=True)\n",
    "        \n",
    "        # Adding Batch Normalization after each GAT layer\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(out_dim)\n",
    "        \n",
    "        # Adding Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # Apply GAT layers\n",
    "        h = self.layer1(g, h)\n",
    "        h = h.view(h.shape[0], -1)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.layer2(g, h).squeeze(1)\n",
    "#         h = self.layer2(g, h)\n",
    "        \n",
    "        # Store the output as a new node feature\n",
    "        g.ndata['h_out'] = h\n",
    "\n",
    "        # Use mean pooling to aggregate this new node feature\n",
    "        h_agg = dgl.mean_nodes(g, feat='h_out')\n",
    "        return h_agg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Forward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(data, model, criterion, device, count=1, which_type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "    batched_g, labels = data\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = labels.to(device)\n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float()) # for GAT\n",
    "    logits = logits.mean(dim=1)\n",
    "#     if count % 8000 == 0:\n",
    "    print(\"labels: \", labels, labels.shape)\n",
    "    print(\"logits: \", logits, logits.shape)\n",
    "    \n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    # Get the class id with the highest probability\n",
    "    preds = logits.argmax(1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "    \n",
    "    if which_type == 'validation' and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Validation: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Validation: {preds} {preds.shape}\")\n",
    "        \n",
    "    elif which_type == 'test'  and count % 1000 == 0:\n",
    "        add_log_msg(f\"labels of Test: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of Test: {preds} {preds.shape}\")\n",
    "        \n",
    "    if count % 5000 == 0: \n",
    "        add_log_msg(f\"labels of {count}: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of {count}: {preds} {preds.shape}\")\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the seed and save the model.state_dict that contains the initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "torch.save(model.state_dict(), 'model1_initial/initial_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1806, -0.0598,  0.0091,  ...,  0.0719,  0.2496,  0.0873],\n",
       "        [ 0.1694, -0.0015, -0.0139,  ...,  0.0147,  0.0892,  0.0146],\n",
       "        [ 0.0969, -0.0595, -0.0115,  ..., -0.0474,  0.0529, -0.0565],\n",
       "        ...,\n",
       "        [-0.0433, -0.2248,  0.3002,  ...,  0.0850,  0.1621,  0.0422],\n",
       "        [ 0.2097, -0.2492,  0.0612,  ..., -0.0041,  0.0365, -0.1483],\n",
       "        [ 0.0971, -0.2221,  0.1652,  ..., -0.1312, -0.2610,  0.0077]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.fc.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if model really load the model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1806, -0.0598,  0.0091,  ...,  0.0719,  0.2496,  0.0873],\n",
       "        [ 0.1694, -0.0015, -0.0139,  ...,  0.0147,  0.0892,  0.0146],\n",
       "        [ 0.0969, -0.0595, -0.0115,  ..., -0.0474,  0.0529, -0.0565],\n",
       "        ...,\n",
       "        [-0.0433, -0.2248,  0.3002,  ...,  0.0850,  0.1621,  0.0422],\n",
       "        [ 0.2097, -0.2492,  0.0612,  ..., -0.0041,  0.0365, -0.1483],\n",
       "        [ 0.0971, -0.2221,  0.1652,  ..., -0.1312, -0.2610,  0.0077]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "model.load_state_dict(torch.load('model1_initial/initial_weight.pth'))\n",
    "model.layer1.fc.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test of valid and test part is ``graph``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch size = 4\n",
    "- use large lr and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48daf2be78514035a00e1453a7d7c3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d631cbccf14fc6b0b1bc01f80cee58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/8300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  tensor([128,  72, 160,   0,  55,   6, 147, 114, 135, 100,  89,  90, 109,  98,\n",
      "         30,  18], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 1.1970e-03, -5.1923e-04, -5.7293e-04,  ..., -9.0656e-04,\n",
      "         -1.1828e-03,  3.9308e-04],\n",
      "        [ 3.9247e-04, -1.6051e-04,  1.2089e-04,  ..., -2.1755e-04,\n",
      "         -4.5752e-05, -1.6995e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([137,   6, 156,  95, 116, 112,  12,  89, 128, 114,  58,  12, 120,   9,\n",
      "         70, 159], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 5.9388e-04, -5.0262e-04, -5.1378e-04,  ..., -5.1681e-04,\n",
      "         -5.3912e-04, -5.0456e-04],\n",
      "        [ 5.7406e-04, -5.0556e-04, -5.6571e-04,  ..., -5.1337e-04,\n",
      "         -5.5141e-04, -5.4863e-04],\n",
      "        [ 1.5520e-03, -4.2811e-04, -1.8481e-03,  ..., -1.5051e-03,\n",
      "         -1.1476e-03,  1.2173e-03],\n",
      "        ...,\n",
      "        [ 5.5055e-04, -5.0920e-04, -5.4017e-04,  ..., -5.4815e-04,\n",
      "         -5.5020e-04, -5.0266e-04],\n",
      "        [ 6.5309e-04, -6.1897e-04, -8.0037e-04,  ..., -6.5671e-04,\n",
      "         -7.8786e-04, -7.9370e-04],\n",
      "        [ 1.2893e-03, -3.3736e-04, -9.6203e-04,  ..., -1.5926e-03,\n",
      "         -1.5405e-03, -1.0838e-05]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 87, 137,  41,  10, 113, 136, 122, 129,  11,   2, 161,  79, 126, 141,\n",
      "          6, 136], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0009, -0.0010, -0.0010,  ..., -0.0010, -0.0011, -0.0010],\n",
      "        [ 0.0009, -0.0011, -0.0010,  ..., -0.0010, -0.0011, -0.0010],\n",
      "        [ 0.0009, -0.0010, -0.0010,  ..., -0.0010, -0.0011, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0010, -0.0010,  ..., -0.0009, -0.0012, -0.0010],\n",
      "        [ 0.0009, -0.0010, -0.0009,  ..., -0.0010, -0.0012, -0.0011],\n",
      "        [ 0.0026, -0.0009, -0.0011,  ..., -0.0030, -0.0023, -0.0003]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 98,  73,  51, 141, 161, 105, 131, 115, 155, 166,  40,   7, 144, 103,\n",
      "         38, 130], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0011, -0.0016, -0.0008,  ..., -0.0015, -0.0017, -0.0015],\n",
      "        [ 0.0014, -0.0019, -0.0009,  ..., -0.0028, -0.0018, -0.0010],\n",
      "        [ 0.0012, -0.0015, -0.0007,  ..., -0.0017, -0.0017, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0016, -0.0008,  ..., -0.0016, -0.0017, -0.0015],\n",
      "        [ 0.0011, -0.0016, -0.0007,  ..., -0.0015, -0.0017, -0.0015],\n",
      "        [ 0.0013, -0.0019, -0.0008,  ..., -0.0017, -0.0022, -0.0019]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 34, 105, 145,  63, 158,  34, 125,  39,  40,  37,  64,   5,  89,  35,\n",
      "        151, 111], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0012, -0.0021, -0.0005,  ..., -0.0022, -0.0015, -0.0021],\n",
      "        [ 0.0008, -0.0023, -0.0010,  ..., -0.0021, -0.0021, -0.0024],\n",
      "        [ 0.0010, -0.0021, -0.0012,  ..., -0.0034, -0.0026, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0029, -0.0014,  ..., -0.0030, -0.0022, -0.0021],\n",
      "        [ 0.0012, -0.0022, -0.0007,  ..., -0.0022, -0.0015, -0.0020],\n",
      "        [ 0.0013, -0.0021, -0.0007,  ..., -0.0022, -0.0014, -0.0021]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([159,  16, 149,  65,  60,  28,  32, 115,  38,  68,  27, 133, 131,   0,\n",
      "        113, 139], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0020, -0.0031, -0.0018,  ..., -0.0034, -0.0027, -0.0025],\n",
      "        [ 0.0011, -0.0030, -0.0006,  ..., -0.0032, -0.0019, -0.0026],\n",
      "        [ 0.0020, -0.0038, -0.0010,  ..., -0.0031, -0.0023, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0033, -0.0005,  ..., -0.0030, -0.0022, -0.0026],\n",
      "        [ 0.0014, -0.0027, -0.0005,  ..., -0.0026, -0.0014, -0.0026],\n",
      "        [ 0.0013, -0.0026, -0.0006,  ..., -0.0027, -0.0014, -0.0026]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 23,  67, 134, 162,  12,  84, 143,  86,  14,   5, 132,  93,   3, 159,\n",
      "         39,  99], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 2.7964e-03, -4.1968e-03, -1.2402e-03,  ..., -3.6702e-03,\n",
      "         -2.0276e-03, -3.5774e-03],\n",
      "        [ 2.4614e-03, -3.8105e-03, -2.7793e-04,  ..., -3.5950e-03,\n",
      "         -1.8421e-03, -3.1262e-03],\n",
      "        [ 3.6706e-03, -4.5508e-03, -1.4068e-03,  ..., -5.0336e-03,\n",
      "         -3.7720e-03, -6.1670e-03],\n",
      "        ...,\n",
      "        [ 2.6958e-03, -3.9871e-03, -1.7908e-03,  ..., -4.6498e-03,\n",
      "         -2.3313e-03, -3.9484e-03],\n",
      "        [ 3.0006e-03, -3.8215e-03,  1.3191e-05,  ..., -3.6752e-03,\n",
      "         -2.0284e-03, -2.9221e-03],\n",
      "        [ 2.4109e-03, -2.6333e-03, -9.5786e-04,  ..., -4.4556e-03,\n",
      "         -4.4705e-03, -4.0501e-03]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 80,   6,  91, 130, 111,  24, 146,  58, 155,  82, 126,  62,  64, 108,\n",
      "        162, 114], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0028, -0.0042, -0.0017,  ..., -0.0055, -0.0016, -0.0034],\n",
      "        [ 0.0016, -0.0037, -0.0008,  ..., -0.0042, -0.0013, -0.0038],\n",
      "        [ 0.0018, -0.0038, -0.0004,  ..., -0.0038, -0.0012, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0038, -0.0006,  ..., -0.0039, -0.0012, -0.0038],\n",
      "        [ 0.0017, -0.0037, -0.0005,  ..., -0.0039, -0.0011, -0.0036],\n",
      "        [ 0.0018, -0.0039, -0.0007,  ..., -0.0040, -0.0012, -0.0038]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 56, 126,  69,  51,  87,  87, 119, 101,  29, 144, 134,  13,  65, 161,\n",
      "         53,  34], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0019, -0.0050, -0.0006,  ..., -0.0051, -0.0024, -0.0045],\n",
      "        [ 0.0021, -0.0041, -0.0006,  ..., -0.0053, -0.0024, -0.0046],\n",
      "        [ 0.0020, -0.0045, -0.0010,  ..., -0.0048, -0.0014, -0.0049],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0043, -0.0007,  ..., -0.0048, -0.0014, -0.0045],\n",
      "        [ 0.0019, -0.0041, -0.0006,  ..., -0.0043, -0.0011, -0.0042],\n",
      "        [ 0.0020, -0.0042, -0.0004,  ..., -0.0043, -0.0012, -0.0041]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([151,   3,  57, 131,  67,  53, 142,  81,  40,  85, 110, 153,  49,  76,\n",
      "         98,  78], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0019, -0.0047, -0.0006,  ..., -0.0048, -0.0013, -0.0047],\n",
      "        [ 0.0038, -0.0063, -0.0024,  ..., -0.0073, -0.0031, -0.0050],\n",
      "        [ 0.0019, -0.0047, -0.0005,  ..., -0.0049, -0.0011, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0047, -0.0007,  ..., -0.0048, -0.0011, -0.0047],\n",
      "        [ 0.0019, -0.0047, -0.0006,  ..., -0.0049, -0.0012, -0.0048],\n",
      "        [ 0.0030, -0.0056, -0.0005,  ..., -0.0056, -0.0021, -0.0043]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([114,  97, 155,  87,  32,   8, 134, 117, 155, 147, 150, 140,  38,  32,\n",
      "         85,  59], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0021, -0.0053, -0.0009,  ..., -0.0055, -0.0014, -0.0054],\n",
      "        [ 0.0021, -0.0053, -0.0006,  ..., -0.0054, -0.0011, -0.0053],\n",
      "        [ 0.0023, -0.0055, -0.0010,  ..., -0.0055, -0.0014, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0029, -0.0064, -0.0022,  ..., -0.0076, -0.0029, -0.0053],\n",
      "        [ 0.0022, -0.0058, -0.0014,  ..., -0.0062, -0.0017, -0.0052],\n",
      "        [ 0.0019, -0.0054, -0.0010,  ..., -0.0057, -0.0013, -0.0053]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 89, 143, 135,  52, 164,  21, 162,   7,  58, 126, 126, 128,  43,  94,\n",
      "          9, 139], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0019, -0.0067, -0.0017,  ..., -0.0076, -0.0021, -0.0066],\n",
      "        [ 0.0020, -0.0058, -0.0008,  ..., -0.0060, -0.0013, -0.0058],\n",
      "        [ 0.0021, -0.0058, -0.0010,  ..., -0.0058, -0.0012, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0029, -0.0068, -0.0017,  ..., -0.0066, -0.0020, -0.0064],\n",
      "        [ 0.0022, -0.0058, -0.0009,  ..., -0.0059, -0.0014, -0.0058],\n",
      "        [ 0.0022, -0.0058, -0.0008,  ..., -0.0060, -0.0014, -0.0058]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([113,  79,  57,  66,  90,  91,  44, 121, 157,  30,   3, 132,  16,  54,\n",
      "         89, 124], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0023, -0.0066, -0.0014,  ..., -0.0066, -0.0014, -0.0066],\n",
      "        [ 0.0021, -0.0067, -0.0010,  ..., -0.0074, -0.0022, -0.0070],\n",
      "        [ 0.0022, -0.0063, -0.0008,  ..., -0.0064, -0.0014, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0021, -0.0063, -0.0008,  ..., -0.0064, -0.0014, -0.0063],\n",
      "        [ 0.0018, -0.0071, -0.0022,  ..., -0.0084, -0.0025, -0.0069],\n",
      "        [ 0.0022, -0.0063, -0.0009,  ..., -0.0064, -0.0014, -0.0064]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  tensor([ 13, 142,  58, 155,  44, 124, 137,  53,  53,  41,  68,  61,  77, 129,\n",
      "         51, 140], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0021, -0.0073, -0.0014,  ..., -0.0081, -0.0023, -0.0073],\n",
      "        [ 0.0022, -0.0069, -0.0013,  ..., -0.0069, -0.0015, -0.0068],\n",
      "        [ 0.0022, -0.0069, -0.0011,  ..., -0.0072, -0.0015, -0.0069],\n",
      "        ...,\n",
      "        [ 0.0021, -0.0070, -0.0013,  ..., -0.0073, -0.0016, -0.0069],\n",
      "        [ 0.0023, -0.0071, -0.0012,  ..., -0.0075, -0.0018, -0.0072],\n",
      "        [ 0.0038, -0.0081, -0.0020,  ..., -0.0077, -0.0031, -0.0077]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 65,  51, 139,  49, 119, 152, 147,   5, 139, 126,  45, 131, 110,   5,\n",
      "          5, 161], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0044, -0.0124, -0.0068,  ..., -0.0103, -0.0032, -0.0101],\n",
      "        [ 0.0019, -0.0074, -0.0017,  ..., -0.0078, -0.0019, -0.0077],\n",
      "        [ 0.0021, -0.0074, -0.0012,  ..., -0.0075, -0.0016, -0.0074],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0085, -0.0021,  ..., -0.0086, -0.0026, -0.0078],\n",
      "        [ 0.0015, -0.0078, -0.0020,  ..., -0.0083, -0.0015, -0.0077],\n",
      "        [ 0.0023, -0.0081, -0.0021,  ..., -0.0083, -0.0019, -0.0080]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([110,   4, 148,  82,  16,  88,  21,  48,  35,  53, 156,  54, 115, 149,\n",
      "          7,  42], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0021, -0.0081, -0.0017,  ..., -0.0083, -0.0018, -0.0080],\n",
      "        [ 0.0020, -0.0080, -0.0015,  ..., -0.0083, -0.0018, -0.0080],\n",
      "        [ 0.0023, -0.0081, -0.0012,  ..., -0.0081, -0.0019, -0.0079],\n",
      "        ...,\n",
      "        [ 0.0032, -0.0098, -0.0029,  ..., -0.0098, -0.0030, -0.0085],\n",
      "        [ 0.0012, -0.0111, -0.0026,  ..., -0.0122, -0.0051, -0.0091],\n",
      "        [ 0.0019, -0.0080, -0.0014,  ..., -0.0080, -0.0018, -0.0078]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([133, 140,  90,  87, 128,  71,  53,  11, 156,   5, 116, 110,  93, 115,\n",
      "         40, 134], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0022, -0.0088, -0.0018,  ..., -0.0088, -0.0022, -0.0085],\n",
      "        [ 0.0028, -0.0097, -0.0028,  ..., -0.0104, -0.0050, -0.0096],\n",
      "        [ 0.0017, -0.0086, -0.0017,  ..., -0.0089, -0.0021, -0.0085],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0105, -0.0036,  ..., -0.0113, -0.0040, -0.0097],\n",
      "        [ 0.0030, -0.0100, -0.0027,  ..., -0.0105, -0.0033, -0.0093],\n",
      "        [ 0.0038, -0.0116, -0.0049,  ..., -0.0122, -0.0056, -0.0129]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 55, 124, 141, 155, 137,   3,  32,  95,  14,  64, 146,  21, 123,   8,\n",
      "         73, 114], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0018, -0.0091, -0.0020,  ..., -0.0093, -0.0020, -0.0091],\n",
      "        [ 0.0020, -0.0091, -0.0017,  ..., -0.0094, -0.0022, -0.0091],\n",
      "        [ 0.0019, -0.0094, -0.0021,  ..., -0.0093, -0.0025, -0.0091],\n",
      "        ...,\n",
      "        [ 0.0021, -0.0096, -0.0024,  ..., -0.0097, -0.0022, -0.0093],\n",
      "        [ 0.0024, -0.0101, -0.0026,  ..., -0.0110, -0.0037, -0.0092],\n",
      "        [ 0.0021, -0.0093, -0.0021,  ..., -0.0096, -0.0024, -0.0094]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([162,  59,  73,  54,  94, 122,  78,  75,  49,  72,  47,  81, 162,  74,\n",
      "         25,  45], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0019, -0.0098, -0.0019,  ..., -0.0099, -0.0022, -0.0095],\n",
      "        [ 0.0020, -0.0102, -0.0027,  ..., -0.0105, -0.0028, -0.0100],\n",
      "        [ 0.0022, -0.0113, -0.0032,  ..., -0.0118, -0.0032, -0.0104],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0100, -0.0024,  ..., -0.0099, -0.0024, -0.0096],\n",
      "        [ 0.0002, -0.0114, -0.0035,  ..., -0.0141, -0.0058, -0.0115],\n",
      "        [ 0.0019, -0.0106, -0.0031,  ..., -0.0113, -0.0034, -0.0110]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([  3,  46,  46,  56,  15, 152, 164,  95,   4,   9, 137,  12,  85, 133,\n",
      "         53,  27], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0032, -0.0127, -0.0048,  ..., -0.0144, -0.0064, -0.0126],\n",
      "        [ 0.0018, -0.0103, -0.0024,  ..., -0.0104, -0.0024, -0.0101],\n",
      "        [ 0.0015, -0.0102, -0.0023,  ..., -0.0105, -0.0025, -0.0103],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0107, -0.0023,  ..., -0.0109, -0.0028, -0.0104],\n",
      "        [ 0.0019, -0.0100, -0.0023,  ..., -0.0104, -0.0025, -0.0102],\n",
      "        [ 0.0020, -0.0111, -0.0036,  ..., -0.0119, -0.0036, -0.0109]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 69, 138,  25,  67,  92, 131,  54, 162,  19,  78,  21,  20,  77,  14,\n",
      "        139,  83], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0020, -0.0118, -0.0036,  ..., -0.0124, -0.0036, -0.0118],\n",
      "        [ 0.0016, -0.0114, -0.0038,  ..., -0.0114, -0.0039, -0.0109],\n",
      "        [ 0.0020, -0.0141, -0.0044,  ..., -0.0144, -0.0075, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0109, -0.0028,  ..., -0.0112, -0.0029, -0.0108],\n",
      "        [ 0.0018, -0.0108, -0.0027,  ..., -0.0112, -0.0029, -0.0109],\n",
      "        [ 0.0016, -0.0110, -0.0026,  ..., -0.0112, -0.0029, -0.0108]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([136, 117,  87,  92, 100,  98, 116,  27,  13,  71, 158,  49, 160,  30,\n",
      "        130,  14], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0030, -0.0132, -0.0049,  ..., -0.0153, -0.0066, -0.0137],\n",
      "        [ 0.0011, -0.0126, -0.0041,  ..., -0.0136, -0.0045, -0.0120],\n",
      "        [ 0.0015, -0.0115, -0.0029,  ..., -0.0117, -0.0029, -0.0113],\n",
      "        ...,\n",
      "        [ 0.0014, -0.0116, -0.0029,  ..., -0.0117, -0.0031, -0.0114],\n",
      "        [ 0.0014, -0.0133, -0.0038,  ..., -0.0132, -0.0044, -0.0123],\n",
      "        [ 0.0015, -0.0113, -0.0029,  ..., -0.0116, -0.0031, -0.0113]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([125, 123,   2,  50, 115,  25, 132, 150,  24,  97,  12, 150,  41,  45,\n",
      "         47,  27], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0012, -0.0121, -0.0032,  ..., -0.0123, -0.0035, -0.0119],\n",
      "        [-0.0001, -0.0142, -0.0057,  ..., -0.0145, -0.0062, -0.0133],\n",
      "        [ 0.0012, -0.0121, -0.0034,  ..., -0.0121, -0.0033, -0.0118],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0130, -0.0045,  ..., -0.0136, -0.0048, -0.0133],\n",
      "        [ 0.0011, -0.0119, -0.0031,  ..., -0.0121, -0.0032, -0.0120],\n",
      "        [ 0.0019, -0.0137, -0.0047,  ..., -0.0142, -0.0053, -0.0127]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([  5,  29,  88,  33, 106,  31, 133,  62,  48, 146, 159, 155, 128,  13,\n",
      "         60,  31], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0006, -0.0138, -0.0047,  ..., -0.0142, -0.0046, -0.0135],\n",
      "        [ 0.0016, -0.0139, -0.0043,  ..., -0.0148, -0.0055, -0.0132],\n",
      "        [ 0.0015, -0.0129, -0.0034,  ..., -0.0133, -0.0042, -0.0128],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0135, -0.0046,  ..., -0.0155, -0.0057, -0.0132],\n",
      "        [ 0.0012, -0.0126, -0.0029,  ..., -0.0128, -0.0036, -0.0125],\n",
      "        [ 0.0013, -0.0125, -0.0032,  ..., -0.0126, -0.0036, -0.0123]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 98,  85, 149,   1,   1, 138, 125,  32, 155, 140, 111,  62, 133,  53,\n",
      "         16, 107], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0008, -0.0130, -0.0029,  ..., -0.0132, -0.0037, -0.0130],\n",
      "        [ 0.0011, -0.0141, -0.0039,  ..., -0.0148, -0.0049, -0.0136],\n",
      "        [ 0.0015, -0.0168, -0.0059,  ..., -0.0166, -0.0071, -0.0144],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0132, -0.0030,  ..., -0.0131, -0.0035, -0.0129],\n",
      "        [ 0.0002, -0.0146, -0.0043,  ..., -0.0151, -0.0055, -0.0141],\n",
      "        [ 0.0013, -0.0133, -0.0036,  ..., -0.0137, -0.0043, -0.0130]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 83,  53, 109,  91,  38, 115, 114,  68,   7,  23,  38, 104,  76,  43,\n",
      "         82,  96], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 5.7639e-04, -1.3030e-02, -3.2508e-03,  ..., -1.4043e-02,\n",
      "         -4.3557e-03, -1.3686e-02],\n",
      "        [ 1.1838e-03, -1.2719e-02, -3.0763e-03,  ..., -1.3723e-02,\n",
      "         -4.1642e-03, -1.3474e-02],\n",
      "        [ 8.1442e-04, -1.3102e-02, -3.2376e-03,  ..., -1.4023e-02,\n",
      "         -4.0891e-03, -1.3544e-02],\n",
      "        ...,\n",
      "        [ 5.7042e-04, -1.2713e-02, -3.1188e-03,  ..., -1.3935e-02,\n",
      "         -4.1274e-03, -1.3688e-02],\n",
      "        [ 1.8705e-04, -1.5972e-02, -6.1413e-03,  ..., -1.5811e-02,\n",
      "         -6.6535e-03, -1.7420e-02],\n",
      "        [-2.3848e-05, -1.5305e-02, -7.6917e-03,  ..., -1.8878e-02,\n",
      "         -7.4080e-03, -1.6498e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 97,  73,   5, 164,  52,   7,  55, 111,  57,  10,  60, 107,  40,  69,\n",
      "         21, 165], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0004, -0.0129, -0.0033,  ..., -0.0147, -0.0046, -0.0142],\n",
      "        [ 0.0005, -0.0144, -0.0047,  ..., -0.0170, -0.0060, -0.0151],\n",
      "        [ 0.0006, -0.0138, -0.0047,  ..., -0.0159, -0.0055, -0.0153],\n",
      "        ...,\n",
      "        [ 0.0002, -0.0144, -0.0048,  ..., -0.0171, -0.0062, -0.0156],\n",
      "        [ 0.0003, -0.0128, -0.0039,  ..., -0.0156, -0.0052, -0.0147],\n",
      "        [ 0.0005, -0.0141, -0.0046,  ..., -0.0170, -0.0062, -0.0155]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  tensor([ 34,  77,   1, 166,  86, 165, 159,  27,  91,  63,  69,  53, 140,  75,\n",
      "        109,   2], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 6.9543e-04, -1.3042e-02, -3.4972e-03,  ..., -1.4790e-02,\n",
      "         -4.8325e-03, -1.4803e-02],\n",
      "        [ 1.5882e-04, -1.3454e-02, -3.7615e-03,  ..., -1.5743e-02,\n",
      "         -5.4504e-03, -1.5302e-02],\n",
      "        [-1.8826e-05, -1.2466e-02, -3.1479e-03,  ..., -1.4515e-02,\n",
      "         -4.6499e-03, -1.4800e-02],\n",
      "        ...,\n",
      "        [ 8.0150e-04, -1.2514e-02, -3.1835e-03,  ..., -1.4405e-02,\n",
      "         -4.5797e-03, -1.4469e-02],\n",
      "        [ 3.2348e-04, -1.2598e-02, -3.1280e-03,  ..., -1.4372e-02,\n",
      "         -4.0637e-03, -1.4389e-02],\n",
      "        [ 4.3556e-04, -1.2859e-02, -3.2964e-03,  ..., -1.4562e-02,\n",
      "         -4.7133e-03, -1.4787e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 77, 111,  67, 139,  97,  51, 155, 142,  33,  94, 147, 111,  63,  38,\n",
      "         91, 150], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-3.3556e-04, -1.3176e-02, -3.9785e-03,  ..., -1.5120e-02,\n",
      "         -5.4875e-03, -1.6076e-02],\n",
      "        [ 1.9988e-04, -1.2521e-02, -3.1838e-03,  ..., -1.4520e-02,\n",
      "         -4.8892e-03, -1.5468e-02],\n",
      "        [ 3.1251e-04, -1.3866e-02, -4.8170e-03,  ..., -1.6628e-02,\n",
      "         -6.4324e-03, -1.6031e-02],\n",
      "        ...,\n",
      "        [ 3.1404e-04, -1.2633e-02, -2.9171e-03,  ..., -1.4281e-02,\n",
      "         -4.3231e-03, -1.5064e-02],\n",
      "        [-8.6246e-05, -1.3689e-02, -3.7922e-03,  ..., -1.5282e-02,\n",
      "         -5.5396e-03, -1.6152e-02],\n",
      "        [ 3.9675e-04, -1.2693e-02, -3.0234e-03,  ..., -1.4104e-02,\n",
      "         -4.5978e-03, -1.4985e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 12,  83, 124,  27,  73,  64,  44, 123,  10, 118,  83, 157, 111,  46,\n",
      "         39,  49], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-2.2007e-04, -1.2414e-02, -3.1169e-03,  ..., -1.3967e-02,\n",
      "         -4.4614e-03, -1.5786e-02],\n",
      "        [ 1.8288e-04, -1.2586e-02, -3.1589e-03,  ..., -1.4494e-02,\n",
      "         -4.6773e-03, -1.5858e-02],\n",
      "        [ 9.3610e-05, -1.2547e-02, -2.9921e-03,  ..., -1.4024e-02,\n",
      "         -4.7067e-03, -1.6139e-02],\n",
      "        ...,\n",
      "        [-2.0629e-04, -1.2252e-02, -2.7011e-03,  ..., -1.3859e-02,\n",
      "         -4.5331e-03, -1.5705e-02],\n",
      "        [ 4.3013e-04, -1.3763e-02, -4.4560e-03,  ..., -1.5110e-02,\n",
      "         -6.2623e-03, -1.6812e-02],\n",
      "        [-7.1170e-05, -1.2106e-02, -2.9988e-03,  ..., -1.4164e-02,\n",
      "         -4.6769e-03, -1.5928e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 86,  78,  16,  15, 140, 140,  97, 152,  99, 110,  60, 109,   2,  33,\n",
      "        129,   4], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0002, -0.0122, -0.0033,  ..., -0.0143, -0.0047, -0.0166],\n",
      "        [-0.0002, -0.0144, -0.0049,  ..., -0.0164, -0.0067, -0.0176],\n",
      "        [-0.0010, -0.0139, -0.0051,  ..., -0.0170, -0.0068, -0.0181],\n",
      "        ...,\n",
      "        [ 0.0002, -0.0122, -0.0028,  ..., -0.0139, -0.0045, -0.0164],\n",
      "        [-0.0007, -0.0126, -0.0038,  ..., -0.0148, -0.0053, -0.0172],\n",
      "        [-0.0003, -0.0124, -0.0030,  ..., -0.0144, -0.0048, -0.0163]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 19,   0, 119,  61,  66,  20, 101, 137,  46, 107,  99,  63,  95,  96,\n",
      "         37,  12], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-6.0766e-04, -1.2419e-02, -3.0676e-03,  ..., -1.4526e-02,\n",
      "         -5.0596e-03, -1.7284e-02],\n",
      "        [-7.9451e-04, -1.3052e-02, -4.0250e-03,  ..., -1.6042e-02,\n",
      "         -6.2152e-03, -1.8668e-02],\n",
      "        [-4.6005e-04, -1.2525e-02, -3.0496e-03,  ..., -1.4169e-02,\n",
      "         -4.7617e-03, -1.6784e-02],\n",
      "        ...,\n",
      "        [-9.1039e-05, -1.6240e-02, -6.0999e-03,  ..., -1.6931e-02,\n",
      "         -8.1969e-03, -2.0298e-02],\n",
      "        [-7.5488e-04, -1.2815e-02, -3.6861e-03,  ..., -1.4809e-02,\n",
      "         -5.6857e-03, -1.7710e-02],\n",
      "        [-5.8062e-04, -1.2330e-02, -2.9498e-03,  ..., -1.4312e-02,\n",
      "         -4.7331e-03, -1.7159e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 67,  62,  94,  59,  37,  69, 111, 115,  79,  46, 114,  35,  97,   7,\n",
      "         54,  72], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0001, -0.0141, -0.0038,  ..., -0.0167, -0.0072, -0.0191],\n",
      "        [-0.0005, -0.0150, -0.0052,  ..., -0.0170, -0.0073, -0.0198],\n",
      "        [-0.0006, -0.0138, -0.0044,  ..., -0.0158, -0.0064, -0.0193],\n",
      "        ...,\n",
      "        [-0.0036, -0.0176, -0.0073,  ..., -0.0202, -0.0098, -0.0226],\n",
      "        [-0.0005, -0.0123, -0.0028,  ..., -0.0139, -0.0047, -0.0178],\n",
      "        [-0.0004, -0.0143, -0.0045,  ..., -0.0157, -0.0065, -0.0198]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([165,   6,  43,  27, 141, 129,  62,  52,  18,  43, 111, 131, 133, 121,\n",
      "          6, 110], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0014, -0.0137, -0.0048,  ..., -0.0168, -0.0082, -0.0209],\n",
      "        [-0.0011, -0.0126, -0.0035,  ..., -0.0158, -0.0065, -0.0201],\n",
      "        [-0.0002, -0.0122, -0.0028,  ..., -0.0141, -0.0050, -0.0182],\n",
      "        ...,\n",
      "        [-0.0005, -0.0122, -0.0029,  ..., -0.0144, -0.0051, -0.0182],\n",
      "        [-0.0010, -0.0135, -0.0040,  ..., -0.0159, -0.0060, -0.0200],\n",
      "        [-0.0007, -0.0120, -0.0031,  ..., -0.0144, -0.0052, -0.0185]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 80, 146,  81,  56, 153, 110, 130,  47, 138, 158, 107, 141,  26,   2,\n",
      "        136,  17], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0007, -0.0156, -0.0075,  ..., -0.0204, -0.0087, -0.0224],\n",
      "        [-0.0019, -0.0158, -0.0056,  ..., -0.0186, -0.0097, -0.0223],\n",
      "        [-0.0002, -0.0119, -0.0024,  ..., -0.0135, -0.0052, -0.0187],\n",
      "        ...,\n",
      "        [-0.0006, -0.0118, -0.0025,  ..., -0.0141, -0.0048, -0.0185],\n",
      "        [-0.0006, -0.0164, -0.0057,  ..., -0.0179, -0.0096, -0.0216],\n",
      "        [-0.0012, -0.0162, -0.0065,  ..., -0.0185, -0.0100, -0.0255]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([121,  10,  99, 128, 104,  92,  91, 106, 153,  27,  26,  24,  53,  89,\n",
      "         71,  99], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0003, -0.0122, -0.0024,  ..., -0.0138, -0.0054, -0.0196],\n",
      "        [-0.0006, -0.0116, -0.0018,  ..., -0.0134, -0.0051, -0.0193],\n",
      "        [ 0.0005, -0.0179, -0.0077,  ..., -0.0186, -0.0120, -0.0253],\n",
      "        ...,\n",
      "        [-0.0012, -0.0140, -0.0042,  ..., -0.0156, -0.0070, -0.0221],\n",
      "        [-0.0005, -0.0120, -0.0020,  ..., -0.0134, -0.0051, -0.0195],\n",
      "        [ 0.0003, -0.0149, -0.0063,  ..., -0.0196, -0.0122, -0.0261]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 43,  36,  33,   5,  96, 130, 159,  75,  24,  86,  68,  94, 125, 134,\n",
      "         27,  31], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0005, -0.0120, -0.0018,  ..., -0.0134, -0.0055, -0.0203],\n",
      "        [-0.0006, -0.0123, -0.0022,  ..., -0.0138, -0.0056, -0.0204],\n",
      "        [-0.0010, -0.0122, -0.0019,  ..., -0.0136, -0.0055, -0.0205],\n",
      "        ...,\n",
      "        [-0.0005, -0.0173, -0.0069,  ..., -0.0174, -0.0133, -0.0286],\n",
      "        [-0.0007, -0.0146, -0.0048,  ..., -0.0164, -0.0089, -0.0223],\n",
      "        [-0.0005, -0.0120, -0.0021,  ..., -0.0137, -0.0052, -0.0201]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 98, 161, 105,  41,  61, 123,  24,  80,  34, 117,  27,  31, 148, 117,\n",
      "         80, 100], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0005, -0.0122, -0.0023,  ..., -0.0137, -0.0057, -0.0207],\n",
      "        [-0.0014, -0.0133, -0.0041,  ..., -0.0143, -0.0068, -0.0228],\n",
      "        [-0.0022, -0.0146, -0.0051,  ..., -0.0166, -0.0074, -0.0243],\n",
      "        ...,\n",
      "        [-0.0012, -0.0149, -0.0042,  ..., -0.0163, -0.0085, -0.0236],\n",
      "        [-0.0020, -0.0151, -0.0063,  ..., -0.0180, -0.0098, -0.0257],\n",
      "        [-0.0011, -0.0127, -0.0023,  ..., -0.0136, -0.0065, -0.0216]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 93, 132, 127,  96,  64, 157,  84, 130, 145,  97, 120, 139,  82, 111,\n",
      "         70,  76], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0014, -0.0132, -0.0030,  ..., -0.0145, -0.0066, -0.0221],\n",
      "        [-0.0011, -0.0142, -0.0031,  ..., -0.0146, -0.0076, -0.0238],\n",
      "        [-0.0011, -0.0157, -0.0043,  ..., -0.0169, -0.0103, -0.0243],\n",
      "        ...,\n",
      "        [-0.0010, -0.0120, -0.0021,  ..., -0.0137, -0.0057, -0.0216],\n",
      "        [-0.0013, -0.0140, -0.0037,  ..., -0.0145, -0.0080, -0.0239],\n",
      "        [-0.0006, -0.0123, -0.0020,  ..., -0.0136, -0.0061, -0.0215]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([152, 159, 149,   9,  37,  38,  99,  29,  64,  64, 102, 113, 158, 109,\n",
      "        109,  43], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0009, -0.0124, -0.0020,  ..., -0.0132, -0.0059, -0.0220],\n",
      "        [-0.0011, -0.0162, -0.0055,  ..., -0.0171, -0.0101, -0.0268],\n",
      "        [-0.0021, -0.0165, -0.0051,  ..., -0.0170, -0.0101, -0.0257],\n",
      "        ...,\n",
      "        [-0.0013, -0.0124, -0.0020,  ..., -0.0136, -0.0062, -0.0223],\n",
      "        [-0.0008, -0.0126, -0.0018,  ..., -0.0131, -0.0058, -0.0218],\n",
      "        [-0.0008, -0.0124, -0.0020,  ..., -0.0130, -0.0061, -0.0219]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 44, 133, 134,  87,   8, 140, 116,  79, 149,  21, 164, 111, 155, 165,\n",
      "         19, 138], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0011, -0.0123, -0.0018,  ..., -0.0132, -0.0064, -0.0226],\n",
      "        [-0.0013, -0.0121, -0.0025,  ..., -0.0136, -0.0065, -0.0230],\n",
      "        [-0.0031, -0.0191, -0.0064,  ..., -0.0189, -0.0137, -0.0312],\n",
      "        ...,\n",
      "        [-0.0023, -0.0154, -0.0041,  ..., -0.0160, -0.0104, -0.0274],\n",
      "        [-0.0005, -0.0127, -0.0015,  ..., -0.0129, -0.0062, -0.0224],\n",
      "        [-0.0011, -0.0134, -0.0032,  ..., -0.0150, -0.0083, -0.0243]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  tensor([104, 140, 111,  89, 118,  89,  11,  43,  56, 123, 156,  46, 121, 151,\n",
      "         80,  54], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0014, -0.0122, -0.0014,  ..., -0.0126, -0.0059, -0.0227],\n",
      "        [-0.0013, -0.0156, -0.0046,  ..., -0.0165, -0.0112, -0.0289],\n",
      "        [-0.0018, -0.0122, -0.0018,  ..., -0.0131, -0.0065, -0.0235],\n",
      "        ...,\n",
      "        [-0.0013, -0.0126, -0.0019,  ..., -0.0133, -0.0065, -0.0235],\n",
      "        [-0.0023, -0.0176, -0.0072,  ..., -0.0180, -0.0121, -0.0276],\n",
      "        [-0.0012, -0.0123, -0.0019,  ..., -0.0132, -0.0064, -0.0231]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([143,  76,   0,  51,  56,  23, 110,  40,  68, 106,  83, 157,  71,  58,\n",
      "          3, 100], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0014, -0.0122, -0.0019,  ..., -0.0130, -0.0071, -0.0241],\n",
      "        [-0.0015, -0.0129, -0.0018,  ..., -0.0132, -0.0069, -0.0239],\n",
      "        [-0.0008, -0.0154, -0.0038,  ..., -0.0152, -0.0101, -0.0274],\n",
      "        ...,\n",
      "        [-0.0016, -0.0126, -0.0021,  ..., -0.0130, -0.0070, -0.0238],\n",
      "        [-0.0010, -0.0188, -0.0072,  ..., -0.0181, -0.0133, -0.0300],\n",
      "        [-0.0019, -0.0134, -0.0022,  ..., -0.0138, -0.0073, -0.0253]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 80,  69, 115,  73, 121, 129, 143, 151,  53,  79,   0,  51,  57, 133,\n",
      "         94,  86], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0036, -0.0192, -0.0104,  ..., -0.0195, -0.0141, -0.0320],\n",
      "        [-0.0025, -0.0145, -0.0045,  ..., -0.0149, -0.0093, -0.0279],\n",
      "        [-0.0022, -0.0170, -0.0056,  ..., -0.0161, -0.0108, -0.0296],\n",
      "        ...,\n",
      "        [-0.0015, -0.0139, -0.0030,  ..., -0.0141, -0.0084, -0.0260],\n",
      "        [-0.0013, -0.0150, -0.0043,  ..., -0.0149, -0.0097, -0.0274],\n",
      "        [-0.0016, -0.0132, -0.0022,  ..., -0.0127, -0.0070, -0.0249]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([153, 151,  62,  51,   0, 162, 145, 127,  67,  85,  90,  64, 151,  47,\n",
      "         51, 141], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0012, -0.0132, -0.0020,  ..., -0.0130, -0.0075, -0.0253],\n",
      "        [-0.0015, -0.0132, -0.0019,  ..., -0.0128, -0.0076, -0.0251],\n",
      "        [-0.0021, -0.0171, -0.0054,  ..., -0.0166, -0.0118, -0.0302],\n",
      "        ...,\n",
      "        [-0.0008, -0.0135, -0.0018,  ..., -0.0129, -0.0074, -0.0250],\n",
      "        [-0.0023, -0.0151, -0.0044,  ..., -0.0146, -0.0095, -0.0283],\n",
      "        [-0.0010, -0.0130, -0.0029,  ..., -0.0132, -0.0080, -0.0257]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([108,  54, 144,   2,  50, 140,  79,  18,  27,   7,  74,   6,  53, 148,\n",
      "         31,  92], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0013, -0.0154, -0.0044,  ..., -0.0141, -0.0097, -0.0291],\n",
      "        [-0.0009, -0.0132, -0.0017,  ..., -0.0127, -0.0081, -0.0255],\n",
      "        [-0.0009, -0.0130, -0.0024,  ..., -0.0130, -0.0081, -0.0262],\n",
      "        ...,\n",
      "        [-0.0012, -0.0145, -0.0031,  ..., -0.0134, -0.0087, -0.0278],\n",
      "        [-0.0009, -0.0132, -0.0022,  ..., -0.0125, -0.0080, -0.0261],\n",
      "        [-0.0013, -0.0139, -0.0029,  ..., -0.0132, -0.0084, -0.0270]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([106,  77,  34, 115,  29,  72,  82,  77,  30,   7,  24,  25, 102,  26,\n",
      "         24, 152], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0027, -0.0207, -0.0078,  ..., -0.0161, -0.0153, -0.0349],\n",
      "        [-0.0012, -0.0152, -0.0041,  ..., -0.0143, -0.0101, -0.0292],\n",
      "        [-0.0008, -0.0133, -0.0024,  ..., -0.0131, -0.0082, -0.0269],\n",
      "        ...,\n",
      "        [-0.0009, -0.0135, -0.0021,  ..., -0.0132, -0.0081, -0.0268],\n",
      "        [-0.0003, -0.0139, -0.0021,  ..., -0.0124, -0.0082, -0.0268],\n",
      "        [-0.0005, -0.0130, -0.0018,  ..., -0.0126, -0.0086, -0.0263]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 39,  42, 162, 109, 160,  77, 123,  67,  46,  44, 158, 142, 138,  58,\n",
      "        130,  60], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0008, -0.0161, -0.0047,  ..., -0.0144, -0.0127, -0.0307],\n",
      "        [-0.0008, -0.0143, -0.0024,  ..., -0.0131, -0.0087, -0.0281],\n",
      "        [-0.0001, -0.0140, -0.0024,  ..., -0.0127, -0.0087, -0.0275],\n",
      "        ...,\n",
      "        [-0.0002, -0.0143, -0.0020,  ..., -0.0131, -0.0089, -0.0278],\n",
      "        [ 0.0005, -0.0171, -0.0049,  ..., -0.0151, -0.0115, -0.0313],\n",
      "        [-0.0001, -0.0139, -0.0017,  ..., -0.0126, -0.0084, -0.0270]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([120, 116,  87, 160,  33,  77,  13,  45, 148,  93, 162, 102, 135,  57,\n",
      "        141,   1], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-6.1065e-04, -1.7752e-02, -5.7992e-03,  ..., -1.6576e-02,\n",
      "         -1.4356e-02, -3.3506e-02],\n",
      "        [ 1.3132e-05, -1.4861e-02, -3.1145e-03,  ..., -1.2960e-02,\n",
      "         -9.0108e-03, -2.8197e-02],\n",
      "        [-5.1765e-04, -1.3710e-02, -2.0805e-03,  ..., -1.3189e-02,\n",
      "         -8.9360e-03, -2.8313e-02],\n",
      "        ...,\n",
      "        [-2.0072e-04, -1.4203e-02, -2.3119e-03,  ..., -1.3185e-02,\n",
      "         -8.8329e-03, -2.7873e-02],\n",
      "        [-7.5975e-04, -1.5078e-02, -2.7588e-03,  ..., -1.3823e-02,\n",
      "         -1.0369e-02, -2.9802e-02],\n",
      "        [-4.1502e-04, -1.4551e-02, -2.5017e-03,  ..., -1.2735e-02,\n",
      "         -9.1771e-03, -2.8344e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 99, 144, 103,  32,  26, 162, 105,  82,  38,  24,  43,  98,  62, 159,\n",
      "         94, 135], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 0.0009, -0.0263, -0.0114,  ..., -0.0197, -0.0235, -0.0397],\n",
      "        [-0.0003, -0.0147, -0.0021,  ..., -0.0133, -0.0095, -0.0289],\n",
      "        [-0.0004, -0.0152, -0.0031,  ..., -0.0143, -0.0104, -0.0301],\n",
      "        ...,\n",
      "        [-0.0010, -0.0190, -0.0063,  ..., -0.0176, -0.0146, -0.0355],\n",
      "        [-0.0002, -0.0170, -0.0048,  ..., -0.0152, -0.0120, -0.0329],\n",
      "        [-0.0001, -0.0144, -0.0023,  ..., -0.0131, -0.0098, -0.0291]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([128, 126,  35,  34, 159,  73, 125,  89, 155, 129, 102,  14,  71, 126,\n",
      "         69, 116], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0008, -0.0206, -0.0071,  ..., -0.0177, -0.0175, -0.0376],\n",
      "        [-0.0001, -0.0166, -0.0045,  ..., -0.0153, -0.0141, -0.0341],\n",
      "        [ 0.0002, -0.0186, -0.0060,  ..., -0.0165, -0.0147, -0.0359],\n",
      "        ...,\n",
      "        [ 0.0002, -0.0169, -0.0048,  ..., -0.0152, -0.0132, -0.0335],\n",
      "        [-0.0006, -0.0175, -0.0061,  ..., -0.0153, -0.0128, -0.0344],\n",
      "        [-0.0002, -0.0140, -0.0016,  ..., -0.0130, -0.0097, -0.0296]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([117, 124,  51, 109, 142, 143,  48,  94,  51,  19,  48, 131,  23,  43,\n",
      "         35,  85], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-0.0007, -0.0176, -0.0046,  ..., -0.0164, -0.0138, -0.0330],\n",
      "        [-0.0005, -0.0144, -0.0025,  ..., -0.0136, -0.0099, -0.0310],\n",
      "        [-0.0003, -0.0168, -0.0040,  ..., -0.0154, -0.0126, -0.0340],\n",
      "        ...,\n",
      "        [ 0.0001, -0.0146, -0.0027,  ..., -0.0133, -0.0101, -0.0305],\n",
      "        [-0.0001, -0.0190, -0.0053,  ..., -0.0167, -0.0148, -0.0360],\n",
      "        [-0.0004, -0.0167, -0.0042,  ..., -0.0151, -0.0122, -0.0332]],\n",
      "       device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 89,  53,  86,  58,  72,  20, 109,  42,  64,  13, 154, 141,  95,  34,\n",
      "        164, 104], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[-1.6978e-04, -1.7026e-02, -4.8496e-03,  ..., -1.5712e-02,\n",
      "         -1.3235e-02, -3.4371e-02],\n",
      "        [ 4.3973e-05, -1.4048e-02, -2.5953e-03,  ..., -1.3472e-02,\n",
      "         -1.0874e-02, -3.1303e-02],\n",
      "        [-2.4729e-04, -1.4268e-02, -3.0259e-03,  ..., -1.3525e-02,\n",
      "         -1.0912e-02, -3.1484e-02],\n",
      "        ...,\n",
      "        [-5.7746e-04, -1.4231e-02, -2.2932e-03,  ..., -1.3547e-02,\n",
      "         -1.0146e-02, -3.0685e-02],\n",
      "        [ 2.2293e-04, -1.4189e-02, -1.9113e-03,  ..., -1.3407e-02,\n",
      "         -1.0380e-02, -3.0293e-02],\n",
      "        [ 2.9442e-04, -1.4960e-02, -2.3138e-03,  ..., -1.3937e-02,\n",
      "         -1.0954e-02, -3.0794e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n",
      "labels:  tensor([ 72,  51, 119,  53,  91,  65, 151,  36,  98,  43,  78, 127,  98,  18,\n",
      "         54, 119], device='cuda:2') torch.Size([16])\n",
      "logits:  tensor([[ 1.0257e-05, -1.8044e-02, -4.9179e-03,  ..., -1.6376e-02,\n",
      "         -1.4973e-02, -3.6721e-02],\n",
      "        [-7.4715e-04, -1.7236e-02, -5.0118e-03,  ..., -1.5624e-02,\n",
      "         -1.4109e-02, -3.6370e-02],\n",
      "        [-5.0003e-04, -1.4547e-02, -2.6130e-03,  ..., -1.3732e-02,\n",
      "         -1.0544e-02, -3.2431e-02],\n",
      "        ...,\n",
      "        [ 3.7026e-04, -1.4880e-02, -2.4902e-03,  ..., -1.3366e-02,\n",
      "         -1.1310e-02, -3.2177e-02],\n",
      "        [-5.8626e-04, -1.4834e-02, -2.7864e-03,  ..., -1.3747e-02,\n",
      "         -1.1126e-02, -3.2172e-02],\n",
      "        [ 5.7350e-04, -1.4426e-02, -2.5854e-03,  ..., -1.3341e-02,\n",
      "         -1.1014e-02, -3.1431e-02]], device='cuda:2', grad_fn=<MeanBackward1>) torch.Size([16, 168])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-42e36038958c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-4bb048b21b5b>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(data, model, criterion, device, count, which_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logits: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Get the class id with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "\n",
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model1_initial/initial_weight.pth'))\n",
    "best_model_path = \"../checkpoint_GAT/best_model_GAT_transR_50.pt\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=18, num_training_steps=total_steps)\n",
    "\n",
    "# T_max control the period of the lr changing -> set 1/10 first\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=36, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 50\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        num_batches += 1\n",
    "        loss, accuracy, _ = model_fn(data, model, criterion, device, num_batches, which_type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "        \n",
    "#     scheduler.step()\n",
    "    add_log_msg(f\"total batches: {num_batches}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloaders['valid'], desc=\"Validation\", position=0, leave=True):\n",
    "            loss, accuracy, _ = model_fn(data, model, criterion, device, num_batches, which_type='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "    \n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}\\n')\n",
    "    \n",
    "            \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "            add_log_msg(\"Find a better model!!\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        \n",
    "#         print(best_model_path)\n",
    "\n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"============================== Early stopping ==================================\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained model\n",
    "pretrained_model_path = '../checkpoint_GAT/best_model_GAT_transR_50.pt'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dataloaders['test'], desc=\"Testing\", position=0, leave=True):\n",
    "#         print(f\"data:{data[1]}\")\n",
    "        loss, accuracy, predicted = model_fn(data, model, criterion, device, count, which_type='test')\n",
    "        labels = data[1].to(device)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        if count % 5000 == 0:\n",
    "            add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "            add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %\\n\\n\\n')\n",
    "\n",
    "\n",
    "# ======================================== handlig the output excel files ========================================\n",
    "mapping_file = './new_mapping.txt'\n",
    "label_mapping = {}\n",
    "with open(mapping_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(': ')\n",
    "        label_mapping[int(parts[1])] = parts[0]\n",
    "        \n",
    "# 将映射后的标签应用到true和predicted标签列表\n",
    "mapped_true_labels = [label_mapping[label] for label in true_labels]\n",
    "mapped_predicted_labels = [label_mapping[label] for label in predicted_labels]\n",
    "\n",
    "# 生成Scikit-learn报告信息的DataFrame\n",
    "report_data = classification_report(mapped_true_labels, mapped_predicted_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "# mapped_true_labels_np = np.array(mapped_true_labels)\n",
    "# mapped_predicted_labels_np = np.array(mapped_predicted_labels)\n",
    "\n",
    "# print(\"mapped_true_labels 的形状:\", mapped_true_labels_np.shape)\n",
    "# print(\"mapped_predicted_labels 的形状:\", mapped_predicted_labels_np.shape)\n",
    "\n",
    "report_folder = 'classification_report'\n",
    "os.makedirs(report_folder, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    report_filename = f'classification_report-transR_50-{count}.xlsx'\n",
    "    labels_filename = f'mapped_true_predicted_labels-transR_50-{count}.xlsx'\n",
    "    \n",
    "    report_path = os.path.join(report_folder, report_filename)\n",
    "    labels_path = os.path.join(report_folder, labels_filename)\n",
    "    \n",
    "    if not os.path.exists(report_path) and not os.path.exists(labels_path):\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "report_df.to_excel(report_path, index_label='Label')\n",
    "\n",
    "mapped_labels_df = pd.DataFrame({'true_label': mapped_true_labels, 'predicted_label': mapped_predicted_labels})\n",
    "mapped_labels_df.to_excel(labels_path, index=False)\n",
    "\n",
    "add_log_msg(f\"report path: {report_path}\")\n",
    "add_log_msg(f\"label path: {labels_path}\")\n",
    "\n",
    "mapped_report = classification_report(mapped_true_labels, mapped_predicted_labels)\n",
    "add_log_msg(f\"mapped_report:\\n{mapped_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
