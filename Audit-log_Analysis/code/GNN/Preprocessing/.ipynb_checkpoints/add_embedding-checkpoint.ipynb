{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load embedding function\n",
    "def load_embedding(input_embedding_name, model):\n",
    "    if model.startswith('trans'):\n",
    "        with open(input_embedding_name) as f:\n",
    "            data = json.load(f)\n",
    "        ent_embeddings = np.array(data['ent_embeddings.weight'])\n",
    "        rel_embeddings = np.array(data['rel_embeddings.weight'])\n",
    "        return ent_embeddings, rel_embeddings\n",
    "    \n",
    "    elif model == 'secureBERT':\n",
    "        ent_embeddings = np.empty((0, 768), dtype=np.float32)\n",
    "        for filename in sorted(os.listdir(input_embedding_name)):\n",
    "            print(filename)\n",
    "\n",
    "            if not filename.startswith('embeddings_chunk'):\n",
    "                continue\n",
    "\n",
    "            embedding = np.load(f'{input_embedding_name}/{filename}')\n",
    "\n",
    "            print(ent_embeddings.shape, embedding.shape)\n",
    "\n",
    "            ent_embeddings = np.concatenate((ent_embeddings, embedding), axis=0)\n",
    "            print(filename, ent_embeddings.shape)\n",
    "\n",
    "        print(f'Reducing entity embedding to ({DIM},)')\n",
    "        print(ent_embeddings.shape, '->', end=' ')\n",
    "        pca = PCA(n_components=DIM)\n",
    "        ent_embeddings = pca.fit_transform(ent_embeddings)\n",
    "        print(ent_embeddings.shape)\n",
    "\n",
    "        rel_embeddings = np.load(f'{input_embedding_name}/relation.npy')\n",
    "        print(f'Reducing relation embedding to ({len(rel_embeddings)},)')\n",
    "        print(rel_embeddings.shape, '->', end=' ')\n",
    "        pca = PCA(n_components=len(rel_embeddings))\n",
    "        rel_embeddings = pca.fit_transform(rel_embeddings)\n",
    "        print(rel_embeddings.shape)\n",
    "        return ent_embeddings, rel_embeddings\n",
    "    else:\n",
    "        print('Error!!')\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a669c9e3e4404990113c6fe34cc2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_new/graph/graph_without_benign.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-476e919a5a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_new/graph/graph_without_benign.jsonl'"
     ]
    }
   ],
   "source": [
    "embedding_files = [\"../data_new/source_data/embedding/secureBERT\"]\n",
    "model = 'secureBERT'\n",
    "DIM = 250\n",
    "\n",
    "# 输入文件列表\n",
    "input_filenames = [\"../data_new/graph/with_benign/graph_benign.jsonl\"]\n",
    "\n",
    "for input_filename in tqdm(input_filenames):\n",
    "    print(\"Start!\")\n",
    "    base, ext = os.path.splitext(input_filename)\n",
    "    \n",
    "    with open(input_filename, \"r\") as f:\n",
    "        input_data = list(f)\n",
    "\n",
    "    for embedding_file in tqdm(embedding_files):\n",
    "        output_filename = f\"{embedding_file.replace('.json', '_embedded').replace('.vec', '')}{ext}\"\n",
    "        print(f\"output file name: {output_filename}\")\n",
    "\n",
    "        with open(output_filename, \"w\") as out_file:\n",
    "            model = embedding_file.split('/')[-1].split('_')[0]\n",
    "            ent_embeddings, rel_embeddings = load_embedding(embedding_file, model)\n",
    "            # ...\n",
    "\n",
    "            for line, data in tqdm(zip(input_data, input_data)):\n",
    "                data = json.loads(data.strip())\n",
    "\n",
    "                # Replace node_feat and edge_attr with embeddings\n",
    "                data[\"node_feat\"] = [ent_embeddings[node_id].tolist() if model == 'secureBERT' else ent_embeddings[node_id] for node_id in data[\"node_feat\"]]\n",
    "                data[\"edge_attr\"] = [rel_embeddings[edge_id].tolist() for edge_id in data[\"edge_attr\"]]\n",
    "\n",
    "                # Convert the data back to a JSON string and write to the output file\n",
    "                out_file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
