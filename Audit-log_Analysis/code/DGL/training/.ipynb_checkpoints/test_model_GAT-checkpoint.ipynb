{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GAT\n",
    "- use DGL\n",
    "- test some model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the GPU and assign the GPU by the best memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_free_gpu():\n",
    "    try:\n",
    "        # Run nvidia-smi command to get GPU details\n",
    "        _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "        command = \"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\"\n",
    "        memory_free_info = _output_to_list(subprocess.check_output(command.split())) \n",
    "        memory_free_values = [int(x) for i, x in enumerate(memory_free_info)]\n",
    "        \n",
    "        # Get the GPU with the maximum free memory\n",
    "        best_gpu_id = memory_free_values.index(max(memory_free_values))\n",
    "        return best_gpu_id\n",
    "    except:\n",
    "        # If any exception occurs, default to GPU 0 (this handles cases where nvidia-smi isn't installed)\n",
    "        return 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get the best GPU ID based on free memory and set it\n",
    "    best_gpu_id = get_free_gpu()\n",
    "    device = torch.device(f\"cuda:{best_gpu_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed = 8787):\n",
    "    torch.manual_seed(seed)\n",
    "    # random.seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, device):\n",
    "        self.data_list = data_list\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "\n",
    "        g = dgl.graph((th.tensor(data[\"edge_index\"][0]), th.tensor(data[\"edge_index\"][1])), num_nodes=data[\"num_nodes\"]).to(self.device)\n",
    "\n",
    "        g.ndata['feat'] = th.tensor(data[\"node_feat\"]).to(self.device)\n",
    "        g.edata['feat'] = th.tensor(data[\"edge_attr\"]).to(self.device)  # Add edge features to graph\n",
    "\n",
    "        return g, th.tensor(data[\"label\"]).to(self.device)\n",
    "\n",
    "\n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0b1281d6a491590a0c5c48bdb8f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data/test_triplet/repeated_test_train.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87898c250fb244bb84cac5959b3d2e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data/test_triplet/repeated_test_valid.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ef12304b734650ad3404b76cf0458f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_processing/dgl/data/test_triplet/repeated_test_test.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ecc71e8e3c4036ae3241d7475b16c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "datasets = ['train', 'valid', 'test']\n",
    "dataset_data = {}\n",
    "\n",
    "# 1. 加載datasets\n",
    "for dataset_name in tqdm(datasets):\n",
    "#     file_path = f\"../../data_processing/dgl/data/test_graph/repeated_{dataset_name}.jsonl\"\n",
    "    file_path = f\"../../data_processing/dgl/data/test_triplet/repeated_test_{dataset_name}.jsonl\"\n",
    "    \n",
    "    print(file_path)\n",
    "    with open(file_path) as f:\n",
    "        data_list = [json.loads(line) for line in tqdm(f, position=0, leave=True)]\n",
    "    \n",
    "    dataset_data[dataset_name] = GraphDataset(data_list, device)\n",
    "\n",
    "print(\"Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f80024db8d0>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7f80024db588>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f80024db278>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataloaders(batch_size, shuffle=False):\n",
    "    dataloaders = {}\n",
    "    for dataset_name, dataset in dataset_data.items():\n",
    "        dataloaders[dataset_name] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate)\n",
    "    return dataloaders\n",
    "\n",
    "dataloaders = create_dataloaders(4)\n",
    "# dataloaders = create_dataloaders(16)\n",
    "\n",
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turn the print message to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log_message/0816_01:51_GAT_model.log\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "formatted_time = now.strftime(\"%m%d_%H:%M\")\n",
    "\n",
    "log_file_path = f\"../log_message/{formatted_time}_GAT_model.log\"\n",
    "\n",
    "def add_log_msg(msg, log_file_path=log_file_path):\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}\\n')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")}# {msg}')\n",
    "\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- Try teh model with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GAT(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden_dim, out_dim, num_heads, dropout_prob=0.25):\n",
    "#         super(GAT, self).__init__()\n",
    "        \n",
    "#         # do not check the zero in_degree since we have all the complete graph\n",
    "#         self.layer1 = GATConv(in_dim, hidden_dim, num_heads=num_heads, activation=F.relu, allow_zero_in_degree=True)\n",
    "# #         self.layer2 = GATConv(hidden_dim * num_heads, hidden_dim, num_heads=num_heads, allow_zero_in_degree=True)\n",
    "# #         self.layer3 = GATConv(hidden_dim * num_heads, out_dim, num_heads=num_heads, allow_zero_in_degree=True)\n",
    "\n",
    "#         self.layer2 = GATConv(hidden_dim * num_heads, hidden_dim, num_heads=1, allow_zero_in_degree=True)\n",
    "#         # input_dim of the layer 3 is hidden_dim\n",
    "#         self.layer3 = GATConv(hidden_dim, out_dim, num_heads=1, allow_zero_in_degree=True) \n",
    "         \n",
    "#         # Adding Batch Normalization after each GAT layer\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "# #         self.batchnorm3 = nn.BatchNorm1d(out_dim) # there's no need to use BN3\n",
    "        \n",
    "#         # Adding Dropout for regularization\n",
    "#         self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "#     def forward(self, g, h):\n",
    "#         # Layer 1\n",
    "#         h1 = self.layer1(g, h)\n",
    "#         h1 = h1.view(h1.shape[0], -1)\n",
    "#         h1 = F.relu(h1)\n",
    "#         h1 = self.dropout(h1)\n",
    "        \n",
    "#         # Layer 2\n",
    "#         h2 = self.layer2(g, h1)\n",
    "#         h2 = h2.view(h2.shape[0], -1)\n",
    "#         h2 = F.relu(h2)\n",
    "#         h2 = self.dropout(h2)\n",
    "\n",
    "#         # Layer 3\n",
    "#         h3 = self.layer3(g, h2).squeeze(1)\n",
    "#         h3 = self.dropout(h3)\n",
    "        \n",
    "#         '''\n",
    "#         問題出現在 h3 = self.layer3(g, h2).squeeze(1)。\n",
    "#         在這裡，你應該得到一個形狀為 [N, num_heads, out_dim] 的tensor，但你使用了 squeeze(1)，\n",
    "#         如果 num_heads 是 1，你會得到 [N, out_dim]，這樣是沒問題的。\n",
    "#         但如果 num_heads 不是 1，那麼squeeze操作不會更改tensor的形狀，結果仍然是 [N, num_heads, out_dim]。\n",
    "#         因此，對這個tensor使用 batch normalization 會導致維度不匹配。\n",
    "#         '''\n",
    "        \n",
    "#         # output layer so not need the BN\n",
    "#         # 不使用BN: GAT本身已經有注意力機制，所以BN不一定是必需的，尤其是在輸出層。\n",
    "#         # h3 = self.batchnorm3(h3)\n",
    "        \n",
    "\n",
    "\n",
    "#         # Aggregate\n",
    "#         g.ndata['h_out'] = h3\n",
    "#         h_agg = dgl.mean_nodes(g, feat='h_out')\n",
    "#         return h_agg\n",
    "\n",
    "    \n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads, dropout_prob=0.25):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATConv(in_dim, hidden_dim, num_heads=num_heads, activation=F.relu, allow_zero_in_degree=True)\n",
    "        self.layer2 = GATConv(hidden_dim * num_heads, hidden_dim, num_heads=1, allow_zero_in_degree=True)\n",
    "        self.layer3 = GATConv(hidden_dim, out_dim, num_heads=1, allow_zero_in_degree=True) \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        h1 = self.layer1(g, h)\n",
    "        h1 = h1.view(h1.shape[0], -1)\n",
    "        h1 = F.relu(h1)\n",
    "        h1 = self.dropout(h1)\n",
    "        \n",
    "        h2 = self.layer2(g, h1)\n",
    "        h2 = h2.view(h2.shape[0], -1)\n",
    "        h2 = F.relu(h2)\n",
    "        h2 = self.dropout(h2)\n",
    "        \n",
    "#         h3 = self.layer3(g, h2).squeeze(1)\n",
    "        h3 = self.layer3(g, h2)\n",
    "        h3 = self.dropout(h3)\n",
    "        \n",
    "        # Store the output as a new node feature\n",
    "        g.ndata['h_out'] = h3\n",
    "\n",
    "        # Use mean pooling to aggregate this new node feature\n",
    "        h_agg = dgl.mean_nodes(g, feat='h_out')\n",
    "        return h_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Forward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(data, model, criterion, device, count=1, type='train'):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "    batched_g, labels = data\n",
    "    batched_g = batched_g.to(device)\n",
    "    \n",
    "    labels = labels.to(device)\n",
    "    logits = model(batched_g, batched_g.ndata['feat'].float()) # for GAT\n",
    "    logits = logits.mean(dim=1)\n",
    "    \n",
    "    loss = criterion(logits, labels)\n",
    "\n",
    "    # Get the class id with the highest probability.\n",
    "    preds = logits.argmax(1)\n",
    "    \n",
    "    # Compute accuracy.\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "    \n",
    "    if type == 'validation':\n",
    "        add_log_msg(f\"labels of validation: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of validation: {preds} {preds.shape}\")\n",
    "        \n",
    "    elif type == 'test':\n",
    "        add_log_msg(f\"labels of test: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of test: {preds} {preds.shape}\")\n",
    "        \n",
    "    if count % 5000 == 0: \n",
    "        add_log_msg(f\"labels of {count}: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted of {count}: {preds} {preds.shape}\")\n",
    "        \n",
    "    return loss, accuracy, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the seed and save the model.state_dict that contains the initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "torch.save(model.state_dict(), 'model2_initial/initial_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1175,  0.2907, -0.0767,  ...,  0.1641,  0.0469,  0.3905],\n",
       "        [-0.0830,  0.0728, -0.0144,  ...,  0.3920, -0.1551, -0.2670],\n",
       "        [ 0.0387,  0.1571, -0.0294,  ..., -0.0508,  0.0537, -0.0706],\n",
       "        ...,\n",
       "        [ 0.1836, -0.0661,  0.0684,  ...,  0.2051, -0.0828,  0.0872],\n",
       "        [-0.2078, -0.1177,  0.1866,  ..., -0.0459, -0.1525,  0.2588],\n",
       "        [-0.1493,  0.0084,  0.2190,  ..., -0.1631,  0.2102,  0.0538]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer2.fc.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if model really load the model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "# model.load_state_dict(torch.load('model2_initial/initial_weight.pth'))\n",
    "# model.layer2.fc.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 26 APs same as above x 5000 times and batch size = 4, model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1956e22fe8c493d95c66fd9927d5866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf8144ce76f4bc096975f2087abf235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/22500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 22500\n",
      "Epoch 0 | Train Loss: 3.2769 | Train Accuracy: 0.0968\n",
      "Validation Loss: 15.4444 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d53d190b18943ebb732e2cc8b0c8793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/22500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 22500\n",
      "Epoch 1 | Train Loss: 2.8865 | Train Accuracy: 0.1606\n",
      "Validation Loss: 17.0036 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8c01549fc243e185eb504746b203bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/22500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 22500\n",
      "Epoch 2 | Train Loss: 2.8316 | Train Accuracy: 0.1755\n",
      "Validation Loss: 19.9229 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924c79bd7f1c4179985ab309c4c8a02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/22500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 22500\n",
      "Epoch 3 | Train Loss: 2.8089 | Train Accuracy: 0.1822\n",
      "Validation Loss: 22.6599 | Validation Accuracy: 0.0000\n",
      "Early stopping\n",
      "labels: tensor([69, 70, 69, 70, 69, 70, 69, 70], device='cuda:0') torch.Size([8])\n",
      "predicted: tensor([128, 132, 128, 132, 128, 132, 128, 132], device='cuda:0') torch.Size([8])\n",
      "labels: tensor([69, 70], device='cuda:0') torch.Size([2])\n",
      "predicted: tensor([128, 132], device='cuda:0') torch.Size([2])\n",
      "Test Accuracy: 0 %\n"
     ]
    }
   ],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model2_initial/initial_weight.pth'))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=total_steps)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 18\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    for data in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        \n",
    "        count += 1\n",
    "        loss, accuracy, _ = model_fn(data, model, criterion, device, count, type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "#     scheduler.step()\n",
    "    add_log_msg(f\"total count: {count}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in dataloaders['valid']:\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, type=='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "#     print(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    \n",
    "    \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "#         torch.save(model.state_dict(), 'best_model.pth')\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, f\"../checkpoint_GAT/best_model_{epoch}.pt\")\n",
    "    \n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "            \n",
    "# Testing Part\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        loss, accuracy, predicted = model_fn(data, model, criterion, device, type=='test')\n",
    "        labels = data[1].to(device)  # Assuming labels are the second element in the tuple\n",
    "        \n",
    "#         print(f\"labels: {labels}\", labels.shape)\n",
    "#         print(f\"predicted: {predicted}\", predicted.shape)\n",
    "        \n",
    "        add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "        \n",
    "        total += labels.size(0) # label.size(0) is the batch size\n",
    "        correct += (predicted == labels).sum().item() \n",
    "        # (predicted == labels).sum() would return how many of them are equal; \n",
    "        # .item() would make the tensor to the regular value\n",
    "        \n",
    "#     print('Test Accuracy: %d %%' % (100 * correct / total))\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2 with triplet test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c06c03a9f44a38977503b10b78004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbf9e5f33584d46ad747c6efd446d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 18:52:52# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:52:52# predicted of 5000: tensor([71, 76, 82, 71], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:54:48# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:54:48# predicted of 10000: tensor([82, 76, 89, 76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:56:40# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:56:40# predicted of 15000: tensor([71, 76, 76, 76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:58:33# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 18:58:33# predicted of 20000: tensor([ 79, 101, 101,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:00:29# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:00:29# predicted of 25000: tensor([ 79, 101,  71,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:01:55# total count: 28750\n",
      "08/15/2023, 19:01:55# Epoch 0 | Train Loss: 3.7425 | Train Accuracy: 0.0334\n",
      "08/15/2023, 19:01:55# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:01:55# predicted of False: tensor([71, 71, 71, 71], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:01:55# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:01:55# predicted of False: tensor([71, 71, 71, 71], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:01:55# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:01:55# predicted of False: tensor([71], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:01:55# Validation Loss: 3.1533 | Validation Accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff6f7d0042d466e8ae570488c31c5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:03:51# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:03:51# predicted of 5000: tensor([ 79,  82, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:05:45# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:05:45# predicted of 10000: tensor([100,  81,  76,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:07:38# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:07:38# predicted of 15000: tensor([81, 88, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:09:34# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:09:34# predicted of 20000: tensor([88, 88, 88, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:11:27# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:11:27# predicted of 25000: tensor([ 88,  88,  78, 102], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:12:55# total count: 28750\n",
      "08/15/2023, 19:12:55# Epoch 1 | Train Loss: 3.2954 | Train Accuracy: 0.0442\n",
      "08/15/2023, 19:12:55# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:12:55# predicted of False: tensor([84, 84, 84, 84], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:12:55# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:12:55# predicted of False: tensor([84, 84, 84, 84], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:12:55# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:12:55# predicted of False: tensor([84], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:12:55# Validation Loss: 3.1349 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bf1473eccd40dc96e32c4caaadce80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:14:50# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:14:50# predicted of 5000: tensor([82, 90, 71, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:16:44# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:16:44# predicted of 10000: tensor([103,  79, 104,  82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:18:33# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:18:33# predicted of 15000: tensor([77, 77, 82, 82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:20:25# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:20:25# predicted of 20000: tensor([119,  82, 119,  82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:22:22# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:22:22# predicted of 25000: tensor([102, 102, 100,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:23:46# total count: 28750\n",
      "08/15/2023, 19:23:46# Epoch 2 | Train Loss: 3.2815 | Train Accuracy: 0.0408\n",
      "08/15/2023, 19:23:46# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:23:46# predicted of False: tensor([102, 102, 102, 102], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:23:46# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:23:46# predicted of False: tensor([102, 102, 102, 102], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:23:46# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:23:46# predicted of False: tensor([102], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:23:46# Validation Loss: 3.1357 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bd22661f9a478c80bda8bb638c7ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:25:38# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:25:38# predicted of 5000: tensor([78, 77, 79, 78], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:27:32# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:27:32# predicted of 10000: tensor([101,  82,  80, 101], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:29:29# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:29:29# predicted of 15000: tensor([102, 100,  85, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:31:24# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:31:24# predicted of 20000: tensor([100, 100,  71, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:33:21# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:33:21# predicted of 25000: tensor([100,  85, 100, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:34:48# total count: 28750\n",
      "08/15/2023, 19:34:48# Epoch 3 | Train Loss: 3.2777 | Train Accuracy: 0.0488\n",
      "08/15/2023, 19:34:48# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:34:48# predicted of False: tensor([100, 100, 100, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:34:48# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:34:48# predicted of False: tensor([100, 100, 100, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:34:48# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:34:48# predicted of False: tensor([100], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:34:48# Validation Loss: 3.1356 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66941238240c49e9b474a002144567ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:36:44# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:36:44# predicted of 5000: tensor([ 77, 100,  80, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:38:36# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:38:36# predicted of 10000: tensor([ 77,  78,  78, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:40:34# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:40:34# predicted of 15000: tensor([78, 78, 78, 78], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:42:28# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:42:28# predicted of 20000: tensor([ 90, 104,  90, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:44:21# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:44:21# predicted of 25000: tensor([ 88, 119,  88,  88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:45:46# total count: 28750\n",
      "08/15/2023, 19:45:46# Epoch 4 | Train Loss: 3.2784 | Train Accuracy: 0.0463\n",
      "08/15/2023, 19:45:46# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:45:46# predicted of False: tensor([86, 86, 86, 86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:45:46# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:45:46# predicted of False: tensor([86, 86, 86, 86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:45:46# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:45:46# predicted of False: tensor([86], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:45:46# Validation Loss: 3.1350 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbcee8361d04a38a955e8c8e9e36fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:47:38# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:47:38# predicted of 5000: tensor([ 86, 105,  86,  86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:49:31# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:49:31# predicted of 10000: tensor([ 78,  70, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:51:26# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:51:26# predicted of 15000: tensor([80, 80, 80, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:53:20# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:53:20# predicted of 20000: tensor([105, 105,  86,  90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:55:15# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:55:15# predicted of 25000: tensor([ 89, 101,  80,  89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:56:44# total count: 28750\n",
      "08/15/2023, 19:56:44# Epoch 5 | Train Loss: 3.2767 | Train Accuracy: 0.0478\n",
      "08/15/2023, 19:56:44# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:56:44# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:56:44# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:56:44# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:56:44# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:56:44# predicted of False: tensor([89], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 19:56:44# Validation Loss: 3.1377 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8807e72ec8488d9f43923b94f00e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 19:58:38# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 19:58:38# predicted of 5000: tensor([ 89,  85,  86, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:00:32# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:00:32# predicted of 10000: tensor([ 76, 102,  89,  89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:02:26# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:02:26# predicted of 15000: tensor([70, 88, 70, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:04:28# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:04:28# predicted of 20000: tensor([70, 70, 85, 85], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:06:42# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:06:42# predicted of 25000: tensor([82, 84, 84, 82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:08:21# total count: 28750\n",
      "08/15/2023, 20:08:21# Epoch 6 | Train Loss: 3.2778 | Train Accuracy: 0.0471\n",
      "08/15/2023, 20:08:21# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:08:21# predicted of False: tensor([82, 82, 82, 82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:08:21# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:08:21# predicted of False: tensor([82, 82, 82, 82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:08:21# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:08:21# predicted of False: tensor([82], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:08:21# Validation Loss: 3.1343 | Validation Accuracy: 0.0833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7170a90dc6c41cd8b96a0fb486636a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 20:10:34# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:10:34# predicted of 5000: tensor([79, 79, 88, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:12:43# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:12:43# predicted of 10000: tensor([79, 86, 86, 79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:14:52# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:14:52# predicted of 15000: tensor([ 86,  85, 102, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:17:04# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:17:04# predicted of 20000: tensor([105, 100, 100, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:19:13# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:19:13# predicted of 25000: tensor([86, 89, 86, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:20:51# total count: 28750\n",
      "08/15/2023, 20:20:51# Epoch 7 | Train Loss: 3.2771 | Train Accuracy: 0.0462\n",
      "08/15/2023, 20:20:51# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:20:51# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:20:51# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:20:51# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:20:51# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:20:51# predicted of False: tensor([89], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:20:51# Validation Loss: 3.1373 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce536d07f294edaa38cc385462bf164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 20:23:01# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:23:01# predicted of 5000: tensor([89, 85, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:25:10# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:25:10# predicted of 10000: tensor([ 77,  89, 101,  89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:27:19# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:27:19# predicted of 15000: tensor([85, 84, 85, 85], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:29:29# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:29:29# predicted of 20000: tensor([ 78,  78,  84, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:31:38# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:31:38# predicted of 25000: tensor([81, 78, 78, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:33:15# total count: 28750\n",
      "08/15/2023, 20:33:15# Epoch 8 | Train Loss: 3.2774 | Train Accuracy: 0.0459\n",
      "08/15/2023, 20:33:15# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:33:15# predicted of False: tensor([104, 104, 104, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:33:15# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:33:15# predicted of False: tensor([104, 104, 104, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:33:15# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:33:15# predicted of False: tensor([104], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:33:15# Validation Loss: 3.1354 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c96e064e0e4e22be657873a78f3f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 20:35:24# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:35:24# predicted of 5000: tensor([ 84, 103, 100, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:37:34# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:37:34# predicted of 10000: tensor([104, 101, 101, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:39:42# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:39:42# predicted of 15000: tensor([ 70, 100, 100,  70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:41:51# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:41:51# predicted of 20000: tensor([70, 70, 70, 84], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:43:56# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:43:56# predicted of 25000: tensor([70, 70, 77, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:45:28# total count: 28750\n",
      "08/15/2023, 20:45:28# Epoch 9 | Train Loss: 3.2777 | Train Accuracy: 0.0464\n",
      "08/15/2023, 20:45:28# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:45:28# predicted of False: tensor([70, 70, 70, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:45:28# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:45:28# predicted of False: tensor([70, 70, 70, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:45:28# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:45:28# predicted of False: tensor([70], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:45:28# Validation Loss: 3.1347 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a174a8b2c409dbd048f88fa1f861d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 20:47:28# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:47:28# predicted of 5000: tensor([ 70, 101,  90, 101], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:49:30# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:49:30# predicted of 10000: tensor([101, 101,  70, 101], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:51:33# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:51:33# predicted of 15000: tensor([ 86,  76, 104, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:53:34# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:53:34# predicted of 20000: tensor([ 77, 105, 105, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:55:37# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:55:37# predicted of 25000: tensor([ 87,  89, 105,  87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:57:08# total count: 28750\n",
      "08/15/2023, 20:57:08# Epoch 10 | Train Loss: 3.2783 | Train Accuracy: 0.0438\n",
      "08/15/2023, 20:57:08# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:57:08# predicted of False: tensor([80, 80, 80, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:57:08# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:57:08# predicted of False: tensor([80, 80, 80, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:57:08# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:57:08# predicted of False: tensor([80], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 20:57:08# Validation Loss: 3.1343 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5041f0979484276ace71f4b9e5cc677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 20:59:08# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 20:59:08# predicted of 5000: tensor([101,  77, 105, 101], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:01:11# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:01:11# predicted of 10000: tensor([104, 103,  78, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:03:13# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:03:13# predicted of 15000: tensor([103,  86,  88, 102], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:05:16# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:05:16# predicted of 20000: tensor([104, 103, 103,  70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:07:18# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:07:18# predicted of 25000: tensor([ 77, 101,  77,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:08:50# total count: 28750\n",
      "08/15/2023, 21:08:50# Epoch 11 | Train Loss: 3.2780 | Train Accuracy: 0.0432\n",
      "08/15/2023, 21:08:50# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:08:50# predicted of False: tensor([81, 81, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:08:50# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:08:50# predicted of False: tensor([81, 81, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:08:50# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:08:50# predicted of False: tensor([81], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:08:50# Validation Loss: 3.1338 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b9be9384b94e568557e7e562ac9528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 21:10:50# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:10:50# predicted of 5000: tensor([77, 77, 77, 77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:12:52# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:12:52# predicted of 10000: tensor([ 90, 102,  87,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:14:54# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:14:54# predicted of 15000: tensor([87, 80, 87, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:16:55# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:16:55# predicted of 20000: tensor([ 79, 101,  79,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:18:56# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:18:56# predicted of 25000: tensor([82, 88, 82, 76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:20:28# total count: 28750\n",
      "08/15/2023, 21:20:28# Epoch 12 | Train Loss: 3.2779 | Train Accuracy: 0.0447\n",
      "08/15/2023, 21:20:28# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:20:28# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:20:28# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:20:28# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:20:28# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:20:28# predicted of False: tensor([90], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:20:28# Validation Loss: 3.1343 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804288d45bef426483dc63a69cbf3126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 21:22:29# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:22:29# predicted of 5000: tensor([84, 84, 84, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:24:30# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:24:30# predicted of 10000: tensor([119,  76, 100, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:26:32# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:26:32# predicted of 15000: tensor([100, 100, 100,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:28:34# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:28:34# predicted of 20000: tensor([ 86,  86, 100,  86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:30:36# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:30:36# predicted of 25000: tensor([84, 71, 87, 78], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:32:07# total count: 28750\n",
      "08/15/2023, 21:32:07# Epoch 13 | Train Loss: 3.2779 | Train Accuracy: 0.0460\n",
      "08/15/2023, 21:32:07# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:32:07# predicted of False: tensor([103, 103, 103, 103], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:32:07# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:32:07# predicted of False: tensor([103, 103, 103, 103], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:32:07# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:32:07# predicted of False: tensor([103], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:32:07# Validation Loss: 3.1324 | Validation Accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49a3ad75da74086b5ae9b1509820747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 21:34:08# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:34:08# predicted of 5000: tensor([ 71, 101,  71,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:36:11# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:36:11# predicted of 10000: tensor([102,  79,  81,  84], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:38:13# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:38:13# predicted of 15000: tensor([101, 102, 102, 102], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:40:14# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:40:14# predicted of 20000: tensor([102, 119, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:42:18# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:42:18# predicted of 25000: tensor([119, 119, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:43:50# total count: 28750\n",
      "08/15/2023, 21:43:50# Epoch 14 | Train Loss: 3.2788 | Train Accuracy: 0.0411\n",
      "08/15/2023, 21:43:50# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:43:50# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:43:50# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:43:50# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:43:50# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:43:50# predicted of False: tensor([90], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:43:50# Validation Loss: 3.1333 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f2593dbdd4cdb81892a707bd1ae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 21:45:51# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:45:51# predicted of 5000: tensor([90, 70, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:47:52# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:47:52# predicted of 10000: tensor([85, 85, 85, 85], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:49:53# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:49:53# predicted of 15000: tensor([ 71, 100,  85, 100], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:51:55# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:51:55# predicted of 20000: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:53:55# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:53:55# predicted of 25000: tensor([86, 88, 86, 86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:55:27# total count: 28750\n",
      "08/15/2023, 21:55:27# Epoch 15 | Train Loss: 3.2759 | Train Accuracy: 0.0472\n",
      "08/15/2023, 21:55:27# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:55:27# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:55:27# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:55:27# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:55:27# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:55:27# predicted of False: tensor([90], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 21:55:27# Validation Loss: 3.1374 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932d7c283e2f4347961afaa089a14c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 21:57:29# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:57:29# predicted of 5000: tensor([ 88, 104,  70,  70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:59:30# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 21:59:30# predicted of 10000: tensor([70, 84, 70, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:01:32# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:01:32# predicted of 15000: tensor([119, 119, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:03:33# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:03:33# predicted of 20000: tensor([88, 80, 82, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:05:34# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:05:34# predicted of 25000: tensor([80, 82, 80, 82], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:07:06# total count: 28750\n",
      "08/15/2023, 22:07:06# Epoch 16 | Train Loss: 3.2783 | Train Accuracy: 0.0443\n",
      "08/15/2023, 22:07:06# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:07:06# predicted of False: tensor([81, 81, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:07:06# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:07:06# predicted of False: tensor([81, 81, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:07:06# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:07:06# predicted of False: tensor([81], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:07:06# Validation Loss: 3.1362 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3b751736c84e3589294d5f9de65dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 22:09:08# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:09:08# predicted of 5000: tensor([ 78, 105,  78, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:11:11# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:11:11# predicted of 10000: tensor([103,  78,  84,  78], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:13:13# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:13:13# predicted of 15000: tensor([104, 119, 104, 104], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:15:15# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:15:15# predicted of 20000: tensor([119, 100, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:17:16# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:17:16# predicted of 25000: tensor([119,  90, 104, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:18:46# total count: 28750\n",
      "08/15/2023, 22:18:46# Epoch 17 | Train Loss: 3.2783 | Train Accuracy: 0.0434\n",
      "08/15/2023, 22:18:46# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:18:46# predicted of False: tensor([119, 119, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:18:46# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:18:46# predicted of False: tensor([119, 119, 119, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:18:46# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:18:46# predicted of False: tensor([119], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:18:46# Validation Loss: 3.1336 | Validation Accuracy: 0.0833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec62322d472427da1d1430e26a1d321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 22:20:46# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:20:46# predicted of 5000: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:22:43# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:22:43# predicted of 10000: tensor([90, 80, 90, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:24:39# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:24:39# predicted of 15000: tensor([71, 84, 80, 71], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:26:35# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:26:35# predicted of 20000: tensor([ 80, 105,  81,  81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:28:33# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:28:33# predicted of 25000: tensor([80, 80, 79, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:29:55# total count: 28750\n",
      "08/15/2023, 22:29:55# Epoch 18 | Train Loss: 3.2772 | Train Accuracy: 0.0466\n",
      "08/15/2023, 22:29:55# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:29:55# predicted of False: tensor([103, 103, 103, 103], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:29:55# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:29:55# predicted of False: tensor([103, 103, 103, 103], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:29:55# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:29:55# predicted of False: tensor([103], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:29:55# Validation Loss: 3.1335 | Validation Accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e0622393ad4dd38b2cd8f2f577e9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 22:31:50# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:31:50# predicted of 5000: tensor([78, 89, 85, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:33:47# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:33:47# predicted of 10000: tensor([ 76, 103, 103,  88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:35:41# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:35:41# predicted of 15000: tensor([ 78, 103,  88,  88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:37:33# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:37:33# predicted of 20000: tensor([103,  90,  77,  89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:39:27# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:39:27# predicted of 25000: tensor([90, 90, 82, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:40:52# total count: 28750\n",
      "08/15/2023, 22:40:52# Epoch 19 | Train Loss: 3.2787 | Train Accuracy: 0.0450\n",
      "08/15/2023, 22:40:52# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:40:52# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:40:52# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:40:52# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:40:52# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:40:52# predicted of False: tensor([90], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:40:52# Validation Loss: 3.1365 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49634a744bf648ef8dfb36b8a9dcdd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 22:42:48# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:42:48# predicted of 5000: tensor([ 77,  79,  80, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:44:41# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:44:41# predicted of 10000: tensor([ 77, 104, 100, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:46:37# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:46:37# predicted of 15000: tensor([77, 77, 77, 77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:48:26# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:48:26# predicted of 20000: tensor([104, 119,  79,  79], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:50:21# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:50:21# predicted of 25000: tensor([88, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:51:46# total count: 28750\n",
      "08/15/2023, 22:51:46# Epoch 20 | Train Loss: 3.2785 | Train Accuracy: 0.0441\n",
      "08/15/2023, 22:51:46# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:51:46# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:51:46# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:51:46# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:51:47# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:51:47# predicted of False: tensor([89], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 22:51:47# Validation Loss: 3.1358 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15ca06692af46a8a7612385153449e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 22:53:43# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:53:43# predicted of 5000: tensor([77, 82, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:55:37# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:55:37# predicted of 10000: tensor([88, 70, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:57:29# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:57:29# predicted of 15000: tensor([70, 70, 70, 70], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:59:23# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 22:59:23# predicted of 20000: tensor([101,  88,  70,  88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:01:16# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:01:16# predicted of 25000: tensor([88, 77, 78, 86], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:02:40# total count: 28750\n",
      "08/15/2023, 23:02:40# Epoch 21 | Train Loss: 3.2776 | Train Accuracy: 0.0450\n",
      "08/15/2023, 23:02:40# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:02:40# predicted of False: tensor([88, 88, 88, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:02:40# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:02:40# predicted of False: tensor([88, 88, 88, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:02:40# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:02:40# predicted of False: tensor([88], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:02:40# Validation Loss: 3.1333 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3162c75cf6e147108da5426f9ebd4a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 23:04:30# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:04:30# predicted of 5000: tensor([88, 81, 76, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:06:25# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:06:25# predicted of 10000: tensor([101, 101,  88,  81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:08:17# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:08:17# predicted of 15000: tensor([81, 77, 81, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:10:10# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:10:10# predicted of 20000: tensor([ 89, 119,  89, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:12:04# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:12:04# predicted of 25000: tensor([88, 77, 88, 88], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:13:29# total count: 28750\n",
      "08/15/2023, 23:13:29# Epoch 22 | Train Loss: 3.2774 | Train Accuracy: 0.0461\n",
      "08/15/2023, 23:13:29# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:13:29# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:13:29# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:13:29# predicted of False: tensor([89, 89, 89, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:13:29# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:13:29# predicted of False: tensor([89], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:13:29# Validation Loss: 3.1350 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4833e6f6ff6d46f4810cb6d3e5a1cc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 23:15:23# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:15:23# predicted of 5000: tensor([ 80,  70, 119,  80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:17:15# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:17:15# predicted of 10000: tensor([70, 80, 80, 80], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:19:08# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:19:08# predicted of 15000: tensor([81, 81, 90, 81], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:21:02# labels of 20000: tensor([119,  78,  79,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:21:02# predicted of 20000: tensor([77, 77, 90, 77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:22:56# labels of 25000: tensor([ 89, 100, 101, 105], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:22:56# predicted of 25000: tensor([ 90, 105,  90,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:24:22# total count: 28750\n",
      "08/15/2023, 23:24:22# Epoch 23 | Train Loss: 3.2773 | Train Accuracy: 0.0438\n",
      "08/15/2023, 23:24:23# labels of False: tensor([ 71,  71, 119,  77], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:24:23# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:24:23# labels of False: tensor([ 82, 103, 103,  76], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:24:23# predicted of False: tensor([90, 90, 90, 90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:24:23# labels of False: tensor([76], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:24:23# predicted of False: tensor([90], device='cuda:0') torch.Size([1])\n",
      "08/15/2023, 23:24:23# Validation Loss: 3.1326 | Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90018c66139742ca9351f66a1704a176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/28750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15/2023, 23:26:20# labels of 5000: tensor([84, 82, 86, 87], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:26:20# predicted of 5000: tensor([ 90,  71, 103,  90], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:28:12# labels of 10000: tensor([ 76,  70,  71, 119], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:28:12# predicted of 10000: tensor([84, 85, 76, 85], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:30:03# labels of 15000: tensor([87, 88, 90, 89], device='cuda:0') torch.Size([4])\n",
      "08/15/2023, 23:30:03# predicted of 15000: tensor([77, 80, 77, 80], device='cuda:0') torch.Size([4])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-2d92393e9025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model2_initial/initial_weight.pth'))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=total_steps)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 180\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 300  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    for data in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        \n",
    "        count += 1\n",
    "        loss, accuracy, _ = model_fn(data, model, criterion, device, count, type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "#     scheduler.step()\n",
    "    add_log_msg(f\"total count: {count}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in dataloaders['valid']:\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, type=='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "#     print(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    \n",
    "    \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "#         torch.save(model.state_dict(), 'best_model.pth')\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, f\"../checkpoint_GAT/best_model_{epoch}.pt\")\n",
    "    \n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "            \n",
    "# Testing Part\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        loss, accuracy, predicted = model_fn(data, model, criterion, device, type=='test')\n",
    "        labels = data[1].to(device)  # Assuming labels are the second element in the tuple\n",
    "        \n",
    "#         print(f\"labels: {labels}\", labels.shape)\n",
    "#         print(f\"predicted: {predicted}\", predicted.shape)\n",
    "        \n",
    "        add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "        \n",
    "        total += labels.size(0) # label.size(0) is the batch size\n",
    "        correct += (predicted == labels).sum().item() \n",
    "        # (predicted == labels).sum() would return how many of them are equal; \n",
    "        # .item() would make the tensor to the regular value\n",
    "        \n",
    "#     print('Test Accuracy: %d %%' % (100 * correct / total))\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b0eea0bb4409a8b630c05259f800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3def0d94e93949e48c475ebe2f9a1830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 8787\n",
    "same_seeds(seed)\n",
    "\n",
    "model = GAT(in_dim=50, hidden_dim=16, out_dim=168, num_heads=8)\n",
    "# in_dim means the dimension of the node_feat(50 dim, since the 50-dim embedding)\n",
    "# out_dim means the # of the categories -> 168 for out tasks\n",
    "model.load_state_dict(torch.load('model2_initial/initial_weight.pth'))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=total_steps)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_steps = 60\n",
    "\n",
    "# save the best model\n",
    "best_val_loss = float('inf')\n",
    "patience = 300  # Number of epochs with no improvement after which training will be stopped.\n",
    "waiting = 0  # The number of epochs with no improvement so far.\n",
    "\n",
    "\n",
    "# Training Part\n",
    "for epoch in tqdm(range(total_steps)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    for data in tqdm(dataloaders['train'], desc=\"Training\", position=0, leave=True):\n",
    "        \n",
    "        count += 1\n",
    "        loss, accuracy, _ = model_fn(data, model, criterion, device, count, type='train')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "#     scheduler.step()\n",
    "    add_log_msg(f\"total count: {count}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    add_log_msg(f'Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "    \n",
    "    # Validation Part\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batched_g in dataloaders['valid']:\n",
    "            loss, accuracy, _ = model_fn(batched_g, model, criterion, device, type=='validation')\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    current_loss = total_loss / num_batches\n",
    "#     print(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    add_log_msg(f'Validation Loss: {current_loss:.4f} | Validation Accuracy: {avg_accuracy:.4f}')\n",
    "    \n",
    "    \n",
    "    if current_loss < best_val_loss:\n",
    "        best_val_loss = current_loss\n",
    "        waiting = 0\n",
    "        \n",
    "#         torch.save(model.state_dict(), 'best_model.pth')\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, f\"../checkpoint_GAT/best_model_{epoch}.pt\")\n",
    "    \n",
    "    else:\n",
    "        waiting += 1\n",
    "        if waiting >= patience:\n",
    "            add_log_msg(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "            \n",
    "# Testing Part\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        loss, accuracy, predicted = model_fn(data, model, criterion, device, type=='test')\n",
    "        labels = data[1].to(device)  # Assuming labels are the second element in the tuple\n",
    "        \n",
    "#         print(f\"labels: {labels}\", labels.shape)\n",
    "#         print(f\"predicted: {predicted}\", predicted.shape)\n",
    "        \n",
    "        add_log_msg(f\"labels: {labels} {labels.shape}\")\n",
    "        add_log_msg(f\"predicted: {predicted} {predicted.shape}\")\n",
    "        \n",
    "        total += labels.size(0) # label.size(0) is the batch size\n",
    "        correct += (predicted == labels).sum().item() \n",
    "        # (predicted == labels).sum() would return how many of them are equal; \n",
    "        # .item() would make the tensor to the regular value\n",
    "        \n",
    "#     print('Test Accuracy: %d %%' % (100 * correct / total))\n",
    "add_log_msg(f'Test Accuracy: {100 * correct / total} %%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
